---
title: DeepSpeed æºç è§£è¯»01
author: zfan
createTime: 2025/06/10
permalink: /system/pre-train/deepspeed/deepspeed01/
tags:
  - system
  - pre-train
---

> è®°å½•ä¸€äº›é˜…è¯»deepspeedæºç è¿‡ç¨‹ä¸­çš„å¿ƒå¾—ä¸æ„Ÿæ‚Ÿ

è¿™é‡Œæ˜¯ä¸€ä¸ªæˆ‘ç”¨cursorç”»çš„ä¸€ä¸ªæ€ç»´å¯¼å›¾ï¼Œå¤§æ¦‚æè¿°äº†è°ƒç”¨å±‚çº§ï¼Œæ‰€ä»¥å°±å…ˆä»launcherå¼€å§‹çœ‹

```mermaid
graph TB
    %% ä¸»å…¥å£å±‚
    A["ğŸš€ launcher/runner.py<br/>ä¸»å¯åŠ¨å…¥å£"] --> B["ğŸ”§ launcher/launch.py<br/>è¿›ç¨‹å¯åŠ¨å™¨"]
    A --> C["ğŸŒ launcher/multinode_runner.py<br/>å¤šèŠ‚ç‚¹è¿è¡Œå™¨"]
    C --> B

    %% æ ¸å¿ƒå¼•æ“å±‚
    B --> D["âš™ï¸ __init__.py<br/>deepspeed.initialize()"]
    D --> E["ğŸ¯ runtime/engine.py<br/>DeepSpeedEngine"]
    D --> F["ğŸ”€ runtime/pipe/engine.py<br/>PipelineEngine"]
    D --> G["ğŸš€ inference/engine.py<br/>InferenceEngine"]

    %% é…ç½®å±‚
    D --> H["ğŸ“‹ runtime/config.py<br/>DeepSpeedConfig"]
    H --> E
    H --> F

    %% é€šä¿¡å’ŒåŠ é€Ÿå™¨å±‚
    E --> I["ğŸ“¡ comm/<br/>é€šä¿¡åç«¯"]
    E --> J["ğŸ”Œ accelerator/<br/>ç¡¬ä»¶æŠ½è±¡"]

    %% ä¼˜åŒ–å™¨å’ŒZeRO
    E --> K["ğŸ”„ runtime/zero/<br/>ZeROä¼˜åŒ–å™¨"]
    E --> L["ğŸ“Š ops/<br/>è‡ªå®šä¹‰ç®—å­"]

    %% å¹¶è¡Œç­–ç•¥å±‚
    E --> M["ğŸ”— pipe/<br/>æµæ°´çº¿å¹¶è¡Œ"]
    E --> N["ğŸŒŸ moe/<br/>ä¸“å®¶æ··åˆæ¨¡å‹"]
    E --> O["ğŸ“ sequence/<br/>åºåˆ—å¹¶è¡Œ"]
    E --> P["ğŸ“ linear/<br/>çº¿æ€§å±‚ä¼˜åŒ–"]

    %% å·¥å…·å’Œç›‘æ§å±‚
    E --> Q["ğŸ“ˆ monitor/<br/>ç›‘æ§å·¥å…·"]
    E --> R["â±ï¸ profiling/<br/>æ€§èƒ½åˆ†æ"]
    E --> S["ğŸ”„ autotuning/<br/>è‡ªåŠ¨è°ƒä¼˜"]
    E --> T["ğŸ’¾ checkpoint/<br/>æ£€æŸ¥ç‚¹"]

    %% é«˜çº§åŠŸèƒ½å±‚
    E --> U["ğŸ¯ elasticity/<br/>å¼¹æ€§è®­ç»ƒ"]
    E --> V["ğŸ—œï¸ compression/<br/>æ¨¡å‹å‹ç¼©"]
    E --> W["ğŸ”§ module_inject/<br/>æ¨¡å—æ³¨å…¥"]
    E --> X["ğŸ’¿ nvme/<br/>NVMeä¼˜åŒ–"]

    %% å·¥å…·æ”¯æ’‘å±‚
    subgraph "å·¥å…·æ”¯æ’‘"
        Y["ğŸ› ï¸ utils/<br/>å·¥å…·å‡½æ•°"]
        Z["ğŸ’¾ io/<br/>è¾“å…¥è¾“å‡º"]
        AA["â˜ï¸ nebula/<br/>äº‘è®¡ç®—"]
        BB["âš¡ compile/<br/>ç¼–è¯‘ä¼˜åŒ–"]
    end

    E --> Y
    E --> Z
    E --> BB

    %% æ ·å¼å®šä¹‰
    classDef entryPoint fill:#ff9999,stroke:#333,stroke-width:3px
    classDef coreEngine fill:#99ccff,stroke:#333,stroke-width:2px
    classDef parallel fill:#99ff99,stroke:#333,stroke-width:2px
    classDef support fill:#ffcc99,stroke:#333,stroke-width:1px

    class A entryPoint
    class E,F,G coreEngine
    class M,N,O,P parallel
    class Q,R,S,T,U,V,W,X,Y,Z,AA,BB support
```

## ä¸€. Launcher

> deepspeed/launcher/

è¿™é‡Œæ˜¯æ•´ä¸ªdeepspeedå¯åŠ¨è®­ç»ƒä»»åŠ¡çš„å…¥å£ï¼Œé¦–å…ˆæ˜¯`runner.py`, å®ƒä¼šæ ¹æ®å•æœºorå¤šæœºåˆ†é…åˆ°`launch.py`æˆ–è€…`multinode_runner.py`.

æš‚ä¸”ä¸è€ƒè™‘å•workerçš„æƒ…å†µï¼Œå› ä¸ºå¤ªç®€å•äº†ï¼Œlauncheræœ€éš¾çš„åœ°æ–¹å…¶å®å°±æ˜¯å¤šæœºçš„åˆå§‹åŒ–å’Œé€šä¿¡ï¼Œè¿™é‡Œæˆ‘ä»¬é¦–å…ˆè¦çŸ¥é“ä¸€äº›ç»†èŠ‚ï¼Œè¿™é‡Œé’ˆå¯¹GPUå¤šæœºå¤šå¡è®­ç»ƒçš„é€šä¿¡ä»‹ç»ä¸€äº›çŸ¥è¯†

### 1. communication

1. ç‰©ç†å±‚ä¼ è¾“ï¼šåº•å±‚é€šä¿¡æ˜¯æŒ‡åº•å±‚ç¡¬ä»¶çš„ç‰©ç†å±‚ä¼ è¾“ï¼Œè¿™äº›æ˜¯ç¡¬ä»¶è‡ªå¸¦çš„èƒ½åŠ›ï¼Œè¿™é‡Œåˆ†ä¸ºintranodeä»¥åŠinternodeï¼Œintranodeæ˜¯å•æœºå¤šå¡å†…çš„é€šä¿¡ï¼Œinternodeæ˜¯å¤šæœºé—´é€šä¿¡

- intranodeï¼šåœ¨NV GPUç¯å¢ƒä¸‹ï¼ŒèŠ‚ç‚¹å†…é€šä¿¡ç›´æ¥ä½¿ç”¨NVLinkå³å¯ï¼Œå¸¦å®½è¾¾åˆ°900GB/sï¼Œä¸‹ä½æ–¹æ¡ˆæ˜¯PCIeé€šç”¨æ€»çº¿ï¼Œå¸¦å®½çº¦32GB/sã€‚

- internodeï¼šé¦–å…ˆå°±æ˜¯InfiniBandï¼Œè¿™æ˜¯ä¸€ç§é«˜é€Ÿç½‘ç»œæŠ€æœ¯ï¼Œæ”¯æŒRDMAï¼Œé€Ÿåº¦æœ€å¿«200Gbps+ï¼Œä¸‹ä½æ–¹æ¡ˆæ˜¯ä»¥å¤ªç½‘TCP/UDPä½¿ç”¨Socketçš„é€šä¿¡ï¼Œåªæœ‰å¤§çº¦10-100Gbpsã€‚

2. é€šä¿¡åº“ï¼šè½¯ä»¶å±‚é¢çš„é€šä¿¡ä¼˜åŒ–ï¼Œå¯ä»¥åœ¨è½¯ä»¶çš„å±‚é¢ä¸Šä¼˜åŒ–é€šä¿¡é€Ÿåº¦ï¼Œé€‰å–åˆé€‚çš„é€šä¿¡åç«¯ï¼ŒåŒæ—¶ä¹Ÿä¼šæä¾›æ•…éšœé‡å¯ï¼Œå¼¹æ€§æ‰©ç¼©å®¹ç­‰æ“ä½œã€‚

- MPIï¼šé«˜æ€§èƒ½æ¶ˆæ¯ä¼ è¾“æ¥å£ï¼ˆMessage Passing Interfaceï¼‰ï¼Œæ˜¯ä¸€ç§é€šç”¨çš„æŠ€æœ¯ï¼Œä¾‹å¦‚OpenMPIï¼ŒåŸºäºMPIæ ‡å‡†ï¼Œå°è£…ç‰©ç†å±‚èƒ½åŠ›ï¼ˆIBï¼ŒTCPç­‰ç­‰ï¼‰æä¾›å¤šæœºé—´é€šä¿¡èƒ½åŠ›ã€‚

- NCCLï¼šå¦‚æœæ˜¯NVç¯å¢ƒï¼Œé‚£ä¹ˆå°±æ˜¯MPIçš„ä¸Šä½æ›¿ä»£ï¼Œæ˜¯NVIDIAå‘å¸ƒçš„ä¸€ä¸ªé«˜æ•ˆçš„é›†ä½“é€šä¿¡åº“ï¼Œä¸“ä¸ºå¤šä¸ªGPUä¹‹é—´æä¾›ä¼˜åŒ–çš„ä¼ è¾“æ•ˆç‡å’Œç®€åŒ–åº”ç”¨è€Œè®¾è®¡ï¼Œé‡‡ç”¨RDMAæŠ€æœ¯åŠ é€Ÿï¼Œintranodeä½¿ç”¨NVLinkï¼Œè‡ªåŠ¨ä¼˜åŒ–é€šä¿¡è·¯å¾„ï¼Œå‡å°‘ç½‘ç»œæ‹¥å¡ï¼Œå½“ç„¶è¿™æ˜¯ä¸€ä¸ªä¸ç‰©ç†å±‚æ— å…³çš„è½¯ä»¶æŠ½è±¡ï¼Œæ‰€ä»¥å¦‚æœNVLinkä¸æ”¯æŒä¼šé™çº§ä¸ºPCIeï¼Œæ‰€ä»¥ä¾‹å¦‚IBï¼ŒNVLinkç­‰å‡ä¸æ„æˆ**å¼ºä¾èµ–**ã€‚

3. åº”ç”¨æ¥å£å±‚ï¼šå…¶å®å°±æ˜¯`torchrun`ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹ä¸€ä¸‹pytorchçš„docï¼Œé‡Œé¢æ˜¯è¿™æ ·è¯´çš„

> By default for Linux, the Gloo and NCCL backends are built and included in PyTorch distributed (NCCL only when building with CUDA). MPI is an optional backend that can only be included if you build PyTorch from source.

ä¹Ÿå°±æ˜¯torchæ”¯æŒ`gloo`çš„cpuè®­ç»ƒä»¥åŠ`nccl`çš„gpuè®­ç»ƒï¼Œ`nccl`ä¸€èˆ¬ä½œä¸º`gloo`çš„å¤‡é€‰æ–¹æ¡ˆã€‚

æ¥ä¸‹æ¥å›åˆ°launcherä¹‹ä¸­ï¼Œdeepspeedå¹¶æ²¡æœ‰ä½¿ç”¨torchï¼Œè€Œæ˜¯è‡ªå·±å®ç°äº†ä¸€å¥—launcherï¼Œå¯ä»¥è®©ç”¨æˆ·é€šè¿‡`--launcher`æ¥é€‰æ‹©ï¼Œé»˜è®¤æ˜¯PDSHï¼Œä¹Ÿå¯ä»¥é€‰æ‹©OpenMPIç­‰ä¸€äº›MPIé€šä¿¡ï¼Œæ²¡æœ‰ä½¿ç”¨ncclï¼Œå› ä¸ºncclå±€é™äºcudaã€‚

### 2. network

æ—¢ç„¶æ˜¯å¤šæœºåˆ†å¸ƒå¼è®­ç»ƒï¼Œæœºå™¨ä¹‹é—´å¿…ç„¶ä¼šäº§ç”Ÿé€šä¿¡ï¼Œè¿™é‡Œdeepspeedæä¾›äº†ä¸¤ç§æ–¹å¼ï¼Œä¸€ç§æ˜¯`ssh`, è¿™è¦æ±‚é…ç½®hostfileï¼Œå¹¶ä¸”æ¯ä¸¤ä¸ªnodeä¹‹é—´éœ€è¦å¯ä»¥sshå…å¯†ç™»å½•ï¼Œå¦å¤–ä¸€ç§æ¨¡å¼æ˜¯`no_ssh`, è¿™ä¸ªæ—¶å€™å¤šä¸ªnodeä¹‹é—´ä¸ä¼šå°è¯•sshéªŒè¯ï¼ŒåŸç†æ˜¯åœ¨æ¯ä¸ªnodeéƒ½å¯åŠ¨ä¸€ä¸ªè®­ç»ƒè¿›ç¨‹ï¼Œç„¶åå¿…é¡»è¦æ‰‹åŠ¨æŒ‡å®š`node_rank`, `master_addr`, `master_port`ç­‰ä¸€äº›ä¿¡æ¯ã€‚

å¯¹äº`ssh`æ¨¡å¼ï¼Œæˆ‘ä»¬ä¼šè®¾ç½®`node_rank`, `master_addr`, `master_port`ç­‰ä¸€äº›å…³é”®ä¿¡æ¯ã€‚å¯¹äº`no_ssh`æ¨¡å¼ï¼Œè¿™ä¸€åˆ‡éœ€è¦é…ç½®å¥½ã€‚

ç»è¿‡ä¸Šè¿°çš„ç½‘ç»œé€šä¿¡åŸºç¡€è®¾ç½®ï¼Œæœ€åå¤šnodeä¼šåœ¨æ¯ä¸ªnodeä¸Šå¯åŠ¨ä¸€ä¸ª`python -m deepspeed.launcher.launch`, å¼€å§‹æ‰§è¡Œåˆ†å¸ƒå¼è®­ç»ƒè¿›ç¨‹ã€‚

### 3. subprocess

æœ€ålauncherè¿™ä¸ªåŒ…ï¼Œä¼šå¯åŠ¨è‹¥å¹²çš„è¿›ç¨‹ï¼Œç„¶åæ‰§è¡Œä¸åŒçš„äº‹æƒ…ã€‚å¯¹äºå¤šnodeï¼Œæˆ‘ä»¬è‚¯å®šä¼šå…ˆé€‰æ‹©ä¸€ä¸ªnodeç™»å½•ï¼Œç„¶ååœ¨è¿™ä¸ªnodeä¸Šæ‰§è¡Œä¸€ä¸ªrunnerè¿›ç¨‹ï¼Œå¯¹äºrunnerè¿›ç¨‹ï¼Œå…³ç³»å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

```shell
Runner (runner.py)
â””â”€â”€ Launcher (launch.py)
    â”œâ”€â”€ Training Process 0 (GPU 0)
    â”œâ”€â”€ Training Process 1 (GPU 1)
    â”œâ”€â”€ Training Process 2 (GPU 2)
    â””â”€â”€ ...
```

å¯ä»¥çœ‹å‡ºï¼Œrunneræ˜¯ä¸»è¿›ç¨‹ï¼Œä¼šæ¥å—ä¸€äº›å‚æ•°åšä¸€äº›é€šä¿¡å’Œç½‘ç»œçš„ç›¸å…³é…ç½®ï¼Œä¹‹åå¯¹äºå¤šnodeè€Œè¨€ï¼Œä¼šåœ¨æ¯ä¸ªnodeä¸Šå¯åŠ¨ä¸€ä¸ªlauncherè¿›ç¨‹ï¼Œè¿™ä¸ªæ˜¯æ¯ä¸ªnodeä¸Šéƒ½æœ‰çš„ï¼Œç”¨äºç®¡ç†è®­ç»ƒè¿›ç¨‹ã€‚

å…·ä½“çš„è®­ç»ƒè¿›ç¨‹æ˜¯è¿è¡Œåœ¨æ¯ä¸ªnodeçš„slotsä¸Šçš„ï¼Œå¦‚æœå½“å‰node 8å¡éƒ½éœ€è¦å‚ä¸ï¼Œé‚£ä¹ˆå°±ä¼šå¯åŠ¨8ä¸ªtraining processï¼Œä»£è¡¨å…·ä½“çš„è®­ç»ƒè¿›ç¨‹ï¼Œlauncherçš„ç›®çš„æ˜¯ç®¡ç†è¿™äº›è¿›ç¨‹ï¼Œä¸æ–­åœ°loopå»çœ‹å½“å‰çš„trainè¿›ç¨‹è¿˜æœ‰å¤šå°‘æ­£åœ¨workï¼Œç„¶åå¯¹äºç”¨æˆ·å‘é€çš„SIGINTæˆ–è€…ç³»ç»Ÿå‘é€çš„SIGTERMï¼Œå†™ä¸€äº›ä¼˜é›…é€€å‡ºçš„handlerå»é€€å‡ºtrainè¿›ç¨‹ã€‚

æˆ‘ä»¬éœ€è¦ä¼ å…¥ä¸€äº›å‚æ•°ï¼Œè¿™äº›å…·ä½“çš„å‚æ•°ï¼Œå¯ä»¥çœ‹deepspeedæ–‡æ¡£ï¼Œè¿™é‡Œå°±ä¸å¤šèµ˜è¿°ã€‚

**ä¸è¿‡ä¸Šè¿°çš„launcherï¼Œä¼¼ä¹å› ä¸ºdeepspeedç‰ˆæœ¬è¿‡è€çš„åŸå› ï¼Œå¦‚ä»Šéƒ½ç”±pytorchè§£å†³äº†ï¼Œç›´æ¥torchrunå³å¯**

## äºŒ. Initialize

ç»è¿‡ä¸Šè¿°çš„launcherï¼Œæˆ‘ä»¬æˆåŠŸåœ¨å„ä¸ªnodeä¸Šå¯åŠ¨äº†è‡ªå·±çš„`train.py`, æ¥ä¸‹æ¥æˆ‘ä»¬å…ˆæä¾›ä¸€ä¸ªå®˜æ–¹çš„`train.py`, ç„¶åä¾æ¬¡å‰–æé‡Œé¢çš„ç»†èŠ‚ã€‚

æˆ‘çœ‹çš„æ˜¯[deepspeed example](https://github.com/deepspeedai/DeepSpeedExamples) é‡Œé¢çš„BERT pre-trainè„šæœ¬ï¼Œåœ¨`training/bing_bert`ä¹‹ä¸­

### 1. distribute

> deepspeed/comm/

åœ¨`prepare_model_optimizer`ä¸­ï¼Œä½¿ç”¨äº†`deepspeed.init_distributed(dist_backend='nccl')`ï¼Œå€Ÿæ­¤æˆ‘ä»¬å¯ä»¥çœ‹ä¸€ä¸‹deepspeedçš„é€šä¿¡åŒ…æ˜¯å¦‚ä½•è®¾è®¡çš„ã€‚

deepspeedçš„é€šä¿¡åŒ…ä¿æŒç€å’Œ`torch.distributed`åŒæ ·çš„APIè®¾è®¡ï¼Œæ–¹ä¾¿ç”¨æˆ·è¿ç§»ï¼Œé˜…è¯»è¿™éƒ¨åˆ†ä»£ç æ„Ÿè§‰ä¹Ÿå¯ä»¥ä¸ºæœªæ¥é˜…è¯»`pytorch`æºç æ‰“ä¸‹åŸºç¡€ã€‚

å¯ä»¥çœ‹å‡ºcommåŒ…ä¸»è¦å°±å„ç§é€šä¿¡op(all_reduce, all_gather)è¿›è¡Œå°è£…ï¼Œé¦–å…ˆå°†é»˜è®¤çš„`torch.distributed`å°è£…ä¸º`TorchBackend`, è¿™æ„å‘³ç€é»˜è®¤çš„backendï¼Œç„¶åè¿™é‡Œä¹Ÿæ”¯æŒç”¨æˆ·å®šåˆ¶å±äºè‡ªå·±çš„backendã€‚å¯¹äºå°è£…çš„`TorchBackend`ä¸»è¦æ˜¯æ›´åŠ çš„æ™®é€‚ï¼Œå¯¹å„ä¸ªtorchç‰ˆæœ¬éƒ½é€‚ç”¨ã€‚å½“ç„¶deepspeedä¹Ÿæä¾›äº†ä¸€ä¸ªè‡ªå·±çš„å®šåˆ¶åç«¯ä½œä¸ºå‚ç…§ï¼š`CCLBackend`Intelé€šä¿¡åº“ã€‚

é€šè¿‡`init_deepspeed_backend()`æ¥é€‰æ‹©è‡ªå·±çš„å®šåˆ¶backendï¼Œå¦‚æœcdbæœ€åè¿˜æ˜¯ä¸ºNoneï¼Œå°±ä½¿ç”¨`TorchBackend`

```python
if cdb is None:
    init_deepspeed_backend(get_accelerator().communication_backend_name(), timeout, init_method)
    set_backend()
    utils.logger.info(f'cdb={cdb}')
if cdb is None and torch.distributed.is_initialized():
    # The user initialized torch.dist themselves, create cdb and short-circuit
    cdb = TorchBackend(dist_backend, timeout, init_method)
    return
```

ç›®å‰çœ‹æ¥è¿™å—ä»£ç è¿˜æŒºå¥‡æ€ªçš„ï¼Œæ¯”è¾ƒåå‘äºåŠæˆå“ï¼Œå¤§è‡´æ€è·¯å…¶å®æ˜¯æƒ³è®¾è®¡ä¸€ä¸ªæ›´åŠ æ™®é€‚é€šç”¨çš„é€šä¿¡åç«¯æ¡†æ¶ï¼Œä½†æ˜¯ç›®å‰åªæ˜¯å¯¹`torch.distributed`è¿›è¡Œäº†ä¸€æ¬¡åŒ…è£…

å’Œ`launcher`æ¨¡å—é¢ä¸´çš„å¤„å¢ƒå·®ä¸å¤šï¼Œåœ¨å¯åŠ¨åˆ†å¸ƒå¼è®­ç»ƒçš„æ—¶å€™ç¡®å®å¯èƒ½éœ€è¦å¾ˆå¤šçš„ç½‘ç»œå’Œé€šä¿¡çš„å‡†å¤‡å·¥ä½œï¼Œä½†æ˜¯ç°ä»£pytorchå·²ç»å°†è¿™äº›ç¹ççš„å·¥ä½œæ”¶æ•›è¿›torchä¹‹ä¸­ï¼Œdeepspeedè¿™é‡Œçš„ä»£ç åªèƒ½è¯´æœ‰ä¸€å®šçš„å¯å‘ä½œç”¨ã€‚

ç›®å‰å¯¹deepspeedçš„é€šä¿¡æœ‰äº†ä¸€å®šçš„äº†è§£ï¼Œåˆ†ä¸ºäº†ä¸¤ä¸ªéƒ¨åˆ†ï¼Œä¸€ä¸ªæ˜¯inité˜¶æ®µï¼Œä½¿ç”¨MPIæ¥é€šä¿¡ä¸€äº›åŸºæœ¬ä¿¡æ¯å’Œç¯å¢ƒå˜é‡ï¼Œä¾‹å¦‚`LOCAL_RANK`è¿™ç§ï¼Œæ„æ€æ˜¯å¦‚æœæ²¡æœ‰è®¾ç½®è¿™ç§rankï¼Œå¯ä»¥åªé€šè¿‡æŒ‡å®šè‹¥å¹²hostæ¥è®©deepspeedå¸®ä½ è‡ªåŠ¨æ’åºï¼Œæœ€åæ³¨å…¥ç¯å¢ƒå˜é‡ã€‚æˆ–è€…è¯´è¿™äº›åŸºç¡€ç¯å¢ƒå˜é‡å®Œå…¨ç”±ç”¨æˆ·æ¥æŒ‡å®šï¼Œè¿™æ ·å°±ä¸éœ€è¦MPIäº†ã€‚ç¬¬äºŒä¸ªé˜¶æ®µæ˜¯worké˜¶æ®µï¼Œè¿™ä¸ªæ—¶å€™å°±éœ€è¦å®šåˆ¶çš„é€šä¿¡åç«¯ï¼Œä¾‹å¦‚cpuä½¿ç”¨`gloo`, nv gpuä½¿ç”¨`nccl`, intelä½¿ç”¨`ccl`ç­‰ç­‰, è¿™é‡Œå¼ºè°ƒçš„æ˜¯é«˜æ€§èƒ½æ‰€ä»¥ä¸èƒ½ä½¿ç”¨MPIã€‚

### 2. deepspeed.initialize

> deepspeed/\_\_init\_\_.py

é‡ç‚¹æ¥äº†ï¼Œè¿™é‡Œåº”è¯¥æ˜¯deepspeedæ•´ä¸ªæ¡†æ¶çš„åˆå§‹åŒ–çš„æ±‡é›†ç‚¹, ç¬¬ä¸€éƒ¨åˆ†çš„åˆ†å¸ƒå¼ç¯å¢ƒåˆå§‹åŒ–ä¹Ÿåº”è¯¥æ˜¯è¿™ä¸ªåˆå§‹åŒ–çš„ä¸€éƒ¨åˆ†ã€‚

```python
# åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ
dist.init_distributed()

#åˆå§‹åŒ–device mesh
dist.initialize_mesh_device(mesh_param, ("data_parallel", "sequence_parallel"))

if not isinstance(model, PipelineModule):
        config_class = DeepSpeedConfig(config, mpu, mesh_device=mesh_device)
        if config_class.hybrid_engine.enabled:
            engine = DeepSpeedHybridEngine(args)
        else:
            engine = DeepSpeedEngine(args)
    else:
        assert mpu is None, "mpu must be None with pipeline parallelism"
        mpu = model.mpu()
        config_class = DeepSpeedConfig(config, mpu)
        engine = PipelineEngine(args)

    # Restore zero.Init context if necessary
    zero.partition_parameters.restore_init_context()

    return_items = [
        engine,
        engine.optimizer,
        engine.training_dataloader,
        engine.lr_scheduler,
    ]
    return tuple(return_items)
```

å¯ä»¥çœ‹å‡ºdeepspeedæ ¸å¿ƒçš„è®¡ç®—å’Œè°ƒåº¦ä»£ç åœ¨`engine`ä¹‹ä¸­ï¼Œè¿™ä¸ªç•™åˆ°ä¸‹ä¸€èŠ‚è®²ã€‚ä¹‹åå°±æ˜¯ä¸€ä¸ª`if pp`çš„é…ç½®ï¼Œé¦–å…ˆGPUæ˜¯ç”±`device_mesh`ç»„ç»‡çš„ï¼Œç›®çš„æ˜¯å°†GPUç»„ç»‡æˆä¸€ä¸ªç½‘æ ¼ç»“æ„ï¼Œæ¯”å¦‚

```python
dist.initialize_mesh_device(mesh_param, ("data_parallel", "sequence_parallel"))
```

è¿™é‡Œå°±æ˜¯å°†å„ä¸ªworkerç»„ç»‡æˆäºŒç»´ç½‘æ ¼ç»“æ„ï¼Œç¬¬ä¸€è¡Œæ˜¯dpçš„gpu groupï¼Œç¬¬äºŒè¡Œæ˜¯spçš„gpu groupï¼Œè¿™æ ·åšçš„å¥½å¤„å°±æ˜¯ä¸éœ€è¦è‡ªå·±å»åˆ’åˆ†ä¸åŒçš„process groupï¼Œæ›´åŠ ä¾¿æ·ã€‚ä¸è¿‡æˆ‘è§‚å¯Ÿmegatronå¹¶æ²¡æœ‰ä½¿ç”¨device mesh, è€Œæ˜¯é€‰æ‹©è‡ªå·±æ‰‹åŠ¨ç®¡ç†process groupçš„å½¢å¼ï¼Œä¸çŸ¥é“æœ‰æ— ä»€ä¹ˆè®²ç©¶

ç„¶åå°±æ˜¯æ„é€ engineï¼Œdeepspeedå°†ppä¸dp+tpåˆ†å‰²å¼€äº†ï¼Œçœ‹æ ·å­deepspeedå¹¶ä¸æ”¯æŒ3D parallelã€‚ä¸è¿‡ä¹Ÿå¯ä»¥ç†è§£ï¼Œdeepspeedé€‚åˆæ¯”è¾ƒå°çš„æ¨¡å‹ï¼Œèµ°çš„æ˜¯ZeROè¿™ä¸€å¥—ï¼Œå¦‚æœæ˜¯çœŸæ­£çš„å¤§æ¨¡å‹ï¼Œè¿˜æ˜¯éœ€è¦ä½¿ç”¨megatron
