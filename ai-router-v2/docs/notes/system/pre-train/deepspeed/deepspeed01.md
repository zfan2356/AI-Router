---
title: DeepSpeed æºç è§£è¯»01
author: zfan
createTime: 2025/06/10
permalink: /system/pre-train/deepspeed/deepspeed01/
tags:
  - system
  - pre-train
---

> è®°å½•ä¸€äº›é˜…è¯»deepspeedæºç è¿‡ç¨‹ä¸­çš„å¿ƒå¾—ä¸æ„Ÿæ‚Ÿ

è¿™é‡Œæ˜¯ä¸€ä¸ªæˆ‘ç”¨cursorç”»çš„ä¸€ä¸ªæ€ç»´å¯¼å›¾ï¼Œå¤§æ¦‚æè¿°äº†è°ƒç”¨å±‚çº§ï¼Œæ‰€ä»¥å°±å…ˆä»launcherå¼€å§‹çœ‹

```mermaid
graph TB
    %% ä¸»å…¥å£å±‚
    A["ğŸš€ launcher/runner.py<br/>ä¸»å¯åŠ¨å…¥å£"] --> B["ğŸ”§ launcher/launch.py<br/>è¿›ç¨‹å¯åŠ¨å™¨"]
    A --> C["ğŸŒ launcher/multinode_runner.py<br/>å¤šèŠ‚ç‚¹è¿è¡Œå™¨"]
    C --> B

    %% æ ¸å¿ƒå¼•æ“å±‚
    B --> D["âš™ï¸ __init__.py<br/>deepspeed.initialize()"]
    D --> E["ğŸ¯ runtime/engine.py<br/>DeepSpeedEngine"]
    D --> F["ğŸ”€ runtime/pipe/engine.py<br/>PipelineEngine"]
    D --> G["ğŸš€ inference/engine.py<br/>InferenceEngine"]

    %% é…ç½®å±‚
    D --> H["ğŸ“‹ runtime/config.py<br/>DeepSpeedConfig"]
    H --> E
    H --> F

    %% é€šä¿¡å’ŒåŠ é€Ÿå™¨å±‚
    E --> I["ğŸ“¡ comm/<br/>é€šä¿¡åç«¯"]
    E --> J["ğŸ”Œ accelerator/<br/>ç¡¬ä»¶æŠ½è±¡"]

    %% ä¼˜åŒ–å™¨å’ŒZeRO
    E --> K["ğŸ”„ runtime/zero/<br/>ZeROä¼˜åŒ–å™¨"]
    E --> L["ğŸ“Š ops/<br/>è‡ªå®šä¹‰ç®—å­"]

    %% å¹¶è¡Œç­–ç•¥å±‚
    E --> M["ğŸ”— pipe/<br/>æµæ°´çº¿å¹¶è¡Œ"]
    E --> N["ğŸŒŸ moe/<br/>ä¸“å®¶æ··åˆæ¨¡å‹"]
    E --> O["ğŸ“ sequence/<br/>åºåˆ—å¹¶è¡Œ"]
    E --> P["ğŸ“ linear/<br/>çº¿æ€§å±‚ä¼˜åŒ–"]

    %% å·¥å…·å’Œç›‘æ§å±‚
    E --> Q["ğŸ“ˆ monitor/<br/>ç›‘æ§å·¥å…·"]
    E --> R["â±ï¸ profiling/<br/>æ€§èƒ½åˆ†æ"]
    E --> S["ğŸ”„ autotuning/<br/>è‡ªåŠ¨è°ƒä¼˜"]
    E --> T["ğŸ’¾ checkpoint/<br/>æ£€æŸ¥ç‚¹"]

    %% é«˜çº§åŠŸèƒ½å±‚
    E --> U["ğŸ¯ elasticity/<br/>å¼¹æ€§è®­ç»ƒ"]
    E --> V["ğŸ—œï¸ compression/<br/>æ¨¡å‹å‹ç¼©"]
    E --> W["ğŸ”§ module_inject/<br/>æ¨¡å—æ³¨å…¥"]
    E --> X["ğŸ’¿ nvme/<br/>NVMeä¼˜åŒ–"]

    %% å·¥å…·æ”¯æ’‘å±‚
    subgraph "å·¥å…·æ”¯æ’‘"
        Y["ğŸ› ï¸ utils/<br/>å·¥å…·å‡½æ•°"]
        Z["ğŸ’¾ io/<br/>è¾“å…¥è¾“å‡º"]
        AA["â˜ï¸ nebula/<br/>äº‘è®¡ç®—"]
        BB["âš¡ compile/<br/>ç¼–è¯‘ä¼˜åŒ–"]
    end

    E --> Y
    E --> Z
    E --> BB

    %% æ ·å¼å®šä¹‰
    classDef entryPoint fill:#ff9999,stroke:#333,stroke-width:3px
    classDef coreEngine fill:#99ccff,stroke:#333,stroke-width:2px
    classDef parallel fill:#99ff99,stroke:#333,stroke-width:2px
    classDef support fill:#ffcc99,stroke:#333,stroke-width:1px

    class A entryPoint
    class E,F,G coreEngine
    class M,N,O,P parallel
    class Q,R,S,T,U,V,W,X,Y,Z,AA,BB support
```

## ä¸€. Launcher

> deepspeed/launcher/

è¿™é‡Œæ˜¯æ•´ä¸ªdeepspeedå¯åŠ¨è®­ç»ƒä»»åŠ¡çš„å…¥å£ï¼Œé¦–å…ˆæ˜¯`runner.py`, å®ƒä¼šæ ¹æ®å•æœºorå¤šæœºåˆ†é…åˆ°`launch.py`æˆ–è€…`multinode_runner.py`.

æš‚ä¸”ä¸è€ƒè™‘å•workerçš„æƒ…å†µï¼Œå› ä¸ºå¤ªç®€å•äº†ï¼Œlauncheræœ€éš¾çš„åœ°æ–¹å…¶å®å°±æ˜¯å¤šæœºçš„åˆå§‹åŒ–å’Œé€šä¿¡ï¼Œè¿™é‡Œæˆ‘ä»¬é¦–å…ˆè¦çŸ¥é“ä¸€äº›ç»†èŠ‚ï¼Œè¿™é‡Œé’ˆå¯¹GPUå¤šæœºå¤šå¡è®­ç»ƒçš„é€šä¿¡ä»‹ç»ä¸€äº›çŸ¥è¯†

### 1. communication

1. ç‰©ç†å±‚ä¼ è¾“ï¼šåº•å±‚é€šä¿¡æ˜¯æŒ‡åº•å±‚ç¡¬ä»¶çš„ç‰©ç†å±‚ä¼ è¾“ï¼Œè¿™äº›æ˜¯ç¡¬ä»¶è‡ªå¸¦çš„èƒ½åŠ›ï¼Œè¿™é‡Œåˆ†ä¸ºintranodeä»¥åŠinternodeï¼Œintranodeæ˜¯å•æœºå¤šå¡å†…çš„é€šä¿¡ï¼Œinternodeæ˜¯å¤šæœºé—´é€šä¿¡

- intranodeï¼šåœ¨NV GPUç¯å¢ƒä¸‹ï¼ŒèŠ‚ç‚¹å†…é€šä¿¡ç›´æ¥ä½¿ç”¨NVLinkå³å¯ï¼Œå¸¦å®½è¾¾åˆ°900GB/sï¼Œä¸‹ä½æ–¹æ¡ˆæ˜¯PCIeé€šç”¨æ€»çº¿ï¼Œå¸¦å®½çº¦32GB/sã€‚

- internodeï¼šé¦–å…ˆå°±æ˜¯InfiniBandï¼Œè¿™æ˜¯ä¸€ç§é«˜é€Ÿç½‘ç»œæŠ€æœ¯ï¼Œæ”¯æŒRDMAï¼Œé€Ÿåº¦æœ€å¿«200Gbps+ï¼Œä¸‹ä½æ–¹æ¡ˆæ˜¯ä»¥å¤ªç½‘TCP/UDPä½¿ç”¨Socketçš„é€šä¿¡ï¼Œåªæœ‰å¤§çº¦10-100Gbpsã€‚

2. é€šä¿¡åº“ï¼šè½¯ä»¶å±‚é¢çš„é€šä¿¡ä¼˜åŒ–ï¼Œå¯ä»¥åœ¨è½¯ä»¶çš„å±‚é¢ä¸Šä¼˜åŒ–é€šä¿¡é€Ÿåº¦ï¼Œé€‰å–åˆé€‚çš„é€šä¿¡åç«¯ï¼ŒåŒæ—¶ä¹Ÿä¼šæä¾›æ•…éšœé‡å¯ï¼Œå¼¹æ€§æ‰©ç¼©å®¹ç­‰æ“ä½œã€‚

- MPIï¼šé«˜æ€§èƒ½æ¶ˆæ¯ä¼ è¾“æ¥å£ï¼ˆMessage Passing Interfaceï¼‰ï¼Œæ˜¯ä¸€ç§é€šç”¨çš„æŠ€æœ¯ï¼Œä¾‹å¦‚OpenMPIï¼ŒåŸºäºMPIæ ‡å‡†ï¼Œå°è£…ç‰©ç†å±‚èƒ½åŠ›ï¼ˆIBï¼ŒTCPç­‰ç­‰ï¼‰æä¾›å¤šæœºé—´é€šä¿¡èƒ½åŠ›ã€‚

- NCCLï¼šå¦‚æœæ˜¯NVç¯å¢ƒï¼Œé‚£ä¹ˆå°±æ˜¯MPIçš„ä¸Šä½æ›¿ä»£ï¼Œæ˜¯NVIDIAå‘å¸ƒçš„ä¸€ä¸ªé«˜æ•ˆçš„é›†ä½“é€šä¿¡åº“ï¼Œä¸“ä¸ºå¤šä¸ªGPUä¹‹é—´æä¾›ä¼˜åŒ–çš„ä¼ è¾“æ•ˆç‡å’Œç®€åŒ–åº”ç”¨è€Œè®¾è®¡ï¼Œé‡‡ç”¨RDMAæŠ€æœ¯åŠ é€Ÿï¼Œintranodeä½¿ç”¨NVLinkï¼Œè‡ªåŠ¨ä¼˜åŒ–é€šä¿¡è·¯å¾„ï¼Œå‡å°‘ç½‘ç»œæ‹¥å¡ï¼Œå½“ç„¶è¿™æ˜¯ä¸€ä¸ªä¸ç‰©ç†å±‚æ— å…³çš„è½¯ä»¶æŠ½è±¡ï¼Œæ‰€ä»¥å¦‚æœNVLinkä¸æ”¯æŒä¼šé™çº§ä¸ºPCIeï¼Œæ‰€ä»¥ä¾‹å¦‚IBï¼ŒNVLinkç­‰å‡ä¸æ„æˆ**å¼ºä¾èµ–**ã€‚

3. åº”ç”¨æ¥å£å±‚ï¼šå…¶å®å°±æ˜¯`torchrun`ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹ä¸€ä¸‹pytorchçš„docï¼Œé‡Œé¢æ˜¯è¿™æ ·è¯´çš„

> By default for Linux, the Gloo and NCCL backends are built and included in PyTorch distributed (NCCL only when building with CUDA). MPI is an optional backend that can only be included if you build PyTorch from source.

ä¹Ÿå°±æ˜¯torchæ”¯æŒ`gloo`çš„cpuè®­ç»ƒä»¥åŠ`nccl`çš„gpuè®­ç»ƒï¼Œ`nccl`ä¸€èˆ¬ä½œä¸º`gloo`çš„å¤‡é€‰æ–¹æ¡ˆã€‚

æ¥ä¸‹æ¥å›åˆ°launcherä¹‹ä¸­ï¼Œdeepspeedå¹¶æ²¡æœ‰ä½¿ç”¨torchï¼Œè€Œæ˜¯è‡ªå·±å®ç°äº†ä¸€å¥—launcherï¼Œå¯ä»¥è®©ç”¨æˆ·é€šè¿‡`--launcher`æ¥é€‰æ‹©ï¼Œé»˜è®¤æ˜¯PDSHï¼Œä¹Ÿå¯ä»¥é€‰æ‹©OpenMPIç­‰ä¸€äº›MPIé€šä¿¡ï¼Œæ²¡æœ‰ä½¿ç”¨ncclï¼Œå› ä¸ºncclå±€é™äºcudaã€‚

### 2. network

æ—¢ç„¶æ˜¯å¤šæœºåˆ†å¸ƒå¼è®­ç»ƒï¼Œæœºå™¨ä¹‹é—´å¿…ç„¶ä¼šäº§ç”Ÿé€šä¿¡ï¼Œè¿™é‡Œdeepspeedæä¾›äº†ä¸¤ç§æ–¹å¼ï¼Œä¸€ç§æ˜¯`ssh`, è¿™è¦æ±‚é…ç½®hostfileï¼Œå¹¶ä¸”æ¯ä¸¤ä¸ªnodeä¹‹é—´éœ€è¦å¯ä»¥sshå…å¯†ç™»å½•ï¼Œå¦å¤–ä¸€ç§æ¨¡å¼æ˜¯`no_ssh`, è¿™ä¸ªæ—¶å€™å¤šä¸ªnodeä¹‹é—´ä¸ä¼šå°è¯•sshéªŒè¯ï¼ŒåŸç†æ˜¯åœ¨æ¯ä¸ªnodeéƒ½å¯åŠ¨ä¸€ä¸ªè®­ç»ƒè¿›ç¨‹ï¼Œç„¶åå¿…é¡»è¦æ‰‹åŠ¨æŒ‡å®š`node_rank`, `master_addr`, `master_port`ç­‰ä¸€äº›ä¿¡æ¯ã€‚

å¯¹äº`ssh`æ¨¡å¼ï¼Œæˆ‘ä»¬ä¼šè®¾ç½®`node_rank`, `master_addr`, `master_port`ç­‰ä¸€äº›å…³é”®ä¿¡æ¯ã€‚å¯¹äº`no_ssh`æ¨¡å¼ï¼Œè¿™ä¸€åˆ‡éœ€è¦é…ç½®å¥½ã€‚

ç»è¿‡ä¸Šè¿°çš„ç½‘ç»œé€šä¿¡åŸºç¡€è®¾ç½®ï¼Œæœ€åå¤šnodeä¼šåœ¨æ¯ä¸ªnodeä¸Šå¯åŠ¨ä¸€ä¸ª`python -m deepspeed.launcher.launch`, å¼€å§‹æ‰§è¡Œåˆ†å¸ƒå¼è®­ç»ƒè¿›ç¨‹ã€‚

### 3. subprocess

æœ€ålauncherè¿™ä¸ªåŒ…ï¼Œä¼šå¯åŠ¨è‹¥å¹²çš„è¿›ç¨‹ï¼Œç„¶åæ‰§è¡Œä¸åŒçš„äº‹æƒ…ã€‚å¯¹äºå¤šnodeï¼Œæˆ‘ä»¬è‚¯å®šä¼šå…ˆé€‰æ‹©ä¸€ä¸ªnodeç™»å½•ï¼Œç„¶ååœ¨è¿™ä¸ªnodeä¸Šæ‰§è¡Œä¸€ä¸ªrunnerè¿›ç¨‹ï¼Œå¯¹äºrunnerè¿›ç¨‹ï¼Œå…³ç³»å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

```shell
Runner (runner.py)
â””â”€â”€ Launcher (launch.py)
    â”œâ”€â”€ Training Process 0 (GPU 0)
    â”œâ”€â”€ Training Process 1 (GPU 1)
    â”œâ”€â”€ Training Process 2 (GPU 2)
    â””â”€â”€ ...
```

å¯ä»¥çœ‹å‡ºï¼Œrunneræ˜¯ä¸»è¿›ç¨‹ï¼Œä¼šæ¥å—ä¸€äº›å‚æ•°åšä¸€äº›é€šä¿¡å’Œç½‘ç»œçš„ç›¸å…³é…ç½®ï¼Œä¹‹åå¯¹äºå¤šnodeè€Œè¨€ï¼Œä¼šåœ¨æ¯ä¸ªnodeä¸Šå¯åŠ¨ä¸€ä¸ªlauncherè¿›ç¨‹ï¼Œè¿™ä¸ªæ˜¯æ¯ä¸ªnodeä¸Šéƒ½æœ‰çš„ï¼Œç”¨äºç®¡ç†è®­ç»ƒè¿›ç¨‹ã€‚

å…·ä½“çš„è®­ç»ƒè¿›ç¨‹æ˜¯è¿è¡Œåœ¨æ¯ä¸ªnodeçš„slotsä¸Šçš„ï¼Œå¦‚æœå½“å‰node 8å¡éƒ½éœ€è¦å‚ä¸ï¼Œé‚£ä¹ˆå°±ä¼šå¯åŠ¨8ä¸ªtraining processï¼Œä»£è¡¨å…·ä½“çš„è®­ç»ƒè¿›ç¨‹ï¼Œlauncherçš„ç›®çš„æ˜¯ç®¡ç†è¿™äº›è¿›ç¨‹ï¼Œä¸æ–­åœ°loopå»çœ‹å½“å‰çš„trainè¿›ç¨‹è¿˜æœ‰å¤šå°‘æ­£åœ¨workï¼Œç„¶åå¯¹äºç”¨æˆ·å‘é€çš„SIGINTæˆ–è€…ç³»ç»Ÿå‘é€çš„SIGTERMï¼Œå†™ä¸€äº›ä¼˜é›…é€€å‡ºçš„handlerå»é€€å‡ºtrainè¿›ç¨‹ã€‚

æˆ‘ä»¬éœ€è¦ä¼ å…¥ä¸€äº›å‚æ•°ï¼Œè¿™äº›å…·ä½“çš„å‚æ•°ï¼Œå¯ä»¥çœ‹deepspeedæ–‡æ¡£ï¼Œè¿™é‡Œå°±ä¸å¤šèµ˜è¿°ã€‚

**ä¸è¿‡ä¸Šè¿°çš„launcherï¼Œä¼¼ä¹å› ä¸ºdeepspeedç‰ˆæœ¬è¿‡è€çš„åŸå› ï¼Œå¦‚ä»Šéƒ½ç”±pytorchè§£å†³äº†ï¼Œç›´æ¥torchrunå³å¯**

## äºŒ. Initialize

ç»è¿‡ä¸Šè¿°çš„launcherï¼Œæˆ‘ä»¬æˆåŠŸåœ¨å„ä¸ªnodeä¸Šå¯åŠ¨äº†è‡ªå·±çš„`train.py`, æ¥ä¸‹æ¥æˆ‘ä»¬å…ˆæä¾›ä¸€ä¸ªå®˜æ–¹çš„`train.py`, ç„¶åä¾æ¬¡å‰–æé‡Œé¢çš„ç»†èŠ‚ã€‚

æˆ‘çœ‹çš„æ˜¯[deepspeed example](https://github.com/deepspeedai/DeepSpeedExamples) é‡Œé¢çš„BERT pre-trainè„šæœ¬ï¼Œåœ¨`training/bing_bert`ä¹‹ä¸­

mainå‡½æ•°å¦‚ä¸‹

```python
def main():
    start = time.time()
    args = construct_arguments()
    model, optimizer = prepare_model_optimizer(args)
    start_epoch = 0
    if not None in [args.load_training_checkpoint, args.load_checkpoint_id]:
        start_epoch = load_checkpoint(args, model)
    run(args, model, optimizer, start_epoch)
    elapsed = time.time() - start
    logger = args.logger
    logger.info(f"Elapsed time: {elapsed} seconds")
```

Inité›†ä¸­åœ¨`prepare_model_optimizer`ä¹‹ä¸­ï¼Œå†…éƒ¨ä¼šè°ƒç”¨DeepSpeedçš„`initialize()`å‡½æ•°ï¼Œå¯¹å…¨å±€çš„æ¡†æ¶è¿›è¡Œåˆå§‹åŒ–.

### 1. distribute

> deepspeed/comm/

åœ¨`prepare_model_optimizer`ä¸­ï¼Œä½¿ç”¨äº†`deepspeed.init_distributed(dist_backend='nccl')`ï¼Œå€Ÿæ­¤æˆ‘ä»¬å¯ä»¥çœ‹ä¸€ä¸‹deepspeedçš„é€šä¿¡åŒ…æ˜¯å¦‚ä½•è®¾è®¡çš„ã€‚

deepspeedçš„é€šä¿¡åŒ…ä¿æŒç€å’Œ`torch.distributed`åŒæ ·çš„APIè®¾è®¡ï¼Œæ–¹ä¾¿ç”¨æˆ·è¿ç§»ï¼Œé˜…è¯»è¿™éƒ¨åˆ†ä»£ç æ„Ÿè§‰ä¹Ÿå¯ä»¥ä¸ºæœªæ¥é˜…è¯»`pytorch`æºç æ‰“ä¸‹åŸºç¡€ã€‚

å¯ä»¥çœ‹å‡ºcommåŒ…ä¸»è¦å°±å„ç§é€šä¿¡op(all_reduce, all_gather)è¿›è¡Œå°è£…ï¼Œé¦–å…ˆå°†é»˜è®¤çš„`torch.distributed`å°è£…ä¸º`TorchBackend`, è¿™æ„å‘³ç€é»˜è®¤çš„backendï¼Œç„¶åè¿™é‡Œä¹Ÿæ”¯æŒç”¨æˆ·å®šåˆ¶å±äºè‡ªå·±çš„backendã€‚å¯¹äºå°è£…çš„`TorchBackend`ä¸»è¦æ˜¯æ›´åŠ çš„æ™®é€‚ï¼Œå¯¹å„ä¸ªtorchç‰ˆæœ¬éƒ½é€‚ç”¨ã€‚å½“ç„¶deepspeedä¹Ÿæä¾›äº†ä¸€ä¸ªè‡ªå·±çš„å®šåˆ¶åç«¯ä½œä¸ºå‚ç…§ï¼š`CCLBackend`Intelé€šä¿¡åº“ã€‚

é€šè¿‡`init_deepspeed_backend()`æ¥é€‰æ‹©è‡ªå·±çš„å®šåˆ¶backendï¼Œå¦‚æœcdbæœ€åè¿˜æ˜¯ä¸ºNoneï¼Œå°±ä½¿ç”¨`TorchBackend`

```python
if cdb is None:
    init_deepspeed_backend(get_accelerator().communication_backend_name(), timeout, init_method)
    set_backend()
    utils.logger.info(f'cdb={cdb}')
if cdb is None and torch.distributed.is_initialized():
    # The user initialized torch.dist themselves, create cdb and short-circuit
    cdb = TorchBackend(dist_backend, timeout, init_method)
    return
```

ç›®å‰çœ‹æ¥è¿™å—ä»£ç è¿˜æŒºå¥‡æ€ªçš„ï¼Œæ¯”è¾ƒåå‘äºåŠæˆå“ï¼Œå¤§è‡´æ€è·¯å…¶å®æ˜¯æƒ³è®¾è®¡ä¸€ä¸ªæ›´åŠ æ™®é€‚é€šç”¨çš„é€šä¿¡åç«¯æ¡†æ¶ï¼Œä½†æ˜¯ç›®å‰åªæ˜¯å¯¹`torch.distributed`è¿›è¡Œäº†ä¸€æ¬¡åŒ…è£…

å’Œ`launcher`æ¨¡å—é¢ä¸´çš„å¤„å¢ƒå·®ä¸å¤šï¼Œåœ¨å¯åŠ¨åˆ†å¸ƒå¼è®­ç»ƒçš„æ—¶å€™ç¡®å®å¯èƒ½éœ€è¦å¾ˆå¤šçš„ç½‘ç»œå’Œé€šä¿¡çš„å‡†å¤‡å·¥ä½œï¼Œä½†æ˜¯ç°ä»£pytorchå·²ç»å°†è¿™äº›ç¹ççš„å·¥ä½œæ”¶æ•›è¿›torchä¹‹ä¸­ï¼Œdeepspeedè¿™é‡Œçš„ä»£ç åªèƒ½è¯´æœ‰ä¸€å®šçš„å¯å‘ä½œç”¨ã€‚

ç›®å‰å¯¹deepspeedçš„é€šä¿¡æœ‰äº†ä¸€å®šçš„äº†è§£ï¼Œåˆ†ä¸ºäº†ä¸¤ä¸ªéƒ¨åˆ†ï¼Œä¸€ä¸ªæ˜¯inité˜¶æ®µï¼Œä½¿ç”¨MPIæ¥é€šä¿¡ä¸€äº›åŸºæœ¬ä¿¡æ¯å’Œç¯å¢ƒå˜é‡ï¼Œä¾‹å¦‚`LOCAL_RANK`è¿™ç§ï¼Œæ„æ€æ˜¯å¦‚æœæ²¡æœ‰è®¾ç½®è¿™ç§rankï¼Œå¯ä»¥åªé€šè¿‡æŒ‡å®šè‹¥å¹²hostæ¥è®©deepspeedå¸®ä½ è‡ªåŠ¨æ’åºï¼Œæœ€åæ³¨å…¥ç¯å¢ƒå˜é‡ã€‚æˆ–è€…è¯´è¿™äº›åŸºç¡€ç¯å¢ƒå˜é‡å®Œå…¨ç”±ç”¨æˆ·æ¥æŒ‡å®šï¼Œè¿™æ ·å°±ä¸éœ€è¦MPIäº†ã€‚ç¬¬äºŒä¸ªé˜¶æ®µæ˜¯worké˜¶æ®µï¼Œè¿™ä¸ªæ—¶å€™å°±éœ€è¦å®šåˆ¶çš„é€šä¿¡åç«¯ï¼Œä¾‹å¦‚cpuä½¿ç”¨`gloo`, nv gpuä½¿ç”¨`nccl`, intelä½¿ç”¨`ccl`ç­‰ç­‰, è¿™é‡Œå¼ºè°ƒçš„æ˜¯é«˜æ€§èƒ½æ‰€ä»¥ä¸èƒ½ä½¿ç”¨MPIã€‚

### 2. deepspeed.initialize

> deepspeed/\_\_init\_\_.py

é‡ç‚¹æ¥äº†ï¼Œè¿™é‡Œåº”è¯¥æ˜¯deepspeedæ•´ä¸ªæ¡†æ¶çš„åˆå§‹åŒ–çš„æ±‡é›†ç‚¹, ç¬¬ä¸€éƒ¨åˆ†çš„åˆ†å¸ƒå¼ç¯å¢ƒåˆå§‹åŒ–ä¹Ÿåº”è¯¥æ˜¯è¿™ä¸ªåˆå§‹åŒ–çš„ä¸€éƒ¨åˆ†ã€‚

```python
# åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ
dist.init_distributed()

#åˆå§‹åŒ–device mesh
dist.initialize_mesh_device(mesh_param, ("data_parallel", "sequence_parallel"))

if not isinstance(model, PipelineModule):
        config_class = DeepSpeedConfig(config, mpu, mesh_device=mesh_device)
        if config_class.hybrid_engine.enabled:
            engine = DeepSpeedHybridEngine(args)
        else:
            engine = DeepSpeedEngine(args)
    else:
        assert mpu is None, "mpu must be None with pipeline parallelism"
        mpu = model.mpu()
        config_class = DeepSpeedConfig(config, mpu)
        engine = PipelineEngine(args)

    # Restore zero.Init context if necessary
    zero.partition_parameters.restore_init_context()

    return_items = [
        engine,
        engine.optimizer,
        engine.training_dataloader,
        engine.lr_scheduler,
    ]
    return tuple(return_items)
```

å¯ä»¥çœ‹å‡ºdeepspeedæ ¸å¿ƒçš„è®¡ç®—å’Œè°ƒåº¦ä»£ç åœ¨`engine`ä¹‹ä¸­ï¼Œè¿™ä¸ªç•™åˆ°ä¸‹ä¸€èŠ‚è®²ã€‚ä¹‹åå°±æ˜¯ä¸€ä¸ª`if pp`çš„é…ç½®ï¼Œé¦–å…ˆGPUæ˜¯ç”±`device_mesh`ç»„ç»‡çš„ï¼Œç›®çš„æ˜¯å°†GPUç»„ç»‡æˆä¸€ä¸ªç½‘æ ¼ç»“æ„ï¼Œæ¯”å¦‚

```python
dist.initialize_mesh_device(mesh_param, ("data_parallel", "sequence_parallel"))
```

è¿™é‡Œå°±æ˜¯å°†å„ä¸ªworkerç»„ç»‡æˆäºŒç»´ç½‘æ ¼ç»“æ„ï¼Œç¬¬ä¸€è¡Œæ˜¯dpçš„gpu groupï¼Œç¬¬äºŒè¡Œæ˜¯spçš„gpu groupï¼Œè¿™æ ·åšçš„å¥½å¤„å°±æ˜¯ä¸éœ€è¦è‡ªå·±å»åˆ’åˆ†ä¸åŒçš„process groupï¼Œæ›´åŠ ä¾¿æ·ã€‚ä¸è¿‡æˆ‘è§‚å¯Ÿmegatronå¹¶æ²¡æœ‰ä½¿ç”¨device mesh, è€Œæ˜¯é€‰æ‹©è‡ªå·±æ‰‹åŠ¨ç®¡ç†process groupçš„å½¢å¼ï¼Œä¸çŸ¥é“æœ‰æ— ä»€ä¹ˆè®²ç©¶

ç„¶åå°±æ˜¯æ„é€ engineï¼Œdeepspeedå°†ppä¸dp+tpåˆ†å‰²å¼€äº†ï¼Œçœ‹æ ·å­deepspeedå¹¶ä¸æ”¯æŒ3D parallelã€‚ä¸è¿‡ä¹Ÿå¯ä»¥ç†è§£ï¼Œdeepspeedé€‚åˆæ¯”è¾ƒå°çš„æ¨¡å‹ï¼Œèµ°çš„æ˜¯ZeROè¿™ä¸€å¥—ï¼Œå¦‚æœæ˜¯çœŸæ­£çš„å¤§æ¨¡å‹ï¼Œè¿˜æ˜¯éœ€è¦ä½¿ç”¨megatron

å¦å¤–deepspeedè¿˜æä¾›äº†ä¸€ä¸ª`init_inference`, æœ€åçš„ç»“æœä»ç„¶æ˜¯è¿”å›ä¸€ä¸ª`engin`, è¿”å›çš„æ˜¯`InferenceEngine`

å¼¹æ€§è®­ç»ƒæ‰“ç®—åœ¨å•ç‹¬å¼€ä¸€ä¸ªç« èŠ‚è®°å½•ï¼Œå› ä¸ºæˆ‘åœ¨megatronä¹‹ä¸­å¹¶æ²¡æœ‰çœ‹åˆ°å¼¹æ€§è®­ç»ƒçš„ä¸œè¥¿ï¼Œåˆ°æ—¶å€™å¯èƒ½éœ€è¦ç»“åˆpytorchåº•å±‚åŸç†ï¼Œè®²è§£ä¸€ä¸‹å¦‚ä½•å¼¹æ€§è®­ç»ƒã€‚

### 3. Config

configæ˜¯ç®¡ç†å„ç§é…ç½®é€‰é¡¹çš„ï¼Œå› ä¸ºè®­ç»ƒæ¡†æ¶å‚æ•°ä¼—å¤šï¼Œå¯å®šåˆ¶åŒ–éœ€è¦åšçš„å¾ˆå¼ºå¾ˆå¼ºï¼Œæ‰€ä»¥configçš„ç®¡ç†ä¼šæ¯”è¾ƒé•¿ï¼Œå¯¹äºè¿™ç§æ¯”è¾ƒè€ƒéªŒæ¶æ„è®¾è®¡èƒ½åŠ›çš„åœ°æ–¹ï¼Œæˆ‘è§‰å¾—å†™å¥½ä¸€ä¸ªconfigè¿˜æ˜¯æ¯”è¾ƒå›°éš¾çš„ã€‚åœ¨deepspeedä¸­ï¼Œæˆ‘å‘ç°äº†è¿™ä¸ªç±»ï¼Œä»–å¯ä»¥è§£å†³ä¸€ä¸ªæ¯”è¾ƒç—›è‹¦çš„åœ°æ–¹ï¼Œé‚£å°±æ˜¯é…ç½®é¡¹çš„åºŸå¼ƒè¿ç§»ã€‚deepspeedå®ç°äº†ä¸€ä¸ª`DeepSpeedConfigModel`, ä¹‹åçš„`config`ç±»å¯ä»¥ç»§æ‰¿è‡ªè¿™ä¸ªç±»ï¼Œå¯ä»¥ä½¿ç”¨`pydantic`æ¯”è¾ƒå·§å¦™åœ°å®ç°æ–°æ—§å­—æ®µçš„åºŸå¼ƒå’Œå…¼å®¹ã€‚

```python
class DeepSpeedConfigModel(BaseModel):
    def __init__(self, strict=False, **data):
        if (not strict):  # This is temporary until we refactor all DS configs, allows HF to load models
            data = {k: v for k, v in data.items() if (v != "auto" or k == "replace_method")}
        super().__init__(**data)
        self._deprecated_fields_check()

    def _process_deprecated_field(self, dep_field):
        # Get information about the deprecated field
        pydantic_config = self
        fields_set = pydantic_config.model_fields_set
        kwargs = type(pydantic_config).model_fields[dep_field].json_schema_extra
        new_param_fn = kwargs.get("new_param_fn", lambda x: x)
        param_value = new_param_fn(getattr(pydantic_config, dep_field))
        new_field = kwargs.get("new_param", "")
        dep_msg = kwargs.get("deprecated_msg", "")
        if dep_field in fields_set:
            logger.warning(f"Config parameter {dep_field} is deprecated" +
                           (f" use {new_field} instead" if new_field else "") + (f". {dep_msg}" if dep_msg else ""))
            # Check if there is a new param and if it should be set with a value
            if new_field and kwargs.get("set_new_param", True):
                # Remove the deprecate field if there is a replacing field
                try:
                    delattr(pydantic_config, dep_field)
                except Exception as e:
                    logger.error(f"Tried removing deprecated '{dep_field}' from config")
                    raise e

                # Set new param value
                new_param_nested = new_field.split(".")
                if len(new_param_nested) > 1:
                    # If the new param exists in a subconfig, we need to get
                    # the fields set for that subconfig
                    pydantic_config = reduce(getattr, new_param_nested[:-1], pydantic_config)
                    fields_set = pydantic_config.model_fields_set
                new_param_name = new_param_nested[-1]
                assert (
                    new_param_name not in fields_set
                ), f"Cannot provide deprecated parameter '{dep_field}' and replacing parameter '{new_field}' together"
                # A custom function for converting the old param value to new param value can be provided
                try:
                    setattr(pydantic_config, new_param_name, param_value)
                except Exception as e:
                    logger.error(f"Tried setting value for '{new_field}' with value from deprecated '{dep_field}'")
                    raise e

    def _deprecated_fields_check(self):
        fields = type(self).model_fields
        for field_name, field_info in fields.items():
            if field_info.json_schema_extra and field_info.json_schema_extra.get("deprecated", False):
                self._process_deprecated_field(field_name)

    # ä¸€äº›æœ‰å…³BaseModelçš„é…ç½®
    model_config = ConfigDict(
        validate_default=True, # å¯¹é»˜è®¤å€¼è¿›è¡ŒéªŒè¯
        validate_assignment=True, # èµ‹å€¼æ—¶è¿›è¡ŒéªŒè¯
        use_enum_values=True, # ä½¿ç”¨æšä¸¾çš„å€¼è€Œä¸æ˜¯æšä¸¾å¯¹è±¡
        populate_by_name=True, # å…è®¸é€šè¿‡å­—æ®µåæ¥å¡«å……æ•°æ®
        extra="forbid", # ç¦æ­¢é¢å¤–çš„å­—æ®µ
        arbitrary_types_allowed=True, #å…è®¸ä»»æ„ç±»å‹ï¼Œjsonä¹‹ä¸­å¦‚æœæœ‰é¢å¤–çš„å­—æ®µä¼šæŠ¥é”™
        protected_namespaces=(),
    )

    @field_serializer("dtype", check_fields=False)
    def serialize_torch_dtype(dtype: torch.dtype) -> str:
        return str(dtype)
```

ä½¿ç”¨æ–¹æ³•å¦‚ä¸‹

```python
class OptimizerConfig(BaseModel):
    lr: float = 0.001

class TrainingConfig(DeepSpeedConfigModel):
    optimizer: OptimizerConfig
    learning_rate: float = Field(
        0.001,
        deprecated=True,
        new_param="optimizer.lr"  # æŒ‡å‘åµŒå¥—é…ç½®ä¸­çš„å­—æ®µ
    )

# ä½¿ç”¨ç¤ºä¾‹
config = TrainingConfig(
    learning_rate=0.01  # æ—§å­—æ®µ
)
# ä¼šè‡ªåŠ¨å°† 0.01 è®¾ç½®åˆ° config.optimizer.lr
```

åœ¨å®ç°`Config`ç±»çš„æ—¶å€™å¯ä»¥é¡ºä¾¿å®ç°ä¸€äº›checkæ–¹æ³•ï¼Œç”¨äºç¡®ä¿é…ç½®çš„æ­£ç¡®æ€§ã€‚å¦å¤–è¿˜éœ€è¦ä¸€äº›åºåˆ—åŒ–æ–¹æ³•ï¼Œä¾‹å¦‚åœ¨deepspeedä¹‹ä¸­ï¼Œç±»ä¹Ÿä¼šç»§æ‰¿

```python
class ScientificNotationEncoder(json.JSONEncoder):
    """
    This class overrides ``json.dumps`` default formatter.

    This version keeps everything as normal except formats numbers bigger than 1e3 using scientific notation.

    Just pass ``cls=ScientificNotationEncoder`` to ``json.dumps`` to activate it

    """

    def iterencode(self, o, _one_shot=False, level=0):
        indent = self.indent if self.indent is not None else 4
        prefix_close = " " * level * indent
        level += 1
        prefix = " " * level * indent
        if isinstance(o, bool):
            return "true" if o else "false"
        elif isinstance(o, float) or isinstance(o, int):
            if o > 1e3:
                return f"{o:e}"
            else:
                return f"{o}"
        elif isinstance(o, collections.abc.Mapping):
            x = [f'\n{prefix}"{k}": {self.iterencode(v, level=level)}' for k, v in o.items()]
            return "{" + ", ".join(x) + f"\n{prefix_close}" + "}"
        elif isinstance(o, collections.abc.Sequence) and not isinstance(o, str):
            return f"[{ f', '.join(map(self.iterencode, o)) }]"
        return "\n, ".join(super().iterencode(o, _one_shot))

class DeepSpeedConfigObject(object):
    """
    For json serialization
    """

    def repr(self):
        return self.__dict__

    def __repr__(self):
        return json.dumps(
            self.__dict__,
            sort_keys=True,
            indent=4,
            cls=ScientificNotationEncoder,
        )
```

ä½†æ˜¯æ€»ä½“æ¥è¯´configä¹Ÿæ˜¯å†™çš„æ¯”è¾ƒä¹±ï¼Œä¸è¿‡è¿™ä¹Ÿæ˜¯æ¯”è¾ƒå¤§çš„é¡¹ç›®çš„ç—›ç‚¹äº†ï¼Œè¿­ä»£è¿‡ç¨‹æ˜¯ä¸€ä¸ªç†µå¢çš„è¿‡ç¨‹ï¼Œå˜å¾—æ‚ä¹±æ˜¯ä¸å¯é¿å…çš„ã€‚

æ¥ä¸‹æ¥å›åˆ°Bertçš„é¢„è®­ç»ƒè„šæœ¬ä¸­ï¼Œä¸Šè¿°çš„Initå¯¹åº”Bertä¹‹ä¸­çš„è¿™ä¸€æ®µä»£ç 

```python
 model.network, optimizer, _, _ = deepspeed.initialize(
        args=args,
        model=model.network,
        model_parameters=optimizer_grouped_parameters)
```

å›åˆ°mainå‡½æ•°ï¼Œé‡Œé¢ä¼šæœ‰load checkpointçš„æ“ä½œï¼Œå¦‚æœæˆ‘æƒ³checkpoint load weightï¼Œä¼šä½¿ç”¨load_checkpointï¼Œè¿™æ˜¯deepspeedæºç ä¸­`engine`çš„å‡½æ•°ï¼Œè™½ç„¶è®¡åˆ’å°†`engine`æ”¾åˆ°ä¸‹ä¸€ç« æ¥è®²ï¼Œä½†æ˜¯æˆ‘ä»¬å¯ä»¥å…ˆçœ‹ä¸€ä¸‹`load_checkpoint`çš„æºç ä¸­æ˜¯å¦‚ä½•è®¾è®¡çš„ã€‚é¦–å…ˆè¿™é‡Œå°±ä¸å¯¹checkpointæŠ€æœ¯åšè¿‡å¤šèµ˜è¿°ï¼Œä¸€å¥è¯æ¦‚æ‹¬ï¼Œå…¶å®å°±æ˜¯å°†è¿˜æ²¡è®­ç»ƒå®Œçš„å„ç§çŠ¶æ€ä¿å­˜ä¸€ä¸‹ï¼Œä¹‹åæœ‰ç©ºå†loadè¿›æ¥ç»§ç»­è®­ç»ƒçš„æŠ€æœ¯ã€‚

å› ä¸ºè®­ç»ƒè¿‡ç¨‹ä¸­å„ç§weightæˆ–è€…å…¶ä»–çŠ¶æ€éƒ½æ˜¯åœ¨æ˜¾å­˜ä¸­çš„ï¼Œè€Œä¿å­˜æ˜¯ä¿å­˜åœ¨ç£ç›˜ä¹‹ä¸­çš„ï¼Œæ‰€ä»¥è¿™é‡Œå°±æ¶‰åŠåˆ°ä¸€äº›é«˜æ•ˆsaveçš„æŠ€æœ¯ï¼Œä½†æ˜¯è¿™é‡Œå°±åªä»‹ç»pytorchè‡ªå¸¦çš„åŸç”Ÿä¿å­˜ï¼Œæ˜¯`torch.save`.

`torch.save`å°±æ˜¯å°†tensoræˆ–è€…modelä¿å­˜åˆ°ç£ç›˜ä¸­ï¼Œ`torch.load`å°±æ˜¯å°†tensoræˆ–è€…model loadåˆ°æ˜¾å­˜ä¸­. ä¸€èˆ¬modelä¿å­˜çš„æ˜¯state_dict, æ‰€ä»¥è¿™é‡Œæˆ‘é¦–å…ˆä½¿ç”¨

```python


```
