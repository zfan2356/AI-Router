export default "{\"documentCount\":287,\"nextId\":287,\"documentIds\":{\"0\":\"/\",\"1\":\"/#sections\",\"2\":\"/#一些想法\",\"3\":\"/friends/\",\"4\":\"/faq/\",\"5\":\"/article/mcz1csb4/\",\"6\":\"/article/mcz1csb4/#概述\",\"7\":\"/article/mcgayb5w/\",\"8\":\"/article/97s6ha1e/\",\"9\":\"/article/2z59hh8g/\",\"10\":\"/article/mcz1csb4/#用途\",\"11\":\"/article/mcgayb5w/#标题锚点\",\"12\":\"/article/i4cuuonn/\",\"13\":\"/article/97s6ha1e/#概述\",\"14\":\"/article/2z59hh8g/#概述\",\"15\":\"/article/p6ciasa4/\",\"16\":\"/algorithm/qa/\",\"17\":\"/article/mcz1csb4/#行内-html\",\"18\":\"/article/mcgayb5w/#自定义锚点\",\"19\":\"/article/i4cuuonn/#概述\",\"20\":\"/algorithm/\",\"21\":\"/article/97s6ha1e/#用途\",\"22\":\"/article/2z59hh8g/#用途\",\"23\":\"/algorithm/qa/#说出resnet的模型结构\",\"24\":\"/article/mcz1csb4/#特殊字元自动转换\",\"25\":\"/article/mcgayb5w/#链接\",\"26\":\"/article/i4cuuonn/#用途\",\"27\":\"/algorithm/attention/\",\"28\":\"/article/97s6ha1e/#行内-html\",\"29\":\"/article/2z59hh8g/#行内-html\",\"30\":\"/algorithm/qa/#transformer-encoder-block的模型结构\",\"31\":\"/article/mcz1csb4/#块元素\",\"32\":\"/article/mcgayb5w/#内部链接\",\"33\":\"/article/i4cuuonn/#行内-html\",\"34\":\"/algorithm/attention/#一-注意力机制简介\",\"35\":\"/algorithm/cnn/\",\"36\":\"/article/97s6ha1e/#特殊字元自动转换\",\"37\":\"/article/2z59hh8g/#特殊字元自动转换\",\"38\":\"/algorithm/qa/#写出batchnorm和softmax的公式-bathnorm由哪些小算子构成-batchnorm和softmax在什么情况下计算结果可能会出现精度问题-为什么-如何解决\",\"39\":\"/algorithm/linear/\",\"40\":\"/article/mcz1csb4/#段落和换行\",\"41\":\"/article/mcgayb5w/#外部链接\",\"42\":\"/article/i4cuuonn/#特殊字元自动转换\",\"43\":\"/algorithm/attention/#_1-引入\",\"44\":\"/algorithm/cnn/#一-从全连接层过渡到卷积层\",\"45\":\"/algorithm/mla/\",\"46\":\"/algorithm/modern_cnn/\",\"47\":\"/algorithm/qa/#加速ai模型的推理速度-该从哪些角度去考虑\",\"48\":\"/algorithm/linear/#一-什么是线性回归\",\"49\":\"/article/mcz1csb4/#标题\",\"50\":\"/article/mcgayb5w/#github风格的表格\",\"51\":\"/algorithm/attention/#_2-非参数注意力汇聚\",\"52\":\"/algorithm/cnn/#_1-介绍\",\"53\":\"/algorithm/moe/\",\"54\":\"/algorithm/modern_cnn/#一-alexnet\",\"55\":\"/algorithm/qa/#模型大小的四大评估指标是什么-举例说明对他们的理解\",\"56\":\"/algorithm/linear/#二-梯度下降\",\"57\":\"/article/mcz1csb4/#blockquotes\",\"58\":\"/article/mcgayb5w/#emoji\",\"59\":\"/algorithm/attention/#_3-带参数注意力汇聚\",\"60\":\"/algorithm/cnn/#_2-特性\",\"61\":\"/algorithm/moe/#basic-moe\",\"62\":\"/algorithm/mtp/\",\"63\":\"/algorithm/modern_cnn/#二-vgg\",\"64\":\"/algorithm/mlp/\",\"65\":\"/algorithm/ppo/\",\"66\":\"/algorithm/qa/#说出加速resnet50推理速度的一些手段\",\"67\":\"/algorithm/linear/#_1-简介\",\"68\":\"/article/mcz1csb4/#列表\",\"69\":\"/article/mcgayb5w/#目录表\",\"70\":\"/algorithm/attention/#_4-注意力评分\",\"71\":\"/algorithm/cnn/#_3-推导\",\"72\":\"/algorithm/moe/#shared-experts-and-router\",\"73\":\"/algorithm/rnn/\",\"74\":\"/algorithm/softmax/\",\"75\":\"/algorithm/modern_cnn/#三-nin\",\"76\":\"/algorithm/transformer/\",\"77\":\"/algorithm/ppo/#ppo\",\"78\":\"/algorithm/linear/#_2-如何理解-沿梯度\",\"79\":\"/article/mcz1csb4/#代码块\",\"80\":\"/article/mcgayb5w/#自定义容器\",\"81\":\"/algorithm/attention/#加性注意力\",\"82\":\"/algorithm/cnn/#_4-通道\",\"83\":\"/algorithm/rnn/#一-rnn引入\",\"84\":\"/cpp/\",\"85\":\"/algorithm/softmax/#一-什么是softmax\",\"86\":\"/algorithm/modern_cnn/#四-googlenet\",\"87\":\"/algorithm/transformer/#一-模型架构\",\"88\":\"/algorithm/linear/#_3-具体解法\",\"89\":\"/article/mcz1csb4/#分隔线\",\"90\":\"/article/mcgayb5w/#默认标题\",\"91\":\"/algorithm/attention/#缩放点积注意力\",\"92\":\"/algorithm/cnn/#_5-特征映射和感受野\",\"93\":\"/algorithm/rnn/#_1-简介\",\"94\":\"/cpp/const/\",\"95\":\"/algorithm/softmax/#_1-引入\",\"96\":\"/algorithm/modern_cnn/#五-batch-normalization\",\"97\":\"/algorithm/transformer/#_1-multi-head-attention\",\"98\":\"/cpp/modern/\",\"99\":\"/article/mcz1csb4/#行内元素\",\"100\":\"/article/mcgayb5w/#自定义标题\",\"101\":\"/algorithm/attention/#二-注意力模型\",\"102\":\"/algorithm/cnn/#_6-总结\",\"103\":\"/algorithm/rnn/#_2-马尔科夫模型\",\"104\":\"/cpp/const/#一-const修饰变量\",\"105\":\"/cpp/move/\",\"106\":\"/cpp/projects/\",\"107\":\"/cpp/type/\",\"108\":\"/algorithm/softmax/#_2-介绍\",\"109\":\"/algorithm/modern_cnn/#六-resnet\",\"110\":\"/algorithm/transformer/#_2-position-wise-feed-forward-networks\",\"111\":\"/python/\",\"112\":\"/cpp/modern/#一-初始化\",\"113\":\"/article/mcz1csb4/#链接\",\"114\":\"/article/mcgayb5w/#导入代码块\",\"115\":\"/algorithm/attention/#_1-bahdanau注意力模型\",\"116\":\"/algorithm/cnn/#二-cnn-实现\",\"117\":\"/algorithm/rnn/#_3-文本预处理\",\"118\":\"/cpp/const/#const修饰函数\",\"119\":\"/cpp/move/#一-value-category\",\"120\":\"/python/async/\",\"121\":\"/pytorch/\",\"122\":\"/cpp/type/#一-模板类型推导\",\"123\":\"/algorithm/softmax/#_3-梯度计算\",\"124\":\"/algorithm/transformer/#_3-positional-encoding\",\"125\":\"/cpp/modern/#二-nullptr\",\"126\":\"/pytorch/autograd/\",\"127\":\"/article/mcz1csb4/#强调\",\"128\":\"/article/mcgayb5w/#数学方程\",\"129\":\"/algorithm/attention/#encoder步骤\",\"130\":\"/algorithm/cnn/#_1-互相关运算\",\"131\":\"/algorithm/rnn/#_4-语言模型\",\"132\":\"/cpp/move/#二-为什么需要move\",\"133\":\"/python/async/#一-多线程\",\"134\":\"/pytorch/basic/\",\"135\":\"/cpp/type/#二-auto类型推导\",\"136\":\"/pytorch/gradient/\",\"137\":\"/algorithm/softmax/#_4-损失函数\",\"138\":\"/algorithm/transformer/#_4-encoder-layer\",\"139\":\"/cpp/modern/#三-using\",\"140\":\"/pytorch/autograd/#torch-autograd-function\",\"141\":\"/article/mcz1csb4/#代码\",\"142\":\"/article/mcgayb5w/#标记\",\"143\":\"/algorithm/attention/#decoder与attention机制步骤\",\"144\":\"/algorithm/cnn/#_2-填充和步幅\",\"145\":\"/algorithm/rnn/#齐普夫定律\",\"146\":\"/cpp/move/#三-其他\",\"147\":\"/python/async/#为什么python中多线程的效率这么差\",\"148\":\"/pytorch/basic/#一-torch-tensor\",\"149\":\"/system/\",\"150\":\"/cpp/type/#三-decltype\",\"151\":\"/pytorch/gradient/#一个简单的梯度计算例子\",\"152\":\"/algorithm/softmax/#二-从零实现softmax回归\",\"153\":\"/algorithm/transformer/#_5-decoder-layer\",\"154\":\"/cpp/modern/#四-scoped-enum\",\"155\":\"/papers/\",\"156\":\"/article/mcz1csb4/#图片\",\"157\":\"/article/mcgayb5w/#上下角标\",\"158\":\"/paper/read/\",\"159\":\"/algorithm/attention/#_2-多头注意力\",\"160\":\"/algorithm/cnn/#_3-多输入和多输出通道\",\"161\":\"/paper/transformer/\",\"162\":\"/algorithm/rnn/#_5-数据集随机采样\",\"163\":\"/python/async/#_1-对比其他语言\",\"164\":\"/pytorch/basic/#_1-基础操作\",\"165\":\"/cuda/\",\"166\":\"/pytorch/gradient/#自动微分对向量的兼容\",\"167\":\"/algorithm/transformer/#transformer\",\"168\":\"/cpp/modern/#五-deleted\",\"169\":\"/cuda/env/\",\"170\":\"/cuda/gemm/\",\"171\":\"/article/mcz1csb4/#其他文本样式\",\"172\":\"/article/mcgayb5w/#自定义对齐\",\"173\":\"/algorithm/attention/#实现\",\"174\":\"/algorithm/cnn/#多输入通道\",\"175\":\"/paper/transformer/#_2-常见问题\",\"176\":\"/algorithm/rnn/#随机采样\",\"177\":\"/python/async/#_2-对比串行\",\"178\":\"/pytorch/basic/#创建操作\",\"179\":\"/cuda/hardware/\",\"180\":\"/pytorch/gradient/#反向传播起点\",\"181\":\"/algorithm/transformer/#二-模型训练\",\"182\":\"/cpp/modern/#六-override-noexcept\",\"183\":\"/cuda/gemm/#cutlass-fast-gemm-with-wgmma\",\"184\":\"/article/mcz1csb4/#其它\",\"185\":\"/article/mcgayb5w/#属性支持\",\"186\":\"/algorithm/attention/#_3-自注意力和位置编码\",\"187\":\"/algorithm/cnn/#多输出通道\",\"188\":\"/algorithm/rnn/#顺序分区\",\"189\":\"/cuda/memory/\",\"190\":\"/python/async/#如何实现真正意义上的并行\",\"191\":\"/pytorch/basic/#计算操作\",\"192\":\"/system/29e039p4/\",\"193\":\"/algorithm/transformer/#三-完整代码\",\"194\":\"/cpp/modern/#七-constexpr\",\"195\":\"/system/inference/flash_attention/\",\"196\":\"/system/inference/kvcache/\",\"197\":\"/cuda/gemm/#gemm\",\"198\":\"/system/inference/gqa/\",\"199\":\"/article/mcz1csb4/#自动链接\",\"200\":\"/article/mcgayb5w/#任务列表\",\"201\":\"/system/inference/page-attn/\",\"202\":\"/algorithm/attention/#对比\",\"203\":\"/algorithm/cnn/#_4-1-1卷积层\",\"204\":\"/algorithm/rnn/#二-rnn介绍\",\"205\":\"/cuda/memory/#一-memory-consistency-model\",\"206\":\"/python/async/#二-async-await异步编程\",\"207\":\"/pytorch/basic/#_2-梯度操作\",\"208\":\"/system/inference/paper/\",\"209\":\"/system/03fa33xq/\",\"210\":\"/system/pre-train/model-parallel/\",\"211\":\"/cpp/modern/#八-const成员函数的线程安全\",\"212\":\"/system/inference/kvcache/#一-decoder-only模型量级分析\",\"213\":\"/system/pre-train/pp/\",\"214\":\"/article/mcz1csb4/#转义字符\",\"215\":\"/article/mcgayb5w/#脚注\",\"216\":\"/algorithm/cnn/#三-汇聚层pooling\",\"217\":\"/algorithm/rnn/#_1-原理\",\"218\":\"/system/m1n84ym5/\",\"219\":\"/python/async/#_1-介绍\",\"220\":\"/pytorch/basic/#_3-转换操作\",\"221\":\"/system/quant/intro/\",\"222\":\"/system/pre-train/model-parallel/#megatron-lm-training-multi-billion-parameter-language-models\",\"223\":\"/system/quant/pytorch-quant/\",\"224\":\"/cpp/modern/#九-特殊成员函数\",\"225\":\"/system/inference/kvcache/#_1-模型参数量\",\"226\":\"/system/sy4ndlm7/\",\"227\":\"/system/rl/intro/\",\"228\":\"/article/mcz1csb4/#快捷键\",\"229\":\"/algorithm/cnn/#_1-最大汇聚层与平均汇聚层\",\"230\":\"/algorithm/rnn/#有隐状态的循环神经网络\",\"231\":\"/python/async/#_2-对比多线程\",\"232\":\"/pytorch/basic/#_4-切片操作\",\"233\":\"/system/quant/intro/#一-什么是模型量化\",\"234\":\"/cuda/exercise/chapter01/\",\"235\":\"/system/pre-train/model-parallel/#megatron-lm2-efficient-large-scale-language-model-training-on-gpu-clusters-using-megatron-lm\",\"236\":\"/system/inference/kvcache/#总结\",\"237\":\"/cuda/lszlsdfw/\",\"238\":\"/article/mcz1csb4/#表格\",\"239\":\"/algorithm/cnn/#_2-总结\",\"240\":\"/cuda/kittens/ptx_inline/\",\"241\":\"/algorithm/rnn/#设计字符级rnn模型\",\"242\":\"/python/async/#_3-对比其他语言的协程\",\"243\":\"/pytorch/basic/#_5-线性代数\",\"244\":\"/system/quant/intro/#二-模型量化分类和粒度\",\"245\":\"/system/pre-train/model-parallel/#_1-mix-parallel\",\"246\":\"/system/inference/kvcache/#_1-1-训练过程显存占用分析\",\"247\":\"/algorithm/cnn/#四-lenet\",\"248\":\"/cuda/kittens/ptx_inline/#一-浅谈一些封装的ptx\",\"249\":\"/algorithm/rnn/#模型困惑度\",\"250\":\"/python/async/#三-在python中书写并行\",\"251\":\"/system/quant/intro/#_1-量化分类\",\"252\":\"/system/pre-train/model-parallel/#_2-interleaved-schedule\",\"253\":\"/system/inference/kvcache/#_1-2-推理过程显存占用分析\",\"254\":\"/cuda/kittens/ptx_inline/#move-t-load-store\",\"255\":\"/algorithm/rnn/#_2-实现\",\"256\":\"/python/async/#_1-进程并行\",\"257\":\"/system/quant/intro/#三-如何做量化\",\"258\":\"/system/pre-train/model-parallel/#_3-sequence-parallel\",\"259\":\"/system/inference/kvcache/#_2-计算量flops估计\",\"260\":\"/cuda/kittens/ptx_inline/#semaphore-mbarrier-barrier-bar\",\"261\":\"/algorithm/rnn/#预测\",\"262\":\"/system/quant/intro/#公式\",\"263\":\"/system/pre-train/model-parallel/#dualpipe\",\"264\":\"/system/inference/kvcache/#_2-1-计算量与参数量关联\",\"265\":\"/cuda/kittens/ptx_inline/#cp-async\",\"266\":\"/algorithm/rnn/#_3-梯度裁剪\",\"267\":\"/system/quant/intro/#四-实际应用\",\"268\":\"/system/inference/kvcache/#_2-2-训练时间估计\",\"269\":\"/cuda/kittens/ptx_inline/#load-async\",\"270\":\"/algorithm/rnn/#_4-训练\",\"271\":\"/system/quant/intro/#五-如何选择\",\"272\":\"/system/inference/kvcache/#_3-中间激活值分析\",\"273\":\"/cuda/kittens/ptx_inline/#store-async\",\"274\":\"/algorithm/rnn/#三-现代rnn\",\"275\":\"/system/inference/kvcache/#_3-1-对比中间激活与模型参数大小\",\"276\":\"/cuda/kittens/ptx_inline/#同步机制\",\"277\":\"/algorithm/rnn/#_1-基本结构\",\"278\":\"/system/inference/kvcache/#二-推理与kv-cache\",\"279\":\"/cuda/kittens/ptx_inline/#with-tma\",\"280\":\"/algorithm/rnn/#_2-encoder-decoder\",\"281\":\"/system/inference/kvcache/#三-kv-cache延伸技术\",\"282\":\"/cuda/kittens/ptx_inline/#non-tma\",\"283\":\"/algorithm/rnn/#_3-seq2seq\",\"284\":\"/system/inference/kvcache/#_1-batch-prompting\",\"285\":\"/algorithm/rnn/#训练\",\"286\":\"/system/inference/kvcache/#_2-ralyattention\"},\"fieldIds\":{\"title\":0,\"titles\":1,\"text\":2},\"fieldLength\":{\"0\":[2,1,4],\"1\":[1,2,31],\"2\":[1,2,12],\"3\":[1,1,1],\"4\":[1,1,2],\"5\":[2,1,7],\"6\":[1,2,59],\"7\":[2,1,1],\"8\":[1,1,1],\"9\":[1,1,1],\"10\":[1,2,32],\"11\":[1,2,2],\"12\":[1,1,1],\"13\":[1,1,59],\"14\":[1,1,59],\"15\":[3,1,30],\"16\":[2,1,1],\"17\":[2,3,54],\"18\":[1,3,8],\"19\":[1,1,59],\"20\":[2,1,3],\"21\":[1,1,32],\"22\":[1,1,32],\"23\":[2,2,23],\"24\":[1,3,80],\"25\":[1,2,20],\"26\":[1,1,32],\"27\":[1,1,1],\"28\":[2,2,54],\"29\":[2,2,54],\"30\":[4,2,3],\"31\":[1,2,1],\"32\":[1,3,19],\"33\":[2,2,54],\"34\":[2,1,1],\"35\":[1,1,5],\"36\":[1,2,80],\"37\":[1,2,80],\"38\":[6,2,28],\"39\":[2,1,1],\"40\":[1,3,52],\"41\":[1,4,8],\"42\":[1,2,80],\"43\":[2,3,11],\"44\":[2,1,1],\"45\":[4,1,2],\"46\":[1,1,3],\"47\":[2,2,10],\"48\":[3,2,44],\"49\":[1,3,39],\"50\":[1,2,21],\"51\":[2,3,110],\"52\":[2,3,13],\"53\":[1,1,1],\"54\":[2,1,1],\"55\":[2,2,72],\"56\":[2,2,1],\"57\":[1,3,92],\"58\":[2,2,11],\"59\":[2,3,156],\"60\":[2,3,13],\"61\":[2,1,97],\"62\":[3,1,2],\"63\":[2,1,80],\"64\":[1,1,1],\"65\":[1,1,1],\"66\":[1,2,18],\"67\":[2,4,28],\"68\":[1,3,144],\"69\":[1,2,6],\"70\":[2,3,104],\"71\":[2,3,90],\"72\":[4,1,19],\"73\":[1,1,1],\"74\":[1,1,1],\"75\":[2,1,42],\"76\":[1,1,3],\"77\":[1,1,5],\"78\":[4,4,55],\"79\":[1,3,91],\"80\":[1,2,3],\"81\":[1,5,132],\"82\":[2,3,68],\"83\":[2,1,1],\"84\":[1,1,1],\"85\":[2,1,1],\"86\":[2,1,96],\"87\":[2,1,79],\"88\":[2,4,208],\"89\":[1,3,8],\"90\":[1,3,16],\"91\":[1,5,106],\"92\":[2,3,14],\"93\":[2,3,21],\"94\":[2,1,1],\"95\":[2,3,60],\"96\":[3,1,86],\"97\":[4,3,127],\"98\":[1,1,1],\"99\":[1,2,1],\"100\":[1,3,195],\"101\":[2,1,1],\"102\":[2,3,14],\"103\":[2,3,218],\"104\":[2,2,32],\"105\":[2,1,1],\"106\":[2,1,23],\"107\":[1,1,1],\"108\":[2,3,69],\"109\":[2,1,1],\"110\":[6,3,53],\"111\":[1,1,1],\"112\":[2,1,78],\"113\":[1,3,168],\"114\":[1,2,27],\"115\":[2,3,137],\"116\":[3,1,1],\"117\":[2,3,154],\"118\":[1,2,48],\"119\":[3,2,69],\"120\":[2,1,1],\"121\":[1,1,1],\"122\":[2,1,66],\"123\":[2,3,102],\"124\":[3,3,57],\"125\":[2,1,11],\"126\":[2,1,41],\"127\":[1,3,48],\"128\":[1,2,75],\"129\":[1,5,18],\"130\":[2,4,127],\"131\":[2,3,48],\"132\":[2,2,4],\"133\":[2,2,14],\"134\":[1,1,1],\"135\":[2,1,56],\"136\":[1,1,5],\"137\":[2,3,89],\"138\":[3,3,93],\"139\":[2,1,30],\"140\":[3,2,133],\"141\":[1,3,71],\"142\":[1,2,15],\"143\":[1,5,45],\"144\":[2,4,106],\"145\":[1,5,33],\"146\":[2,2,4],\"147\":[2,4,1],\"148\":[3,1,1],\"149\":[1,1,1],\"150\":[2,1,84],\"151\":[1,1,150],\"152\":[2,1,144],\"153\":[3,3,95],\"154\":[3,1,98],\"155\":[1,1,1],\"156\":[1,3,42],\"157\":[1,2,12],\"158\":[1,1,30],\"159\":[2,3,108],\"160\":[2,4,3],\"161\":[1,1,2],\"162\":[2,3,6],\"163\":[2,6,46],\"164\":[2,4,4],\"165\":[1,1,1],\"166\":[1,1,100],\"167\":[1,3,63],\"168\":[2,1,14],\"169\":[1,1,147],\"170\":[1,1,10],\"171\":[1,3,7],\"172\":[1,2,6],\"173\":[1,5,103],\"174\":[1,6,66],\"175\":[2,1,18],\"176\":[1,5,57],\"177\":[2,6,14],\"178\":[1,6,22],\"179\":[2,1,6],\"180\":[1,1,34],\"181\":[2,1,65],\"182\":[3,1,11],\"183\":[5,1,5],\"184\":[1,2,1],\"185\":[1,2,38],\"186\":[2,3,56],\"187\":[1,6,57],\"188\":[1,5,60],\"189\":[2,1,1],\"190\":[1,4,14],\"191\":[1,6,40],\"192\":[1,1,1],\"193\":[2,1,304],\"194\":[2,1,4],\"195\":[3,1,2],\"196\":[2,1,1],\"197\":[1,1,113],\"198\":[3,1,1],\"199\":[1,3,57],\"200\":[1,2,8],\"201\":[3,1,1],\"202\":[1,5,140],\"203\":[3,4,52],\"204\":[2,1,1],\"205\":[4,2,71],\"206\":[3,2,1],\"207\":[2,4,8],\"208\":[2,1,6],\"209\":[1,1,1],\"210\":[5,1,1],\"211\":[2,1,10],\"212\":[3,2,26],\"213\":[2,1,143],\"214\":[1,3,28],\"215\":[1,2,12],\"216\":[2,1,15],\"217\":[2,3,50],\"218\":[1,1,1],\"219\":[2,5,20],\"220\":[2,4,41],\"221\":[1,1,1],\"222\":[8,5,76],\"223\":[1,1,16],\"224\":[2,1,7],\"225\":[2,5,76],\"226\":[1,1,1],\"227\":[1,1,1],\"228\":[1,2,17],\"229\":[2,3,112],\"230\":[1,5,83],\"231\":[2,5,41],\"232\":[2,4,18],\"233\":[2,1,1],\"234\":[1,1,2],\"235\":[13,5,19],\"236\":[1,7,23],\"237\":[1,1,1],\"238\":[1,2,12],\"239\":[2,3,10],\"240\":[2,1,2],\"241\":[1,5,10],\"242\":[2,5,6],\"243\":[2,4,16],\"244\":[2,1,1],\"245\":[3,16,27],\"246\":[2,7,48],\"247\":[2,1,164],\"248\":[2,2,32],\"249\":[1,5,65],\"250\":[2,2,5],\"251\":[2,3,39],\"252\":[3,16,111],\"253\":[3,7,27],\"254\":[6,4,124],\"255\":[2,3,164],\"256\":[2,4,52],\"257\":[2,1,19],\"258\":[3,16,6],\"259\":[2,5,118],\"260\":[4,4,141],\"261\":[1,5,65],\"262\":[1,3,56],\"263\":[1,5,130],\"264\":[3,7,39],\"265\":[2,4,93],\"266\":[2,3,80],\"267\":[2,1,51],\"268\":[2,7,49],\"269\":[2,6,179],\"270\":[2,3,133],\"271\":[2,3,68],\"272\":[2,5,139],\"273\":[2,6,217],\"274\":[2,1,1],\"275\":[3,7,39],\"276\":[1,6,3],\"277\":[2,3,66],\"278\":[3,2,165],\"279\":[3,7,89],\"280\":[3,3,31],\"281\":[3,2,1],\"282\":[2,7,99],\"283\":[2,3,139],\"284\":[3,4,8],\"285\":[1,5,147],\"286\":[2,4,3]},\"averageFieldLength\":[1.8641114982578397,2.609756097560974,45.01045296167246],\"storedFields\":{\"0\":{\"title\":\"AI-Router\",\"titles\":[]},\"1\":{\"title\":\"Sections\",\"titles\":[\"AI-Router\"]},\"2\":{\"title\":\"一些想法\",\"titles\":[\"AI-Router\"]},\"3\":{\"title\":\"友情链接\",\"titles\":[]},\"4\":{\"title\":\"常见问题\",\"titles\":[]},\"5\":{\"title\":\"Markdown 基础\",\"titles\":[]},\"6\":{\"title\":\"概述\",\"titles\":[\"Markdown 基础\"]},\"7\":{\"title\":\"markdown 扩展\",\"titles\":[]},\"8\":{\"title\":\"全屏水印\",\"titles\":[]},\"9\":{\"title\":\"内容水印\",\"titles\":[]},\"10\":{\"title\":\"用途\",\"titles\":[\"Markdown 基础\"]},\"11\":{\"title\":\"标题锚点\",\"titles\":[\"markdown 扩展\"]},\"12\":{\"title\":\"图片水印\",\"titles\":[]},\"13\":{\"title\":\"概述\",\"titles\":[\"全屏水印\"]},\"14\":{\"title\":\"概述\",\"titles\":[\"内容水印\"]},\"15\":{\"title\":\"Some TODO Notes\",\"titles\":[]},\"16\":{\"title\":\"Q&A\",\"titles\":[]},\"17\":{\"title\":\"行内 HTML\",\"titles\":[\"Markdown 基础\",\"用途\"]},\"18\":{\"title\":\"自定义锚点\",\"titles\":[\"markdown 扩展\",\"标题锚点\"]},\"19\":{\"title\":\"概述\",\"titles\":[\"图片水印\"]},\"20\":{\"title\":\"Linear Regression\",\"titles\":[]},\"21\":{\"title\":\"用途\",\"titles\":[\"全屏水印\"]},\"22\":{\"title\":\"用途\",\"titles\":[\"内容水印\"]},\"23\":{\"title\":\"说出ResNet的模型结构?\",\"titles\":[\"Q&A\"]},\"24\":{\"title\":\"特殊字元自动转换\",\"titles\":[\"Markdown 基础\",\"用途\"]},\"25\":{\"title\":\"链接\",\"titles\":[\"markdown 扩展\"]},\"26\":{\"title\":\"用途\",\"titles\":[\"图片水印\"]},\"27\":{\"title\":\"注意力机制\",\"titles\":[]},\"28\":{\"title\":\"行内 HTML\",\"titles\":[\"全屏水印\",\"用途\"]},\"29\":{\"title\":\"行内 HTML\",\"titles\":[\"内容水印\",\"用途\"]},\"30\":{\"title\":\"Transformer encoder block的模型结构？\",\"titles\":[\"Q&A\"]},\"31\":{\"title\":\"块元素\",\"titles\":[\"Markdown 基础\"]},\"32\":{\"title\":\"内部链接\",\"titles\":[\"markdown 扩展\",\"链接\"]},\"33\":{\"title\":\"行内 HTML\",\"titles\":[\"图片水印\",\"用途\"]},\"34\":{\"title\":\"一. 注意力机制简介\",\"titles\":[\"注意力机制\"]},\"35\":{\"title\":\"卷积神经网络CNN\",\"titles\":[]},\"36\":{\"title\":\"特殊字元自动转换\",\"titles\":[\"全屏水印\",\"用途\"]},\"37\":{\"title\":\"特殊字元自动转换\",\"titles\":[\"内容水印\",\"用途\"]},\"38\":{\"title\":\"写出batchnorm和softmax的公式，bathnorm由哪些小算子构成，batchnorm和softmax在什么情况下计算结果可能会出现精度问题？为什么？如何解决？\",\"titles\":[\"Q&A\"]},\"39\":{\"title\":\"Linear Regression\",\"titles\":[]},\"40\":{\"title\":\"段落和换行\",\"titles\":[\"Markdown 基础\",\"块元素\"]},\"41\":{\"title\":\"外部链接\",\"titles\":[\"markdown 扩展\",\"链接\",\"内部链接\"]},\"42\":{\"title\":\"特殊字元自动转换\",\"titles\":[\"图片水印\",\"用途\"]},\"43\":{\"title\":\"1. 引入\",\"titles\":[\"注意力机制\",\"一. 注意力机制简介\"]},\"44\":{\"title\":\"一. 从全连接层过渡到卷积层\",\"titles\":[\"卷积神经网络CNN\"]},\"45\":{\"title\":\"Multi-Head Latent Attention\",\"titles\":[]},\"46\":{\"title\":\"现代卷积神经网络\",\"titles\":[]},\"47\":{\"title\":\"加速AI模型的推理速度，该从哪些角度去考虑\",\"titles\":[\"Q&A\"]},\"48\":{\"title\":\"一. 什么是线性回归？\",\"titles\":[\"Linear Regression\"]},\"49\":{\"title\":\"标题\",\"titles\":[\"Markdown 基础\",\"块元素\"]},\"50\":{\"title\":\"Github风格的表格\",\"titles\":[\"markdown 扩展\"]},\"51\":{\"title\":\"2. 非参数注意力汇聚\",\"titles\":[\"注意力机制\",\"一. 注意力机制简介\"]},\"52\":{\"title\":\"1. 介绍\",\"titles\":[\"卷积神经网络CNN\",\"一. 从全连接层过渡到卷积层\"]},\"53\":{\"title\":\"MoE架构\",\"titles\":[]},\"54\":{\"title\":\"一. AlexNet\",\"titles\":[\"现代卷积神经网络\"]},\"55\":{\"title\":\"模型大小的四大评估指标是什么，举例说明对他们的理解\",\"titles\":[\"Q&A\"]},\"56\":{\"title\":\"二. 梯度下降\",\"titles\":[\"Linear Regression\"]},\"57\":{\"title\":\"Blockquotes\",\"titles\":[\"Markdown 基础\",\"块元素\"]},\"58\":{\"title\":\"Emoji 🎉\",\"titles\":[\"markdown 扩展\"]},\"59\":{\"title\":\"3. 带参数注意力汇聚\",\"titles\":[\"注意力机制\",\"一. 注意力机制简介\"]},\"60\":{\"title\":\"2. 特性\",\"titles\":[\"卷积神经网络CNN\",\"一. 从全连接层过渡到卷积层\"]},\"61\":{\"title\":\"Basic MoE\",\"titles\":[\"MoE架构\"]},\"62\":{\"title\":\"Multi-Token Prediction\",\"titles\":[]},\"63\":{\"title\":\"二. VGG\",\"titles\":[\"现代卷积神经网络\"]},\"64\":{\"title\":\"多层感知机MLP\",\"titles\":[]},\"65\":{\"title\":\"PPO\",\"titles\":[]},\"66\":{\"title\":\"说出加速ResNet50推理速度的一些手段\",\"titles\":[\"Q&A\"]},\"67\":{\"title\":\"1. 简介\",\"titles\":[\"Linear Regression\",\"二. 梯度下降\"]},\"68\":{\"title\":\"列表\",\"titles\":[\"Markdown 基础\",\"块元素\"]},\"69\":{\"title\":\"目录表\",\"titles\":[\"markdown 扩展\"]},\"70\":{\"title\":\"4. 注意力评分\",\"titles\":[\"注意力机制\",\"一. 注意力机制简介\"]},\"71\":{\"title\":\"3. 推导\",\"titles\":[\"卷积神经网络CNN\",\"一. 从全连接层过渡到卷积层\"]},\"72\":{\"title\":\"Shared Experts and Router\",\"titles\":[\"MoE架构\"]},\"73\":{\"title\":\"循环神经网络RNN\",\"titles\":[]},\"74\":{\"title\":\"Softmax\",\"titles\":[]},\"75\":{\"title\":\"三. NiN\",\"titles\":[\"现代卷积神经网络\"]},\"76\":{\"title\":\"Transformer架构\",\"titles\":[]},\"77\":{\"title\":\"PPO\",\"titles\":[\"PPO\"]},\"78\":{\"title\":\"2. 如何理解“沿梯度”\",\"titles\":[\"Linear Regression\",\"二. 梯度下降\"]},\"79\":{\"title\":\"代码块\",\"titles\":[\"Markdown 基础\",\"块元素\"]},\"80\":{\"title\":\"自定义容器\",\"titles\":[\"markdown 扩展\"]},\"81\":{\"title\":\"加性注意力\",\"titles\":[\"注意力机制\",\"一. 注意力机制简介\",\"4. 注意力评分\"]},\"82\":{\"title\":\"4. 通道\",\"titles\":[\"卷积神经网络CNN\",\"一. 从全连接层过渡到卷积层\"]},\"83\":{\"title\":\"一. RNN引入\",\"titles\":[\"循环神经网络RNN\"]},\"84\":{\"title\":\"cpp\",\"titles\":[]},\"85\":{\"title\":\"一. 什么是Softmax\",\"titles\":[\"Softmax\"]},\"86\":{\"title\":\"四. GoogLeNet\",\"titles\":[\"现代卷积神经网络\"]},\"87\":{\"title\":\"一. 模型架构\",\"titles\":[\"Transformer架构\"]},\"88\":{\"title\":\"3. 具体解法\",\"titles\":[\"Linear Regression\",\"二. 梯度下降\"]},\"89\":{\"title\":\"分隔线\",\"titles\":[\"Markdown 基础\",\"块元素\"]},\"90\":{\"title\":\"默认标题\",\"titles\":[\"markdown 扩展\",\"自定义容器\"]},\"91\":{\"title\":\"缩放点积注意力\",\"titles\":[\"注意力机制\",\"一. 注意力机制简介\",\"4. 注意力评分\"]},\"92\":{\"title\":\"5. 特征映射和感受野\",\"titles\":[\"卷积神经网络CNN\",\"一. 从全连接层过渡到卷积层\"]},\"93\":{\"title\":\"1. 简介\",\"titles\":[\"循环神经网络RNN\",\"一. RNN引入\"]},\"94\":{\"title\":\"Const 语义\",\"titles\":[]},\"95\":{\"title\":\"1. 引入\",\"titles\":[\"Softmax\",\"一. 什么是Softmax\"]},\"96\":{\"title\":\"五. Batch Normalization\",\"titles\":[\"现代卷积神经网络\"]},\"97\":{\"title\":\"1. Multi-Head Attention\",\"titles\":[\"Transformer架构\",\"一. 模型架构\"]},\"98\":{\"title\":\"现代cpp的一些特性\",\"titles\":[]},\"99\":{\"title\":\"行内元素\",\"titles\":[\"Markdown 基础\"]},\"100\":{\"title\":\"自定义标题\",\"titles\":[\"markdown 扩展\",\"自定义容器\"]},\"101\":{\"title\":\"二. 注意力模型\",\"titles\":[\"注意力机制\"]},\"102\":{\"title\":\"6. 总结\",\"titles\":[\"卷积神经网络CNN\",\"一. 从全连接层过渡到卷积层\"]},\"103\":{\"title\":\"2. 马尔科夫模型\",\"titles\":[\"循环神经网络RNN\",\"一. RNN引入\"]},\"104\":{\"title\":\"一. const修饰变量\",\"titles\":[\"Const 语义\"]},\"105\":{\"title\":\"move 语义\",\"titles\":[]},\"106\":{\"title\":\"cpp 手搓项目合集\",\"titles\":[]},\"107\":{\"title\":\"类型推导\",\"titles\":[]},\"108\":{\"title\":\"2. 介绍\",\"titles\":[\"Softmax\",\"一. 什么是Softmax\"]},\"109\":{\"title\":\"六. ResNet\",\"titles\":[\"现代卷积神经网络\"]},\"110\":{\"title\":\"2. Position-wise Feed-Forward Networks\",\"titles\":[\"Transformer架构\",\"一. 模型架构\"]},\"111\":{\"title\":\"python\",\"titles\":[]},\"112\":{\"title\":\"一. {} 初始化\",\"titles\":[\"现代cpp的一些特性\"]},\"113\":{\"title\":\"链接\",\"titles\":[\"Markdown 基础\",\"行内元素\"]},\"114\":{\"title\":\"导入代码块\",\"titles\":[\"markdown 扩展\"]},\"115\":{\"title\":\"1. Bahdanau注意力模型\",\"titles\":[\"注意力机制\",\"二. 注意力模型\"]},\"116\":{\"title\":\"二. CNN 实现\",\"titles\":[\"卷积神经网络CNN\"]},\"117\":{\"title\":\"3. 文本预处理\",\"titles\":[\"循环神经网络RNN\",\"一. RNN引入\"]},\"118\":{\"title\":\"const修饰函数\",\"titles\":[\"Const 语义\"]},\"119\":{\"title\":\"一. Value Category\",\"titles\":[\"move 语义\"]},\"120\":{\"title\":\"Python中多线程和async/await异步\",\"titles\":[]},\"121\":{\"title\":\"pytorch\",\"titles\":[]},\"122\":{\"title\":\"一. 模板类型推导\",\"titles\":[\"类型推导\"]},\"123\":{\"title\":\"3. 梯度计算\",\"titles\":[\"Softmax\",\"一. 什么是Softmax\"]},\"124\":{\"title\":\"3. Positional Encoding\",\"titles\":[\"Transformer架构\",\"一. 模型架构\"]},\"125\":{\"title\":\"二. nullptr\",\"titles\":[\"现代cpp的一些特性\"]},\"126\":{\"title\":\"PyTorch AutoGrad\",\"titles\":[]},\"127\":{\"title\":\"强调\",\"titles\":[\"Markdown 基础\",\"行内元素\"]},\"128\":{\"title\":\"数学方程\",\"titles\":[\"markdown 扩展\"]},\"129\":{\"title\":\"Encoder步骤\",\"titles\":[\"注意力机制\",\"二. 注意力模型\",\"1. Bahdanau注意力模型\"]},\"130\":{\"title\":\"1. 互相关运算\",\"titles\":[\"卷积神经网络CNN\",\"二. CNN 实现\"]},\"131\":{\"title\":\"4. 语言模型\",\"titles\":[\"循环神经网络RNN\",\"一. RNN引入\"]},\"132\":{\"title\":\"二. 为什么需要move\",\"titles\":[\"move 语义\"]},\"133\":{\"title\":\"一. 多线程\",\"titles\":[\"Python中多线程和async/await异步\"]},\"134\":{\"title\":\"PyTorch常用函数以及方法\",\"titles\":[]},\"135\":{\"title\":\"二. auto类型推导\",\"titles\":[\"类型推导\"]},\"136\":{\"title\":\"PyTorch中的梯度计算\",\"titles\":[]},\"137\":{\"title\":\"4. 损失函数\",\"titles\":[\"Softmax\",\"一. 什么是Softmax\"]},\"138\":{\"title\":\"4. Encoder Layer\",\"titles\":[\"Transformer架构\",\"一. 模型架构\"]},\"139\":{\"title\":\"三. using\",\"titles\":[\"现代cpp的一些特性\"]},\"140\":{\"title\":\"torch.autograd.Function\",\"titles\":[\"PyTorch AutoGrad\"]},\"141\":{\"title\":\"代码\",\"titles\":[\"Markdown 基础\",\"行内元素\"]},\"142\":{\"title\":\"标记\",\"titles\":[\"markdown 扩展\"]},\"143\":{\"title\":\"Decoder与Attention机制步骤\",\"titles\":[\"注意力机制\",\"二. 注意力模型\",\"1. Bahdanau注意力模型\"]},\"144\":{\"title\":\"2. 填充和步幅\",\"titles\":[\"卷积神经网络CNN\",\"二. CNN 实现\"]},\"145\":{\"title\":\"齐普夫定律\",\"titles\":[\"循环神经网络RNN\",\"一. RNN引入\",\"4. 语言模型\"]},\"146\":{\"title\":\"三. 其他\",\"titles\":[\"move 语义\"]},\"147\":{\"title\":\"为什么Python中多线程的效率这么差？\",\"titles\":[\"Python中多线程和async/await异步\",\"一. 多线程\"]},\"148\":{\"title\":\"一. torch.tensor\",\"titles\":[\"PyTorch常用函数以及方法\"]},\"149\":{\"title\":\"system\",\"titles\":[]},\"150\":{\"title\":\"三. decltype\",\"titles\":[\"类型推导\"]},\"151\":{\"title\":\"一个简单的梯度计算例子\",\"titles\":[\"PyTorch中的梯度计算\"]},\"152\":{\"title\":\"二. 从零实现Softmax回归\",\"titles\":[\"Softmax\"]},\"153\":{\"title\":\"5. Decoder Layer\",\"titles\":[\"Transformer架构\",\"一. 模型架构\"]},\"154\":{\"title\":\"四. scoped enum\",\"titles\":[\"现代cpp的一些特性\"]},\"155\":{\"title\":\"papers\",\"titles\":[]},\"156\":{\"title\":\"图片\",\"titles\":[\"Markdown 基础\",\"行内元素\"]},\"157\":{\"title\":\"上下角标\",\"titles\":[\"markdown 扩展\"]},\"158\":{\"title\":\"paper阅读记录\",\"titles\":[]},\"159\":{\"title\":\"2. 多头注意力\",\"titles\":[\"注意力机制\",\"二. 注意力模型\"]},\"160\":{\"title\":\"3. 多输入和多输出通道\",\"titles\":[\"卷积神经网络CNN\",\"二. CNN 实现\"]},\"161\":{\"title\":\"Transformer论文\",\"titles\":[]},\"162\":{\"title\":\"5. 数据集随机采样\",\"titles\":[\"循环神经网络RNN\",\"一. RNN引入\"]},\"163\":{\"title\":\"1. 对比其他语言\",\"titles\":[\"Python中多线程和async/await异步\",\"一. 多线程\",\"为什么Python中多线程的效率这么差？\"]},\"164\":{\"title\":\"1. 基础操作\",\"titles\":[\"PyTorch常用函数以及方法\",\"一. torch.tensor\"]},\"165\":{\"title\":\"cuda\",\"titles\":[]},\"166\":{\"title\":\"自动微分对向量的兼容\",\"titles\":[\"PyTorch中的梯度计算\"]},\"167\":{\"title\":\"transformer\",\"titles\":[\"Transformer架构\",\"一. 模型架构\"]},\"168\":{\"title\":\"五. deleted\",\"titles\":[\"现代cpp的一些特性\"]},\"169\":{\"title\":\"Gemm\",\"titles\":[]},\"170\":{\"title\":\"Gemm\",\"titles\":[]},\"171\":{\"title\":\"其他文本样式\",\"titles\":[\"Markdown 基础\",\"行内元素\"]},\"172\":{\"title\":\"自定义对齐\",\"titles\":[\"markdown 扩展\"]},\"173\":{\"title\":\"实现\",\"titles\":[\"注意力机制\",\"二. 注意力模型\",\"2. 多头注意力\"]},\"174\":{\"title\":\"多输入通道\",\"titles\":[\"卷积神经网络CNN\",\"二. CNN 实现\",\"3. 多输入和多输出通道\"]},\"175\":{\"title\":\"2. 常见问题\",\"titles\":[\"Transformer论文\"]},\"176\":{\"title\":\"随机采样\",\"titles\":[\"循环神经网络RNN\",\"一. RNN引入\",\"5. 数据集随机采样\"]},\"177\":{\"title\":\"2. 对比串行\",\"titles\":[\"Python中多线程和async/await异步\",\"一. 多线程\",\"为什么Python中多线程的效率这么差？\"]},\"178\":{\"title\":\"创建操作\",\"titles\":[\"PyTorch常用函数以及方法\",\"一. torch.tensor\",\"1. 基础操作\"]},\"179\":{\"title\":\"hardware paper\",\"titles\":[]},\"180\":{\"title\":\"反向传播起点\",\"titles\":[\"PyTorch中的梯度计算\"]},\"181\":{\"title\":\"二. 模型训练\",\"titles\":[\"Transformer架构\"]},\"182\":{\"title\":\"六. override/noexcept\",\"titles\":[\"现代cpp的一些特性\"]},\"183\":{\"title\":\"Cutlass: Fast GEMM with WGMMA\",\"titles\":[\"Gemm\"]},\"184\":{\"title\":\"其它\",\"titles\":[\"Markdown 基础\"]},\"185\":{\"title\":\"属性支持\",\"titles\":[\"markdown 扩展\"]},\"186\":{\"title\":\"3. 自注意力和位置编码\",\"titles\":[\"注意力机制\",\"二. 注意力模型\"]},\"187\":{\"title\":\"多输出通道\",\"titles\":[\"卷积神经网络CNN\",\"二. CNN 实现\",\"3. 多输入和多输出通道\"]},\"188\":{\"title\":\"顺序分区\",\"titles\":[\"循环神经网络RNN\",\"一. RNN引入\",\"5. 数据集随机采样\"]},\"189\":{\"title\":\"Memory Model\",\"titles\":[]},\"190\":{\"title\":\"如何实现真正意义上的并行\",\"titles\":[\"Python中多线程和async/await异步\",\"一. 多线程\"]},\"191\":{\"title\":\"计算操作\",\"titles\":[\"PyTorch常用函数以及方法\",\"一. torch.tensor\",\"1. 基础操作\"]},\"192\":{\"title\":\"README\",\"titles\":[]},\"193\":{\"title\":\"三. 完整代码\",\"titles\":[\"Transformer架构\"]},\"194\":{\"title\":\"七. constexpr\",\"titles\":[\"现代cpp的一些特性\"]},\"195\":{\"title\":\"Flash Attention 优化\",\"titles\":[]},\"196\":{\"title\":\"KV Cache\",\"titles\":[]},\"197\":{\"title\":\"GEMM\",\"titles\":[\"Gemm\"]},\"198\":{\"title\":\"MHA/GQA/MQA优化技术\",\"titles\":[]},\"199\":{\"title\":\"自动链接\",\"titles\":[\"Markdown 基础\",\"其它\"]},\"200\":{\"title\":\"任务列表\",\"titles\":[\"markdown 扩展\"]},\"201\":{\"title\":\"Page Attention 显存优化\",\"titles\":[]},\"202\":{\"title\":\"对比\",\"titles\":[\"注意力机制\",\"二. 注意力模型\",\"3. 自注意力和位置编码\"]},\"203\":{\"title\":\"4. 1 * 1卷积层\",\"titles\":[\"卷积神经网络CNN\",\"二. CNN 实现\"]},\"204\":{\"title\":\"二. RNN介绍\",\"titles\":[\"循环神经网络RNN\"]},\"205\":{\"title\":\"一. Memory Consistency Model\",\"titles\":[\"Memory Model\"]},\"206\":{\"title\":\"二. async/await异步编程\",\"titles\":[\"Python中多线程和async/await异步\"]},\"207\":{\"title\":\"2. 梯度操作\",\"titles\":[\"PyTorch常用函数以及方法\",\"一. torch.tensor\"]},\"208\":{\"title\":\"some papers\",\"titles\":[]},\"209\":{\"title\":\"README\",\"titles\":[]},\"210\":{\"title\":\"Large Model Distributed Parallelism Strategies\",\"titles\":[]},\"211\":{\"title\":\"八. const成员函数的线程安全\",\"titles\":[\"现代cpp的一些特性\"]},\"212\":{\"title\":\"一. decoder-only模型量级分析\",\"titles\":[\"KV Cache\"]},\"213\":{\"title\":\"Pipline Communication\",\"titles\":[]},\"214\":{\"title\":\"转义字符\",\"titles\":[\"Markdown 基础\",\"其它\"]},\"215\":{\"title\":\"脚注\",\"titles\":[\"markdown 扩展\"]},\"216\":{\"title\":\"三. 汇聚层pooling\",\"titles\":[\"卷积神经网络CNN\"]},\"217\":{\"title\":\"1. 原理\",\"titles\":[\"循环神经网络RNN\",\"二. RNN介绍\"]},\"218\":{\"title\":\"README\",\"titles\":[]},\"219\":{\"title\":\"1. 介绍\",\"titles\":[\"Python中多线程和async/await异步\",\"二. async/await异步编程\"]},\"220\":{\"title\":\"3. 转换操作\",\"titles\":[\"PyTorch常用函数以及方法\",\"一. torch.tensor\"]},\"221\":{\"title\":\"大模型量化简介\",\"titles\":[]},\"222\":{\"title\":\"Megatron-LM: Training Multi-Billion Parameter Language Models\",\"titles\":[\"Large Model Distributed Parallelism Strategies\"]},\"223\":{\"title\":\"PyTorch模型量化\",\"titles\":[]},\"224\":{\"title\":\"九. 特殊成员函数\",\"titles\":[\"现代cpp的一些特性\"]},\"225\":{\"title\":\"1. 模型参数量\",\"titles\":[\"KV Cache\",\"一. decoder-only模型量级分析\"]},\"226\":{\"title\":\"README\",\"titles\":[]},\"227\":{\"title\":\"RL介绍\",\"titles\":[]},\"228\":{\"title\":\"快捷键\",\"titles\":[\"Markdown 基础\"]},\"229\":{\"title\":\"1. 最大汇聚层与平均汇聚层\",\"titles\":[\"卷积神经网络CNN\",\"三. 汇聚层pooling\"]},\"230\":{\"title\":\"有隐状态的循环神经网络\",\"titles\":[\"循环神经网络RNN\",\"二. RNN介绍\",\"1. 原理\"]},\"231\":{\"title\":\"2. 对比多线程\",\"titles\":[\"Python中多线程和async/await异步\",\"二. async/await异步编程\"]},\"232\":{\"title\":\"4. 切片操作\",\"titles\":[\"PyTorch常用函数以及方法\",\"一. torch.tensor\"]},\"233\":{\"title\":\"一. 什么是模型量化\",\"titles\":[\"大模型量化简介\"]},\"234\":{\"title\":\"CUDA实战01\",\"titles\":[]},\"235\":{\"title\":\"Megatron-LM2: Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM\",\"titles\":[\"Large Model Distributed Parallelism Strategies\"]},\"236\":{\"title\":\"总结\",\"titles\":[\"KV Cache\",\"一. decoder-only模型量级分析\",\"1. 模型参数量\"]},\"237\":{\"title\":\"README\",\"titles\":[]},\"238\":{\"title\":\"表格\",\"titles\":[\"Markdown 基础\"]},\"239\":{\"title\":\"2. 总结\",\"titles\":[\"卷积神经网络CNN\",\"三. 汇聚层pooling\"]},\"240\":{\"title\":\"Kittens PTX\",\"titles\":[]},\"241\":{\"title\":\"设计字符级RNN模型\",\"titles\":[\"循环神经网络RNN\",\"二. RNN介绍\",\"1. 原理\"]},\"242\":{\"title\":\"3. 对比其他语言的协程\",\"titles\":[\"Python中多线程和async/await异步\",\"二. async/await异步编程\"]},\"243\":{\"title\":\"5. 线性代数\",\"titles\":[\"PyTorch常用函数以及方法\",\"一. torch.tensor\"]},\"244\":{\"title\":\"二. 模型量化分类和粒度\",\"titles\":[\"大模型量化简介\"]},\"245\":{\"title\":\"1. Mix Parallel\",\"titles\":[\"Large Model Distributed Parallelism Strategies\",\"Megatron-LM2: Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM\"]},\"246\":{\"title\":\"1.1 训练过程显存占用分析\",\"titles\":[\"KV Cache\",\"一. decoder-only模型量级分析\",\"1. 模型参数量\"]},\"247\":{\"title\":\"四. LeNet\",\"titles\":[\"卷积神经网络CNN\"]},\"248\":{\"title\":\"一. 浅谈一些封装的PTX\",\"titles\":[\"Kittens PTX\"]},\"249\":{\"title\":\"模型困惑度\",\"titles\":[\"循环神经网络RNN\",\"二. RNN介绍\",\"1. 原理\"]},\"250\":{\"title\":\"三. 在Python中书写并行\",\"titles\":[\"Python中多线程和async/await异步\"]},\"251\":{\"title\":\"1. 量化分类\",\"titles\":[\"大模型量化简介\",\"二. 模型量化分类和粒度\"]},\"252\":{\"title\":\"2. Interleaved Schedule\",\"titles\":[\"Large Model Distributed Parallelism Strategies\",\"Megatron-LM2: Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM\"]},\"253\":{\"title\":\"1.2 推理过程显存占用分析\",\"titles\":[\"KV Cache\",\"一. decoder-only模型量级分析\",\"1. 模型参数量\"]},\"254\":{\"title\":\"move&lt;T&gt;: load/store\",\"titles\":[\"Kittens PTX\",\"一. 浅谈一些封装的PTX\"]},\"255\":{\"title\":\"2. 实现\",\"titles\":[\"循环神经网络RNN\",\"二. RNN介绍\"]},\"256\":{\"title\":\"1. 进程并行\",\"titles\":[\"Python中多线程和async/await异步\",\"三. 在Python中书写并行\"]},\"257\":{\"title\":\"三. 如何做量化\",\"titles\":[\"大模型量化简介\"]},\"258\":{\"title\":\"3. Sequence Parallel\",\"titles\":[\"Large Model Distributed Parallelism Strategies\",\"Megatron-LM2: Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM\"]},\"259\":{\"title\":\"2. 计算量FlOPs估计\",\"titles\":[\"KV Cache\",\"一. decoder-only模型量级分析\"]},\"260\":{\"title\":\"semaphore: mbarrier/barrier/bar\",\"titles\":[\"Kittens PTX\",\"一. 浅谈一些封装的PTX\"]},\"261\":{\"title\":\"预测\",\"titles\":[\"循环神经网络RNN\",\"二. RNN介绍\",\"2. 实现\"]},\"262\":{\"title\":\"公式\",\"titles\":[\"大模型量化简介\",\"三. 如何做量化\"]},\"263\":{\"title\":\"Dualpipe\",\"titles\":[\"Large Model Distributed Parallelism Strategies\"]},\"264\":{\"title\":\"2.1 计算量与参数量关联\",\"titles\":[\"KV Cache\",\"一. decoder-only模型量级分析\",\"2. 计算量FlOPs估计\"]},\"265\":{\"title\":\"cp.async\",\"titles\":[\"Kittens PTX\",\"一. 浅谈一些封装的PTX\"]},\"266\":{\"title\":\"3. 梯度裁剪\",\"titles\":[\"循环神经网络RNN\",\"二. RNN介绍\"]},\"267\":{\"title\":\"四. 实际应用\",\"titles\":[\"大模型量化简介\"]},\"268\":{\"title\":\"2.2 训练时间估计\",\"titles\":[\"KV Cache\",\"一. decoder-only模型量级分析\",\"2. 计算量FlOPs估计\"]},\"269\":{\"title\":\"load_async\",\"titles\":[\"Kittens PTX\",\"一. 浅谈一些封装的PTX\",\"cp.async\"]},\"270\":{\"title\":\"4. 训练\",\"titles\":[\"循环神经网络RNN\",\"二. RNN介绍\"]},\"271\":{\"title\":\"五. 如何选择\",\"titles\":[\"大模型量化简介\",\"四. 实际应用\"]},\"272\":{\"title\":\"3. 中间激活值分析\",\"titles\":[\"KV Cache\",\"一. decoder-only模型量级分析\"]},\"273\":{\"title\":\"store_async\",\"titles\":[\"Kittens PTX\",\"一. 浅谈一些封装的PTX\",\"cp.async\"]},\"274\":{\"title\":\"三. 现代RNN\",\"titles\":[\"循环神经网络RNN\"]},\"275\":{\"title\":\"3.1 对比中间激活与模型参数大小\",\"titles\":[\"KV Cache\",\"一. decoder-only模型量级分析\",\"3. 中间激活值分析\"]},\"276\":{\"title\":\"同步机制\",\"titles\":[\"Kittens PTX\",\"一. 浅谈一些封装的PTX\",\"cp.async\"]},\"277\":{\"title\":\"1. 基本结构\",\"titles\":[\"循环神经网络RNN\",\"三. 现代RNN\"]},\"278\":{\"title\":\"二. 推理与KV Cache\",\"titles\":[\"KV Cache\"]},\"279\":{\"title\":\"With-TMA：\",\"titles\":[\"Kittens PTX\",\"一. 浅谈一些封装的PTX\",\"cp.async\",\"同步机制\"]},\"280\":{\"title\":\"2. encoder-decoder\",\"titles\":[\"循环神经网络RNN\",\"三. 现代RNN\"]},\"281\":{\"title\":\"三. KV Cache延伸技术\",\"titles\":[\"KV Cache\"]},\"282\":{\"title\":\"Non-TMA\",\"titles\":[\"Kittens PTX\",\"一. 浅谈一些封装的PTX\",\"cp.async\",\"同步机制\"]},\"283\":{\"title\":\"3. seq2seq\",\"titles\":[\"循环神经网络RNN\",\"三. 现代RNN\"]},\"284\":{\"title\":\"1. Batch Prompting\",\"titles\":[\"KV Cache\",\"三. KV Cache延伸技术\"]},\"285\":{\"title\":\"训练\",\"titles\":[\"循环神经网络RNN\",\"三. 现代RNN\",\"3. seq2seq\"]},\"286\":{\"title\":\"2. RalyAttention\",\"titles\":[\"KV Cache\",\"三. KV Cache延伸技术\"]}},\"dirtCount\":0,\"index\":[[\"知乎\",{\"2\":{\"286\":3}}],[\"广播context\",{\"2\":{\"283\":1}}],[\"嵌入层\",{\"2\":{\"283\":1}}],[\"新的state记为state\",{\"2\":{\"283\":1}}],[\"借助初始的隐状态\",{\"2\":{\"283\":1}}],[\"思路其实就是对于encoder\",{\"2\":{\"283\":1}}],[\"思路其实就是在函数上放一个\",{\"2\":{\"67\":1}}],[\"故忽略\",{\"2\":{\"282\":1}}],[\"仔细阅读上文中with\",{\"2\":{\"279\":1}}],[\"仔细思考一下\",{\"2\":{\"130\":1}}],[\"←concat\",{\"2\":{\"278\":2}}],[\"∣\",{\"2\":{\"278\":2}}],[\"流程有很多可以复用的中间状态\",{\"2\":{\"278\":1}}],[\"否则应该是1\",{\"2\":{\"277\":1}}],[\"否则为零\",{\"2\":{\"95\":1}}],[\"问题时\",{\"2\":{\"275\":1}}],[\"综上\",{\"2\":{\"272\":1}}],[\"综上所述\",{\"2\":{\"61\":1}}],[\"激活函数保存其输入\",{\"2\":{\"272\":1}}],[\"激活重计算的系数\",{\"2\":{\"268\":1}}],[\"唯一例外的是\",{\"2\":{\"272\":1}}],[\"唯一的限制是\",{\"2\":{\"127\":1}}],[\"σ2\",{\"2\":{\"272\":1}}],[\"μ\",{\"2\":{\"272\":1}}],[\"忽略掉一些小的buffers\",{\"2\":{\"272\":1}}],[\"含有relu激活层的模型\",{\"2\":{\"271\":1}}],[\"理论上可以从\",{\"2\":{\"275\":1}}],[\"理论上\",{\"2\":{\"271\":1}}],[\"硬件环境配置的情况下\",{\"2\":{\"268\":1}}],[\"策略就是当计算完成之后\",{\"2\":{\"267\":1}}],[\"肯定不会一直保持在int8的值域\",{\"2\":{\"267\":1}}],[\"裁剪梯度\",{\"2\":{\"266\":1}}],[\"∥g∥θ​\",{\"2\":{\"266\":1}}],[\"→\",{\"2\":{\"265\":2}}],[\"貌似只能从global\",{\"2\":{\"265\":1}}],[\"启动一个异步数据拷贝\",{\"2\":{\"265\":1}}],[\"启动和管理进程会带来更大的开销以及更高昂的内存消耗\",{\"2\":{\"190\":1}}],[\"足够大\",{\"2\":{\"264\":1}}],[\"获得一个输出output\",{\"2\":{\"283\":1}}],[\"获得数据\",{\"2\":{\"263\":1}}],[\"获取\",{\"2\":{\"205\":1}}],[\"稳定阶段的dualpipev\",{\"2\":{\"263\":1}}],[\"灵活地进行调度\",{\"2\":{\"263\":1}}],[\"抹去了这一次通信\",{\"2\":{\"263\":1}}],[\"开启stage2的forward需要再度传给first\",{\"2\":{\"263\":1}}],[\"开始向前\",{\"2\":{\"103\":1}}],[\"观察1f1b\",{\"2\":{\"263\":1}}],[\"观察损失函数其实就是一个二元函数\",{\"2\":{\"48\":1}}],[\"果然tp已经是时代的眼泪了\",{\"2\":{\"263\":1}}],[\"题外话\",{\"2\":{\"263\":1}}],[\"复杂度为\",{\"2\":{\"259\":3}}],[\"复制num\",{\"2\":{\"173\":1}}],[\"复制到x所在显存上\",{\"2\":{\"96\":1}}],[\"×\",{\"2\":{\"259\":8}}],[\"×n×c×h×w×sizeof\",{\"2\":{\"55\":2}}],[\"次乘法运算和加法运算\",{\"2\":{\"259\":1}}],[\"衡量了计算量的大小\",{\"2\":{\"259\":1}}],[\"粒度更细致\",{\"2\":{\"257\":1}}],[\"粒度更大一些\",{\"2\":{\"257\":1}}],[\"张量最后一个维度为词表大小\",{\"2\":{\"255\":1}}],[\"张量操作\",{\"2\":{\"140\":1}}],[\"附加梯度\",{\"2\":{\"255\":1}}],[\"里面大多封装了关于ld\",{\"2\":{\"254\":1}}],[\"里面放上图片的网址\",{\"2\":{\"156\":1}}],[\"里面放上图片的替代文字\",{\"2\":{\"156\":1}}],[\"少了梯度\",{\"2\":{\"253\":1}}],[\"虽然tp分割的是hidden\",{\"2\":{\"258\":1}}],[\"虽然这里我感觉\",{\"2\":{\"252\":1}}],[\"虽然python创建的也是原生线程\",{\"2\":{\"163\":1}}],[\"量\",{\"2\":{\"252\":1}}],[\"量化可以分为均匀量化和非均匀量化\",{\"2\":{\"251\":1}}],[\"量化分类\",{\"0\":{\"251\":1}}],[\"浅色为chunk2\",{\"2\":{\"252\":1}}],[\"浅谈一些封装的ptx\",{\"0\":{\"248\":1},\"1\":{\"254\":1,\"260\":1,\"265\":1,\"269\":1,\"273\":1,\"276\":1,\"279\":1,\"282\":1}}],[\"深色为chunk1\",{\"2\":{\"252\":1}}],[\"深度学习框架\",{\"2\":{\"1\":1}}],[\"成为多个chunk\",{\"2\":{\"252\":1}}],[\"成员函数\",{\"2\":{\"118\":1}}],[\"立马执行bwd\",{\"2\":{\"252\":1}}],[\"立即数\",{\"2\":{\"248\":1}}],[\"伴随着过多的outlier值的突出\",{\"2\":{\"251\":1}}],[\"适用的场景就是数据分布非常不均匀\",{\"2\":{\"251\":1}}],[\"适合io密集型任务\",{\"2\":{\"219\":1}}],[\"困惑度\",{\"2\":{\"270\":1}}],[\"困惑度等于词表中唯一词元的数量\",{\"2\":{\"249\":1}}],[\"困惑度是正无穷大\",{\"2\":{\"249\":1}}],[\"符合认知的语言\",{\"2\":{\"249\":1}}],[\"符号作为\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"符号上\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"符号的话\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"符号\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"符号其实很容易让写作网络文件的人感到困扰\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"符号则用于标记\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"符号用于起始标签\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"惊异度\",{\"2\":{\"249\":1}}],[\"惊叹号\",{\"2\":{\"214\":1}}],[\"寄存器的高16位\",{\"2\":{\"248\":1}}],[\"感性理解一下lenet\",{\"2\":{\"247\":1}}],[\"感受野可能大于输入的实际大小\",{\"2\":{\"92\":1}}],[\"样本数\",{\"2\":{\"247\":1}}],[\"样式的引言\",{\"2\":{\"57\":1}}],[\"占用的显存大小只与模型参数量和参数数据类型有关\",{\"2\":{\"275\":1}}],[\"占用为\",{\"2\":{\"272\":2}}],[\"占用大小\",{\"2\":{\"272\":1}}],[\"占用显存大小合计为\",{\"2\":{\"272\":1}}],[\"占用显存大小为\",{\"2\":{\"272\":1}}],[\"占用显存的大头就是前向传递过程中计算得到的中间激活值了\",{\"2\":{\"272\":1}}],[\"占用显存的大头主要是模型参数\",{\"2\":{\"253\":1}}],[\"占用显存的大头主要分为四部分\",{\"2\":{\"246\":1}}],[\"占用了\",{\"2\":{\"246\":1}}],[\"ϕ\",{\"2\":{\"246\":2}}],[\"后展平\",{\"2\":{\"270\":1}}],[\"后向传递\",{\"2\":{\"268\":1}}],[\"后向传递的系数\",{\"2\":{\"264\":1}}],[\"后向传递的计算量是前向传递的2倍\",{\"2\":{\"264\":1}}],[\"后向传递计算得到的梯度\",{\"2\":{\"246\":1}}],[\"后者是第二种\",{\"2\":{\"166\":1}}],[\"后者可以针对硬件做更大程度的系统级别的优化\",{\"2\":{\"66\":1}}],[\"划分完virtual\",{\"2\":{\"252\":1}}],[\"划分weight到不同gpu上\",{\"2\":{\"245\":1}}],[\"划分batch为若干mini\",{\"2\":{\"245\":1}}],[\"矩阵乘法\",{\"2\":{\"243\":1,\"272\":1}}],[\"矩阵的形式\",{\"2\":{\"123\":1}}],[\"右对齐使用\",{\"2\":{\"238\":1}}],[\"右对齐\",{\"2\":{\"238\":1}}],[\"居中使用\",{\"2\":{\"238\":1}}],[\"居中\",{\"2\":{\"238\":1}}],[\"较大的时候\",{\"2\":{\"236\":1}}],[\"整篇论文中有如下三个要点\",{\"2\":{\"235\":1}}],[\"整个运算就定义了卷积层\",{\"2\":{\"71\":1}}],[\"切片操作\",{\"0\":{\"232\":1}}],[\"亦或是async协程\",{\"2\":{\"231\":1}}],[\"亦可以视作对向量\",{\"2\":{\"78\":1}}],[\"长度的字节码之后也会释放gil锁\",{\"2\":{\"231\":1}}],[\"长度为num\",{\"2\":{\"176\":1}}],[\"长度为784\",{\"2\":{\"152\":1}}],[\"能更加高效的处理io任务\",{\"2\":{\"231\":1}}],[\"能很好的支持\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"且有固定的类型和位置\",{\"2\":{\"260\":1}}],[\"且只写\",{\"2\":{\"248\":1}}],[\"且步长为3\",{\"2\":{\"229\":1}}],[\"且相互独立\",{\"2\":{\"93\":1}}],[\"池运算是确定性的\",{\"2\":{\"229\":1}}],[\"池化层\",{\"2\":{\"216\":1}}],[\"遍历的每个位置计算一个输出\",{\"2\":{\"229\":1}}],[\"⌘\",{\"2\":{\"228\":2}}],[\"快捷键\",{\"0\":{\"228\":1},\"2\":{\"228\":1}}],[\"映射回词表\",{\"2\":{\"225\":1}}],[\"映射回\",{\"2\":{\"225\":1}}],[\"映射为\",{\"2\":{\"108\":1,\"225\":1}}],[\"平均汇聚层会输出该窗口内的平均值\",{\"2\":{\"239\":1}}],[\"平移参数\",{\"2\":{\"225\":1}}],[\"平方损失\",{\"2\":{\"59\":1}}],[\"九\",{\"0\":{\"224\":1}}],[\"仍然会出现梯度消失\",{\"2\":{\"266\":1}}],[\"仍然保持分割状态\",{\"2\":{\"222\":1}}],[\"仍然使用小批次训练的方式\",{\"2\":{\"152\":1}}],[\"处元素置为1\",{\"2\":{\"255\":1}}],[\"处理gemm\",{\"2\":{\"222\":1}}],[\"处相对于\",{\"2\":{\"151\":1}}],[\"沿新维度堆叠\",{\"2\":{\"220\":1}}],[\"沿梯度\",{\"0\":{\"78\":1}}],[\"协程可以自主切换\",{\"2\":{\"219\":1}}],[\"异常方便\",{\"2\":{\"219\":1}}],[\"挨个处理会很耗时\",{\"2\":{\"219\":1}}],[\"步的所有序列信息\",{\"2\":{\"217\":1}}],[\"步幅\",{\"2\":{\"144\":1}}],[\"≈p\",{\"2\":{\"217\":2}}],[\"回想一下\",{\"2\":{\"255\":1}}],[\"回想一下网络的本质\",{\"2\":{\"219\":1}}],[\"回顾一下我们引入过程中的马尔科夫模型\",{\"2\":{\"217\":1}}],[\"回到本节开头提到的对象边缘检测示例\",{\"2\":{\"229\":1}}],[\"回到我们一开始的模型公式\",{\"2\":{\"152\":1}}],[\"回到我们一开始提到的生成序列的方法\",{\"2\":{\"131\":1}}],[\"回到autograd\",{\"2\":{\"140\":1}}],[\"回到原来的问题\",{\"2\":{\"88\":1}}],[\"降低对空间降采样表示的敏感性\",{\"2\":{\"216\":1}}],[\"降低卷积层对位置的敏感性\",{\"2\":{\"216\":1}}],[\"聚集信息\",{\"2\":{\"216\":1}}],[\"↩︎\",{\"2\":{\"215\":1}}],[\"过零丁洋\",{\"2\":{\"215\":2}}],[\"宋\",{\"2\":{\"215\":2}}],[\"留取丹心照汗青\",{\"2\":{\"215\":2}}],[\"人生自古谁无死\",{\"2\":{\"215\":2}}],[\"英文句点\",{\"2\":{\"214\":1}}],[\"井字号\",{\"2\":{\"214\":1}}],[\"括号\",{\"2\":{\"214\":1}}],[\"底线\",{\"2\":{\"214\":1}}],[\"底线来建立一个分隔线\",{\"2\":{\"89\":1}}],[\"星号\",{\"2\":{\"214\":1}}],[\"存储了从起始状态到\",{\"2\":{\"217\":1}}],[\"存储在input\",{\"2\":{\"213\":1}}],[\"存在舍入误差\",{\"2\":{\"38\":1}}],[\"伪释放\",{\"2\":{\"213\":1}}],[\"此后的调度策略通过实现这个基类来进行\",{\"2\":{\"213\":1}}],[\"此外logits计算会将隐藏向量映射为词表大小\",{\"2\":{\"259\":1}}],[\"此外\",{\"2\":{\"100\":1,\"253\":1}}],[\"序列长度\",{\"2\":{\"212\":1}}],[\"隐状态的值会更加适合预测\",{\"2\":{\"261\":1}}],[\"隐藏单元数\",{\"2\":{\"255\":1,\"277\":1}}],[\"隐藏变量捕获并保留了序列直到当前时间步的历史信息\",{\"2\":{\"230\":1}}],[\"隐藏层参数\",{\"2\":{\"255\":1}}],[\"隐藏层的输出为\",{\"2\":{\"230\":1}}],[\"隐藏层维度\",{\"2\":{\"212\":1}}],[\"隐变量一般使用递推式更新\",{\"2\":{\"217\":1}}],[\"隐变量自回归模型\",{\"2\":{\"103\":1}}],[\"八\",{\"0\":{\"211\":1}}],[\"发现预测出来了奇怪的东西\",{\"2\":{\"261\":1}}],[\"发送完之后\",{\"2\":{\"213\":1}}],[\"发布\",{\"2\":{\"205\":1}}],[\"发生溢出\",{\"2\":{\"38\":1}}],[\"必须按照某个全局顺序执行\",{\"2\":{\"205\":1}}],[\"必须在前后加上空行\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"导致出现a\",{\"2\":{\"205\":1}}],[\"导致一些矛盾\",{\"2\":{\"205\":1}}],[\"导入代码块\",{\"0\":{\"114\":1}}],[\"读一下\",{\"2\":{\"251\":1}}],[\"读操作\",{\"2\":{\"205\":2}}],[\"读取语料库\",{\"2\":{\"117\":1}}],[\"位置编码\",{\"2\":{\"202\":1}}],[\"位置编码使用相同形状的位置嵌入矩阵\",{\"2\":{\"202\":1}}],[\"位置编码是为了让self\",{\"2\":{\"202\":1}}],[\"拥有更少的bubbles\",{\"2\":{\"263\":1}}],[\"拥有权重矩阵\",{\"2\":{\"225\":1}}],[\"拥有\",{\"2\":{\"202\":1}}],[\"考虑一个具有\",{\"2\":{\"266\":1}}],[\"考虑一个卷积核大小为\",{\"2\":{\"202\":1}}],[\"考察的是transformer的模型结构\",{\"2\":{\"30\":1}}],[\"路径越短则更可以学习序列中的远距离依赖关系\",{\"2\":{\"202\":1}}],[\"路径都比较固定\",{\"2\":{\"169\":1}}],[\"顺序操作会妨碍并行计算\",{\"2\":{\"202\":1}}],[\"顺序操作和最大路径长度\",{\"2\":{\"202\":1}}],[\"顺序分区\",{\"0\":{\"188\":1}}],[\"任务\",{\"2\":{\"200\":6}}],[\"任务列表\",{\"0\":{\"200\":1}}],[\"任何函数都可以标记为deleted\",{\"2\":{\"168\":1}}],[\"任何可以被解析为declaration的东西就必须解析为declaration\",{\"2\":{\"112\":1}}],[\"任何标准的文字编辑器都能简单地建立\",{\"2\":{\"57\":1}}],[\"任何数量的\",{\"2\":{\"49\":1}}],[\"公式\",{\"0\":{\"262\":1}}],[\"公式为\",{\"2\":{\"259\":1}}],[\"公式就变为\",{\"2\":{\"82\":1}}],[\"公开你的信箱终究会引来广告信件的\",{\"2\":{\"199\":1}}],[\"把文字字元转成\",{\"2\":{\"199\":1}}],[\"帮助我们调度需要计算的block\",{\"2\":{\"197\":1}}],[\"官方教程中是对m维度划分了group\",{\"2\":{\"197\":1}}],[\"官方解释器\",{\"2\":{\"163\":1}}],[\"依赖于triton\",{\"2\":{\"197\":1}}],[\"又随着硬件而变化\",{\"2\":{\"197\":1}}],[\"他们会在需要的时候才会自动生成\",{\"2\":{\"224\":1}}],[\"他们会包含fwd和bwd所需的信息\",{\"2\":{\"140\":1}}],[\"他们也享有独立的shared\",{\"2\":{\"197\":1}}],[\"事实上\",{\"2\":{\"249\":1}}],[\"事实上虽然在cuda编程的范式上\",{\"2\":{\"197\":1}}],[\"事实上如果当前有nn\",{\"2\":{\"140\":1}}],[\"详情请阅读上面的gemm\",{\"2\":{\"197\":1}}],[\"详细叙述如下\",{\"2\":{\"156\":1}}],[\"循环神经网络模型\",{\"2\":{\"277\":1}}],[\"循环神经网络rnn\",{\"0\":{\"73\":1},\"1\":{\"83\":1,\"93\":1,\"103\":1,\"117\":1,\"131\":1,\"145\":1,\"162\":1,\"176\":1,\"188\":1,\"204\":1,\"217\":1,\"230\":1,\"241\":1,\"249\":1,\"255\":1,\"261\":1,\"266\":1,\"270\":1,\"274\":1,\"277\":1,\"280\":1,\"283\":1,\"285\":1}}],[\"循环式地处理每块数据\",{\"2\":{\"197\":1}}],[\"优质博客\",{\"2\":{\"195\":1}}],[\"优化为\",{\"2\":{\"275\":1}}],[\"优化器更新\",{\"2\":{\"268\":1}}],[\"优化器状态占用的显存大小也是一样\",{\"2\":{\"275\":1}}],[\"优化器状态外\",{\"2\":{\"272\":1}}],[\"优化器状态\",{\"2\":{\"246\":1,\"253\":1}}],[\"优化\",{\"0\":{\"195\":1}}],[\"优先度no\",{\"2\":{\"170\":1}}],[\"七\",{\"0\":{\"194\":1}}],[\"逐元素相乘\",{\"2\":{\"191\":1}}],[\"兼容问题\",{\"2\":{\"190\":1}}],[\"堆叠操作\",{\"2\":{\"187\":1}}],[\"变为新的x\",{\"2\":{\"283\":1}}],[\"变为\",{\"2\":{\"255\":1,\"283\":2}}],[\"变为四维张量\",{\"2\":{\"187\":1}}],[\"变换\",{\"2\":{\"220\":1}}],[\"变化时的规律\",{\"2\":{\"151\":1}}],[\"经常用在llm量化中\",{\"2\":{\"257\":1}}],[\"经常使用cnn或者rnn对序列进行编码\",{\"2\":{\"186\":1}}],[\"经过堆叠之后\",{\"2\":{\"225\":1}}],[\"经过变换后\",{\"2\":{\"173\":1}}],[\"名为\",{\"2\":{\"185\":1}}],[\"名为高斯核\",{\"2\":{\"51\":1}}],[\"尤其是作用于拷贝移动赋值\",{\"2\":{\"182\":1}}],[\"便于编译器检查\",{\"2\":{\"182\":1}}],[\"便会被视为空行\",{\"2\":{\"40\":1}}],[\"链式法则用于计算复合函数的导数\",{\"2\":{\"180\":1}}],[\"链式法则\",{\"2\":{\"180\":1}}],[\"链接到\",{\"2\":{\"113\":1}}],[\"链接标签和链接文字会视为相同\",{\"2\":{\"113\":1}}],[\"链接辨识标签可以有字母\",{\"2\":{\"113\":1}}],[\"链接网址也可以用方括号包起来\",{\"2\":{\"113\":1}}],[\"链接的文字就和链接位置一样\",{\"2\":{\"199\":1}}],[\"链接的文字都是用\",{\"2\":{\"113\":1}}],[\"链接的定义可以放在文件中的任何一个地方\",{\"2\":{\"113\":1}}],[\"链接的网址\",{\"2\":{\"113\":1}}],[\"链接定义的形式为\",{\"2\":{\"113\":1}}],[\"链接\",{\"0\":{\"25\":1,\"113\":1},\"1\":{\"32\":1,\"41\":1},\"2\":{\"25\":1,\"199\":1}}],[\"偏差+\",{\"2\":{\"178\":1}}],[\"小批量中的子序列不一定在原始序列上相邻\",{\"2\":{\"176\":1}}],[\"小批量随机梯度下降\",{\"2\":{\"88\":1}}],[\"时间步数\",{\"2\":{\"255\":3,\"277\":2}}],[\"时\",{\"2\":{\"174\":1,\"264\":1,\"278\":1}}],[\"时可以把卷积核看为二维张量\",{\"2\":{\"174\":1}}],[\"时的解码器隐状态为\",{\"2\":{\"115\":1}}],[\"基本结构\",{\"0\":{\"277\":1}}],[\"基于这个前提分析显存占用\",{\"2\":{\"246\":1}}],[\"基于适当的张量操作\",{\"2\":{\"173\":1}}],[\"基础操作\",{\"0\":{\"164\":1},\"1\":{\"178\":1,\"191\":1}}],[\"基础\",{\"0\":{\"5\":1},\"1\":{\"6\":1,\"10\":1,\"17\":1,\"24\":1,\"31\":1,\"40\":1,\"49\":1,\"57\":1,\"68\":1,\"79\":1,\"89\":1,\"99\":1,\"113\":1,\"127\":1,\"141\":1,\"156\":1,\"171\":1,\"184\":1,\"199\":1,\"214\":1,\"228\":1,\"238\":1}}],[\"逆转transpose\",{\"2\":{\"173\":1}}],[\"换言之对称量化的值域的零点就是中点\",{\"2\":{\"251\":1}}],[\"换行符\",{\"2\":{\"171\":1}}],[\"换句话说\",{\"2\":{\"68\":1}}],[\"段落之间空一行\",{\"2\":{\"171\":1}}],[\"段落\",{\"2\":{\"171\":1}}],[\"段落和换行\",{\"0\":{\"40\":1}}],[\"删除\",{\"2\":{\"171\":1}}],[\"正确预测的数量\",{\"2\":{\"247\":1}}],[\"正确地运行错误提示以及代码补全\",{\"2\":{\"169\":1}}],[\"正交性\",{\"2\":{\"245\":1}}],[\"正如我们推导的一样\",{\"2\":{\"144\":1}}],[\"虚拟环境使用micromamba\",{\"2\":{\"169\":1}}],[\"插件主要使用clangd\",{\"2\":{\"169\":1}}],[\"插入范例用的\",{\"2\":{\"79\":1}}],[\"调用backward\",{\"2\":{\"166\":1}}],[\"意思是启动一个批量异步拷贝\",{\"2\":{\"265\":1}}],[\"意为第一维取所有\",{\"2\":{\"232\":1}}],[\"意为一个张量\",{\"2\":{\"164\":1}}],[\"意味着指针不可变\",{\"2\":{\"104\":1}}],[\"意味着对象不可变\",{\"2\":{\"104\":1}}],[\"意味着我们一个token会对所有的experts都计算\",{\"2\":{\"72\":1}}],[\"秒\",{\"2\":{\"163\":1,\"270\":1}}],[\"另一种是不间断运行了一定量的字节码\",{\"2\":{\"163\":1}}],[\"另外我们考虑两个layer\",{\"2\":{\"272\":1}}],[\"另外一个与lll呈幂律关系\",{\"2\":{\"158\":1}}],[\"另外一个好处就是提供了书写上的便利\",{\"2\":{\"144\":1}}],[\"另外图片是一个二维像素点矩阵\",{\"2\":{\"152\":1}}],[\"另外数组和函数会退化为指针\",{\"2\":{\"122\":1}}],[\"释放锁的时机有两种\",{\"2\":{\"163\":1}}],[\"让我们首先定义预测函数来生成prefix之后的新字符\",{\"2\":{\"261\":1}}],[\"让我们用数学语言描述一下多头注意力模型\",{\"2\":{\"159\":1}}],[\"让渡给其他协程\",{\"2\":{\"219\":1}}],[\"让你可以把一些标记相关的资讯移到段落文字之外\",{\"2\":{\"113\":1}}],[\"组变换后的查询\",{\"2\":{\"159\":1}}],[\"组不同的\",{\"2\":{\"159\":1}}],[\"线性变换复杂度为\",{\"2\":{\"259\":1}}],[\"线性代数\",{\"0\":{\"243\":1}}],[\"线性投影\",{\"2\":{\"159\":1}}],[\"线性回归模型\",{\"2\":{\"88\":1}}],[\"线性回归主要描述一个或者多个自变量与一个因变量之间的线性关系的模型\",{\"2\":{\"48\":1}}],[\"子空间表示\",{\"2\":{\"159\":1}}],[\"子层表示为\",{\"2\":{\"87\":1}}],[\"短距离依赖和长距离依赖关系\",{\"2\":{\"159\":1}}],[\"捕获序列内各种范围的依赖关系\",{\"2\":{\"159\":1}}],[\"论文中对dualpipe的描述是这样的\",{\"2\":{\"263\":1}}],[\"论文图中\",{\"2\":{\"252\":1}}],[\"论文地址\",{\"2\":{\"161\":1}}],[\"论文\",{\"2\":{\"158\":1,\"208\":1}}],[\"论文甚至是用非常少量的代码完成最小可用原型\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"限域写法\",{\"2\":{\"154\":1}}],[\"限域enum避免了命名空间污染\",{\"2\":{\"154\":1}}],[\"枚举名是强类型\",{\"2\":{\"154\":1}}],[\"交叉熵\",{\"2\":{\"152\":1}}],[\"交叉熵函数\",{\"2\":{\"137\":1}}],[\"测试数据\",{\"2\":{\"152\":1}}],[\"先load\",{\"2\":{\"269\":1}}],[\"先照抄下来\",{\"2\":{\"266\":1}}],[\"先求一下scale\",{\"2\":{\"262\":1}}],[\"先将输入的参数reshape一下\",{\"2\":{\"152\":1}}],[\"先计算出来预期结果\",{\"2\":{\"130\":1}}],[\"按照第二维拼接\",{\"2\":{\"283\":1}}],[\"按照第一维拼接\",{\"2\":{\"220\":1}}],[\"按照块来分治\",{\"2\":{\"197\":1}}],[\"按行求和\",{\"2\":{\"152\":1}}],[\"按出现频率排序\",{\"2\":{\"117\":1}}],[\"关于\",{\"2\":{\"151\":2}}],[\"~mask\",{\"2\":{\"285\":1}}],[\"~~delete~~\",{\"2\":{\"171\":1}}],[\"~\",{\"2\":{\"151\":1,\"157\":2}}],[\"~t\",{\"2\":{\"104\":1,\"118\":1}}],[\"避免无意义的拷贝内存开销\",{\"2\":{\"150\":1}}],[\"避免了拷贝构造带来的性能开销\",{\"2\":{\"132\":1}}],[\"强制教学\",{\"2\":{\"285\":1}}],[\"强化\",{\"2\":{\"150\":1}}],[\"强调也可以直接插在文字中间\",{\"2\":{\"127\":1}}],[\"强调用户在快速浏览文档时也不应忽略的重要信息\",{\"2\":{\"100\":2}}],[\"强调\",{\"0\":{\"127\":1},\"2\":{\"6\":1,\"13\":1,\"14\":1,\"17\":1,\"19\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"针对我们这个函数而言\",{\"2\":{\"150\":1}}],[\"针对此类数据而设计特定模型\",{\"2\":{\"93\":1}}],[\"完全销毁掉\",{\"2\":{\"213\":1}}],[\"完全保留\",{\"2\":{\"213\":1}}],[\"完全连接层的输出数量或卷积层的输出通道数\",{\"2\":{\"96\":1}}],[\"完整代码如下\",{\"2\":{\"197\":1}}],[\"完整代码\",{\"0\":{\"193\":1}}],[\"完美转发\",{\"2\":{\"146\":1}}],[\"万能引用\",{\"2\":{\"146\":1}}],[\"剩余所有的单词大致遵循双对数坐标图上的一条直线\",{\"2\":{\"145\":1}}],[\"剩下的\",{\"2\":{\"79\":1}}],[\"齐普夫定律\",{\"0\":{\"145\":1},\"2\":{\"145\":1}}],[\"总预测的数量\",{\"2\":{\"247\":1}}],[\"总效应\",{\"2\":{\"180\":1}}],[\"总是不方便的\",{\"2\":{\"154\":1}}],[\"总共添加了2行2列\",{\"2\":{\"144\":1}}],[\"总结下来\",{\"2\":{\"236\":1}}],[\"总结下来就是\",{\"2\":{\"102\":1}}],[\"总结来说\",{\"2\":{\"123\":1,\"260\":1}}],[\"总结\",{\"0\":{\"102\":1,\"236\":1,\"239\":1},\"2\":{\"122\":1,\"135\":1,\"166\":1,\"202\":1,\"213\":2,\"222\":1,\"259\":1,\"273\":1,\"282\":1}}],[\"去等待io阻塞\",{\"2\":{\"177\":1}}],[\"去掉批量和通道\",{\"2\":{\"144\":1}}],[\"去从最基础的东西讲起\",{\"2\":{\"2\":1}}],[\"与模型参数量有关\",{\"2\":{\"275\":1}}],[\"与优化器类型有关\",{\"2\":{\"275\":1}}],[\"与输入数据的大小是没有关系的\",{\"2\":{\"275\":1}}],[\"与全连接层一样\",{\"2\":{\"247\":1}}],[\"与上一层相比\",{\"2\":{\"247\":1}}],[\"与卷积层类似\",{\"2\":{\"229\":1}}],[\"与卷积核进行互相关计算得到的\",{\"2\":{\"144\":1}}],[\"与其只使用单独一个注意力汇聚\",{\"2\":{\"159\":1}}],[\"与t\",{\"2\":{\"104\":1}}],[\"均匀量化适用于数据比较均匀\",{\"2\":{\"251\":1}}],[\"均匀分配即可\",{\"2\":{\"144\":1}}],[\"均方误差\",{\"2\":{\"88\":1}}],[\"均方损失\",{\"2\":{\"88\":1}}],[\"左对齐使用\",{\"2\":{\"238\":1}}],[\"左对齐\",{\"2\":{\"238\":1}}],[\"左右\",{\"2\":{\"144\":1}}],[\"左值实参会被特殊对待\",{\"2\":{\"122\":1}}],[\"左值引用\",{\"2\":{\"119\":1}}],[\"左值\",{\"2\":{\"119\":1}}],[\"填充和步幅\",{\"0\":{\"144\":1}}],[\"重新映射回int8\",{\"2\":{\"267\":1}}],[\"重新排列\",{\"2\":{\"220\":1}}],[\"重载是一个不错的选择\",{\"2\":{\"150\":1}}],[\"重复步骤3\",{\"2\":{\"143\":1}}],[\"重点在于\",{\"2\":{\"68\":1}}],[\"迭代时间步数\",{\"2\":{\"255\":1}}],[\"迭代输出\",{\"2\":{\"143\":1}}],[\"迭代次数和批次\",{\"2\":{\"63\":1}}],[\"概率分布\",{\"2\":{\"143\":1}}],[\"概述\",{\"0\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"根据具体情况\",{\"2\":{\"223\":1}}],[\"根据注意力权重用加权求和生成上下文向量\",{\"2\":{\"143\":1}}],[\"根据pytorch的自动微分机制\",{\"2\":{\"126\":1}}],[\"简而言之\",{\"2\":{\"255\":1}}],[\"简单了很多\",{\"2\":{\"213\":1}}],[\"简洁美观\",{\"2\":{\"142\":1}}],[\"简介\",{\"0\":{\"67\":1,\"93\":1}}],[\"结合我们的概率输出和softmax\",{\"2\":{\"255\":1}}],[\"结合了gpipe与data\",{\"2\":{\"235\":1}}],[\"结合线程池能得到较大的改善\",{\"2\":{\"231\":1}}],[\"结合当前decoder隐状态和encoder的隐状态序列\",{\"2\":{\"143\":1}}],[\"结束端前面一个\",{\"2\":{\"141\":1}}],[\"结果为\",{\"2\":{\"166\":1,\"243\":1}}],[\"结果\",{\"2\":{\"68\":1}}],[\"起始端后面一个\",{\"2\":{\"141\":1}}],[\"显然1\",{\"2\":{\"203\":1}}],[\"显然f2会导致悬垂引用\",{\"2\":{\"150\":1}}],[\"显示前驱节点\",{\"2\":{\"140\":1}}],[\"显示创建y的操作\",{\"2\":{\"140\":1}}],[\"显存优化\",{\"0\":{\"201\":1}}],[\"显存占用的峰值\",{\"2\":{\"55\":1}}],[\"显存大小\",{\"2\":{\"55\":1}}],[\"显存带宽的需求\",{\"2\":{\"55\":1}}],[\"显存的字节大小\",{\"2\":{\"55\":1}}],[\"节点信息\",{\"2\":{\"140\":1}}],[\"原来的fp32\",{\"2\":{\"271\":1}}],[\"原理\",{\"0\":{\"217\":1},\"1\":{\"230\":1,\"241\":1,\"249\":1}}],[\"原理就是其中的枚举名被隐式转换为了std\",{\"2\":{\"154\":1}}],[\"原因在于它的核心算法\",{\"2\":{\"180\":1}}],[\"原生线程\",{\"2\":{\"163\":1}}],[\"原地操作\",{\"2\":{\"140\":1}}],[\"原始码\",{\"2\":{\"79\":1,\"141\":1}}],[\"纯python操作\",{\"2\":{\"140\":1}}],[\"纯右值\",{\"2\":{\"119\":2}}],[\"索引操作\",{\"2\":{\"140\":1}}],[\"条件操作\",{\"2\":{\"140\":1}}],[\"神经网络操作\",{\"2\":{\"140\":1}}],[\"神经网络的每一层应该只探索图像中的局部区域\",{\"2\":{\"60\":1}}],[\"创建和销毁都是一笔开销\",{\"2\":{\"231\":1}}],[\"创建一个足够长的p\",{\"2\":{\"202\":1}}],[\"创建操作\",{\"0\":{\"178\":1}}],[\"创建计算图节点\",{\"2\":{\"140\":1}}],[\"创建求和节点\",{\"2\":{\"140\":1}}],[\"创建视图节点\",{\"2\":{\"140\":1}}],[\"创建线性层节点\",{\"2\":{\"140\":1}}],[\"创建relu节点\",{\"2\":{\"140\":1}}],[\"创建乘法节点\",{\"2\":{\"140\":1}}],[\"创建加法节点\",{\"2\":{\"140\":1}}],[\"视为创建一个计算图节点\",{\"2\":{\"140\":1}}],[\"视频中的图像帧\",{\"2\":{\"93\":1}}],[\"需要有一套sync机制保证\",{\"2\":{\"276\":1}}],[\"需要保存其输入\",{\"2\":{\"272\":1}}],[\"需要保存softmax的结果\",{\"2\":{\"272\":1}}],[\"需要保存输入\",{\"2\":{\"272\":1}}],[\"需要保存中间激活\",{\"2\":{\"272\":1}}],[\"需要保存中间激活以便在后向传递计算梯度时使用\",{\"2\":{\"272\":1}}],[\"需要保存他们的共同的输入\",{\"2\":{\"272\":1}}],[\"需要使用tma\",{\"2\":{\"269\":1}}],[\"需要传入mbarrier\",{\"2\":{\"265\":1}}],[\"需要创建tensor\",{\"2\":{\"265\":1}}],[\"需要进行8次浮点数运算\",{\"2\":{\"268\":1}}],[\"需要进行一次额外的前向传递\",{\"2\":{\"268\":1}}],[\"需要进行6次浮点数运算\",{\"2\":{\"264\":1}}],[\"需要进行2次浮点数运算\",{\"2\":{\"264\":1}}],[\"需要显式arrive一下\",{\"2\":{\"260\":1}}],[\"需要input\",{\"2\":{\"213\":1}}],[\"需要考虑更多的细节\",{\"2\":{\"213\":1}}],[\"需要具备以下一些特点\",{\"2\":{\"197\":1}}],[\"需要构造一个与输入具有相同通道数的卷积核\",{\"2\":{\"174\":1}}],[\"需要自己实现fwd和bwd方法\",{\"2\":{\"140\":1}}],[\"需要做的就是将有效的语言别名附加到代码块的开头\",{\"2\":{\"100\":1}}],[\"别名声明可以模板化\",{\"2\":{\"139\":1}}],[\"减少prefill的计算\",{\"2\":{\"284\":1}}],[\"减少了bubble\",{\"2\":{\"263\":1}}],[\"减去1\",{\"2\":{\"176\":1}}],[\"减一\",{\"2\":{\"137\":1}}],[\"减号\",{\"2\":{\"89\":1,\"214\":1}}],[\"函数变为\",{\"2\":{\"137\":1}}],[\"函数的基本定义如下\",{\"2\":{\"108\":1}}],[\"置为1\",{\"2\":{\"137\":1}}],[\"程序需要在cpu上执行\",{\"2\":{\"133\":1}}],[\"网络io\",{\"2\":{\"133\":1}}],[\"网址定义只有在产生链接的时候用到\",{\"2\":{\"113\":1}}],[\"网址太长的话\",{\"2\":{\"113\":1}}],[\"出自\",{\"2\":{\"215\":2}}],[\"出现某个单词的条件概率\",{\"2\":{\"131\":1}}],[\"出来的维度为1\",{\"2\":{\"88\":1}}],[\"尽量使用using\",{\"2\":{\"139\":1}}],[\"尽量使用nullptr\",{\"2\":{\"125\":1}}],[\"尽管这样并不严谨\",{\"2\":{\"130\":1}}],[\"下文会详细介绍\",{\"2\":{\"268\":1}}],[\"下文中我们会将互相关运算称为卷积运算\",{\"2\":{\"130\":1}}],[\"下图展示了使用全连接层来实现可学习的线性变换的多头注意力\",{\"2\":{\"159\":1}}],[\"下面是用行内形式写的同样一段内容的\",{\"2\":{\"113\":1}}],[\"下面是一个参考式链接的范例\",{\"2\":{\"113\":1}}],[\"下面这三种链接的定义相同\",{\"2\":{\"113\":1}}],[\"下面为代码实现\",{\"2\":{\"91\":1}}],[\"下面每种写法都可以建立分隔线\",{\"2\":{\"89\":1}}],[\"下面的输入\",{\"2\":{\"79\":1}}],[\"运行\",{\"2\":{\"256\":1}}],[\"运行了\",{\"2\":{\"163\":1}}],[\"运行一下可以看出偏差在不断变小\",{\"2\":{\"130\":1}}],[\"运行时优化\",{\"2\":{\"66\":1}}],[\"宽度\",{\"2\":{\"130\":1}}],[\"高开销\",{\"2\":{\"190\":1}}],[\"高度\",{\"2\":{\"130\":1}}],[\"高亮\",{\"2\":{\"100\":1}}],[\"更具体地说\",{\"2\":{\"278\":1}}],[\"更加精细的异步与tensor内存释放\",{\"2\":{\"263\":1}}],[\"更新结果\",{\"2\":{\"270\":1}}],[\"更新decoder的隐状态\",{\"2\":{\"143\":1}}],[\"更新移动平均的均值和方差\",{\"2\":{\"96\":1}}],[\"更复杂的卷积核例子\",{\"2\":{\"130\":1}}],[\"前面提到当模型参数为\",{\"2\":{\"264\":1}}],[\"前向传播的时候第\",{\"2\":{\"266\":1}}],[\"前向传播就是对输入扫描了一遍互相关运算得出结果\",{\"2\":{\"130\":1}}],[\"前向传递过程中计算得到的\",{\"2\":{\"272\":1}}],[\"前向传递\",{\"2\":{\"264\":1}}],[\"前向计算过程中产生的中间激活\",{\"2\":{\"246\":1}}],[\"前者是第一种\",{\"2\":{\"166\":1}}],[\"前言\",{\"2\":{\"35\":1}}],[\"⋅xv\",{\"2\":{\"278\":3}}],[\"⋅w2​+tout\",{\"2\":{\"278\":1}}],[\"⋅w2​+xout\",{\"2\":{\"278\":1}}],[\"⋅w2+tout\",{\"2\":{\"278\":1}}],[\"⋅w2+xout\",{\"2\":{\"278\":1}}],[\"⋅w1\",{\"2\":{\"278\":2}}],[\"⋅wo\",{\"2\":{\"278\":2}}],[\"⋅wq\",{\"2\":{\"278\":4}}],[\"⋅wv\",{\"2\":{\"278\":4}}],[\"⋅wk\",{\"2\":{\"278\":4}}],[\"⋅v⋅wo​+x\",{\"2\":{\"259\":1}}],[\"⋅v⋅wo+xx\",{\"2\":{\"259\":1}}],[\"⋅\",{\"2\":{\"130\":2,\"144\":2}}],[\"探究二维张量的互相关运算\",{\"2\":{\"130\":1}}],[\"互相关运算是怎么做的\",{\"2\":{\"160\":1}}],[\"互相关运算就可以转化为卷积运算\",{\"2\":{\"130\":1}}],[\"互相关运算\",{\"0\":{\"130\":1}}],[\"∇×b⃗−\",{\"2\":{\"128\":1}}],[\"∇×e+c1​∂t∂b​=0\",{\"2\":{\"128\":1}}],[\"∇×e⃗\",{\"2\":{\"128\":1}}],[\"∇⋅b⃗=0\",{\"2\":{\"128\":1}}],[\"∇f\",{\"2\":{\"78\":3}}],[\"两边都有空白的话\",{\"2\":{\"127\":1}}],[\"两个张量形状大致均为\",{\"2\":{\"272\":1}}],[\"两个thread均执行以下操作\",{\"2\":{\"205\":1}}],[\"两个值矩阵是相同的\",{\"2\":{\"81\":1}}],[\"两个shape为\",{\"2\":{\"55\":2}}],[\"两个符号都一定会被转换成\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"被重组了\",{\"2\":{\"169\":1}}],[\"被\",{\"2\":{\"127\":1}}],[\"被称之为注意力权重\",{\"2\":{\"51\":1}}],[\"范数有一个简单的形式\",{\"2\":{\"123\":1}}],[\"范围内\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"∂xi​∂​j=1∑n​yj​\",{\"2\":{\"166\":1}}],[\"∂x∂loss\",{\"2\":{\"137\":1}}],[\"∂x=p−onehot\",{\"2\":{\"137\":1}}],[\"∂xj​∂pi​​=pi​δi\",{\"2\":{\"123\":1}}],[\"∂loss\",{\"2\":{\"137\":1}}],[\"∂e⃗∂t=4πcj⃗∇⋅e⃗=4πρ\",{\"2\":{\"128\":1}}],[\"∂b⃗∂t=0⃗\",{\"2\":{\"128\":1}}],[\"∂∂xi∑j=1nyj\",{\"2\":{\"166\":1}}],[\"∂∂xiexi∑k=1nexk=\",{\"2\":{\"123\":1}}],[\"∂∂xjexi∑k=1nexk=\",{\"2\":{\"123\":1}}],[\"∂pi∂xj=piδi\",{\"2\":{\"123\":1}}],[\"∂pi∂xj=\",{\"2\":{\"123\":2}}],[\"维度\",{\"2\":{\"213\":1}}],[\"维度为2\",{\"2\":{\"178\":1}}],[\"维embedding向量\",{\"2\":{\"202\":1}}],[\"维隐状态\",{\"2\":{\"202\":1}}],[\"维向量\",{\"2\":{\"202\":1}}],[\"维张量\",{\"2\":{\"123\":2}}],[\"维的张量\",{\"2\":{\"95\":1,\"108\":1}}],[\"了解一个函数的性质最重要的方式之一就是了解它的梯度\",{\"2\":{\"123\":1}}],[\"顶层const会去除\",{\"2\":{\"122\":1}}],[\"无法很好的处理计算密集型任务\",{\"2\":{\"231\":1}}],[\"无法并行化\",{\"2\":{\"202\":1}}],[\"无法编译通过\",{\"2\":{\"135\":1}}],[\"无论\",{\"2\":{\"229\":1}}],[\"无论如何\",{\"2\":{\"199\":1}}],[\"无论传递什么\",{\"2\":{\"122\":1}}],[\"无序列表使用减号作为列表标记\",{\"2\":{\"68\":1}}],[\"传入权重和偏置参数\",{\"2\":{\"255\":1}}],[\"传入上一个隐状态\",{\"2\":{\"255\":1}}],[\"传入当前时间步的输入\",{\"2\":{\"255\":1}}],[\"传入的是维度\",{\"2\":{\"178\":1}}],[\"传入的实参会忽略const和ref\",{\"2\":{\"122\":1}}],[\"传入一个二维的卷积核\",{\"2\":{\"130\":1}}],[\"传入ref会先忽略ref\",{\"2\":{\"122\":1}}],[\"规则的一些特性\",{\"2\":{\"122\":1}}],[\"规则\",{\"2\":{\"122\":4}}],[\"字面量\",{\"2\":{\"119\":1}}],[\"字符串\",{\"2\":{\"117\":1}}],[\"临时对象\",{\"2\":{\"119\":1}}],[\"给右值一个续命的\",{\"2\":{\"119\":1}}],[\"给定当前生成词在第\",{\"2\":{\"278\":1}}],[\"给定计算量\",{\"2\":{\"268\":1}}],[\"给定硬件gpu类型的情况下\",{\"2\":{\"268\":1}}],[\"给定一个由词元组成的输入序列\",{\"2\":{\"186\":1}}],[\"给定一个默认类型int\",{\"2\":{\"154\":1}}],[\"给定查询\",{\"2\":{\"81\":1,\"159\":1}}],[\"给定任何查询\",{\"2\":{\"43\":1}}],[\"返回rnn的初始隐状态\",{\"2\":{\"255\":1}}],[\"返回元素个数\",{\"2\":{\"191\":1}}],[\"返回从pos位置开始的长度为num\",{\"2\":{\"176\":1}}],[\"返回类型推导\",{\"2\":{\"154\":1}}],[\"返回的c\",{\"2\":{\"150\":1}}],[\"返回值的表达式\",{\"2\":{\"119\":1}}],[\"返回左值引用的函数\",{\"2\":{\"119\":1}}],[\"返回\",{\"2\":{\"119\":1}}],[\"包含一个线性层\",{\"2\":{\"225\":1}}],[\"包含一个序列中\",{\"2\":{\"202\":1}}],[\"包含两个可训练模型参数\",{\"2\":{\"225\":1}}],[\"包含字面值\",{\"2\":{\"119\":1}}],[\"包起来的话\",{\"2\":{\"127\":1}}],[\"包围的字词会被转成用\",{\"2\":{\"127\":1}}],[\"包括代码补全\",{\"2\":{\"169\":1}}],[\"包括标题\",{\"2\":{\"57\":1}}],[\"包括\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1,\"40\":1}}],[\"普通乘法\",{\"2\":{\"191\":1}}],[\"普通对象则会优先调用普通方法\",{\"2\":{\"118\":1}}],[\"普通对象则都可以调用\",{\"2\":{\"118\":1}}],[\"普通moe并行策略\",{\"2\":{\"15\":1}}],[\"常用约束符\",{\"2\":{\"248\":1}}],[\"常量对象会优先调用常量方法\",{\"2\":{\"118\":1}}],[\"常量对象只能调用常量函数\",{\"2\":{\"118\":1}}],[\"常成员函数\",{\"2\":{\"118\":1}}],[\"常见的数学方法就是分别对θ0\",{\"2\":{\"48\":1}}],[\"常见问题\",{\"0\":{\"4\":1,\"175\":1}}],[\"保存mask矩阵\",{\"2\":{\"272\":1}}],[\"保存一个mask矩阵\",{\"2\":{\"272\":1}}],[\"保存的tensor一般是一份引用\",{\"2\":{\"213\":1}}],[\"保存更新过的moving\",{\"2\":{\"96\":1}}],[\"保留grad\",{\"2\":{\"213\":1}}],[\"保证后续的操作能够正确的读取\",{\"2\":{\"205\":1}}],[\"保证能看到\",{\"2\":{\"205\":1}}],[\"保证之前的操作对\",{\"2\":{\"205\":1}}],[\"保证该读操作后的所有操作能看到该读操作前的所有写操作\",{\"2\":{\"205\":1}}],[\"保证该写操作前的所有操作对其他线程可见\",{\"2\":{\"205\":1}}],[\"保证了任何时刻\",{\"2\":{\"163\":1}}],[\"保证了\",{\"2\":{\"118\":1}}],[\"展平\",{\"2\":{\"117\":1}}],[\"统计词元的频率\",{\"2\":{\"117\":1}}],[\"未知词元的索引为0\",{\"2\":{\"117\":2}}],[\"未知词元类型\",{\"2\":{\"117\":1}}],[\"词元\",{\"2\":{\"270\":1}}],[\"词元数量\",{\"2\":{\"270\":1,\"285\":1}}],[\"词元的本质就是一个个字符\",{\"2\":{\"117\":1}}],[\"词表大小\",{\"2\":{\"212\":1,\"255\":2,\"277\":1}}],[\"词高亮\",{\"2\":{\"100\":1}}],[\"建立一个词表\",{\"2\":{\"117\":1}}],[\"建议来细读这一篇megatron\",{\"2\":{\"222\":1}}],[\"建议将其声明为\",{\"2\":{\"182\":1}}],[\"建议\",{\"2\":{\"89\":1,\"127\":2}}],[\"举一个bf16的特化模板例子\",{\"2\":{\"254\":1}}],[\"举一个例子\",{\"2\":{\"115\":1,\"131\":1}}],[\"举例说明对他们的理解\",{\"0\":{\"55\":1}}],[\"举例来说\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1,\"68\":1}}],[\"带遮蔽的softmax交叉熵损失函数\",{\"2\":{\"285\":1}}],[\"带有下划线的意思是就地操作\",{\"2\":{\"267\":1}}],[\"带有注意力机制解码器的基本接口\",{\"2\":{\"115\":1}}],[\"带参数注意力汇聚\",{\"0\":{\"59\":1}}],[\"既是键\",{\"2\":{\"115\":1}}],[\"编号从0开始\",{\"2\":{\"232\":1}}],[\"编译是另外一回事\",{\"2\":{\"169\":1}}],[\"编译器可能会对指令进行重排序\",{\"2\":{\"205\":1}}],[\"编译器以及include\",{\"2\":{\"169\":1}}],[\"编译器将会从函数实现中推导出函数的返回类型\",{\"2\":{\"150\":1}}],[\"编码器\",{\"2\":{\"280\":3}}],[\"编码器隐状态\",{\"2\":{\"115\":1}}],[\"编码处理\",{\"2\":{\"129\":1}}],[\"编写\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"替换\",{\"2\":{\"115\":1}}],[\"该模型的预测是词表的所有可用词元上的均匀分布\",{\"2\":{\"249\":1}}],[\"该窗口根据其步幅大小在输入的所有区域上滑动\",{\"2\":{\"229\":1}}],[\"该序列的自注意力输出为一个长度相同的序列\",{\"2\":{\"186\":1}}],[\"该如何计算概率呢\",{\"2\":{\"131\":1}}],[\"该注意力模型优化了seq2seq模型\",{\"2\":{\"115\":1}}],[\"该从哪些角度去考虑\",{\"0\":{\"47\":1}}],[\"仅导入第\",{\"2\":{\"114\":1}}],[\"提高了效率\",{\"2\":{\"263\":1}}],[\"提高效率\",{\"2\":{\"88\":1}}],[\"提出了dp\",{\"2\":{\"235\":1}}],[\"提供了最基础的load\",{\"2\":{\"273\":1}}],[\"提供了更加灵活的方式\",{\"2\":{\"166\":1}}],[\"提供作为比较之用\",{\"2\":{\"113\":1}}],[\"预填充\",{\"2\":{\"278\":1}}],[\"预填充阶段\",{\"2\":{\"278\":1}}],[\"预热期\",{\"2\":{\"261\":1}}],[\"预热期结束之后\",{\"2\":{\"261\":1}}],[\"预测num\",{\"2\":{\"261\":1}}],[\"预测\",{\"0\":{\"261\":1}}],[\"预测模式\",{\"2\":{\"96\":1}}],[\"预设的链接标签功能让你可以省略指定链接标签\",{\"2\":{\"113\":1}}],[\"双引号或是括号包括\",{\"2\":{\"113\":1}}],[\"选per\",{\"2\":{\"271\":1}}],[\"选int8还是uint8\",{\"2\":{\"271\":1}}],[\"选asym还是sym\",{\"2\":{\"271\":1}}],[\"选中后\",{\"2\":{\"228\":1}}],[\"选择性地添加\",{\"2\":{\"113\":1}}],[\"选项\",{\"2\":{\"40\":1}}],[\"选项来禁用这个功能\",{\"2\":{\"25\":1}}],[\"冒号\",{\"2\":{\"113\":1}}],[\"接近\",{\"2\":{\"123\":1}}],[\"接着将输入序列放入decoder中\",{\"2\":{\"283\":1}}],[\"接着在cuda开发之中一般都需要使用torch库\",{\"2\":{\"169\":1}}],[\"接着\",{\"2\":{\"113\":1}}],[\"接下来引入本篇主角\",{\"2\":{\"278\":1}}],[\"接下来引入新的概念\",{\"2\":{\"82\":1}}],[\"接下来\",{\"2\":{\"255\":1}}],[\"接下来就是pipedream里面提出的1f1b调度\",{\"2\":{\"252\":1}}],[\"接下来回到cuda中的内存一致性模型\",{\"2\":{\"205\":1}}],[\"接下来让clangd插件能够识别我们的项目\",{\"2\":{\"169\":1}}],[\"接下来便是重头戏\",{\"2\":{\"151\":1}}],[\"接下来是进行词元分割\",{\"2\":{\"117\":1}}],[\"接下来有了目标输出\",{\"2\":{\"95\":1}}],[\"接下来开始正式训练模型\",{\"2\":{\"88\":1}}],[\"接下来从代码的层面演示一下如何求解线性回归模型首先我们需要生成一个数据集\",{\"2\":{\"88\":1}}],[\"接下来我们分别分析self\",{\"2\":{\"272\":1}}],[\"接下来我们分模块针对transformer的架构实现代码\",{\"2\":{\"87\":1}}],[\"接下来我们初始化rnn状态\",{\"2\":{\"255\":1}}],[\"接下来我们设计一个语言模型\",{\"2\":{\"241\":1}}],[\"接下来我们详细地写一个triton\",{\"2\":{\"197\":1}}],[\"接下来我们开始对其进行建模\",{\"2\":{\"131\":1}}],[\"接下来我们整合所有的功能为一个函数\",{\"2\":{\"117\":1}}],[\"接下来我们实现一下注意力优化的encoder\",{\"2\":{\"115\":1}}],[\"接下来我们实践一下\",{\"2\":{\"103\":1}}],[\"接下来我们正式介绍一下马尔科夫条件\",{\"2\":{\"103\":1}}],[\"接下来我们定义出常用的函数\",{\"2\":{\"88\":1}}],[\"接下来我们介绍一下其他的一些注意力评分函数\",{\"2\":{\"70\":1}}],[\"接下来我们介绍注意力评分函数\",{\"2\":{\"70\":1}}],[\"接下来会一一讲解\",{\"2\":{\"61\":1}}],[\"方法是设置\",{\"2\":{\"169\":1}}],[\"方向的变化比较敏感\",{\"2\":{\"151\":1}}],[\"方向的变化不敏感\",{\"2\":{\"151\":1}}],[\"方便模型操作\",{\"2\":{\"117\":1}}],[\"方括号\",{\"2\":{\"113\":2,\"214\":1}}],[\"方差为\",{\"2\":{\"91\":1}}],[\"甚至普通构造函数和移动构造函数也会被劫持\",{\"2\":{\"112\":1}}],[\"产生的效果是相同的\",{\"2\":{\"112\":1}}],[\"产品文档\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"zp是zero\",{\"2\":{\"251\":1}}],[\"zp\",{\"2\":{\"251\":1,\"262\":4}}],[\"zhihu\",{\"2\":{\"175\":1}}],[\"zhuanlan\",{\"2\":{\"175\":1}}],[\"zip\",{\"2\":{\"152\":1,\"174\":1}}],[\"za\",{\"2\":{\"117\":1}}],[\"z\",{\"2\":{\"112\":4,\"117\":1,\"140\":3,\"191\":1,\"269\":2,\"271\":6,\"273\":2}}],[\"zeros\",{\"2\":{\"88\":1,\"96\":2,\"103\":1,\"124\":1,\"130\":2,\"140\":1,\"152\":2,\"178\":1,\"193\":1,\"202\":1,\"229\":1,\"255\":3,\"269\":2,\"277\":3,\"283\":1}}],[\"zero\",{\"2\":{\"59\":1,\"88\":2,\"103\":1,\"128\":2,\"130\":1,\"181\":1,\"193\":1,\"207\":1,\"223\":1,\"247\":1,\"251\":1,\"270\":1,\"285\":1}}],[\"zebra\",{\"2\":{\"50\":2}}],[\"六\",{\"0\":{\"109\":1,\"182\":1}}],[\"满足概率的性质\",{\"2\":{\"108\":1}}],[\"模板类型推导时\",{\"2\":{\"122\":1}}],[\"模板类型推导主要使用以下模板和调用来解释\",{\"2\":{\"122\":1}}],[\"模板类型推导\",{\"0\":{\"122\":1}}],[\"模板学习\",{\"2\":{\"106\":1}}],[\"模型推理阶段\",{\"2\":{\"253\":1}}],[\"模型推理阶段占用的显存要远小于训练阶段\",{\"2\":{\"253\":1}}],[\"模型总是预测标签词元的概率为0\",{\"2\":{\"249\":1}}],[\"模型总是完美地估计标签词元的概率为1\",{\"2\":{\"249\":1}}],[\"模型困惑度\",{\"0\":{\"249\":1}}],[\"模型参数\",{\"2\":{\"246\":1,\"275\":1}}],[\"模型参数量和训练总tokens数决定了训练transformer模型需要的计算量\",{\"2\":{\"268\":1}}],[\"模型参数量\",{\"0\":{\"225\":1},\"1\":{\"236\":1,\"246\":1,\"253\":1},\"2\":{\"268\":1}}],[\"模型量化分类和粒度\",{\"0\":{\"244\":1},\"1\":{\"251\":1}}],[\"模型层数\",{\"2\":{\"212\":1}}],[\"模型的困惑度为1\",{\"2\":{\"249\":1}}],[\"模型的架构主要有两大类\",{\"2\":{\"212\":1}}],[\"模型的整体计算量等于模型中每个算子的计算量之和\",{\"2\":{\"55\":1}}],[\"模型训练\",{\"0\":{\"181\":1}}],[\"模型网络\",{\"2\":{\"152\":1}}],[\"模型代码\",{\"2\":{\"152\":1}}],[\"模型其实就是开头的公式\",{\"2\":{\"152\":1}}],[\"模型通过这种方式逐步生成目标语句\",{\"2\":{\"143\":1}}],[\"模型架构\",{\"0\":{\"87\":1},\"1\":{\"97\":1,\"110\":1,\"124\":1,\"138\":1,\"153\":1,\"167\":1}}],[\"模型中的参数的综合\",{\"2\":{\"55\":1}}],[\"模型大小的四大评估指标是什么\",{\"0\":{\"55\":1}}],[\"数值操作\",{\"2\":{\"191\":1}}],[\"数值计算lib\",{\"2\":{\"106\":1}}],[\"数据集随机采样\",{\"0\":{\"162\":1},\"1\":{\"176\":1,\"188\":1}}],[\"数据库操作\",{\"2\":{\"133\":1}}],[\"数学运算\",{\"2\":{\"140\":1}}],[\"数学方程\",{\"0\":{\"128\":1}}],[\"数组或者函数名实参会退化为指针\",{\"2\":{\"122\":1}}],[\"数字\",{\"2\":{\"113\":1}}],[\"数量最多的\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"各种lock\",{\"2\":{\"106\":1}}],[\"手搓项目合集\",{\"0\":{\"106\":1}}],[\"手搓一个rdma\",{\"2\":{\"15\":1}}],[\"手搓一个pipline\",{\"2\":{\"15\":1}}],[\"单位是bytes\",{\"2\":{\"272\":1}}],[\"单位是ops\",{\"2\":{\"55\":1}}],[\"单一的值\",{\"2\":{\"180\":1}}],[\"单调性\",{\"2\":{\"108\":1}}],[\"单步预测效果不错\",{\"2\":{\"103\":1}}],[\"初始状态选择的是encoder输出的state\",{\"2\":{\"283\":1}}],[\"初始值均为0\",{\"2\":{\"205\":1}}],[\"初始化对于\",{\"2\":{\"112\":1}}],[\"初始化的好处\",{\"2\":{\"112\":1}}],[\"初始化不允许内置类型间隐式的变窄转换\",{\"2\":{\"112\":1}}],[\"初始化具有如下的好处\",{\"2\":{\"112\":1}}],[\"初始化\",{\"0\":{\"112\":1},\"2\":{\"143\":1,\"270\":1}}],[\"初始化模型的权重\",{\"2\":{\"103\":1}}],[\"初始参数\",{\"2\":{\"88\":1}}],[\"采用的是正弦波+一个随机噪声\",{\"2\":{\"103\":1}}],[\"∑k=1n​exk​exi​​\",{\"2\":{\"123\":1}}],[\"∑k=1n​exk​\",{\"2\":{\"123\":2}}],[\"∑k=1nexk\",{\"2\":{\"123\":2}}],[\"∑xt​​p\",{\"2\":{\"103\":2}}],[\"∑j=1mexp⁡\",{\"2\":{\"70\":1}}],[\"∑j=1ngradientj∗∂yj∂xi=∑j=1n∂yj∂xi=4xi\",{\"2\":{\"166\":1}}],[\"∑j=1n∂yj∂xi\",{\"2\":{\"166\":1}}],[\"∑j=1nexp⁡\",{\"2\":{\"51\":1,\"59\":1}}],[\"∑j=1nk\",{\"2\":{\"51\":1}}],[\"现在如果我们规定virtual\",{\"2\":{\"252\":1}}],[\"现在我们将使用卷积层的输出作为\",{\"2\":{\"229\":1}}],[\"现在业界的大模型都是基于transformer架构\",{\"2\":{\"212\":1}}],[\"现在主要有两种方式\",{\"2\":{\"169\":1}}],[\"现在假设有一个需求\",{\"2\":{\"154\":1}}],[\"现在有一个常见的假设\",{\"2\":{\"103\":1}}],[\"现代rnn\",{\"0\":{\"274\":1},\"1\":{\"277\":1,\"280\":1,\"283\":1,\"285\":1}}],[\"现代cpp的一些特性\",{\"0\":{\"98\":1},\"1\":{\"112\":1,\"125\":1,\"139\":1,\"154\":1,\"168\":1,\"182\":1,\"194\":1,\"211\":1,\"224\":1}}],[\"现代的moe会设置shared\",{\"2\":{\"61\":1}}],[\"现代卷积神经网络\",{\"0\":{\"46\":1},\"1\":{\"54\":1,\"63\":1,\"75\":1,\"86\":1,\"96\":1,\"109\":1}}],[\"由语言模型给出\",{\"2\":{\"249\":1}}],[\"由两个线性层组成\",{\"2\":{\"225\":1}}],[\"由os调度\",{\"2\":{\"163\":1}}],[\"由于我们每次采样的小批量数据形状为二维张量\",{\"2\":{\"255\":1}}],[\"由于bwd耗时往往为fwd的两倍\",{\"2\":{\"252\":1,\"263\":1}}],[\"由于历史原因\",{\"2\":{\"249\":1}}],[\"由于序列长度为\",{\"2\":{\"202\":2}}],[\"由于序列数据本质上是连续的\",{\"2\":{\"162\":1}}],[\"由于查询\",{\"2\":{\"186\":1}}],[\"由于cpp中的继承重写有诸多限制\",{\"2\":{\"182\":1}}],[\"由于求导的线性特性\",{\"2\":{\"166\":1}}],[\"由于链接文字可能包含空白\",{\"2\":{\"113\":1}}],[\"由于\",{\"2\":{\"103\":1,\"272\":1}}],[\"由此得知卷积层的权重也应该调整为\",{\"2\":{\"82\":1}}],[\"由此我们就得到了每次参数的变化公式\",{\"2\":{\"78\":1}}],[\"设模型参数为\",{\"2\":{\"246\":1}}],[\"设计字符级rnn模型\",{\"0\":{\"241\":1}}],[\"设计模型\",{\"2\":{\"103\":1}}],[\"设置为评估模式\",{\"2\":{\"247\":1}}],[\"设置卷积层输入为\",{\"2\":{\"229\":1}}],[\"设置transpose\",{\"2\":{\"91\":1}}],[\"设\",{\"2\":{\"103\":1,\"166\":1}}],[\"之间的传输\",{\"2\":{\"273\":1}}],[\"之间\",{\"2\":{\"268\":1}}],[\"之前gpu0的layer\",{\"2\":{\"252\":1}}],[\"之外的时间点我们认为其实是没有很大必要的\",{\"2\":{\"103\":1}}],[\"之后wait\",{\"2\":{\"252\":1}}],[\"之后计算一个backward\",{\"2\":{\"252\":1}}],[\"之后将介绍\",{\"2\":{\"247\":1,\"277\":1}}],[\"之后input\",{\"2\":{\"213\":1}}],[\"之后再完善\",{\"2\":{\"175\":1}}],[\"之后settings\",{\"2\":{\"169\":1}}],[\"之后这段代码使得x0x\",{\"2\":{\"151\":1}}],[\"之后逐一分配下标\",{\"2\":{\"117\":1}}],[\"之后附加文本来设置自定义标题\",{\"2\":{\"100\":1}}],[\"之后我们的目标其实就是随机钦定w0w\",{\"2\":{\"88\":1}}],[\"τ\",{\"2\":{\"103\":3}}],[\"想要预测股票所能依靠的信息只有\",{\"2\":{\"103\":1}}],[\"想象一下\",{\"2\":{\"103\":1}}],[\"天的价格\",{\"2\":{\"103\":1}}],[\"马尔科夫模型\",{\"0\":{\"103\":1}}],[\"至此我们就完成了从全连接到卷积层cnn的过渡\",{\"2\":{\"102\":1}}],[\"警告\",{\"2\":{\"100\":1}}],[\"错误检查\",{\"2\":{\"169\":1}}],[\"错误\",{\"2\":{\"100\":1,\"117\":1}}],[\"注释将会为该行相应的着色\",{\"2\":{\"100\":1}}],[\"注释将会为该行创建\",{\"2\":{\"100\":1}}],[\"注释将聚焦它并模糊代码的其他部分\",{\"2\":{\"100\":1}}],[\"注释实现行高亮\",{\"2\":{\"100\":1}}],[\"注意这里不需要\",{\"2\":{\"279\":1}}],[\"注意这些函数签名是写死的\",{\"2\":{\"224\":1}}],[\"注意内存占用\",{\"2\":{\"55\":1}}],[\"注意力头数\",{\"2\":{\"212\":1}}],[\"注意力权重函数\",{\"2\":{\"115\":1}}],[\"注意力模型\",{\"0\":{\"101\":1},\"1\":{\"115\":1,\"129\":1,\"143\":1,\"159\":1,\"173\":1,\"186\":1,\"202\":1}}],[\"注意力保留了自回归\",{\"2\":{\"87\":1}}],[\"注意力汇聚输出的形状为\",{\"2\":{\"81\":1}}],[\"注意力汇聚是\",{\"2\":{\"51\":1}}],[\"注意力评分\",{\"0\":{\"70\":1},\"1\":{\"81\":1,\"91\":1}}],[\"注意力分为自主性和非自主性的提示\",{\"2\":{\"43\":1}}],[\"注意力机制通过注意力汇聚\",{\"2\":{\"43\":1}}],[\"注意力机制简介\",{\"0\":{\"34\":1},\"1\":{\"43\":1,\"51\":1,\"59\":1,\"70\":1,\"81\":1,\"91\":1}}],[\"注意力机制\",{\"0\":{\"27\":1},\"1\":{\"34\":1,\"43\":1,\"51\":1,\"59\":1,\"70\":1,\"81\":1,\"91\":1,\"101\":1,\"115\":1,\"129\":1,\"143\":1,\"159\":1,\"173\":1,\"186\":1,\"202\":1}}],[\"`code`\",{\"2\":{\"228\":1}}],[\"`foo`\",{\"2\":{\"141\":1}}],[\"``\",{\"2\":{\"141\":5}}],[\"``there\",{\"2\":{\"141\":1}}],[\"```ts\",{\"2\":{\"100\":3}}],[\"```html\",{\"2\":{\"100\":1}}],[\"```md\",{\"2\":{\"100\":1}}],[\"````\",{\"2\":{\"79\":1}}],[\"````md\",{\"2\":{\"79\":1,\"100\":1}}],[\"```js\",{\"2\":{\"79\":2,\"100\":10}}],[\"```\",{\"2\":{\"79\":4,\"100\":15}}],[\"`printf\",{\"2\":{\"141\":1}}],[\"`options`\",{\"2\":{\"100\":1}}],[\"`highlighted\",{\"2\":{\"100\":2}}],[\"`\",{\"2\":{\"100\":28,\"141\":10,\"214\":1,\"228\":1}}],[\"多卡通信和记录日志的时间\",{\"2\":{\"268\":1}}],[\"多输出通道并不仅是学习多个单通道的检测器\",{\"2\":{\"187\":1}}],[\"多输出通道\",{\"0\":{\"187\":1},\"2\":{\"187\":1}}],[\"多输入通道\",{\"0\":{\"174\":1}}],[\"多输入和多输出通道\",{\"0\":{\"160\":1},\"1\":{\"174\":1,\"187\":1}}],[\"多头注意力融合了来自于多个注意力汇聚的不同知识\",{\"2\":{\"173\":1}}],[\"多头注意力的输出需要经过另一个线性变换\",{\"2\":{\"159\":1}}],[\"多头注意力\",{\"0\":{\"159\":1},\"1\":{\"173\":1},\"2\":{\"173\":1}}],[\"多元语法也同样满足齐普夫定律\",{\"2\":{\"145\":1}}],[\"多线程是受限于cil机制\",{\"2\":{\"231\":1}}],[\"多线程之间的线程切换也是一笔开销\",{\"2\":{\"231\":1}}],[\"多线程和协程\",{\"2\":{\"231\":1}}],[\"多线程\",{\"0\":{\"133\":1},\"1\":{\"147\":1,\"163\":1,\"177\":1,\"190\":1}}],[\"多个输入和输出通道使模型在每个空间位置可以获取图像的多方面特征\",{\"2\":{\"102\":1}}],[\"多个单行\",{\"2\":{\"100\":1}}],[\"多行与单行\",{\"2\":{\"100\":1}}],[\"多行\",{\"2\":{\"100\":2}}],[\"多层感知机mlp\",{\"0\":{\"64\":1}}],[\"合法的编程语言列表\",{\"2\":{\"100\":1}}],[\"行填充和\",{\"2\":{\"144\":1}}],[\"行高亮\",{\"2\":{\"114\":1}}],[\"行\",{\"2\":{\"114\":1}}],[\"行至第\",{\"2\":{\"114\":1}}],[\"行为可能带来的负面影响\",{\"2\":{\"100\":2}}],[\"行内图片的语法看起来像是\",{\"2\":{\"156\":1}}],[\"行内和参考两种形式\",{\"2\":{\"113\":1}}],[\"行内元素\",{\"0\":{\"99\":1},\"1\":{\"113\":1,\"127\":1,\"141\":1,\"156\":1,\"171\":1}}],[\"行内不能有其他东西\",{\"2\":{\"89\":1}}],[\"行内\",{\"0\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1},\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1,\"156\":1}}],[\"风格的警报\",{\"2\":{\"100\":2}}],[\"点积\",{\"2\":{\"130\":1}}],[\"点积的方差在不考虑向量长度的情况下仍然是1\",{\"2\":{\"91\":1}}],[\"点我查看代码\",{\"2\":{\"100\":2}}],[\"90+会有\",{\"2\":{\"260\":1}}],[\"99\",{\"2\":{\"199\":2}}],[\"98\",{\"2\":{\"181\":1,\"193\":1}}],[\"9\",{\"2\":{\"96\":1,\"100\":1,\"174\":1,\"181\":2,\"193\":2,\"220\":1,\"247\":1,\"252\":1}}],[\"96\",{\"2\":{\"75\":2,\"86\":3}}],[\"直接变为virtual\",{\"2\":{\"252\":1}}],[\"直接使用传入的移动平均所得的均值和方差\",{\"2\":{\"96\":1}}],[\"直观地说\",{\"2\":{\"187\":1}}],[\"直到生成\",{\"2\":{\"143\":1}}],[\"直到这里\",{\"2\":{\"71\":1}}],[\"直到找到j\",{\"2\":{\"67\":1}}],[\"五\",{\"0\":{\"96\":1,\"168\":1,\"271\":1}}],[\"元语法模型\",{\"2\":{\"217\":1}}],[\"元的离散型概率分布\",{\"2\":{\"95\":1}}],[\"元素个数为\",{\"2\":{\"272\":1}}],[\"元素添加属性\",{\"2\":{\"185\":1}}],[\"元素\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"属于该类别的分量为1\",{\"2\":{\"95\":1}}],[\"属性支持\",{\"0\":{\"185\":1}}],[\"属性为true\",{\"2\":{\"151\":1}}],[\"属性放到下一行\",{\"2\":{\"113\":1}}],[\"属性\",{\"2\":{\"87\":1,\"185\":2}}],[\"属性里\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"类型\",{\"2\":{\"150\":1}}],[\"类型推导\",{\"0\":{\"107\":1},\"1\":{\"122\":1,\"135\":1,\"150\":1}}],[\"类别\",{\"2\":{\"95\":1}}],[\"类似滑动窗口\",{\"2\":{\"103\":1}}],[\"类似于隐藏层\",{\"2\":{\"103\":1}}],[\"类似于rnn中将一些特殊词元忽略掉\",{\"2\":{\"70\":1}}],[\"类似的状况也会发生在\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"软性\",{\"2\":{\"95\":1}}],[\"鸡鸭鹅\",{\"2\":{\"95\":1}}],[\"语言底层实现了gmp机制\",{\"2\":{\"242\":1}}],[\"语言模型\",{\"0\":{\"131\":1},\"1\":{\"145\":1}}],[\"语义\",{\"0\":{\"94\":1,\"105\":1},\"1\":{\"104\":1,\"118\":1,\"119\":1,\"132\":1,\"146\":1}}],[\"语法相关的文件\",{\"2\":{\"79\":1}}],[\"语法撰写\",{\"2\":{\"79\":1}}],[\"语法不会被转换\",{\"2\":{\"79\":1}}],[\"语法\",{\"2\":{\"57\":1}}],[\"语法中\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"语法在\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"语法受到一些既有\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"同步机制\",{\"0\":{\"276\":1},\"1\":{\"279\":1,\"282\":1}}],[\"同上\",{\"2\":{\"191\":1}}],[\"同形状的全1张量作为梯度权重\",{\"2\":{\"166\":1}}],[\"同形状的gradient参数来计算\",{\"2\":{\"166\":1}}],[\"同理\",{\"2\":{\"108\":1,\"151\":1}}],[\"同样也允许两种样式\",{\"2\":{\"156\":1}}],[\"同样支持以标注的方式渲染\",{\"2\":{\"100\":1}}],[\"同样\",{\"2\":{\"93\":1}}],[\"同时\",{\"2\":{\"247\":1}}],[\"同时也提供了aync方法\",{\"2\":{\"273\":1}}],[\"同时也支持其他属性\",{\"2\":{\"185\":1}}],[\"同时也会有上面\",{\"2\":{\"122\":1}}],[\"同时也为学好cuda打下基础\",{\"2\":{\"1\":1}}],[\"同时保留代码块的颜色\",{\"2\":{\"100\":1}}],[\"同时收敛稳定\",{\"2\":{\"88\":1}}],[\"大模型在训练过程中通常采用混合精度训练\",{\"2\":{\"272\":1}}],[\"大模型量化简介\",{\"0\":{\"221\":1},\"1\":{\"233\":1,\"244\":1,\"251\":1,\"257\":1,\"262\":1,\"267\":1,\"271\":1}}],[\"大头在计算\",{\"2\":{\"252\":1}}],[\"大括号\",{\"2\":{\"214\":1}}],[\"大概浏览了一下summary\",{\"2\":{\"158\":1}}],[\"大约增加\",{\"2\":{\"151\":1}}],[\"大多数的数据并非如此\",{\"2\":{\"93\":1}}],[\"大小为\",{\"2\":{\"272\":3}}],[\"大小\",{\"2\":{\"82\":1}}],[\"卷积的本质是有效提取相邻像素之间的特征\",{\"2\":{\"203\":1}}],[\"卷积的形状取决于输入形状和卷积核的形状\",{\"2\":{\"144\":1}}],[\"卷积核为\",{\"2\":{\"174\":1}}],[\"卷积核的高度和宽度均为2\",{\"2\":{\"144\":1}}],[\"卷积核shape\",{\"2\":{\"130\":1}}],[\"卷积核窗口其实就是从左上角到右下角的一个滑动窗口\",{\"2\":{\"130\":1}}],[\"卷积神经网络\",{\"2\":{\"102\":1}}],[\"卷积神经网络cnn\",{\"0\":{\"35\":1},\"1\":{\"44\":1,\"52\":1,\"60\":1,\"71\":1,\"82\":1,\"92\":1,\"102\":1,\"116\":1,\"130\":1,\"144\":1,\"160\":1,\"174\":1,\"187\":1,\"203\":1,\"216\":1,\"229\":1,\"239\":1,\"247\":1}}],[\"卷积层仍然可以识别到模式\",{\"2\":{\"229\":1}}],[\"卷积层的输出都不会受到影响\",{\"2\":{\"130\":1}}],[\"卷积层其实是一个错误的叫法\",{\"2\":{\"130\":1}}],[\"卷积层通常比全连接层需要更少的参数\",{\"2\":{\"102\":1}}],[\"卷积层\",{\"2\":{\"96\":1,\"203\":1}}],[\"卷积层有时被称为特征映射\",{\"2\":{\"92\":1}}],[\"评分函数为\",{\"2\":{\"91\":1}}],[\"则默认为0\",{\"2\":{\"283\":1}}],[\"则会被转成\",{\"2\":{\"127\":1}}],[\"则缩放点积注意力\",{\"2\":{\"91\":1}}],[\"则该行也会被视为空行\",{\"2\":{\"40\":1}}],[\"缩放点积注意力\",{\"0\":{\"91\":1},\"2\":{\"91\":1}}],[\"缩小一下通道数\",{\"2\":{\"63\":1}}],[\"默认标题\",{\"0\":{\"90\":1}}],[\"随后会再使用cuda写一遍\",{\"2\":{\"197\":1}}],[\"随着\",{\"2\":{\"275\":2}}],[\"随着层叠的上升\",{\"2\":{\"247\":1}}],[\"随着神经网络层数的加深\",{\"2\":{\"187\":1}}],[\"随着我工作的时间变久\",{\"2\":{\"2\":1}}],[\"随机的\",{\"2\":{\"176\":1}}],[\"随机范围包括num\",{\"2\":{\"176\":1}}],[\"随机采样\",{\"0\":{\"176\":1}}],[\"随机梯度下降\",{\"2\":{\"88\":1}}],[\"没有优化器状态和梯度\",{\"2\":{\"253\":1}}],[\"没有过多的异常值的类型\",{\"2\":{\"251\":1}}],[\"没有限定上下界\",{\"2\":{\"108\":1}}],[\"没有除以样本\",{\"2\":{\"88\":1}}],[\"没有局部性\",{\"2\":{\"82\":1}}],[\"损失函数的标量进行\",{\"2\":{\"285\":1}}],[\"损失函数会如何变化\",{\"2\":{\"180\":1}}],[\"损失函数是一个标量\",{\"2\":{\"180\":1}}],[\"损失函数这里采取上文所述的交叉熵\",{\"2\":{\"152\":1}}],[\"损失函数\",{\"0\":{\"137\":1},\"2\":{\"88\":1}}],[\"损失函数可以定义为\",{\"2\":{\"48\":1}}],[\"称之为\",{\"2\":{\"103\":1}}],[\"称之为线性回归模型linreg\",{\"2\":{\"88\":1}}],[\"称为编码器\",{\"2\":{\"87\":1}}],[\"批次大小\",{\"2\":{\"275\":1}}],[\"批次返回\",{\"2\":{\"88\":1}}],[\"批量导入数据\",{\"2\":{\"103\":1}}],[\"批量规范化是一种流行且有效的技术\",{\"2\":{\"96\":1}}],[\"批量大小\",{\"2\":{\"81\":2,\"130\":1,\"255\":4,\"277\":2}}],[\"批量矩阵乘法\",{\"2\":{\"59\":1}}],[\"真实的参数\",{\"2\":{\"88\":1}}],[\"已经在上一章attention机制中讲过了\",{\"2\":{\"87\":1}}],[\"已经广泛使用\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"确保预测仅依赖于已生成的输出词元\",{\"2\":{\"87\":1}}],[\"层数不变\",{\"2\":{\"252\":1}}],[\"层之后\",{\"2\":{\"236\":1}}],[\"层\",{\"2\":{\"87\":1}}],[\"层的输入为\",{\"2\":{\"278\":1}}],[\"层的\",{\"2\":{\"55\":1}}],[\"除非是const左值\",{\"2\":{\"150\":1}}],[\"除非他们被用于初始化引用\",{\"2\":{\"122\":1}}],[\"除了模型参数\",{\"2\":{\"272\":1}}],[\"除了单行之外\",{\"2\":{\"100\":1}}],[\"除了编码器中描述的两个子层之外\",{\"2\":{\"87\":1}}],[\"除此之外\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"紧接着应用层规范化\",{\"2\":{\"87\":1}}],[\"受限于cpython\",{\"2\":{\"231\":1}}],[\"受\",{\"2\":{\"87\":1}}],[\"汇聚窗口形状为\",{\"2\":{\"229\":1}}],[\"汇聚层的主要优点之一是减轻卷积层对位置的过度敏感\",{\"2\":{\"239\":1}}],[\"汇聚层的输出通道数与输入通道数相同\",{\"2\":{\"229\":1,\"239\":1}}],[\"汇聚层在每个输入通道上单独计算\",{\"2\":{\"229\":1}}],[\"汇聚层也会有填充和步幅\",{\"2\":{\"229\":1}}],[\"汇聚层始终输出\",{\"2\":{\"229\":1}}],[\"汇聚层输出为\",{\"2\":{\"229\":1}}],[\"汇聚层不包含参数\",{\"2\":{\"229\":1}}],[\"汇聚层运算符由一个固定形状的窗口组成\",{\"2\":{\"229\":1}}],[\"汇聚层pooling\",{\"0\":{\"216\":1},\"1\":{\"229\":1,\"239\":1},\"2\":{\"229\":1}}],[\"汇聚\",{\"2\":{\"87\":1,\"229\":1}}],[\"四\",{\"0\":{\"86\":1,\"154\":1,\"247\":1,\"267\":1},\"1\":{\"271\":1}}],[\"什么是模型量化\",{\"0\":{\"233\":1}}],[\"什么是softmax\",{\"0\":{\"85\":1},\"1\":{\"95\":1,\"108\":1,\"123\":1,\"137\":1}}],[\"什么是线性回归\",{\"0\":{\"48\":1}}],[\"颜色等\",{\"2\":{\"82\":1}}],[\"外表\",{\"2\":{\"82\":1}}],[\"外部链接带有\",{\"2\":{\"41\":1}}],[\"外部链接\",{\"0\":{\"41\":1}}],[\"第三项和第四项可以预先计算得出\",{\"2\":{\"271\":1}}],[\"第三维就是时间\",{\"2\":{\"230\":1}}],[\"第三维就是颜色\",{\"2\":{\"82\":1}}],[\"第一项其实就是sym量化\",{\"2\":{\"271\":1}}],[\"第一步总是先求scale\",{\"2\":{\"262\":1}}],[\"第一个轴对应于时间步\",{\"2\":{\"283\":1}}],[\"第一个卷积层使用2个像素的填充\",{\"2\":{\"247\":1}}],[\"第一个线性层保存其输入\",{\"2\":{\"272\":1}}],[\"第一个线性层\",{\"2\":{\"259\":1}}],[\"第一个线性层拥有权重矩阵\",{\"2\":{\"225\":1}}],[\"第一个线性层维度将\",{\"2\":{\"225\":1}}],[\"第一个子层是多头自注意力\",{\"2\":{\"87\":1}}],[\"第1维变成第0维\",{\"2\":{\"220\":1}}],[\"第\",{\"2\":{\"145\":1}}],[\"第二项就为0\",{\"2\":{\"271\":1}}],[\"第二维只取第一列\",{\"2\":{\"232\":1}}],[\"第二个线性层保存其输入\",{\"2\":{\"272\":1}}],[\"第二个线性层\",{\"2\":{\"259\":1}}],[\"第二个线性层再将维度从\",{\"2\":{\"225\":1}}],[\"第二个卷积层没有填充\",{\"2\":{\"247\":1}}],[\"第二个拥有权重矩阵\",{\"2\":{\"225\":1}}],[\"第二个子层是基于位置的前馈网络\",{\"2\":{\"87\":1}}],[\"第二阶标题\",{\"2\":{\"49\":1}}],[\"查询或者\",{\"2\":{\"173\":6}}],[\"查询来自前一个解码器层的输出\",{\"2\":{\"87\":1}}],[\"查询的步数\",{\"2\":{\"81\":1}}],[\"查询的个数\",{\"2\":{\"81\":4,\"91\":2,\"173\":3}}],[\"查询\",{\"2\":{\"81\":1,\"87\":2}}],[\"查询个数\",{\"2\":{\"59\":3}}],[\"超参数为\",{\"2\":{\"81\":1}}],[\"当前生成的词依赖于之前已经生成的词\",{\"2\":{\"278\":1}}],[\"当前pp\",{\"2\":{\"252\":1}}],[\"当输入的token序列为\",{\"2\":{\"278\":1}}],[\"当输入包含多个通道时\",{\"2\":{\"174\":1}}],[\"当生成了一个token之后\",{\"2\":{\"278\":1}}],[\"当我们训练神经网络遇到显存不足oom\",{\"2\":{\"275\":1}}],[\"当我们生成一个常量对象时\",{\"2\":{\"118\":1}}],[\"当请求到来时\",{\"2\":{\"256\":1}}],[\"当你有一个向量或矩阵输出时\",{\"2\":{\"180\":1}}],[\"当做挖个坑吧\",{\"2\":{\"169\":1}}],[\"当给定相同的查询\",{\"2\":{\"159\":1}}],[\"当出现函数重载的时候\",{\"2\":{\"118\":1}}],[\"当\",{\"2\":{\"103\":1,\"236\":1}}],[\"当一个特征图中的任意元素需要检测更广区域的输入特征时\",{\"2\":{\"92\":1}}],[\"当查询和键是不同长度的向量时\",{\"2\":{\"81\":1}}],[\"当然其本身的调度也很优秀\",{\"2\":{\"263\":1}}],[\"当然也可以向量化ld\",{\"2\":{\"254\":1}}],[\"当然也可以精细化设置\",{\"2\":{\"229\":1}}],[\"当然也可以单独设置\",{\"2\":{\"144\":1}}],[\"当然对于ffn层后也会有一层layer\",{\"2\":{\"225\":1}}],[\"当然这里只讨论补全和check\",{\"2\":{\"169\":1}}],[\"当然你如果有第三方库或者项目内头文件目录的依赖\",{\"2\":{\"169\":1}}],[\"当然不光是返回值\",{\"2\":{\"150\":1}}],[\"当然要保证input\",{\"2\":{\"140\":1}}],[\"当然我们也可以追求对象和指针同时不可变\",{\"2\":{\"104\":1}}],[\"当然\",{\"2\":{\"61\":1,\"68\":2,\"88\":1,\"229\":1}}],[\"增加到第一个卷积层之后的6个\",{\"2\":{\"247\":1}}],[\"增加一个\",{\"2\":{\"151\":1}}],[\"增长最快的地方\",{\"2\":{\"78\":1}}],[\"增强版中比较有名的有\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"指的是\",{\"2\":{\"272\":1}}],[\"指的是cpp会自己生成的函数\",{\"2\":{\"224\":1}}],[\"指令\",{\"2\":{\"248\":1}}],[\"指定一个长度可变的输入\",{\"2\":{\"280\":1}}],[\"指定输入输出通道\",{\"2\":{\"130\":1}}],[\"指定kernel\",{\"2\":{\"130\":1}}],[\"指定代码语言\",{\"2\":{\"114\":1}}],[\"指针本身不可变\",{\"2\":{\"104\":1}}],[\"指针指向的对象是常量\",{\"2\":{\"104\":1}}],[\"指向的是\",{\"2\":{\"78\":1}}],[\"指模型计算时所需访问内存\",{\"2\":{\"55\":1}}],[\"得出的梯度是一个二维向量\",{\"2\":{\"78\":1}}],[\"得到一个标量\",{\"2\":{\"166\":1}}],[\"得到encoder的隐状态序列\",{\"2\":{\"129\":1}}],[\"得到\",{\"2\":{\"71\":1}}],[\"求映射就可以了\",{\"2\":{\"262\":1}}],[\"求平均值\",{\"2\":{\"191\":1}}],[\"求和\",{\"2\":{\"166\":1,\"174\":1}}],[\"求导\",{\"2\":{\"78\":1}}],[\"求方差\",{\"2\":{\"38\":1}}],[\"求方差时\",{\"2\":{\"38\":1}}],[\"上文中说到\",{\"2\":{\"282\":1}}],[\"上文讲到一次前向传递中\",{\"2\":{\"268\":1}}],[\"上文提到\",{\"2\":{\"256\":1}}],[\"上图中\",{\"2\":{\"252\":1}}],[\"上述计算量为\",{\"2\":{\"259\":1}}],[\"上述配置在我自己的centos\",{\"2\":{\"169\":1}}],[\"上述是一维函数举例\",{\"2\":{\"78\":1}}],[\"上下角标\",{\"0\":{\"157\":1}}],[\"上一个时间步生成的单词作为下一时间步的输入\",{\"2\":{\"143\":1}}],[\"上面我们介绍了encoder\",{\"2\":{\"283\":1}}],[\"上面两种写法都会产生下面的\",{\"2\":{\"113\":1}}],[\"上面介绍了注意力汇聚的建模方式\",{\"2\":{\"70\":1}}],[\"上面的列表所产生的\",{\"2\":{\"68\":1}}],[\"梯度和优化器的显存\",{\"2\":{\"275\":1}}],[\"梯度和优化器状态的显存占用\",{\"2\":{\"246\":1}}],[\"梯度\",{\"2\":{\"272\":1}}],[\"梯度爆炸的现象\",{\"2\":{\"266\":1}}],[\"梯度裁剪\",{\"0\":{\"266\":1}}],[\"梯度清零\",{\"2\":{\"207\":1}}],[\"梯度操作\",{\"0\":{\"207\":1}}],[\"梯度在机器学习很重要\",{\"2\":{\"151\":1}}],[\"梯度的计算一般是依赖pytorch的自动微分\",{\"2\":{\"136\":1}}],[\"梯度消失现象会很严重\",{\"2\":{\"123\":1}}],[\"梯度计算\",{\"0\":{\"123\":1}}],[\"梯度肯定是一个和自变量维数等同的向量\",{\"2\":{\"78\":1}}],[\"梯度向量对应着增长最快的方向\",{\"2\":{\"78\":1}}],[\"梯度下降计算函数sgd\",{\"2\":{\"88\":1}}],[\"梯度下降法其实就是用来计算函数最小值的\",{\"2\":{\"67\":1}}],[\"梯度下降\",{\"0\":{\"56\":1},\"1\":{\"67\":1,\"78\":1,\"88\":1}}],[\"通用寄存器\",{\"2\":{\"248\":1}}],[\"通用引用会进行类型推导\",{\"2\":{\"119\":1}}],[\"通信复杂\",{\"2\":{\"190\":1}}],[\"通篇读下来\",{\"2\":{\"170\":1}}],[\"通常会尝试减小批次大小来避免显存不足的问题\",{\"2\":{\"275\":1}}],[\"通常会选择可以表示这个enum的最小类型\",{\"2\":{\"154\":1}}],[\"通常比较大\",{\"2\":{\"272\":1}}],[\"通常当我们处理图像时\",{\"2\":{\"216\":1}}],[\"通常需要一个标量\",{\"2\":{\"207\":1}}],[\"通常这些块我们并不希望它以一般段落文件的方式去排版\",{\"2\":{\"79\":1}}],[\"通道的数量从输入时的1个\",{\"2\":{\"247\":1}}],[\"通道\",{\"0\":{\"82\":1},\"2\":{\"82\":1,\"130\":1}}],[\"通俗易懂的ppo解析\",{\"2\":{\"77\":1}}],[\"通过控制sm数量和高效的all2all\",{\"2\":{\"263\":1}}],[\"通过划分micro\",{\"2\":{\"252\":1}}],[\"通过output\",{\"2\":{\"225\":1}}],[\"通过同步代码的方式写异步\",{\"2\":{\"219\":1}}],[\"通过协程的方式管理并发\",{\"2\":{\"219\":1}}],[\"通过以上两种方式\",{\"2\":{\"188\":1}}],[\"通过减少空间分辨率以获得更大的通道深度\",{\"2\":{\"187\":1}}],[\"通过将输出转换为标量\",{\"2\":{\"180\":1}}],[\"通过\",{\"2\":{\"169\":1}}],[\"通过编写cmakelists\",{\"2\":{\"169\":1}}],[\"通过一个rnn逐步处理嵌入\",{\"2\":{\"129\":1}}],[\"通过使用tanh作为激活函数\",{\"2\":{\"81\":1}}],[\"通过学习图像本身的空间特征\",{\"2\":{\"71\":1}}],[\"通过在最后一个轴上掩蔽元素来执行softmax操作\",{\"2\":{\"70\":1}}],[\"通过层与层之间的叠加来实现最终整个图像的识别\",{\"2\":{\"60\":1}}],[\"通过矩阵变换\",{\"2\":{\"52\":1}}],[\"通过简单的标记语法\",{\"2\":{\"5\":1}}],[\"三者中的其中两者不是瓶颈的时候\",{\"2\":{\"158\":1}}],[\"三种原色\",{\"2\":{\"82\":1}}],[\"三\",{\"0\":{\"75\":1,\"139\":1,\"146\":1,\"150\":1,\"193\":1,\"216\":1,\"250\":1,\"257\":1,\"274\":1,\"281\":1},\"1\":{\"229\":1,\"239\":1,\"256\":1,\"262\":1,\"277\":1,\"280\":1,\"283\":1,\"284\":1,\"285\":1,\"286\":1}}],[\"匹配度\",{\"2\":{\"72\":1}}],[\"作者通过实验提出来了当\",{\"2\":{\"158\":1}}],[\"作用有如下\",{\"2\":{\"154\":1}}],[\"作用是获取类型\",{\"2\":{\"150\":1}}],[\"作用是提供类内部属性的安全访问\",{\"2\":{\"118\":1}}],[\"作用是对于每个结果都会经过共享的experts\",{\"2\":{\"72\":1}}],[\"作为另外一个rnn的初始隐状态\",{\"2\":{\"283\":1}}],[\"作为model\",{\"2\":{\"222\":1}}],[\"作为mlsys方向的必不可少的语言\",{\"2\":{\"1\":1}}],[\"作为下一个节点的grad\",{\"2\":{\"140\":1}}],[\"作为标记强调字词的符号\",{\"2\":{\"127\":1}}],[\"作为查询\",{\"2\":{\"115\":1}}],[\"作为一个股票预测员\",{\"2\":{\"103\":1}}],[\"作为内部链接的目标\",{\"2\":{\"32\":1}}],[\"作为底层的算子\",{\"2\":{\"1\":1}}],[\"δt\",{\"2\":{\"137\":2}}],[\"δ\",{\"2\":{\"71\":1,\"151\":1}}],[\"定值\",{\"2\":{\"71\":1}}],[\"定义rnn计算层\",{\"2\":{\"255\":1}}],[\"定义一个通用的schedule基类\",{\"2\":{\"213\":1}}],[\"定义一个层\",{\"2\":{\"88\":1}}],[\"定义模型以及损失函数\",{\"2\":{\"152\":1}}],[\"定义模型参数\",{\"2\":{\"152\":1}}],[\"定义w2对象\",{\"2\":{\"112\":1}}],[\"定义要聚焦的行数\",{\"2\":{\"100\":1}}],[\"定义初始值w\",{\"2\":{\"88\":1}}],[\"定义学习率\",{\"2\":{\"63\":1}}],[\"定义块的数量和通道\",{\"2\":{\"63\":1}}],[\"∀c∈r\",{\"2\":{\"108\":1}}],[\"∀c∈rsoftmax\",{\"2\":{\"108\":1}}],[\"∀\",{\"2\":{\"71\":2}}],[\"实际应用\",{\"0\":{\"267\":1},\"1\":{\"271\":1}}],[\"实际上也离不开量化最基础的步骤\",{\"2\":{\"223\":1}}],[\"实际上不依赖于\",{\"2\":{\"71\":1}}],[\"实际进行的计算为\",{\"2\":{\"166\":1}}],[\"实现一个\",{\"2\":{\"234\":1}}],[\"实现一些高效的gpu算子\",{\"2\":{\"140\":1}}],[\"实现真正意义上的并行只能通过多进程的方式\",{\"2\":{\"190\":1}}],[\"实现各个核的负载均衡\",{\"2\":{\"163\":1}}],[\"实现softmax操作\",{\"2\":{\"152\":1}}],[\"实现通用引用\",{\"2\":{\"150\":1}}],[\"实现计算操作\",{\"2\":{\"140\":1}}],[\"实现\",{\"0\":{\"116\":1,\"173\":1,\"255\":1},\"1\":{\"130\":1,\"144\":1,\"160\":1,\"174\":1,\"187\":1,\"203\":1,\"261\":1}}],[\"实现多头但是只有一次矩阵乘法\",{\"2\":{\"97\":1}}],[\"实体中使用\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"实体\",{\"2\":{\"24\":3,\"36\":3,\"37\":3,\"42\":3,\"79\":1,\"141\":1,\"199\":1}}],[\"权重参数变为了\",{\"2\":{\"71\":1}}],[\"代码目前如下\",{\"2\":{\"152\":1}}],[\"代码码区段的起始和结束端都可以放入一个空白\",{\"2\":{\"141\":1}}],[\"代码\",{\"0\":{\"141\":1}}],[\"代码中出现很多io操作\",{\"2\":{\"133\":1}}],[\"代码语言会根据文件扩展名进行推断\",{\"2\":{\"114\":1}}],[\"代码组\",{\"2\":{\"100\":1}}],[\"代码执行的操作不会被记录在计算图中\",{\"2\":{\"88\":1}}],[\"代码块中的颜色差异\",{\"2\":{\"100\":1}}],[\"代码块中的语法高亮\",{\"2\":{\"100\":1}}],[\"代码块中聚焦\",{\"2\":{\"100\":1}}],[\"代码块中使用彩色文本实现语法高亮\",{\"2\":{\"100\":1}}],[\"代码块中\",{\"2\":{\"79\":1,\"100\":1}}],[\"代码块\",{\"0\":{\"79\":1}}],[\"代码块等\",{\"2\":{\"57\":1}}],[\"代价就是\",{\"2\":{\"71\":1}}],[\"代表\",{\"2\":{\"283\":1}}],[\"代表的是一个卷积核啥时候可以覆盖到两个词元\",{\"2\":{\"202\":1}}],[\"代表的t是一个指向t对象的指针\",{\"2\":{\"104\":1}}],[\"代表一次训练十张图片\",{\"2\":{\"152\":1}}],[\"代表一个方向\",{\"2\":{\"78\":1}}],[\"代表丢弃了某些采样点\",{\"2\":{\"144\":1}}],[\"代表我们需要训练的权重参数\",{\"2\":{\"71\":1}}],[\"代表偏置参数\",{\"2\":{\"71\":1}}],[\"应该具有相同的结构\",{\"2\":{\"71\":1}}],[\"应用笔记\",{\"2\":{\"1\":1}}],[\"首先会进入embedding\",{\"2\":{\"283\":1}}],[\"首先设第\",{\"2\":{\"278\":1}}],[\"首先要明确\",{\"2\":{\"278\":1}}],[\"首先要生成数据\",{\"2\":{\"88\":1}}],[\"首先将y的形状改为\",{\"2\":{\"277\":1}}],[\"首先输入的x和目标y\",{\"2\":{\"270\":1}}],[\"首先是with\",{\"2\":{\"269\":1}}],[\"首先是均匀量化\",{\"2\":{\"251\":1}}],[\"首先来看kittens中实现的最基础的async\",{\"2\":{\"265\":1}}],[\"首先如果\",{\"2\":{\"264\":1}}],[\"首先对于\",{\"2\":{\"259\":1}}],[\"首先介绍均匀量化\",{\"2\":{\"257\":1}}],[\"首先准备数据\",{\"2\":{\"255\":1}}],[\"首先需要理解gpipe中的native\",{\"2\":{\"252\":1}}],[\"首先定义\",{\"2\":{\"212\":1}}],[\"首先定义一个函数f\",{\"2\":{\"151\":1}}],[\"首先\",{\"2\":{\"131\":1}}],[\"首先造一个数据\",{\"2\":{\"130\":1}}],[\"首先它的输入是一个\",{\"2\":{\"123\":1}}],[\"首先我们会将输入矩阵quant成int8类型的矩阵\",{\"2\":{\"267\":1}}],[\"首先我们实现评估函数\",{\"2\":{\"247\":1}}],[\"首先我们设定输入和输出\",{\"2\":{\"241\":1}}],[\"首先我们需要选择量化的粒度\",{\"2\":{\"257\":1}}],[\"首先我们需要明确两个点\",{\"2\":{\"213\":1}}],[\"首先我们需要设置\",{\"2\":{\"169\":1}}],[\"首先我们来实现一下scheduler\",{\"2\":{\"197\":1}}],[\"首先我们的第一想法就是直接计算词元在语料库中出现的频率\",{\"2\":{\"131\":1}}],[\"首先我们将通道设为1\",{\"2\":{\"130\":1}}],[\"首先我们读取数据集\",{\"2\":{\"117\":1}}],[\"首先我们输入一个二维图像\",{\"2\":{\"71\":1}}],[\"首先假设现在有三个类别\",{\"2\":{\"95\":1}}],[\"首先引入上述第一个原则不变性\",{\"2\":{\"71\":1}}],[\"首先引入掩蔽softmax操作\",{\"2\":{\"70\":1}}],[\"​+t\",{\"2\":{\"278\":1}}],[\"​+x\",{\"2\":{\"278\":1}}],[\"​←concat\",{\"2\":{\"278\":2}}],[\"​⋅w1​\",{\"2\":{\"278\":2}}],[\"​⋅wo\",{\"2\":{\"278\":2}}],[\"​t​​⋅xv\",{\"2\":{\"278\":1}}],[\"​xk\",{\"2\":{\"278\":2}}],[\"​v\",{\"2\":{\"159\":1}}],[\"​k\",{\"2\":{\"159\":1}}],[\"​q\",{\"2\":{\"159\":1}}],[\"​i=ji=j​\",{\"2\":{\"123\":1}}],[\"​∂xj​∂pi​​∂xj​∂​∑k=1n​exk​exi​​\",{\"2\":{\"123\":1}}],[\"​∂xj​∂pi​​∂xi​∂​∑k=1n​exk​exi​​\",{\"2\":{\"123\":1}}],[\"​​const左值引用\",{\"2\":{\"119\":1}}],[\"​​右值引用\",{\"2\":{\"119\":1}}],[\"​\",{\"2\":{\"115\":1,\"262\":3,\"278\":19}}],[\"​=softmax\",{\"2\":{\"278\":1}}],[\"​=softmax​h​xq\",{\"2\":{\"278\":1}}],[\"​=t\",{\"2\":{\"278\":1}}],[\"​=t=1∑t​α\",{\"2\":{\"115\":1}}],[\"​=x\",{\"2\":{\"278\":3}}],[\"​=xt​∑​p\",{\"2\":{\"103\":1}}],[\"​=p−onehot\",{\"2\":{\"137\":1}}],[\"​=p\",{\"2\":{\"103\":1}}],[\"​=θi​−αdθi​d​j\",{\"2\":{\"88\":1}}],[\"​∈rpv​∗dv​\",{\"2\":{\"159\":1}}],[\"​∈rpk​∗dk​\",{\"2\":{\"159\":1}}],[\"​∈rpq​∗dq​\",{\"2\":{\"159\":1}}],[\"​∈r\",{\"2\":{\"70\":1}}],[\"​yi​\",{\"2\":{\"51\":2,\"59\":1}}],[\"∈rpo\",{\"2\":{\"159\":1}}],[\"∈rpk∗dk\",{\"2\":{\"159\":1}}],[\"∈rpq∗dq\",{\"2\":{\"159\":1}}],[\"∈rpv∗dv\",{\"2\":{\"159\":1}}],[\"∈rpv​\",{\"2\":{\"159\":1}}],[\"∈rpv\",{\"2\":{\"159\":1}}],[\"∈rn\",{\"2\":{\"108\":2}}],[\"∈rd\",{\"2\":{\"87\":1,\"186\":2}}],[\"∈rdsublayer\",{\"2\":{\"87\":1}}],[\"∈r\",{\"2\":{\"70\":1,\"81\":2}}],[\"再获得一个隐变量state\",{\"2\":{\"283\":1}}],[\"再次kittens\",{\"2\":{\"282\":1}}],[\"再次地\",{\"2\":{\"68\":1}}],[\"再下一轮的时候wait\",{\"2\":{\"252\":1}}],[\"再到第二个卷积层之后的16个\",{\"2\":{\"247\":1}}],[\"再算上output和embedding\",{\"2\":{\"236\":1}}],[\"再以对应该输出通道的卷积核计算出结果\",{\"2\":{\"187\":1}}],[\"再加上缩进就可以了\",{\"2\":{\"79\":1}}],[\"再经过softmax运算得到的\",{\"2\":{\"70\":1}}],[\"假定序列的动力学不变\",{\"2\":{\"103\":1}}],[\"假设中间激活值是以float16或bfloat16数据格式来保存的\",{\"2\":{\"272\":1}}],[\"假设来了1k请求\",{\"2\":{\"256\":1}}],[\"假设词表的大小为\",{\"2\":{\"255\":1}}],[\"假设数量为mmm\",{\"2\":{\"252\":1}}],[\"假设当前有两个共享变量\",{\"2\":{\"205\":1}}],[\"假设输入\",{\"2\":{\"202\":1}}],[\"假设输入的通道数是\",{\"2\":{\"174\":1}}],[\"假设输入序列中有\",{\"2\":{\"115\":1}}],[\"假设我们有一个一维张量\",{\"2\":{\"166\":1}}],[\"假设我们有一个查询\",{\"2\":{\"70\":1}}],[\"假设模型的任务是翻译为英语\",{\"2\":{\"115\":1}}],[\"假设查询和键的所有元素都是独立的随机变量\",{\"2\":{\"91\":1}}],[\"假如cpu\",{\"2\":{\"271\":1}}],[\"假如说最后计算完的矩阵的某个元素类型是int32\",{\"2\":{\"267\":1}}],[\"假如说一个序列满足一阶马尔科夫模型\",{\"2\":{\"103\":1}}],[\"假如现在基于\",{\"2\":{\"91\":1}}],[\"假如f\",{\"2\":{\"78\":1}}],[\"假如你有使用过电子邮件\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"空白和标点符号\",{\"2\":{\"113\":1}}],[\"空白\",{\"2\":{\"68\":1}}],[\"空行的定义是显示上看起来像是空行\",{\"2\":{\"40\":1}}],[\"句点\",{\"2\":{\"68\":1}}],[\"项目列表很可能会不小心产生\",{\"2\":{\"68\":1}}],[\"项目标记后面则一定要接着至少一个空白或\",{\"2\":{\"68\":1}}],[\"看起来会看好很多\",{\"2\":{\"68\":1}}],[\"看起来就像\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"会发现需要传入一个mbarrier\",{\"2\":{\"279\":1}}],[\"会发现我们的输入其实是在不断变大的\",{\"2\":{\"103\":1}}],[\"会经过如下的运算\",{\"2\":{\"271\":1}}],[\"会进入到fwd\",{\"2\":{\"263\":1}}],[\"会进行\",{\"2\":{\"259\":1}}],[\"会使用float32的优化器状态\",{\"2\":{\"246\":1}}],[\"会使用float16的模型参数进行前向传递和后向传递\",{\"2\":{\"246\":1}}],[\"会使用新添加的构造函数\",{\"2\":{\"112\":1}}],[\"会带来比较大的负担\",{\"2\":{\"231\":1}}],[\"会配备一个layer\",{\"2\":{\"225\":1}}],[\"会根据当前的配置选择适合的调度策略\",{\"2\":{\"213\":1}}],[\"会先做一个编码转换的过程\",{\"2\":{\"199\":1}}],[\"会将其重组\",{\"2\":{\"169\":1}}],[\"会引入一种机制\",{\"2\":{\"163\":1}}],[\"会引起整个系统重新编译\",{\"2\":{\"154\":1}}],[\"会更加敏感\",{\"2\":{\"151\":1}}],[\"会缩减采样次数\",{\"2\":{\"144\":1}}],[\"会把下面这段\",{\"2\":{\"141\":1}}],[\"会把项目的内容在输出时用\",{\"2\":{\"68\":1}}],[\"会创建节点\",{\"2\":{\"140\":3}}],[\"会遇到很多复杂的表述\",{\"2\":{\"139\":1}}],[\"会遇到参数过大导致训练困难以及过拟合的问题\",{\"2\":{\"52\":1}}],[\"会转为\",{\"2\":{\"199\":1}}],[\"会转成\",{\"2\":{\"127\":1,\"199\":1}}],[\"会转换成\",{\"2\":{\"79\":1}}],[\"会针对cpu或者gpu进行优化\",{\"2\":{\"126\":1}}],[\"会被推导为std\",{\"2\":{\"125\":1}}],[\"会被转换为\",{\"2\":{\"68\":2,\"79\":2}}],[\"会有更好的效果\",{\"2\":{\"168\":1}}],[\"会有\",{\"2\":{\"113\":1}}],[\"会有天然的优势\",{\"2\":{\"112\":1}}],[\"会忽略单引号包起来的链接\",{\"2\":{\"113\":1}}],[\"会产生\",{\"2\":{\"113\":1,\"141\":2}}],[\"会高亮显示近两个\",{\"2\":{\"100\":1}}],[\"会渲染为\",{\"2\":{\"79\":1}}],[\"会自动转成\",{\"2\":{\"79\":1}}],[\"会用\",{\"2\":{\"79\":1}}],[\"很明显地\",{\"2\":{\"156\":1}}],[\"很重要的一点是\",{\"2\":{\"68\":1}}],[\"很好的一篇文章\",{\"2\":{\"45\":1}}],[\"加载序列数据的迭代器\",{\"2\":{\"188\":1}}],[\"加性注意力\",{\"0\":{\"81\":1},\"2\":{\"81\":1}}],[\"加号\",{\"2\":{\"68\":1,\"214\":1}}],[\"加速ai模型的推理速度\",{\"0\":{\"47\":1}}],[\"递减\",{\"2\":{\"67\":1}}],[\"钦定θ0\",{\"2\":{\"67\":1}}],[\"非均匀量化\",{\"2\":{\"251\":1}}],[\"非对称量化\",{\"2\":{\"251\":1}}],[\"非常厉害\",{\"2\":{\"170\":1}}],[\"非模型参数的变量初始化为0和1\",{\"2\":{\"96\":1}}],[\"非凸的局部最小值\",{\"2\":{\"67\":1}}],[\"非参数的模型收敛其实取决于key的数目\",{\"2\":{\"59\":1}}],[\"非参数注意力汇聚\",{\"0\":{\"51\":1}}],[\"来做reduce\",{\"2\":{\"265\":1}}],[\"来预取\",{\"2\":{\"265\":1}}],[\"来预测每个类的概率\",{\"2\":{\"137\":1}}],[\"来预测下一个时间点的值\",{\"2\":{\"103\":1}}],[\"来等待异步操作完成\",{\"2\":{\"265\":1}}],[\"来完成overlap\",{\"2\":{\"263\":1}}],[\"来达到每个warpgroup出一个warp来load的目的\",{\"2\":{\"260\":1}}],[\"来补偿卷积核导致的特征减少\",{\"2\":{\"247\":1}}],[\"来扩大语法模型\",{\"2\":{\"217\":1}}],[\"来实现的\",{\"2\":{\"213\":1}}],[\"来禁止某些矛盾的结果\",{\"2\":{\"205\":1}}],[\"来让triton帮我们选择吞吐最高的超参数\",{\"2\":{\"197\":1}}],[\"来调整网络参数\",{\"2\":{\"180\":1}}],[\"来自两个相邻的\",{\"2\":{\"176\":1}}],[\"来自于所有先前层\",{\"2\":{\"92\":1}}],[\"来计算\",{\"2\":{\"166\":1}}],[\"来计算梯度\",{\"2\":{\"151\":1}}],[\"来变换查询\",{\"2\":{\"159\":1}}],[\"来洞察\",{\"2\":{\"151\":1}}],[\"来\",{\"2\":{\"150\":1}}],[\"来使用梯度下降方法训练模型\",{\"2\":{\"137\":1}}],[\"来进行计算\",{\"2\":{\"133\":1}}],[\"来标记\",{\"2\":{\"113\":1}}],[\"来初始化\",{\"2\":{\"112\":1}}],[\"来求解jjj的最小值\",{\"2\":{\"88\":1}}],[\"来获得它的最小值\",{\"2\":{\"67\":1}}],[\"来说\",{\"2\":{\"55\":1,\"213\":1}}],[\"滚去\",{\"2\":{\"67\":1}}],[\"谷底\",{\"2\":{\"67\":1}}],[\"球\",{\"2\":{\"67\":1}}],[\"静态显存管理\",{\"2\":{\"66\":1}}],[\"说出加速resnet50推理速度的一些手段\",{\"0\":{\"66\":1}}],[\"说出resnet的模型结构\",{\"0\":{\"23\":1}}],[\"7h\",{\"2\":{\"225\":1}}],[\"7的一维张量\",{\"2\":{\"220\":1}}],[\"784\",{\"2\":{\"152\":3}}],[\"7\",{\"2\":{\"63\":2,\"87\":1,\"100\":2,\"130\":1,\"174\":2,\"191\":1,\"220\":2,\"269\":2,\"273\":1,\"283\":1}}],[\"生成下一个token需要重新走一下所有流程\",{\"2\":{\"278\":1}}],[\"生成一个0\",{\"2\":{\"220\":1}}],[\"生成输出\",{\"2\":{\"143\":1}}],[\"生成时间序列数据\",{\"2\":{\"103\":1}}],[\"生成数据\",{\"2\":{\"88\":1}}],[\"生成器函数\",{\"2\":{\"88\":1}}],[\"生成\",{\"2\":{\"88\":1}}],[\"生成vgg网络\",{\"2\":{\"63\":2}}],[\"生成vgg块\",{\"2\":{\"63\":1}}],[\"生成的输出表征的维数为\",{\"2\":{\"144\":1}}],[\"生成的\",{\"2\":{\"32\":1}}],[\"文天祥\",{\"2\":{\"215\":2}}],[\"文本词表\",{\"2\":{\"117\":1}}],[\"文本预处理\",{\"0\":{\"117\":1}}],[\"文字包起来即可\",{\"2\":{\"113\":1}}],[\"文字\",{\"2\":{\"113\":1,\"156\":1}}],[\"文章中的单词是按顺序写的\",{\"2\":{\"93\":1}}],[\"文章\",{\"2\":{\"62\":1}}],[\"文件\",{\"2\":{\"113\":1}}],[\"文件的列表数字和输出的结果相同\",{\"2\":{\"68\":1}}],[\"文件的绝对路径作为内部链接的目标\",{\"2\":{\"32\":1}}],[\"文件的相对路径作为内部链接的目标\",{\"2\":{\"32\":1}}],[\"文件的\",{\"2\":{\"25\":1}}],[\"文件自动生成一个新的\",{\"2\":{\"25\":1}}],[\"文件里面写出\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"文件里加上一段\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"文件中建立一个块引言\",{\"2\":{\"57\":1}}],[\"文件中\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"核心思想就是将所有的experts划分为若干local\",{\"2\":{\"61\":1}}],[\"核回归其实定义了一种汇聚方式\",{\"2\":{\"51\":1}}],[\"局部性意味着计算相应的隐藏表示只需一小部分局部图像像素\",{\"2\":{\"102\":1}}],[\"局部性\",{\"2\":{\"60\":1,\"71\":1}}],[\"反引号\",{\"2\":{\"214\":1}}],[\"反斜线\",{\"2\":{\"214\":1}}],[\"反向传播\",{\"2\":{\"270\":1,\"285\":1}}],[\"反向传播的时候根据链式法则\",{\"2\":{\"266\":1}}],[\"反向传播计算梯度\",{\"2\":{\"207\":1}}],[\"反向传播起点\",{\"0\":{\"180\":1}}],[\"反之\",{\"2\":{\"177\":1}}],[\"反应\",{\"2\":{\"60\":1}}],[\"反映了模型对内存\",{\"2\":{\"55\":1}}],[\"反映了模型对硬件计算单元的需求\",{\"2\":{\"55\":1}}],[\"反映了模型站的磁盘空间\",{\"2\":{\"55\":1}}],[\"某个固定的物体不管出现在图像的哪个位置\",{\"2\":{\"60\":1}}],[\"某个物体会具有以下两种特性\",{\"2\":{\"60\":1}}],[\"具体如下\",{\"2\":{\"266\":1}}],[\"具体讲解可以看ptx文档的第八节\",{\"2\":{\"205\":1}}],[\"具体的内容将在后面讲解\",{\"2\":{\"150\":1}}],[\"具体的底层原理可能在后面的章节会有讲解\",{\"2\":{\"122\":1}}],[\"具体的解析我放到另外一篇文章中\",{\"2\":{\"87\":1}}],[\"具体解法\",{\"0\":{\"88\":1}}],[\"具体原理的话\",{\"2\":{\"87\":1}}],[\"具体来讲\",{\"2\":{\"256\":1}}],[\"具体来讲是平移不变性\",{\"2\":{\"60\":1}}],[\"具体来说\",{\"2\":{\"87\":1,\"95\":1,\"151\":1,\"186\":1,\"283\":1}}],[\"具体步骤如下\",{\"2\":{\"67\":1}}],[\"具有一系列衍生版本\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"特别是x\",{\"2\":{\"278\":1}}],[\"特殊成员函数有六个\",{\"2\":{\"224\":1}}],[\"特殊成员函数\",{\"0\":{\"224\":1}}],[\"特殊的\",{\"2\":{\"103\":1}}],[\"特殊字元自动转换\",{\"0\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"特征映射和感受野\",{\"0\":{\"92\":1}}],[\"特征\",{\"2\":{\"82\":1}}],[\"特征大小\",{\"2\":{\"81\":1}}],[\"特性\",{\"0\":{\"60\":1}}],[\"列填充\",{\"2\":{\"144\":1}}],[\"列不拓展\",{\"2\":{\"59\":1}}],[\"列表项目可以包含多个段落\",{\"2\":{\"68\":1}}],[\"列表项目标记通常是放在最左边\",{\"2\":{\"68\":1}}],[\"列表\",{\"0\":{\"68\":1},\"2\":{\"40\":1,\"57\":1,\"58\":1}}],[\"每行两个\",{\"2\":{\"254\":1}}],[\"每次启动一个异步拷贝之后记得\",{\"2\":{\"265\":1}}],[\"每次滑动多个元素\",{\"2\":{\"144\":1}}],[\"每次默认移动1\",{\"2\":{\"144\":1}}],[\"每次随机分别取出小批次数据\",{\"2\":{\"88\":1}}],[\"每一层特征的高度和宽度都减小了\",{\"2\":{\"247\":1}}],[\"每一层有多个输出通道是至关重要的\",{\"2\":{\"187\":1}}],[\"每一维都是一个带有隐藏层的神经网络\",{\"2\":{\"230\":1}}],[\"每一个注意力汇聚都被称作一个头\",{\"2\":{\"159\":1}}],[\"每一个节点的任务\",{\"2\":{\"140\":1}}],[\"每一行是一个样本\",{\"2\":{\"88\":1}}],[\"每一行都包含着相同的训练输出\",{\"2\":{\"59\":1}}],[\"每一行都包含着相同的训练输入\",{\"2\":{\"59\":1}}],[\"每个元素只占1个bytes\",{\"2\":{\"272\":1}}],[\"每个元素占了2个bytes\",{\"2\":{\"272\":1}}],[\"每个元素的梯度权重\",{\"2\":{\"166\":1}}],[\"每个元素的梯度\",{\"2\":{\"151\":1}}],[\"每个模型参数\",{\"2\":{\"264\":2,\"268\":2}}],[\"每个token的hidden\",{\"2\":{\"257\":1}}],[\"每个transformer层的参数量为\",{\"2\":{\"236\":1}}],[\"每个通道的量化参数不同\",{\"2\":{\"257\":1}}],[\"每个应用进程会分到\",{\"2\":{\"256\":1}}],[\"每个词元其实都表示为一个数字索引\",{\"2\":{\"255\":1}}],[\"每个词元都通过自注意力直接连接到其他的词元\",{\"2\":{\"202\":1}}],[\"每个全连接层减少维数\",{\"2\":{\"247\":1}}],[\"每个汇聚层的高度和宽度都减半\",{\"2\":{\"247\":1}}],[\"每个卷积块中的基本单元是一个卷积层\",{\"2\":{\"247\":1}}],[\"每个卷积核可以视为一个通道\",{\"2\":{\"82\":1}}],[\"每个可训练模型参数都会对应1个梯度\",{\"2\":{\"246\":1}}],[\"每个层有两个子层\",{\"2\":{\"225\":1}}],[\"每个层都有两个子层\",{\"2\":{\"87\":1}}],[\"每个神经元对其敏感的感受野\",{\"2\":{\"216\":1}}],[\"每个进程都会持有一把锁\",{\"2\":{\"190\":1}}],[\"每个输出通道先获取所有输入通道\",{\"2\":{\"187\":1}}],[\"每个查询都会关注所有的键\",{\"2\":{\"186\":1}}],[\"每个查询对应\",{\"2\":{\"59\":1}}],[\"每个注意力头\",{\"2\":{\"159\":1}}],[\"每个计算图的节点都有如下的一些属性\",{\"2\":{\"140\":1}}],[\"每个子层都采用了残差连接\",{\"2\":{\"87\":1}}],[\"每个项目下的段落都必须缩进\",{\"2\":{\"68\":1}}],[\"每个expert都是一个mlp\",{\"2\":{\"61\":1}}],[\"每个换行都转换为\",{\"2\":{\"40\":1}}],[\"值对并生成一个注意力输出\",{\"2\":{\"186\":1}}],[\"值为\",{\"2\":{\"185\":1}}],[\"值随机的矩阵\",{\"2\":{\"178\":1}}],[\"值得一提的是\",{\"2\":{\"130\":1}}],[\"值v∈rm∗v\",{\"2\":{\"91\":1}}],[\"值的长度为\",{\"2\":{\"91\":1}}],[\"值的维度v\",{\"2\":{\"91\":1}}],[\"值的维度\",{\"2\":{\"81\":3}}],[\"值\",{\"2\":{\"59\":2,\"81\":4,\"91\":2,\"173\":6}}],[\"键和值来自同一组输入\",{\"2\":{\"186\":1}}],[\"键和值将并行地送到注意力汇聚中\",{\"2\":{\"159\":1}}],[\"键和值\",{\"2\":{\"159\":1,\"186\":1}}],[\"键和值的不同的子空间表示\",{\"2\":{\"173\":1}}],[\"键和值的不同\",{\"2\":{\"159\":1}}],[\"键和值的集合时\",{\"2\":{\"159\":1}}],[\"键和值的形状为\",{\"2\":{\"81\":1}}],[\"键和值都来自上一个解码器层的输出\",{\"2\":{\"87\":1}}],[\"键和值都来自前一个编码器层的输出\",{\"2\":{\"87\":1}}],[\"键\",{\"2\":{\"59\":2,\"81\":4,\"91\":2,\"173\":6}}],[\"集中看一下模型的定义以及训练\",{\"2\":{\"59\":1}}],[\"执行对应矩阵相乘\",{\"2\":{\"59\":1}}],[\"从\",{\"2\":{\"285\":1}}],[\"从图中可以看出\",{\"2\":{\"263\":1}}],[\"从零开始实现的循环神经网络模型\",{\"2\":{\"255\":1}}],[\"从零实现softmax回归\",{\"0\":{\"152\":1}}],[\"从smem1中加载16bit的数据存入reg0\",{\"2\":{\"254\":1}}],[\"从随机偏移量开始划分序列\",{\"2\":{\"188\":1}}],[\"从随机偏移量开始对序列进行分区\",{\"2\":{\"176\":1}}],[\"从而在单线程中处理大量的io任务\",{\"2\":{\"219\":1}}],[\"从而可以应用链式法则来计算对每个输入的影响\",{\"2\":{\"180\":1}}],[\"从而变为右值引用或者左值引用\",{\"2\":{\"119\":1}}],[\"从而其softmax输出为0\",{\"2\":{\"70\":1}}],[\"从文件中导入代码块\",{\"2\":{\"114\":1}}],[\"从宏观角度来看\",{\"2\":{\"87\":1}}],[\"从上述例子可以看出\",{\"2\":{\"59\":1}}],[\"从全连接层过渡到卷积层\",{\"0\":{\"44\":1},\"1\":{\"52\":1,\"60\":1,\"71\":1,\"82\":1,\"92\":1,\"102\":1}}],[\"从全连接层过渡到卷积\",{\"2\":{\"35\":1}}],[\"💯\",{\"2\":{\"58\":1}}],[\"🎉目录表自定义容器默认标题导入代码块数学方程标记上下角标自定义对齐属性支持任务列表脚注\",{\"2\":{\"69\":1}}],[\"🎉\",{\"0\":{\"58\":1},\"2\":{\"58\":1}}],[\"o^\",{\"2\":{\"278\":1}}],[\"os自然会将其调度到各个核上实现并行\",{\"2\":{\"256\":1}}],[\"other\",{\"2\":{\"260\":1}}],[\"ot​=ht​whq​+bq​\",{\"2\":{\"230\":1}}],[\"ot=htwhq+bqo\",{\"2\":{\"230\":1}}],[\"o=wn+1​hn​+bn+1​loss=l\",{\"2\":{\"266\":1}}],[\"o=wn+1hn+bn+1loss=l\",{\"2\":{\"266\":1}}],[\"o=hwhq​+bq​\",{\"2\":{\"230\":1}}],[\"o=hwhq+bqo\",{\"2\":{\"230\":1}}],[\"o=x⋅w+b\",{\"2\":{\"95\":2}}],[\"owo​\",{\"2\":{\"225\":1,\"259\":1}}],[\"o$\",{\"2\":{\"225\":1}}],[\"oci​\",{\"2\":{\"187\":1}}],[\"oi=629375409599549440\",{\"2\":{\"175\":1}}],[\"overlap阶段\",{\"2\":{\"263\":1}}],[\"overlap执行\",{\"2\":{\"263\":1}}],[\"overlap起来\",{\"2\":{\"263\":1}}],[\"overlaps\",{\"2\":{\"263\":1}}],[\"overhead\",{\"2\":{\"263\":1}}],[\"override\",{\"0\":{\"182\":1}}],[\"over\",{\"2\":{\"128\":2}}],[\"order的部分\",{\"2\":{\"197\":1}}],[\"order\",{\"2\":{\"197\":2,\"205\":7}}],[\"ordering可以让l2\",{\"2\":{\"197\":1}}],[\"or\",{\"2\":{\"113\":4,\"117\":2,\"163\":1,\"213\":1,\"231\":1,\"247\":2,\"254\":1,\"266\":1,\"270\":1}}],[\"obtain\",{\"2\":{\"97\":2,\"193\":2}}],[\"o\",{\"2\":{\"95\":3,\"97\":2,\"159\":4,\"173\":4,\"187\":1,\"193\":2,\"202\":30,\"203\":3,\"259\":1,\"266\":4,\"275\":6,\"278\":2}}],[\"on\",{\"0\":{\"235\":1},\"1\":{\"245\":1,\"252\":1,\"258\":1},\"2\":{\"100\":2,\"153\":1,\"193\":1,\"247\":2,\"265\":1,\"269\":1,\"285\":1}}],[\"only模型量级分析\",{\"0\":{\"212\":1},\"1\":{\"225\":1,\"236\":1,\"246\":1,\"253\":1,\"259\":1,\"264\":1,\"268\":1,\"272\":1,\"275\":1}}],[\"only架构下的transformer模型的参数量\",{\"2\":{\"212\":1}}],[\"only架构\",{\"2\":{\"158\":1}}],[\"only\",{\"2\":{\"68\":1,\"212\":1}}],[\"onehot会将这个二维张量转化为三维张量\",{\"2\":{\"255\":1}}],[\"onehot\",{\"2\":{\"137\":2}}],[\"onehot编码将每个类别表示为一个向量\",{\"2\":{\"95\":1}}],[\"one\",{\"2\":{\"123\":1,\"254\":1,\"255\":1,\"265\":3,\"277\":1,\"282\":1}}],[\"onednn\",{\"2\":{\"66\":1}}],[\"ones\",{\"2\":{\"59\":1,\"81\":1,\"96\":2,\"130\":1,\"166\":2,\"167\":1,\"193\":1,\"285\":1}}],[\"ol>\",{\"2\":{\"68\":2}}],[\"out部分\",{\"2\":{\"278\":1}}],[\"out=128\",{\"2\":{\"61\":1}}],[\"output的shape为\",{\"2\":{\"283\":1}}],[\"output的形状\",{\"2\":{\"173\":1,\"283\":2}}],[\"outputs=10\",{\"2\":{\"152\":1}}],[\"outputs的形状为\",{\"2\":{\"115\":3}}],[\"outputs\",{\"2\":{\"110\":1,\"115\":13,\"152\":6,\"153\":1,\"193\":2,\"255\":6,\"261\":5,\"280\":3,\"283\":2}}],[\"output\",{\"2\":{\"61\":4,\"86\":1,\"97\":9,\"104\":2,\"138\":4,\"140\":9,\"153\":13,\"167\":10,\"173\":7,\"181\":2,\"193\":38,\"213\":7,\"225\":1,\"277\":2,\"278\":1,\"282\":3,\"283\":10}}],[\"out\",{\"2\":{\"61\":12,\"63\":7,\"75\":6,\"86\":3,\"115\":2,\"130\":1,\"144\":1,\"187\":2,\"203\":3,\"259\":3,\"275\":1,\"278\":6}}],[\"opaque\",{\"2\":{\"260\":1}}],[\"ops\",{\"2\":{\"248\":1,\"265\":1}}],[\"opo​\",{\"2\":{\"173\":1}}],[\"optional\",{\"2\":{\"113\":6,\"156\":2}}],[\"options\",{\"2\":{\"100\":8}}],[\"optimize\",{\"2\":{\"263\":1}}],[\"optimizer\",{\"2\":{\"181\":3,\"193\":3,\"247\":3,\"270\":1,\"285\":3}}],[\"optim\",{\"2\":{\"59\":1,\"88\":1,\"103\":1,\"181\":1,\"193\":3,\"247\":1,\"270\":2,\"285\":1}}],[\"open\",{\"2\":{\"117\":1}}],[\"openrlhf\",{\"2\":{\"77\":1}}],[\"operation\",{\"2\":{\"260\":1,\"265\":3}}],[\"operations\",{\"2\":{\"55\":2,\"259\":1,\"260\":1}}],[\"operator\",{\"2\":{\"260\":1}}],[\"operator层面可以做一些conv2d的优化\",{\"2\":{\"23\":1}}],[\"offset\",{\"2\":{\"188\":6}}],[\"of\",{\"2\":{\"57\":1,\"61\":1,\"79\":2,\"97\":5,\"124\":1,\"128\":8,\"138\":2,\"141\":2,\"153\":5,\"193\":13,\"260\":2,\"263\":1,\"275\":1,\"279\":1}}],[\">http\",{\"2\":{\"199\":1}}],[\">i++\",{\"2\":{\"118\":1}}],[\">i\",{\"2\":{\"118\":2}}],[\">msn\",{\"2\":{\"113\":1}}],[\">yahoo\",{\"2\":{\"113\":1}}],[\">google\",{\"2\":{\"113\":1}}],[\">this\",{\"2\":{\"113\":1}}],[\">\",{\"2\":{\"57\":19,\"63\":2,\"68\":1,\"75\":1,\"79\":1,\"96\":1,\"100\":12,\"113\":1,\"114\":3,\"117\":1,\"119\":1,\"130\":1,\"140\":1,\"144\":1,\"150\":1,\"152\":6,\"154\":2,\"174\":1,\"176\":1,\"185\":1,\"187\":1,\"188\":1,\"199\":3,\"203\":1,\"213\":1,\"229\":1,\"252\":6,\"254\":2,\"255\":1,\"265\":4,\"266\":1,\"269\":1,\"273\":1,\"282\":3,\"285\":2}}],[\"信件中引言\",{\"2\":{\"57\":1}}],[\"二者合计占用\",{\"2\":{\"272\":1}}],[\"二者占用显存一共\",{\"2\":{\"272\":1}}],[\"二维卷积层\",{\"2\":{\"130\":1}}],[\"二维互相关运算\",{\"2\":{\"130\":1}}],[\"二\",{\"0\":{\"56\":1,\"63\":1,\"101\":1,\"116\":1,\"125\":1,\"132\":1,\"135\":1,\"152\":1,\"181\":1,\"204\":1,\"206\":1,\"244\":1,\"278\":1},\"1\":{\"67\":1,\"78\":1,\"88\":1,\"115\":1,\"129\":1,\"130\":1,\"143\":1,\"144\":1,\"159\":1,\"160\":1,\"173\":1,\"174\":1,\"186\":1,\"187\":1,\"202\":1,\"203\":1,\"217\":1,\"219\":1,\"230\":1,\"231\":1,\"241\":1,\"242\":1,\"249\":1,\"251\":1,\"255\":1,\"261\":1,\"266\":1,\"270\":1}}],[\"≠\",{\"2\":{\"55\":1}}],[\"所有线程看到的操作顺序必须一致\",{\"2\":{\"205\":1}}],[\"所有元素求和\",{\"2\":{\"191\":1}}],[\"所有token首先都会流经shared\",{\"2\":{\"61\":1}}],[\"所有支持的\",{\"2\":{\"58\":1}}],[\"所占用的内存\",{\"2\":{\"55\":1}}],[\"所以显存占用为\",{\"2\":{\"272\":1}}],[\"所以综上所述\",{\"2\":{\"259\":1}}],[\"所以会尝试mps加速\",{\"2\":{\"255\":1}}],[\"所以占据两个格子\",{\"2\":{\"252\":1,\"263\":1}}],[\"所以训练过程显存占用为\",{\"2\":{\"246\":1}}],[\"所以对于计算型代码\",{\"2\":{\"231\":1}}],[\"所以对于派生类的函数重写\",{\"2\":{\"182\":1}}],[\"所以被命名为循环神经网络\",{\"2\":{\"230\":1}}],[\"所以参数量为\",{\"2\":{\"225\":1}}],[\"所以参数数量为\",{\"2\":{\"225\":1}}],[\"所以\",{\"2\":{\"203\":1,\"236\":1,\"272\":1}}],[\"所以在init的时候会设置thread\",{\"2\":{\"260\":1}}],[\"所以在cpp中\",{\"2\":{\"205\":1}}],[\"所以在长序列的计算中会很慢\",{\"2\":{\"202\":1}}],[\"所以在python中\",{\"2\":{\"163\":1}}],[\"所以每一次计算复杂度为\",{\"2\":{\"202\":1}}],[\"所以有\",{\"2\":{\"202\":1}}],[\"所以卷积层的计算复杂度为\",{\"2\":{\"202\":1}}],[\"所以更加复杂\",{\"2\":{\"190\":1}}],[\"所以下面的yaml配置文件你只需改变一下你的env路径\",{\"2\":{\"169\":1}}],[\"所以网络上设置\",{\"2\":{\"169\":1}}],[\"所以一般采用的是\",{\"2\":{\"271\":1}}],[\"所以一般都是直接指定完整的目录\",{\"2\":{\"169\":1}}],[\"所以一个更好的语言模型应该可以让我们更准确的预测下一个词元\",{\"2\":{\"249\":1}}],[\"所以一把防止数据竞争的锁仍然是有必要的\",{\"2\":{\"163\":1}}],[\"所以需要运行时才知道\",{\"2\":{\"271\":1}}],[\"所以需要将\",{\"2\":{\"169\":1}}],[\"所以需要用户立即关注的关键内容\",{\"2\":{\"100\":2}}],[\"所以很多路径需要我们手动指定\",{\"2\":{\"169\":1}}],[\"所以c++98的不限域enum总是要求定义\",{\"2\":{\"154\":1}}],[\"所以为了简单\",{\"2\":{\"152\":1}}],[\"所以ffn层总共需要保存的参数为\",{\"2\":{\"272\":1}}],[\"所以f2返回int\",{\"2\":{\"150\":1}}],[\"所以f1返回int\",{\"2\":{\"150\":1}}],[\"所以上式又可以表达为\",{\"2\":{\"137\":1}}],[\"所以上述的注意力汇聚其实是非参数注意力汇聚模型\",{\"2\":{\"51\":1}}],[\"所以无论这些层执行严格的卷积运算还是互相关运算\",{\"2\":{\"130\":1}}],[\"所以这里进行deallocate\",{\"2\":{\"213\":1}}],[\"所以这里可以学习dualpipe的方式\",{\"2\":{\"213\":1}}],[\"所以这里可以使用std\",{\"2\":{\"150\":1}}],[\"所以这种简化的标签内也可以包含多个文字\",{\"2\":{\"113\":1}}],[\"所以这被称为\",{\"2\":{\"103\":1}}],[\"所以全连接层这种模型可能不符合我们的预期\",{\"2\":{\"103\":1}}],[\"所以鸡鸭鹅可以表示为\",{\"2\":{\"95\":1}}],[\"所以要除以batch\",{\"2\":{\"88\":1}}],[\"所以图像其实是一个三维张量\",{\"2\":{\"82\":1}}],[\"所以我们在进行async\",{\"2\":{\"282\":1}}],[\"所以我们使用cp\",{\"2\":{\"265\":1}}],[\"所以我们每个phase需要传入一个kphasebit来表示当前的阶段\",{\"2\":{\"260\":1}}],[\"所以我们可以近似的认为\",{\"2\":{\"264\":1}}],[\"所以我们可以通过一个序列中所有的\",{\"2\":{\"249\":1}}],[\"所以我们可以从图像的特点入手\",{\"2\":{\"52\":1}}],[\"所以我们只需要算一份\",{\"2\":{\"225\":1}}],[\"所以我们不妨使用隐变量模型\",{\"2\":{\"217\":1}}],[\"所以我们input\",{\"2\":{\"213\":1}}],[\"所以我们考虑的是grad的传递问题\",{\"2\":{\"213\":1}}],[\"所以我们应当尽可能地在代码中应用constexpr\",{\"2\":{\"194\":1}}],[\"所以我们如果对一个向量反向传播的时候\",{\"2\":{\"166\":1}}],[\"所以我们输出x0\",{\"2\":{\"151\":1}}],[\"所以我们需要人为的去使用mutex等同步原语来保证const线程安全\",{\"2\":{\"211\":1}}],[\"所以我们需要更有效的模型\",{\"2\":{\"131\":1}}],[\"所以我们需要加一个负号\",{\"2\":{\"78\":1}}],[\"所以我们采取全部遍历求和的形式\",{\"2\":{\"82\":1}}],[\"所以注意力其实是query与key的交互汇聚过程\",{\"2\":{\"43\":1}}],[\"所以你如果要在文件中插入一个著作权的符号\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"训练损失总和\",{\"2\":{\"285\":1}}],[\"训练损失之和\",{\"2\":{\"247\":1,\"270\":1}}],[\"训练序列到序列模型\",{\"2\":{\"285\":1}}],[\"训练和预测\",{\"2\":{\"270\":1}}],[\"训练模型\",{\"2\":{\"270\":1}}],[\"训练模式下\",{\"2\":{\"96\":1}}],[\"训练模式\",{\"2\":{\"96\":1}}],[\"训练\",{\"0\":{\"270\":1,\"285\":1}}],[\"训练transformer模型的计算时间为\",{\"2\":{\"268\":1}}],[\"训练时间=gpu数×gpu峰值flops×gpu利用率8×tokens数×模型参数量​\",{\"2\":{\"268\":1}}],[\"训练时间=8×tokens数×模型参数量gpu数×gpu峰值flops×gpu利用率\",{\"2\":{\"268\":1}}],[\"训练时间\",{\"2\":{\"268\":2}}],[\"训练时间估计\",{\"0\":{\"268\":1}}],[\"训练准确率之和\",{\"2\":{\"247\":1}}],[\"训练大模型时通常会采用adamw优化器\",{\"2\":{\"246\":1}}],[\"训练过程显存占用分析\",{\"0\":{\"246\":1}}],[\"训练过程与推理过程具有不同的特点\",{\"2\":{\"66\":1}}],[\"训练数据批次大小\",{\"2\":{\"212\":1}}],[\"训练网络一个迭代周期\",{\"2\":{\"270\":1}}],[\"训练网络\",{\"2\":{\"63\":1}}],[\"训练或者推理\",{\"2\":{\"55\":1}}],[\"训练样本数\",{\"2\":{\"51\":1}}],[\"即不同的句子有相同的system\",{\"2\":{\"284\":1}}],[\"即一次乘法法运算和一次加法运算\",{\"2\":{\"264\":1}}],[\"即使在高度或宽度上移动一个元素\",{\"2\":{\"229\":1}}],[\"即使你在成员函数或者友元函数里面调用deleted函数也不能通过编译\",{\"2\":{\"168\":1}}],[\"即使cpp文件中的定义发生改变\",{\"2\":{\"154\":1}}],[\"即使其他的构造函数更匹配\",{\"2\":{\"112\":1}}],[\"即可使得输入和输出具有相同的形状\",{\"2\":{\"144\":1}}],[\"即假设有一个\",{\"2\":{\"137\":1}}],[\"即对角线的情况\",{\"2\":{\"123\":1}}],[\"即得到属于每个类别的概率\",{\"2\":{\"95\":1}}],[\"即上文提到的j函数\",{\"2\":{\"88\":1}}],[\"即add\",{\"2\":{\"55\":1}}],[\"即浮点计算次数\",{\"2\":{\"55\":1}}],[\"相同\",{\"2\":{\"272\":1}}],[\"相反\",{\"2\":{\"229\":1,\"247\":1}}],[\"相当于x\",{\"2\":{\"285\":1}}],[\"相当于针对tensor的批量异步拷贝\",{\"2\":{\"265\":1}}],[\"相当于torch\",{\"2\":{\"191\":1}}],[\"相当于套了层娃\",{\"2\":{\"169\":1}}],[\"相对于串行\",{\"2\":{\"177\":1}}],[\"相对而言\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"相加\",{\"2\":{\"55\":1}}],[\"构造函数的调用\",{\"2\":{\"112\":1}}],[\"构造一个pytorch数据迭代器\",{\"2\":{\"88\":1}}],[\"构成\",{\"2\":{\"55\":1}}],[\"构建模型必备\",{\"2\":{\"1\":1}}],[\"例\",{\"2\":{\"143\":1}}],[\"例子\",{\"2\":{\"55\":2}}],[\"例如矩阵乘法\",{\"2\":{\"267\":1}}],[\"例如之前的conv2d的卷积操作使用的数据类型是fp32\",{\"2\":{\"267\":1}}],[\"例如都适合处理io密集型任务\",{\"2\":{\"231\":1}}],[\"例如1f1b\",{\"2\":{\"213\":1}}],[\"例如在顺序一致性模型中\",{\"2\":{\"205\":1}}],[\"例如因为thread1和thread2的视角顺序不同\",{\"2\":{\"205\":1}}],[\"例如对于左值表达式\",{\"2\":{\"150\":1}}],[\"例如我们可以实现一个自己的exp运算\",{\"2\":{\"140\":1}}],[\"例如如下的一些x\",{\"2\":{\"135\":1}}],[\"例如文件读取\",{\"2\":{\"133\":1}}],[\"例如tensor的释放与回收\",{\"2\":{\"213\":1}}],[\"例如t\",{\"2\":{\"119\":1}}],[\"例如std\",{\"2\":{\"112\":1}}],[\"例如一个卷积核所覆盖的区域中\",{\"2\":{\"82\":1}}],[\"例如内存池\",{\"2\":{\"23\":1}}],[\"例如\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"17\":1,\"19\":1,\"28\":1,\"29\":1,\"33\":1,\"49\":2,\"57\":2,\"79\":3,\"93\":1,\"100\":4,\"103\":1,\"113\":1,\"127\":1,\"141\":1,\"143\":1,\"159\":1,\"199\":2,\"214\":1}}],[\"峰值内存占用指运行时的内存\",{\"2\":{\"55\":1}}],[\"峰值\",{\"2\":{\"55\":2}}],[\"访存量为\",{\"2\":{\"55\":1}}],[\"访存量单位为\",{\"2\":{\"55\":1}}],[\"访存量\",{\"2\":{\"55\":3}}],[\"访存效率\",{\"2\":{\"47\":1}}],[\"参考文章\",{\"2\":{\"286\":1}}],[\"参考式的图片语法则长得像这样\",{\"2\":{\"156\":1}}],[\"参考式的链接其实重点不在于它比较好写\",{\"2\":{\"113\":1}}],[\"参考\",{\"2\":{\"156\":1}}],[\"参考形式的链接使用另外一个方括号接在链接文字的括号后面\",{\"2\":{\"113\":1}}],[\"参考资料\",{\"2\":{\"15\":1}}],[\"参与求梯度和迭代的拉伸和偏移参数\",{\"2\":{\"96\":1}}],[\"参数主要是由\",{\"2\":{\"55\":1}}],[\"参数量大小为\",{\"2\":{\"236\":1}}],[\"参数量\",{\"2\":{\"55\":2}}],[\"进入decoder\",{\"2\":{\"283\":1}}],[\"进入encoder\",{\"2\":{\"283\":1}}],[\"进入rnn网络计算\",{\"2\":{\"270\":1}}],[\"进入的维度为2\",{\"2\":{\"88\":1}}],[\"进一步印证了\",{\"2\":{\"265\":1}}],[\"进程并行\",{\"0\":{\"256\":1}}],[\"进程间通信需要通过管道等方式\",{\"2\":{\"190\":1}}],[\"进而更新各个权重参数\",{\"2\":{\"241\":1}}],[\"进而改进这一结构\",{\"2\":{\"52\":1}}],[\"进位码的\",{\"2\":{\"199\":1}}],[\"进行2次浮点数计算\",{\"2\":{\"268\":1}}],[\"进行互相关运算\",{\"2\":{\"174\":1}}],[\"进行下角标标注\",{\"2\":{\"157\":1}}],[\"进行上角标标注\",{\"2\":{\"157\":1}}],[\"进行标记\",{\"2\":{\"142\":1}}],[\"进行三轮迭代\",{\"2\":{\"88\":1}}],[\"进行完softmax操作之后attention\",{\"2\":{\"59\":1}}],[\"进阶指南\",{\"2\":{\"1\":1}}],[\"图片参考的定义方式则和链接参考一样\",{\"2\":{\"156\":1}}],[\"图片\",{\"0\":{\"156\":1}}],[\"图片水印\",{\"0\":{\"12\":1},\"1\":{\"19\":1,\"26\":1,\"33\":1,\"42\":1}}],[\"图像的平移不变性使我们以相同的方式处理局部图像\",{\"2\":{\"102\":1}}],[\"图像的一个像素点一般包含三个通道\",{\"2\":{\"82\":1}}],[\"图像天然本就拥有丰富的空间结构\",{\"2\":{\"52\":1}}],[\"操作系统会提供线程管理器\",{\"2\":{\"163\":1}}],[\"操作\",{\"2\":{\"52\":1,\"130\":1}}],[\"拟合\",{\"2\":{\"52\":1}}],[\"全连接层输出形状是\",{\"2\":{\"277\":1}}],[\"全连接层变换后\",{\"2\":{\"115\":1}}],[\"全连接层\",{\"2\":{\"96\":1,\"203\":1}}],[\"全连接层可以理解为一种\",{\"2\":{\"52\":1}}],[\"全屏水印\",{\"0\":{\"8\":1},\"1\":{\"13\":1,\"21\":1,\"28\":1,\"36\":1}}],[\"介绍一下西安\",{\"2\":{\"115\":1,\"129\":1}}],[\"介绍\",{\"0\":{\"52\":1,\"108\":1,\"219\":1}}],[\"也需要考虑硬件\",{\"2\":{\"271\":1}}],[\"也需要在\",{\"2\":{\"169\":1}}],[\"也有cp\",{\"2\":{\"265\":1}}],[\"也被称为\",{\"2\":{\"257\":1}}],[\"也被成为一元语法\",{\"2\":{\"145\":1}}],[\"也会有cp\",{\"2\":{\"265\":1}}],[\"也会开多个进程来负载均衡\",{\"2\":{\"256\":1}}],[\"也会变成三维张量\",{\"2\":{\"82\":1}}],[\"也不需要保存中间激活\",{\"2\":{\"253\":1}}],[\"也不会使得头文件跟着重新编译\",{\"2\":{\"154\":1}}],[\"也不会对它做任何转换\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"也是本论文采取的pp调度策略\",{\"2\":{\"252\":1}}],[\"也是值\",{\"2\":{\"115\":1}}],[\"也无能为力\",{\"2\":{\"231\":1}}],[\"也能更好地利用和控制sm\",{\"2\":{\"197\":1}}],[\"也接近于我们初始设定的\",{\"2\":{\"130\":1}}],[\"也包括左值引用int\",{\"2\":{\"119\":1}}],[\"也就是gpu算完这么多flops的计算时间\",{\"2\":{\"268\":1}}],[\"也就是相当于将计算单元拆小\",{\"2\":{\"263\":1}}],[\"也就是从fp32\",{\"2\":{\"262\":1}}],[\"也就是h0h\",{\"2\":{\"255\":1}}],[\"也就是8x8\",{\"2\":{\"254\":1}}],[\"也就是人为指定的零点\",{\"2\":{\"251\":1}}],[\"也就是我们第\",{\"2\":{\"217\":1}}],[\"也就是可以实现多核并行操作\",{\"2\":{\"163\":1}}],[\"也就是系统级别的线程\",{\"2\":{\"163\":1}}],[\"也就是浮点数运算次数\",{\"2\":{\"158\":1}}],[\"也就是反向传播\",{\"2\":{\"151\":1}}],[\"也就是在自然语言中\",{\"2\":{\"145\":1}}],[\"也就是在行首出现数字\",{\"2\":{\"68\":1}}],[\"也就是将一段段话分割为更小的单元\",{\"2\":{\"117\":1}}],[\"也就是序列其实总是满足某个潜在的规律\",{\"2\":{\"103\":1}}],[\"也就是说要保证每个线程的操作在全局顺序中保证其线程内的顺序\",{\"2\":{\"205\":1}}],[\"也就是说\",{\"2\":{\"103\":1,\"137\":1,\"229\":1}}],[\"也就是上述的运算只适合灰度图像\",{\"2\":{\"82\":1}}],[\"也就是local\",{\"2\":{\"72\":1}}],[\"也就意味着获得了更多的注意力\",{\"2\":{\"51\":1}}],[\"也允许\",{\"2\":{\"68\":1}}],[\"也允许你只在整个段落的第一行最前面加上\",{\"2\":{\"57\":1}}],[\"也可能相互依赖\",{\"2\":{\"180\":1}}],[\"也可以实现这样的overlap\",{\"2\":{\"252\":1}}],[\"也可以写为torch\",{\"2\":{\"243\":1}}],[\"也可以按照维度求\",{\"2\":{\"191\":1}}],[\"也可以设置步幅\",{\"2\":{\"144\":1}}],[\"也可以是单词单元\",{\"2\":{\"117\":1}}],[\"也可以加一些缩进\",{\"2\":{\"113\":1}}],[\"也可以理解为definition\",{\"2\":{\"112\":1}}],[\"也可以使用decltype\",{\"2\":{\"150\":1}}],[\"也可以使用\",{\"2\":{\"100\":1}}],[\"也可以\",{\"2\":{\"68\":1}}],[\"也可使用星号\",{\"2\":{\"68\":1}}],[\"越是接近给定的\",{\"2\":{\"51\":1}}],[\"−min\",{\"2\":{\"262\":2}}],[\"−n1​t=1∑n​logp\",{\"2\":{\"249\":1}}],[\"−∂xj​∂lnpt​​=pj​−δt\",{\"2\":{\"137\":1}}],[\"−∂lnpt∂xj=pj−δt\",{\"2\":{\"137\":1}}],[\"−pi​pj​\",{\"2\":{\"123\":1}}],[\"−pipj\",{\"2\":{\"123\":1}}],[\"−exi∑k=1nexk⋅exj∑k=1nexk=\",{\"2\":{\"123\":1}}],[\"−1n∑t=1nlog⁡p\",{\"2\":{\"249\":1}}],[\"−1s\",{\"2\":{\"115\":1}}],[\"−1t\",{\"2\":{\"115\":1}}],[\"−1​\",{\"2\":{\"115\":2}}],[\"−1\",{\"2\":{\"115\":2}}],[\"−128\",{\"2\":{\"262\":2}}],[\"−12\",{\"2\":{\"51\":3,\"59\":3}}],[\"−21​\",{\"2\":{\"51\":3,\"59\":3}}],[\"−2u2​\",{\"2\":{\"51\":1}}],[\"−u22\",{\"2\":{\"51\":1}}],[\"−yi\",{\"2\":{\"48\":2}}],[\"u32\",{\"2\":{\"273\":2}}],[\"upper\",{\"2\":{\"282\":1}}],[\"updater\",{\"2\":{\"270\":8}}],[\"up\",{\"2\":{\"261\":1,\"269\":1,\"273\":1}}],[\"util\",{\"2\":{\"248\":2,\"265\":1}}],[\"utils\",{\"2\":{\"88\":1,\"193\":1,\"213\":1}}],[\"utm\",{\"2\":{\"175\":2}}],[\"uint8的指令\",{\"2\":{\"271\":1}}],[\"uint8的每个单位长度的规格\",{\"2\":{\"262\":1}}],[\"uint8的话就是127\",{\"2\":{\"251\":1}}],[\"uint64\",{\"2\":{\"260\":1,\"269\":2,\"273\":2}}],[\"uint16\",{\"2\":{\"254\":4}}],[\"uint32\",{\"2\":{\"254\":14,\"269\":6,\"273\":13,\"279\":3}}],[\"uinfo\",{\"2\":{\"154\":1}}],[\"uiname>\",{\"2\":{\"154\":1}}],[\"uiname\",{\"2\":{\"154\":2}}],[\"uireputation\",{\"2\":{\"154\":2}}],[\"uiemail\",{\"2\":{\"154\":4}}],[\"us\",{\"2\":{\"263\":1}}],[\"using有一个吸引人的特性\",{\"2\":{\"139\":1}}],[\"using\",{\"0\":{\"139\":1,\"235\":1},\"1\":{\"245\":1,\"252\":1,\"258\":1},\"2\":{\"139\":1,\"154\":1,\"263\":1,\"269\":1,\"273\":1}}],[\"user\",{\"2\":{\"154\":4}}],[\"userinfofields\",{\"2\":{\"154\":1}}],[\"userinfofields2\",{\"2\":{\"154\":1}}],[\"userinfofields1\",{\"2\":{\"154\":2}}],[\"userinfo\",{\"2\":{\"154\":2}}],[\"userconfig\",{\"2\":{\"100\":6}}],[\"use\",{\"2\":{\"141\":3,\"188\":2,\"269\":1,\"270\":4,\"282\":3}}],[\"useful\",{\"2\":{\"97\":1,\"138\":1,\"193\":2}}],[\"used\",{\"2\":{\"97\":1,\"124\":1,\"193\":2}}],[\"uref4\",{\"2\":{\"135\":1}}],[\"uref3\",{\"2\":{\"135\":1}}],[\"uref2\",{\"2\":{\"135\":1}}],[\"uref1\",{\"2\":{\"135\":1}}],[\"url\",{\"2\":{\"117\":1,\"156\":1}}],[\"unweighted\",{\"2\":{\"285\":2}}],[\"unroll\",{\"2\":{\"269\":1,\"273\":1}}],[\"unpacked\",{\"2\":{\"254\":1}}],[\"underlying\",{\"2\":{\"154\":6}}],[\"underscores\",{\"2\":{\"127\":4}}],[\"un\",{\"2\":{\"127\":1}}],[\"unit\",{\"2\":{\"269\":9,\"273\":8}}],[\"uni\",{\"2\":{\"260\":2}}],[\"unified\",{\"2\":{\"254\":1}}],[\"uniform\",{\"2\":{\"103\":1,\"247\":1,\"285\":2}}],[\"universal\",{\"2\":{\"122\":5}}],[\"unk\",{\"2\":{\"117\":2}}],[\"unk>\",{\"2\":{\"117\":1}}],[\"unsqueeze\",{\"2\":{\"59\":5,\"61\":2,\"81\":2,\"115\":2,\"124\":2,\"167\":4,\"193\":6}}],[\"uv\",{\"2\":{\"71\":2}}],[\"uuu\",{\"2\":{\"71\":1}}],[\"ul>\",{\"2\":{\"68\":4,\"100\":4}}],[\"u^2\",{\"2\":{\"51\":1}}],[\"u\",{\"2\":{\"51\":3,\"71\":9,\"82\":2}}],[\"α\",{\"2\":{\"51\":1,\"70\":3,\"78\":1,\"115\":1,\"143\":1}}],[\"其它\",{\"0\":{\"184\":1},\"1\":{\"199\":1,\"214\":1}}],[\"其它的格式会把每个断行都转成\",{\"2\":{\"40\":1}}],[\"其次就是cuda的库\",{\"2\":{\"169\":1}}],[\"其次我们使用第二个特性\",{\"2\":{\"71\":1}}],[\"其余不变\",{\"2\":{\"137\":1}}],[\"其他文本样式\",{\"0\":{\"171\":1}}],[\"其他\",{\"0\":{\"146\":1}}],[\"其他全部置为0\",{\"2\":{\"137\":1}}],[\"其他算子也有参数\",{\"2\":{\"55\":1}}],[\"其就可以调用常量函数\",{\"2\":{\"118\":1}}],[\"其感受野是指在前向传播中可能影响到\",{\"2\":{\"92\":1}}],[\"其实更加native的写法\",{\"2\":{\"282\":1}}],[\"其实也就是使用cp\",{\"2\":{\"282\":1}}],[\"其实和上一轮计算的时候没有变化\",{\"2\":{\"278\":1}}],[\"其实通篇下来\",{\"2\":{\"222\":1}}],[\"其实能释放就都得释放掉\",{\"2\":{\"213\":1}}],[\"其实很多选项我这里也没有很清楚\",{\"2\":{\"169\":1}}],[\"其实如果使用clion会省下来很多麻烦\",{\"2\":{\"169\":1}}],[\"其实两种方法都等价于计算\",{\"2\":{\"166\":1}}],[\"其实是一种很大的亏损\",{\"2\":{\"250\":1}}],[\"其实是一个loop\",{\"2\":{\"219\":1}}],[\"其实是模型的输出\",{\"2\":{\"152\":1}}],[\"其实是为了去忽略一些值\",{\"2\":{\"70\":1}}],[\"其实实际上表达的就是\",{\"2\":{\"137\":1}}],[\"其实我们的互相关运算和卷积的差别不大\",{\"2\":{\"130\":1}}],[\"其实从式子中\",{\"2\":{\"108\":1}}],[\"其实他们的样本之间都遵循着某种分布\",{\"2\":{\"93\":1}}],[\"其实就对应于某个函数f\",{\"2\":{\"151\":1}}],[\"其实就是使用的上文中提到的move中的st指令\",{\"2\":{\"273\":1}}],[\"其实就是替代算子的过程\",{\"2\":{\"267\":1}}],[\"其实就是将seq\",{\"2\":{\"258\":1}}],[\"其实就是因为限域enum无法进行隐式的类型转换\",{\"2\":{\"154\":1}}],[\"其实就是相当于计算2\",{\"2\":{\"151\":1}}],[\"其实就是根据grad\",{\"2\":{\"140\":1}}],[\"其实就是根据已知的量来计算y\",{\"2\":{\"88\":1}}],[\"其实就是简单的前向计算的过程\",{\"2\":{\"140\":1}}],[\"其实就是沿着计算图根据链式法则进行求导\",{\"2\":{\"126\":1}}],[\"其实就是torch\",{\"2\":{\"126\":1}}],[\"其实就是我们想要的权重\",{\"2\":{\"95\":1}}],[\"其实就是上文提到的j\",{\"2\":{\"88\":1}}],[\"其实就是卷积核kernel\",{\"2\":{\"71\":1}}],[\"其实就相当于存在一个x0x\",{\"2\":{\"88\":1}}],[\"其实上述的高斯核就可以被视为注意力评分函数\",{\"2\":{\"70\":1}}],[\"其实这里批量就是\",{\"2\":{\"59\":1}}],[\"其中的accuracy等函数都在前面的章节实现过\",{\"2\":{\"247\":1}}],[\"其中的计算部分是调用的torch\",{\"2\":{\"126\":1}}],[\"其中批量大小为\",{\"2\":{\"230\":1}}],[\"其中output\",{\"2\":{\"213\":1}}],[\"其中任意\",{\"2\":{\"186\":1}}],[\"其中每个输入词元或者输出词元都是\",{\"2\":{\"202\":1}}],[\"其中每个\",{\"2\":{\"166\":1}}],[\"其中可学习的参数为\",{\"2\":{\"159\":1}}],[\"其中可学习的参数是\",{\"2\":{\"81\":1}}],[\"其中std\",{\"2\":{\"154\":1}}],[\"其中包含了从0\",{\"2\":{\"151\":1}}],[\"其中包含了一个隐藏层\",{\"2\":{\"81\":1}}],[\"其中xxx\",{\"2\":{\"151\":1}}],[\"其中x为矩阵形式\",{\"2\":{\"88\":1}}],[\"其中时间步\",{\"2\":{\"115\":1}}],[\"其中也包含了常见面试问题\",{\"2\":{\"87\":1}}],[\"其中查询和键的长度为\",{\"2\":{\"91\":1}}],[\"其中查询\",{\"2\":{\"70\":1}}],[\"其中\",{\"2\":{\"51\":1,\"71\":1,\"78\":1,\"95\":1,\"103\":1,\"230\":2,\"249\":1,\"261\":1,\"265\":1}}],[\"形状与\",{\"2\":{\"272\":1}}],[\"形状的张量\",{\"2\":{\"243\":1}}],[\"形状为\",{\"2\":{\"129\":2,\"272\":1}}],[\"形参既不是指针也不是引用\",{\"2\":{\"122\":1}}],[\"形成一种更为通用的注意力汇聚方式\",{\"2\":{\"51\":1}}],[\"形式如下\",{\"2\":{\"137\":1}}],[\"形式则是在行首插入\",{\"2\":{\"49\":1}}],[\"形式是用底线的形式\",{\"2\":{\"49\":1}}],[\"形式\",{\"2\":{\"49\":1}}],[\"形式的块引言\",{\"2\":{\"57\":1}}],[\"形式的\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"k^\",{\"2\":{\"278\":3}}],[\"kq\",{\"2\":{\"272\":2}}],[\"kphasebit\",{\"2\":{\"260\":1}}],[\"k=xwk​\",{\"2\":{\"259\":1}}],[\"k=xwk\",{\"2\":{\"259\":1}}],[\"k=1\",{\"2\":{\"123\":10}}],[\"k$\",{\"2\":{\"225\":1}}],[\"knd^2\",{\"2\":{\"202\":1}}],[\"knd2\",{\"2\":{\"202\":2}}],[\"k维度采取的是完整的k\",{\"2\":{\"197\":1}}],[\"kv\",{\"0\":{\"196\":1,\"281\":1},\"1\":{\"212\":1,\"225\":1,\"236\":1,\"246\":1,\"253\":1,\"259\":1,\"264\":1,\"268\":1,\"272\":1,\"275\":1,\"278\":1,\"281\":1,\"284\":2,\"286\":2},\"2\":{\"253\":2,\"278\":2}}],[\"kw​\",{\"2\":{\"174\":1}}],[\"kw\",{\"2\":{\"174\":1}}],[\"kwargs\",{\"2\":{\"59\":2,\"81\":2,\"91\":2,\"115\":4,\"173\":2,\"213\":3,\"277\":2,\"280\":6,\"283\":4}}],[\"kh​\",{\"2\":{\"174\":1}}],[\"kh\",{\"2\":{\"174\":1}}],[\"kkk\",{\"2\":{\"130\":1,\"202\":1,\"259\":1,\"272\":1}}],[\"k∈rdk​\",{\"2\":{\"159\":1}}],[\"k∈rdk\",{\"2\":{\"159\":1}}],[\"k∈rm∗d\",{\"2\":{\"91\":2}}],[\"k∈rk\",{\"2\":{\"81\":1}}],[\"k​\",{\"2\":{\"82\":2}}],[\"kj​\",{\"2\":{\"70\":1}}],[\"kj\",{\"2\":{\"70\":1}}],[\"kittens\",{\"0\":{\"240\":1},\"1\":{\"248\":1,\"254\":1,\"260\":1,\"265\":1,\"269\":1,\"273\":1,\"276\":1,\"279\":1,\"282\":1},\"2\":{\"269\":3,\"273\":3,\"279\":4,\"282\":4}}],[\"kik\",{\"2\":{\"70\":1}}],[\"ki​\",{\"2\":{\"70\":4}}],[\"ki\",{\"2\":{\"70\":4}}],[\"km​\",{\"2\":{\"70\":2}}],[\"km\",{\"2\":{\"70\":2}}],[\"k1​\",{\"2\":{\"70\":2}}],[\"k1\",{\"2\":{\"70\":2}}],[\"k\",{\"2\":{\"51\":6,\"70\":9,\"71\":7,\"81\":10,\"82\":4,\"91\":6,\"97\":15,\"123\":10,\"130\":7,\"144\":4,\"159\":12,\"173\":3,\"174\":10,\"175\":1,\"187\":13,\"193\":15,\"197\":4,\"202\":3,\"203\":8,\"259\":2,\"272\":1,\"278\":6}}],[\"keepdim=true\",{\"2\":{\"96\":2,\"152\":2}}],[\"key=lambda\",{\"2\":{\"117\":1}}],[\"key=\",{\"2\":{\"100\":2,\"197\":1}}],[\"key的个数\",{\"2\":{\"81\":1}}],[\"key的形状\",{\"2\":{\"81\":1}}],[\"keys的形状\",{\"2\":{\"59\":1,\"91\":1}}],[\"keys\",{\"2\":{\"59\":6,\"81\":6,\"91\":2,\"173\":6}}],[\"key\",{\"2\":{\"43\":1,\"81\":3,\"115\":1,\"173\":2,\"202\":1,\"278\":2}}],[\"kernel来演示一下如何利用上述的优化\",{\"2\":{\"197\":1}}],[\"kernel\",{\"2\":{\"15\":1,\"63\":2,\"75\":7,\"86\":15,\"130\":4,\"144\":5,\"170\":1,\"197\":3,\"229\":1,\"247\":5}}],[\"对其\",{\"2\":{\"283\":1}}],[\"对值做一个上下界的截断\",{\"2\":{\"262\":1}}],[\"对称量化\",{\"2\":{\"251\":1}}],[\"对第二维求和\",{\"2\":{\"191\":1}}],[\"对第一维求和\",{\"2\":{\"191\":1}}],[\"对每个通道输入的二维张量和每个通道的卷积核的二维张量\",{\"2\":{\"174\":1}}],[\"对比中间激活与模型参数大小\",{\"0\":{\"275\":1}}],[\"对比多线程\",{\"0\":{\"231\":1}}],[\"对比\",{\"0\":{\"202\":1}}],[\"对比串行\",{\"0\":{\"177\":1}}],[\"对比其他语言的协程\",{\"0\":{\"242\":1}}],[\"对比其他语言\",{\"0\":{\"163\":1}}],[\"对比全量来说\",{\"2\":{\"88\":1}}],[\"对\",{\"2\":{\"151\":1}}],[\"对程序的性能有极大的影响\",{\"2\":{\"150\":1}}],[\"对用户达成目标至关重要的信息\",{\"2\":{\"100\":2}}],[\"对话中的音频信号以及网站上的浏览行为都是有顺序的\",{\"2\":{\"93\":1}}],[\"对的个数\",{\"2\":{\"81\":4,\"91\":2,\"173\":6}}],[\"对应都有一个权重矩阵\",{\"2\":{\"225\":1}}],[\"对应\",{\"2\":{\"174\":1}}],[\"对应每个的查询结果\",{\"2\":{\"59\":1}}],[\"对应到标题\",{\"2\":{\"49\":1}}],[\"对个数\",{\"2\":{\"59\":2}}],[\"对于训练的损失函数\",{\"2\":{\"285\":1}}],[\"对于训练来说\",{\"2\":{\"117\":1}}],[\"对于encoder传入的state\",{\"2\":{\"283\":1}}],[\"对于decoder来说\",{\"2\":{\"283\":1}}],[\"对于data来说\",{\"2\":{\"213\":1}}],[\"对于tma的async操作\",{\"2\":{\"276\":1}}],[\"对于transformer类模型\",{\"2\":{\"278\":1}}],[\"对于transformer\",{\"2\":{\"212\":1}}],[\"对于softmax\",{\"2\":{\"272\":1}}],[\"对于layer\",{\"2\":{\"272\":2}}],[\"对于l2\",{\"2\":{\"197\":1}}],[\"对于y进行reshape操作\",{\"2\":{\"270\":1}}],[\"对于最后的数据再次执行requantization\",{\"2\":{\"267\":1}}],[\"对于量化的过程\",{\"2\":{\"267\":1}}],[\"对于非对称量化\",{\"2\":{\"262\":1}}],[\"对于uint8\",{\"2\":{\"262\":1}}],[\"对于对称量化\",{\"2\":{\"262\":1}}],[\"对于async\",{\"2\":{\"260\":1,\"265\":1}}],[\"对于到达的thread\",{\"2\":{\"260\":1}}],[\"对于global\",{\"2\":{\"273\":1}}],[\"对于gil机制\",{\"2\":{\"256\":1}}],[\"对于go的goroutine来说\",{\"2\":{\"242\":1}}],[\"对于interleaved\",{\"2\":{\"252\":1}}],[\"对于io阻塞\",{\"2\":{\"219\":1}}],[\"对于native\",{\"2\":{\"252\":1}}],[\"对于nullptr\",{\"2\":{\"125\":1}}],[\"对于多核处理器\",{\"2\":{\"250\":1}}],[\"对于多线程和协程\",{\"2\":{\"231\":1}}],[\"对于mix\",{\"2\":{\"245\":1}}],[\"对于megatronv1来说\",{\"2\":{\"222\":1}}],[\"对于协程可以做到语言层面的调度\",{\"2\":{\"242\":1}}],[\"对于协程来说\",{\"2\":{\"231\":1}}],[\"对于给定输入元素\",{\"2\":{\"239\":1}}],[\"对于时间步\",{\"2\":{\"230\":1}}],[\"对于再往前的单词如果我们还想统计它们的影响的话\",{\"2\":{\"217\":1}}],[\"对于此类线程\",{\"2\":{\"163\":1}}],[\"对于第二种\",{\"2\":{\"154\":1}}],[\"对于第三维通道\",{\"2\":{\"82\":1}}],[\"对于每个token\",{\"2\":{\"264\":2,\"268\":2}}],[\"对于每个进程\",{\"2\":{\"256\":1}}],[\"对于每个可训练模型参数\",{\"2\":{\"246\":1}}],[\"对于每个self\",{\"2\":{\"225\":1}}],[\"对于每个块\",{\"2\":{\"197\":1}}],[\"对于每个数据\",{\"2\":{\"152\":1}}],[\"对于每个窗口内实行\",{\"2\":{\"130\":1}}],[\"对于每行数据都是采用onehot编码的结果\",{\"2\":{\"152\":1}}],[\"对于这个函数来说\",{\"2\":{\"151\":1}}],[\"对于任何二维张量\",{\"2\":{\"144\":1}}],[\"对于目标序列\",{\"2\":{\"143\":1}}],[\"对于bwd来说\",{\"2\":{\"140\":1}}],[\"对于继承了torch\",{\"2\":{\"140\":1}}],[\"对于模型的训练\",{\"2\":{\"137\":1}}],[\"对于模板类型推导\",{\"2\":{\"122\":1}}],[\"对于一个stage\",{\"2\":{\"252\":1}}],[\"对于一个exp函数来说\",{\"2\":{\"140\":1}}],[\"对于一个任务\",{\"2\":{\"133\":1}}],[\"对于一些计算操作\",{\"2\":{\"133\":1}}],[\"对于\",{\"2\":{\"123\":3,\"151\":2,\"159\":1,\"272\":2}}],[\"对于传值类型推导\",{\"2\":{\"122\":1}}],[\"对于通用引用的推导\",{\"2\":{\"122\":1}}],[\"对于输入的y\",{\"2\":{\"270\":1}}],[\"对于输入序列\",{\"2\":{\"115\":1}}],[\"对于输出来说\",{\"2\":{\"82\":1}}],[\"对于解析问题\",{\"2\":{\"112\":1}}],[\"对于hth\",{\"2\":{\"103\":1}}],[\"对于图像数据\",{\"2\":{\"93\":1}}],[\"对于表格数据我们可以使用全连接层来拟合\",{\"2\":{\"93\":1}}],[\"对于某一层的任意元素\",{\"2\":{\"92\":1}}],[\"对于某个函数\",{\"2\":{\"67\":1}}],[\"对于序列中任何位置的任何输入\",{\"2\":{\"87\":1}}],[\"对于f\",{\"2\":{\"78\":1}}],[\"对于其的改进其实就是将可学习的参数集成到注意力汇聚中\",{\"2\":{\"59\":1}}],[\"对于query和key\",{\"2\":{\"51\":1}}],[\"ys\",{\"2\":{\"188\":4}}],[\"yn​\",{\"2\":{\"186\":1}}],[\"yny\",{\"2\":{\"186\":1}}],[\"y4​\",{\"2\":{\"166\":1}}],[\"y4\",{\"2\":{\"166\":1}}],[\"y3​\",{\"2\":{\"166\":1}}],[\"y3\",{\"2\":{\"166\":1}}],[\"y2​\",{\"2\":{\"166\":1,\"186\":1,\"222\":1}}],[\"y2\",{\"2\":{\"166\":1,\"186\":1,\"203\":2,\"222\":1}}],[\"y1​\",{\"2\":{\"166\":1,\"222\":1}}],[\"y1\",{\"2\":{\"166\":1,\"186\":1,\"203\":2,\"222\":1}}],[\"yyy\",{\"2\":{\"166\":7,\"205\":1,\"222\":1,\"229\":1}}],[\"yty\",{\"2\":{\"137\":1}}],[\"yahoo\",{\"2\":{\"113\":12}}],[\"y=gelu\",{\"2\":{\"222\":5}}],[\"y=\",{\"2\":{\"95\":2,\"166\":2}}],[\"your\",{\"2\":{\"169\":9}}],[\"you\",{\"2\":{\"68\":1}}],[\"ylabel=\",{\"2\":{\"59\":1,\"270\":1,\"285\":1}}],[\"yield\",{\"2\":{\"88\":1,\"176\":1,\"188\":1}}],[\"yi=f\",{\"2\":{\"186\":1}}],[\"yi=2xi2y\",{\"2\":{\"166\":1}}],[\"yi=\",{\"2\":{\"51\":1}}],[\"yiy\",{\"2\":{\"51\":3}}],[\"yi\",{\"2\":{\"51\":2,\"59\":2}}],[\"yi​=f\",{\"2\":{\"186\":1}}],[\"yi​\",{\"2\":{\"51\":4,\"59\":2}}],[\"yif\",{\"2\":{\"51\":3,\"59\":1}}],[\"y\",{\"2\":{\"51\":8,\"59\":8,\"88\":14,\"95\":1,\"96\":4,\"103\":2,\"112\":4,\"130\":11,\"137\":1,\"140\":15,\"144\":6,\"150\":1,\"151\":3,\"152\":25,\"166\":13,\"176\":2,\"186\":3,\"188\":2,\"191\":1,\"203\":2,\"205\":4,\"220\":2,\"222\":3,\"229\":7,\"247\":13,\"255\":4,\"261\":4,\"266\":3,\"269\":2,\"270\":10,\"273\":2,\"277\":3,\"285\":9}}],[\"y^i\",{\"2\":{\"48\":1}}],[\"8bsh8bsh8bsh\",{\"2\":{\"272\":2}}],[\"8bsh28bsh^28bsh2\",{\"2\":{\"259\":2}}],[\"84\",{\"2\":{\"247\":2}}],[\"8h2+7h\",{\"2\":{\"225\":1}}],[\"8h2+7h8h^2\",{\"2\":{\"225\":1}}],[\"8212\",{\"2\":{\"141\":2}}],[\"81\",{\"2\":{\"113\":1}}],[\"832\",{\"2\":{\"86\":2}}],[\"8\",{\"2\":{\"51\":1,\"100\":2,\"130\":2,\"144\":2,\"151\":1,\"166\":3,\"174\":2,\"181\":1,\"191\":1,\"193\":1,\"197\":2,\"220\":2,\"252\":1,\"268\":1,\"269\":1}}],[\"fp32\",{\"2\":{\"271\":1}}],[\"fp8e4m3\",{\"2\":{\"254\":9}}],[\"f32占4个bytes\",{\"2\":{\"246\":1}}],[\"fwd执行完毕之后\",{\"2\":{\"252\":1}}],[\"fwd\",{\"2\":{\"213\":1,\"252\":1}}],[\"fwd没啥好说的\",{\"2\":{\"140\":1}}],[\"false\",{\"2\":{\"269\":1}}],[\"fallbackflags\",{\"2\":{\"169\":1}}],[\"fast\",{\"0\":{\"183\":1}}],[\"fashion\",{\"2\":{\"63\":1,\"152\":1}}],[\"f2\",{\"2\":{\"150\":1}}],[\"f16占2个bytes\",{\"2\":{\"246\":1}}],[\"f1\",{\"2\":{\"150\":1}}],[\"fn=rnn\",{\"2\":{\"255\":1}}],[\"fn之类的元数据来执行bwd\",{\"2\":{\"213\":1}}],[\"fn\",{\"2\":{\"140\":2,\"188\":3,\"213\":1,\"255\":4}}],[\"full\",{\"2\":{\"185\":2}}],[\"fuse一些重复启动的函数\",{\"2\":{\"140\":1}}],[\"fun∣deep\",{\"2\":{\"131\":2}}],[\"fun\",{\"2\":{\"131\":5}}],[\"func\",{\"2\":{\"119\":2,\"213\":1}}],[\"function的ctx\",{\"2\":{\"213\":1}}],[\"function的函数类\",{\"2\":{\"140\":1}}],[\"function里面\",{\"2\":{\"140\":1}}],[\"functions\",{\"2\":{\"140\":1}}],[\"function\",{\"0\":{\"140\":1},\"2\":{\"100\":2,\"140\":1,\"141\":2}}],[\"functional中的函数可以满足我们的一部分需求\",{\"2\":{\"126\":1}}],[\"functional中自带的函数\",{\"2\":{\"126\":1}}],[\"functional\",{\"2\":{\"59\":1,\"70\":2,\"117\":1}}],[\"ffn计算\",{\"2\":{\"259\":1}}],[\"ffn\",{\"2\":{\"225\":1,\"272\":1}}],[\"fff\",{\"2\":{\"159\":1}}],[\"ff\",{\"2\":{\"110\":3,\"138\":4,\"153\":4,\"167\":3,\"181\":2,\"193\":16}}],[\"finish\",{\"2\":{\"282\":1}}],[\"find\",{\"2\":{\"273\":1}}],[\"finally\",{\"2\":{\"263\":1}}],[\"final\",{\"2\":{\"97\":1,\"193\":1}}],[\"file\",{\"2\":{\"114\":1,\"248\":1,\"265\":1}}],[\"fill\",{\"2\":{\"88\":1,\"97\":2,\"193\":2}}],[\"fireball\",{\"2\":{\"113\":2}}],[\"first\",{\"2\":{\"57\":3,\"68\":1,\"197\":3}}],[\"fence\",{\"2\":{\"273\":2,\"279\":1}}],[\"fewer\",{\"2\":{\"263\":1}}],[\"feed\",{\"0\":{\"110\":1},\"2\":{\"87\":1,\"110\":1,\"138\":3,\"153\":3,\"193\":7,\"225\":1}}],[\"features\",{\"2\":{\"81\":4,\"88\":9,\"96\":4,\"103\":3,\"110\":1,\"193\":1}}],[\"feature\",{\"2\":{\"61\":17}}],[\"four\",{\"2\":{\"282\":1}}],[\"found\",{\"2\":{\"114\":1}}],[\"followed\",{\"2\":{\"138\":1,\"193\":1,\"222\":1}}],[\"focused\",{\"2\":{\"100\":2}}],[\"focus\",{\"2\":{\"100\":4}}],[\"footprint\",{\"2\":{\"263\":1}}],[\"footer\",{\"2\":{\"79\":2}}],[\"foo\",{\"2\":{\"79\":4,\"100\":8,\"113\":3,\"114\":1}}],[\"forceinline\",{\"2\":{\"260\":2}}],[\"forge安装的库\",{\"2\":{\"169\":1}}],[\"form\",{\"2\":{\"138\":1,\"153\":1,\"193\":2}}],[\"formatting\",{\"2\":{\"100\":2}}],[\"for=\",{\"2\":{\"100\":2}}],[\"forall\",{\"2\":{\"71\":1,\"108\":1}}],[\"for\",{\"2\":{\"59\":1,\"61\":2,\"63\":3,\"86\":1,\"88\":6,\"97\":4,\"103\":3,\"110\":1,\"113\":2,\"115\":1,\"117\":12,\"130\":3,\"138\":1,\"140\":1,\"152\":2,\"158\":1,\"167\":4,\"174\":1,\"176\":3,\"181\":1,\"187\":1,\"188\":1,\"193\":11,\"197\":6,\"213\":4,\"229\":2,\"247\":4,\"254\":1,\"255\":2,\"260\":1,\"261\":3,\"266\":3,\"269\":1,\"270\":3,\"273\":1,\"282\":3,\"285\":4}}],[\"forward的时候会逐层计算\",{\"2\":{\"252\":1}}],[\"forward\",{\"0\":{\"110\":1},\"2\":{\"59\":1,\"61\":2,\"81\":1,\"86\":2,\"87\":1,\"91\":1,\"96\":1,\"97\":1,\"110\":2,\"115\":1,\"124\":1,\"126\":1,\"130\":1,\"138\":4,\"140\":1,\"150\":2,\"153\":4,\"167\":1,\"173\":1,\"193\":13,\"202\":1,\"213\":1,\"225\":1,\"255\":5,\"263\":2,\"277\":1,\"280\":3,\"283\":2,\"285\":2}}],[\"flat\",{\"2\":{\"285\":1}}],[\"flatten\",{\"2\":{\"63\":1,\"75\":1,\"86\":1,\"247\":1}}],[\"flash\",{\"0\":{\"195\":1}}],[\"float4>\",{\"2\":{\"269\":1,\"273\":4}}],[\"float4\",{\"2\":{\"269\":2,\"273\":5}}],[\"float\",{\"2\":{\"59\":2,\"88\":1,\"96\":2,\"124\":2,\"152\":3,\"193\":2,\"203\":1}}],[\"float32的模型参数来更新模型参数\",{\"2\":{\"246\":1}}],[\"float32的梯度\",{\"2\":{\"246\":1}}],[\"float32\",{\"2\":{\"55\":3,\"81\":1,\"103\":1,\"202\":2,\"229\":1,\"255\":1,\"277\":1,\"285\":1}}],[\"floating\",{\"2\":{\"55\":1,\"259\":1}}],[\"flops\",{\"2\":{\"55\":1,\"259\":1}}],[\"fc2\",{\"2\":{\"110\":2,\"193\":2}}],[\"fc1\",{\"2\":{\"110\":2,\"193\":2}}],[\"fc\",{\"2\":{\"55\":1,\"167\":2,\"193\":2}}],[\"f\",{\"2\":{\"51\":9,\"59\":3,\"70\":3,\"78\":7,\"88\":4,\"103\":3,\"117\":4,\"122\":20,\"126\":1,\"130\":1,\"135\":4,\"140\":2,\"150\":4,\"151\":21,\"159\":1,\"181\":1,\"186\":1,\"193\":1,\"217\":1,\"247\":4,\"255\":1,\"259\":1,\"269\":4,\"270\":1,\"277\":1,\"278\":2,\"285\":2}}],[\"frigging\",{\"2\":{\"127\":1}}],[\"fringilla\",{\"2\":{\"57\":2,\"68\":3}}],[\"freq\",{\"2\":{\"117\":3}}],[\"freqs\",{\"2\":{\"117\":4}}],[\"freq=0\",{\"2\":{\"117\":1}}],[\"free\",{\"2\":{\"106\":1}}],[\"from\",{\"2\":{\"61\":1,\"88\":3,\"100\":2,\"113\":8,\"117\":5,\"152\":2,\"153\":1,\"193\":1,\"254\":2,\"265\":3,\"273\":1,\"282\":1}}],[\"frontmatter\",{\"2\":{\"25\":1}}],[\"frac1c\",{\"2\":{\"128\":4}}],[\"frac\",{\"2\":{\"48\":1,\"51\":7,\"59\":4,\"70\":1,\"88\":1,\"91\":2,\"103\":2,\"108\":1,\"123\":19,\"128\":6,\"137\":2,\"145\":1,\"151\":1,\"166\":4,\"173\":1,\"202\":4,\"249\":2,\"252\":2,\"259\":1,\"262\":5,\"266\":1,\"268\":1,\"278\":2}}],[\"输出照例为一个output和一个state\",{\"2\":{\"283\":1}}],[\"输出层参数\",{\"2\":{\"255\":1}}],[\"输出层的数据可以写为\",{\"2\":{\"230\":1}}],[\"输出操作数约束\",{\"2\":{\"248\":1}}],[\"输出后的效果\",{\"2\":{\"228\":1}}],[\"输出x的形状\",{\"2\":{\"173\":2}}],[\"输出x的形状为\",{\"2\":{\"115\":1}}],[\"输出的state的shape为\",{\"2\":{\"283\":1}}],[\"输出的y\",{\"2\":{\"270\":1}}],[\"输出的queries\",{\"2\":{\"173\":1}}],[\"输出的维度为\",{\"2\":{\"81\":1}}],[\"输出形状就为\",{\"2\":{\"144\":1}}],[\"输出也是一个\",{\"2\":{\"123\":1}}],[\"输出设置为\",{\"2\":{\"71\":1}}],[\"输出\",{\"2\":{\"50\":1,\"58\":1,\"68\":1,\"69\":1,\"90\":1,\"100\":12,\"114\":1,\"118\":2,\"128\":1,\"142\":1,\"144\":1,\"157\":1,\"172\":1,\"200\":1,\"215\":1,\"283\":2}}],[\"输入一个prompt序列\",{\"2\":{\"278\":1}}],[\"输入一个长度为\",{\"2\":{\"278\":1}}],[\"输入映射需要保存输入\",{\"2\":{\"272\":1}}],[\"输入包含了\",{\"2\":{\"272\":1}}],[\"输入和输出为\",{\"2\":{\"259\":1}}],[\"输入和输出的通道数都是\",{\"2\":{\"202\":1}}],[\"输入的均值\",{\"2\":{\"272\":1}}],[\"输入的tokens数为\",{\"2\":{\"264\":1}}],[\"输入的数据\",{\"2\":{\"259\":1}}],[\"输入的高度和宽度均为3\",{\"2\":{\"144\":1}}],[\"输入数据也需要放到gpu上\",{\"2\":{\"253\":1}}],[\"输入操作数约束\",{\"2\":{\"248\":1}}],[\"输入维度为\",{\"2\":{\"230\":1}}],[\"输入为\",{\"2\":{\"225\":1}}],[\"输入x的形状\",{\"2\":{\"173\":1}}],[\"输入输出为自然语言\",{\"2\":{\"158\":1}}],[\"输入到gru中\",{\"2\":{\"143\":1}}],[\"输入到一个mlp中\",{\"2\":{\"81\":1}}],[\"输入嵌入\",{\"2\":{\"129\":1}}],[\"输入链接的标识\",{\"2\":{\"113\":1}}],[\"输入不固定的情况下我们可以有以下两种策略\",{\"2\":{\"103\":1}}],[\"输入序列对应的每个位置\",{\"2\":{\"87\":1}}],[\"输入\",{\"2\":{\"50\":1,\"58\":1,\"69\":1,\"90\":1,\"100\":12,\"114\":1,\"128\":1,\"142\":1,\"157\":1,\"172\":1,\"200\":1,\"215\":1,\"216\":1,\"272\":1}}],[\"|\",{\"2\":{\"50\":20,\"57\":1,\"123\":2,\"128\":15,\"131\":3,\"266\":2,\"278\":1}}],[\"34bsh\",{\"2\":{\"272\":1}}],[\"34bsh+5bs2a\",{\"2\":{\"272\":2}}],[\"3bsh3bsh3bsh\",{\"2\":{\"272\":1}}],[\"3>\",{\"2\":{\"269\":2,\"273\":2}}],[\"3$\",{\"2\":{\"264\":1}}],[\"3∗2∗bsh23\",{\"2\":{\"259\":1}}],[\"35\",{\"2\":{\"255\":1}}],[\"3这样的标号访问\",{\"2\":{\"154\":1}}],[\"3x2​\",{\"2\":{\"151\":1}}],[\"3^\",{\"2\":{\"151\":1}}],[\"3f\",{\"2\":{\"130\":1,\"247\":3,\"285\":1}}],[\"3e\",{\"2\":{\"130\":1}}],[\"30\",{\"2\":{\"122\":1}}],[\"320\",{\"2\":{\"86\":2}}],[\"32\",{\"2\":{\"86\":5,\"255\":1}}],[\"384\",{\"2\":{\"75\":1,\"86\":1}}],[\"3d张量\",{\"2\":{\"70\":1}}],[\"3\",{\"0\":{\"59\":1,\"71\":1,\"88\":1,\"117\":1,\"123\":1,\"124\":1,\"160\":1,\"186\":1,\"220\":1,\"242\":1,\"258\":1,\"266\":1,\"272\":1,\"275\":1,\"283\":1},\"1\":{\"174\":1,\"187\":1,\"202\":1,\"275\":1,\"285\":1},\"2\":{\"49\":1,\"50\":2,\"68\":1,\"75\":2,\"88\":3,\"95\":1,\"96\":2,\"100\":1,\"112\":3,\"113\":2,\"140\":1,\"144\":4,\"151\":7,\"152\":2,\"166\":7,\"167\":1,\"173\":3,\"174\":4,\"178\":1,\"191\":1,\"193\":1,\"197\":1,\"200\":2,\"203\":4,\"220\":6,\"229\":6,\"232\":1,\"243\":2,\"247\":1,\"252\":1,\"254\":4,\"268\":3,\"269\":2,\"273\":3}}],[\"阶段\",{\"2\":{\"278\":1}}],[\"阶马尔科夫模型又被称为\",{\"2\":{\"217\":1}}],[\"阶马尔科夫模型\",{\"2\":{\"103\":1}}],[\"阶\",{\"2\":{\"49\":1}}],[\"个transformer层的向量表示为\",{\"2\":{\"278\":1}}],[\"个transformer层的权重矩阵为\",{\"2\":{\"278\":1}}],[\"个transformer层需要保存的中间激活占用显存大小为\",{\"2\":{\"272\":1}}],[\"个元素\",{\"2\":{\"272\":2}}],[\"个隐藏层的输入\",{\"2\":{\"266\":1}}],[\"个隐藏层的输出作为第\",{\"2\":{\"266\":1}}],[\"个隐藏层的dnn\",{\"2\":{\"266\":1}}],[\"个请求\",{\"2\":{\"256\":1}}],[\"个应用框架\",{\"2\":{\"256\":1}}],[\"个进程在使用\",{\"2\":{\"256\":1}}],[\"个进程\",{\"2\":{\"256\":1}}],[\"个相同层堆叠而成\",{\"2\":{\"225\":1}}],[\"个单词\",{\"2\":{\"217\":1}}],[\"个顺序操作\",{\"2\":{\"202\":3}}],[\"个头连结后的结果\",{\"2\":{\"159\":1}}],[\"个注意力汇聚输出\",{\"2\":{\"159\":1}}],[\"个注意力汇聚的输出拼接在一起\",{\"2\":{\"159\":1}}],[\"个最常用单词的频率\",{\"2\":{\"145\":1}}],[\"个词元的交叉熵损失的平均值来衡量\",{\"2\":{\"249\":1}}],[\"个词元的\",{\"2\":{\"202\":1}}],[\"个词元组成的序列映射到另一个长度相等的序列\",{\"2\":{\"202\":1}}],[\"个词元\",{\"2\":{\"115\":1}}],[\"个字元\",{\"2\":{\"113\":3}}],[\"个时间点跨度\",{\"2\":{\"103\":1}}],[\"个查询和\",{\"2\":{\"91\":1}}],[\"个空白或是\",{\"2\":{\"79\":2}}],[\"个空白或是一个\",{\"2\":{\"68\":1}}],[\"个键值对计算注意力\",{\"2\":{\"91\":1}}],[\"个键值对\",{\"2\":{\"70\":1}}],[\"个键值对匹配\",{\"2\":{\"59\":1}}],[\"个\",{\"2\":{\"49\":1,\"79\":2}}],[\"6bsh26bsh^26bsh2\",{\"2\":{\"259\":1}}],[\"6h\",{\"2\":{\"225\":1}}],[\"600\",{\"2\":{\"103\":1}}],[\"6节中残差网络的启发\",{\"2\":{\"87\":1}}],[\"64bit\",{\"2\":{\"260\":1}}],[\"64位寄存器\",{\"2\":{\"248\":1}}],[\"64\",{\"2\":{\"63\":1,\"86\":3,\"169\":2,\"181\":2,\"193\":2,\"197\":1,\"199\":2}}],[\"6f\",{\"2\":{\"59\":1}}],[\"6\",{\"0\":{\"102\":1},\"2\":{\"49\":3,\"81\":1,\"100\":1,\"130\":4,\"152\":1,\"174\":2,\"181\":1,\"191\":2,\"193\":1,\"203\":1,\"220\":2,\"232\":1,\"247\":3,\"269\":2,\"273\":2}}],[\"到这里其实可以发现一个很简单的性质\",{\"2\":{\"231\":1}}],[\"到目前为止\",{\"2\":{\"156\":1}}],[\"到\",{\"2\":{\"49\":2}}],[\"推导会去掉表达式的引用性ref\",{\"2\":{\"150\":1}}],[\"推导\",{\"0\":{\"71\":1}}],[\"推荐\",{\"2\":{\"49\":1}}],[\"推理与kv\",{\"0\":{\"278\":1}}],[\"推理过程中的中间结果用完会尽快释放掉\",{\"2\":{\"253\":1}}],[\"推理过程显存占用分析\",{\"0\":{\"253\":1}}],[\"推理阶段模型参数占用的显存大概是\",{\"2\":{\"253\":1}}],[\"推理加速的整体原则\",{\"2\":{\"66\":1}}],[\"推理框架\",{\"2\":{\"1\":1}}],[\"推理infra中\",{\"2\":{\"1\":1}}],[\"最好以单个token维度展现求和\",{\"2\":{\"278\":1}}],[\"最好加上override\",{\"2\":{\"182\":1}}],[\"最简单粗暴规避的方式就是直接实现多进程\",{\"2\":{\"256\":1}}],[\"最终输出一个维数与结果分类数相匹配的输出\",{\"2\":{\"247\":1}}],[\"最终输出的形状\",{\"2\":{\"173\":1}}],[\"最大汇聚层会输出该窗口内的最大值\",{\"2\":{\"239\":1}}],[\"最大汇聚层与平均汇聚层\",{\"0\":{\"229\":1}}],[\"最大汇聚的输入\",{\"2\":{\"229\":1}}],[\"最大路径长度也是\",{\"2\":{\"202\":2}}],[\"最大路径长度为\",{\"2\":{\"202\":1}}],[\"最重要的一步就是准备数据\",{\"2\":{\"117\":1}}],[\"最重要的一点\",{\"2\":{\"112\":1}}],[\"最多三个空白\",{\"2\":{\"68\":1}}],[\"最后写入memory\",{\"2\":{\"267\":1}}],[\"最后再对数据进行映射\",{\"2\":{\"262\":1}}],[\"最后我们组合在一起\",{\"2\":{\"255\":1}}],[\"最后我们介绍lenet\",{\"2\":{\"247\":1}}],[\"最后我们得到o\",{\"2\":{\"95\":1}}],[\"最后all\",{\"2\":{\"245\":1}}],[\"最后对梯度all\",{\"2\":{\"245\":1}}],[\"最后演变为了async\",{\"2\":{\"219\":1}}],[\"最后\",{\"2\":{\"159\":1,\"247\":1}}],[\"最后还可以用引号包住并加上选择性的\",{\"2\":{\"156\":1}}],[\"最后一个droupout操作\",{\"2\":{\"272\":1}}],[\"最后一步\",{\"2\":{\"95\":1}}],[\"最后一轴上被掩蔽的元素使用一个非常大的负值替换\",{\"2\":{\"70\":1}}],[\"最后的结果会按照加权综合考虑shared\",{\"2\":{\"72\":1}}],[\"最后汇集在一起\",{\"2\":{\"61\":1}}],[\"最后输出shape为\",{\"2\":{\"59\":1}}],[\"最常用的数据格式为float32\",{\"2\":{\"55\":1}}],[\"最高阶标题\",{\"2\":{\"49\":1}}],[\"最小值或者局部最小值\",{\"2\":{\"67\":1}}],[\"最小\",{\"2\":{\"48\":1}}],[\"利用多核实现并行\",{\"2\":{\"256\":1}}],[\"利用torch的按维度求和\",{\"2\":{\"152\":1}}],[\"利用decoder的隐状态生成当前时间步的输出单词\",{\"2\":{\"143\":1}}],[\"利用\",{\"2\":{\"49\":1}}],[\"解决这个问题的方式就是填充\",{\"2\":{\"144\":1}}],[\"解决方案就是堆叠多个卷积核\",{\"2\":{\"82\":1}}],[\"解决方案\",{\"2\":{\"38\":2}}],[\"解码\",{\"2\":{\"278\":1}}],[\"解码阶段\",{\"2\":{\"278\":1}}],[\"解码过程中逐词生成\",{\"2\":{\"143\":1}}],[\"解码器架构的基类\",{\"2\":{\"280\":1}}],[\"解码器架构的基本解码器接口\",{\"2\":{\"280\":1}}],[\"解码器架构的基本编码器接口\",{\"2\":{\"280\":1}}],[\"解码器中的每个位置只能考虑该位置之前的所有位置\",{\"2\":{\"87\":1}}],[\"解码器注意力中\",{\"2\":{\"87\":1}}],[\"解码器注意力\",{\"2\":{\"87\":1}}],[\"解码器还在这两个子层之间插入了第三个子层\",{\"2\":{\"87\":1}}],[\"解方程\",{\"2\":{\"48\":1}}],[\"^=\",{\"2\":{\"282\":1}}],[\"^l\",{\"2\":{\"278\":1}}],[\"^脚注1\",{\"2\":{\"215\":2}}],[\"^d\",{\"2\":{\"186\":1}}],[\"^a\",{\"2\":{\"117\":1}}],[\"^t\",{\"2\":{\"103\":1,\"278\":1}}],[\"^kk∈rk\",{\"2\":{\"81\":1}}],[\"^qq∈rq\",{\"2\":{\"81\":1}}],[\"^v\",{\"2\":{\"70\":1}}],[\"^m\",{\"2\":{\"70\":2}}],[\"^nx=\",{\"2\":{\"108\":1}}],[\"^n\",{\"2\":{\"51\":7,\"166\":1,\"249\":2}}],[\"^\",{\"2\":{\"48\":1,\"59\":4,\"71\":2,\"78\":1,\"81\":3,\"82\":4,\"87\":2,\"91\":6,\"103\":1,\"108\":1,\"115\":1,\"123\":10,\"131\":1,\"137\":1,\"152\":2,\"157\":2,\"159\":9,\"166\":3,\"186\":1,\"202\":2,\"278\":12}}],[\"^2\",{\"2\":{\"38\":1,\"48\":1,\"51\":3,\"59\":3,\"123\":3}}],[\"2∗2∗bsh=4bsh2\",{\"2\":{\"272\":1}}],[\"2bs2a+2bsh2bs^2a\",{\"2\":{\"272\":1}}],[\"2bs2a2bs^2a2bs2a\",{\"2\":{\"272\":2}}],[\"2bs2h+2bsh22bs^2h\",{\"2\":{\"259\":1}}],[\"2bs2h2bs^2h2bs2h\",{\"2\":{\"259\":1}}],[\"2bsbsh+2bs\",{\"2\":{\"272\":1}}],[\"2bsh2bs2a+2bsh\",{\"2\":{\"272\":1}}],[\"2bsh2bsh2bsh\",{\"2\":{\"272\":3}}],[\"2bshv\",{\"2\":{\"259\":1}}],[\"2bshv2bshv2bshv\",{\"2\":{\"259\":1}}],[\"2bsh^22bs2h+2bsh2\",{\"2\":{\"259\":1}}],[\"2了\",{\"2\":{\"252\":1}}],[\"2+4\",{\"2\":{\"246\":4}}],[\"2+1\",{\"2\":{\"55\":2}}],[\"2ϕ2\",{\"2\":{\"246\":1}}],[\"2$\",{\"2\":{\"225\":1}}],[\"2的矩阵\",{\"2\":{\"178\":1}}],[\"2的全零矩阵\",{\"2\":{\"178\":1}}],[\"28x=\",{\"2\":{\"151\":1}}],[\"288\",{\"2\":{\"86\":1}}],[\"2^\",{\"2\":{\"151\":1}}],[\"22⋅2\",{\"2\":{\"144\":1,\"229\":1}}],[\"224lbsh2\",{\"2\":{\"264\":1}}],[\"224\",{\"2\":{\"86\":1}}],[\"2⋅22\",{\"2\":{\"144\":1,\"229\":1}}],[\"2a\",{\"2\":{\"128\":2,\"222\":1}}],[\"21​​∂x∂p​​1​=21​i\",{\"2\":{\"123\":1}}],[\"2pi​−pi2​​\",{\"2\":{\"123\":1}}],[\"2exi​∑k=1n​exk​−e2xi​​∑k=1n​exk​exi​​−\",{\"2\":{\"123\":1}}],[\"2=\",{\"2\":{\"123\":3}}],[\"29\",{\"2\":{\"122\":1}}],[\"27\",{\"2\":{\"100\":1,\"135\":4}}],[\"234\",{\"2\":{\"113\":1}}],[\"23\",{\"2\":{\"100\":1}}],[\"2表示完全连接层\",{\"2\":{\"96\":1}}],[\"24lbsh2\",{\"2\":{\"264\":1}}],[\"24lbsh224lbsh^224lbsh2\",{\"2\":{\"264\":1}}],[\"24bsh^2\",{\"2\":{\"259\":1}}],[\"24bsh2+4bs2h\",{\"2\":{\"259\":2}}],[\"24bsh2+4bs2h24bsh^2\",{\"2\":{\"259\":1}}],[\"24\",{\"2\":{\"86\":2}}],[\"2x^txf\",{\"2\":{\"151\":2}}],[\"2x\",{\"2\":{\"78\":1,\"123\":1,\"166\":1}}],[\"256\",{\"2\":{\"63\":1,\"75\":1,\"86\":2,\"152\":1,\"197\":1}}],[\"20ϕ20\",{\"2\":{\"246\":1}}],[\"20bytes\",{\"2\":{\"246\":1}}],[\"2048\",{\"2\":{\"181\":1,\"193\":1}}],[\"20⋅∑k=1n​exk​−exi​+xj​​−∑k=1n​exk​exi​​⋅∑k=1n​exk​exj​​−pi​pj​​\",{\"2\":{\"123\":1}}],[\"208\",{\"2\":{\"86\":1}}],[\"2004\",{\"2\":{\"79\":2}}],[\"20\",{\"2\":{\"59\":1,\"81\":1,\"118\":1,\"122\":1,\"232\":1}}],[\"2\",{\"0\":{\"51\":1,\"60\":1,\"78\":1,\"103\":1,\"108\":1,\"110\":1,\"144\":1,\"159\":1,\"175\":1,\"177\":1,\"207\":1,\"231\":1,\"239\":1,\"252\":1,\"253\":1,\"255\":1,\"259\":1,\"264\":1,\"268\":2,\"280\":1,\"286\":1},\"1\":{\"173\":1,\"261\":1,\"264\":1,\"268\":1},\"2\":{\"48\":1,\"49\":1,\"50\":2,\"51\":12,\"55\":1,\"59\":18,\"61\":5,\"63\":3,\"68\":2,\"78\":2,\"81\":6,\"88\":8,\"91\":1,\"95\":1,\"96\":7,\"97\":3,\"100\":4,\"103\":1,\"108\":1,\"112\":4,\"113\":2,\"114\":1,\"115\":4,\"118\":1,\"119\":1,\"123\":5,\"124\":3,\"130\":5,\"131\":1,\"140\":4,\"144\":4,\"151\":14,\"152\":3,\"154\":2,\"166\":7,\"167\":1,\"173\":4,\"174\":4,\"178\":8,\"186\":2,\"187\":1,\"191\":8,\"193\":7,\"200\":2,\"202\":3,\"203\":1,\"205\":1,\"220\":8,\"222\":6,\"229\":3,\"232\":2,\"243\":2,\"246\":2,\"247\":4,\"252\":3,\"254\":4,\"255\":1,\"259\":2,\"264\":1,\"266\":1,\"267\":1,\"269\":3,\"270\":1,\"272\":1,\"273\":5,\"277\":2,\"278\":3,\"282\":1,\"283\":4,\"285\":2}}],[\"2m\",{\"2\":{\"48\":1}}],[\"2j+1​=cos\",{\"2\":{\"202\":1}}],[\"2j+1\",{\"2\":{\"202\":1}}],[\"2j+1=cos⁡\",{\"2\":{\"202\":1}}],[\"2j​=sin\",{\"2\":{\"202\":1}}],[\"2j=sin⁡\",{\"2\":{\"202\":1}}],[\"2j\",{\"2\":{\"48\":1,\"202\":3}}],[\"2−e\",{\"2\":{\"38\":2}}],[\"θ∥g∥\",{\"2\":{\"266\":1}}],[\"θi\",{\"2\":{\"88\":2}}],[\"θ1​初值\",{\"2\":{\"67\":1}}],[\"θ1​求偏导\",{\"2\":{\"48\":1}}],[\"θ1​\",{\"2\":{\"48\":2,\"67\":3,\"88\":1}}],[\"θ1\",{\"2\":{\"48\":3,\"67\":4,\"88\":1}}],[\"θ0​\",{\"2\":{\"48\":2,\"67\":2,\"88\":1}}],[\"θ0\",{\"2\":{\"48\":2,\"67\":2,\"88\":1}}],[\"join\",{\"2\":{\"261\":1}}],[\"java中\",{\"2\":{\"163\":1}}],[\"jacobianjacobianjacobian\",{\"2\":{\"123\":1}}],[\"jpg\",{\"2\":{\"156\":2}}],[\"jpi​\",{\"2\":{\"108\":1}}],[\"j=t​\",{\"2\":{\"137\":1}}],[\"j≠t\",{\"2\":{\"137\":1}}],[\"j∑​​∂xj​∂pi​​​=21​i∑​\",{\"2\":{\"123\":1}}],[\"j∣∂pi∂xj∣=12∑i\",{\"2\":{\"123\":1}}],[\"j−pipj=\",{\"2\":{\"123\":1}}],[\"json的路径就可以了\",{\"2\":{\"169\":1}}],[\"json下面的clangd参数指定compile\",{\"2\":{\"169\":1}}],[\"json下配置\",{\"2\":{\"169\":1}}],[\"json\",{\"2\":{\"169\":1}}],[\"js\",{\"2\":{\"100\":2,\"114\":6}}],[\"j+2\",{\"2\":{\"229\":2}}],[\"j+1\",{\"2\":{\"229\":4}}],[\"j+b​\",{\"2\":{\"71\":2}}],[\"j+b\",{\"2\":{\"71\":4,\"82\":6}}],[\"j+∑a∑b\",{\"2\":{\"71\":1}}],[\"j+∑k∑l\",{\"2\":{\"71\":1}}],[\"jit\",{\"2\":{\"197\":1}}],[\"ji=j\",{\"2\":{\"123\":1}}],[\"ji=j\",{\"2\":{\"123\":1}}],[\"ji\",{\"2\":{\"71\":2}}],[\"j​\",{\"2\":{\"137\":1}}],[\"j​−pi​pj​=\",{\"2\":{\"123\":1}}],[\"j​+a∑​b∑​\",{\"2\":{\"71\":1}}],[\"j​+k∑​l∑​\",{\"2\":{\"71\":1}}],[\"j​=u+a=−δ∑δ​b=−δ∑δ​c∑​\",{\"2\":{\"82\":1}}],[\"j​=u+a=−δ∑δ​b=−δ∑δ​\",{\"2\":{\"71\":1}}],[\"j​=u+a∑​b∑​\",{\"2\":{\"71\":1}}],[\"j​=\",{\"2\":{\"71\":2,\"137\":1}}],[\"j=tpj​\",{\"2\":{\"137\":1}}],[\"j=tpj\",{\"2\":{\"137\":1}}],[\"j=u+∑a=−δδ∑b=−δδ∑c\",{\"2\":{\"82\":1}}],[\"j=u+∑a=−δδ∑b=−δδ\",{\"2\":{\"71\":1}}],[\"j=u+∑a∑b\",{\"2\":{\"71\":1}}],[\"j=\",{\"2\":{\"71\":2,\"137\":1}}],[\"j=1∑n​gradientj​∗∂xi​∂yj​​=j=1∑n​∂xi​∂yj​​=4xi​\",{\"2\":{\"166\":1}}],[\"j=1∑n​∂xi​∂yj​​\",{\"2\":{\"166\":1}}],[\"j=1\",{\"2\":{\"51\":2,\"59\":1,\"70\":1,\"108\":1,\"166\":4}}],[\"j\",{\"2\":{\"48\":4,\"51\":2,\"59\":1,\"67\":4,\"70\":1,\"71\":19,\"78\":3,\"82\":10,\"88\":3,\"104\":2,\"108\":2,\"118\":2,\"123\":16,\"128\":2,\"130\":4,\"137\":9,\"144\":6,\"166\":5,\"176\":4,\"229\":16}}],[\"使其具有与x相同的num\",{\"2\":{\"283\":1}}],[\"使其等于0\",{\"2\":{\"48\":1}}],[\"使得其天然支持并行\",{\"2\":{\"242\":1}}],[\"使得其近似正确\",{\"2\":{\"103\":1}}],[\"使得我们可以按照自己的需求分配各个元素的贡献\",{\"2\":{\"166\":1}}],[\"使得输入和输出shape相同\",{\"2\":{\"144\":1}}],[\"使得它不会立刻被析构\",{\"2\":{\"119\":1}}],[\"使得卷积层的参数大幅下降\",{\"2\":{\"71\":1}}],[\"使得j\",{\"2\":{\"67\":1}}],[\"使得损失函数最小\",{\"2\":{\"48\":1}}],[\"使用kittens就有了一个范式\",{\"2\":{\"282\":1}}],[\"使用一个thread去wait之前的cp\",{\"2\":{\"279\":1}}],[\"使用一种和链接很相似的语法来标记图片\",{\"2\":{\"156\":1}}],[\"使用并更新kv\",{\"2\":{\"278\":1}}],[\"使用st\",{\"2\":{\"273\":1}}],[\"使用cp\",{\"2\":{\"273\":1}}],[\"使用激活重计算的一次训练迭代中\",{\"2\":{\"268\":1}}],[\"使用激活重计算技术来减少中间激活显存\",{\"2\":{\"268\":1}}],[\"使用tma\",{\"2\":{\"265\":1}}],[\"使用gpu计算模型在数据集上的精度\",{\"2\":{\"247\":1}}],[\"使用最大汇聚层以及大于1的步幅\",{\"2\":{\"239\":1}}],[\"使用最大汇聚层\",{\"2\":{\"229\":1}}],[\"使用顺序分区生成一个小批量子序列\",{\"2\":{\"188\":1}}],[\"使用其他创建\",{\"2\":{\"178\":1}}],[\"使用随机抽样生成一个小批量子序列\",{\"2\":{\"176\":1}}],[\"使用deleted\",{\"2\":{\"168\":1}}],[\"使用交叉熵来反映\",{\"2\":{\"158\":1}}],[\"使用星号\",{\"2\":{\"127\":1}}],[\"使用了加性注意力打分函数\",{\"2\":{\"115\":1}}],[\"使用参考式的文章本身只有\",{\"2\":{\"113\":1}}],[\"使用点积可以得到计算效率更高的评分函数\",{\"2\":{\"91\":1}}],[\"使用梯度下降来尽可能靠近true\",{\"2\":{\"88\":1}}],[\"使用广播方式进行求和\",{\"2\":{\"81\":1}}],[\"使用某个可以更好地解决这个token问题的expert来处理该token\",{\"2\":{\"61\":1}}],[\"使用\",{\"2\":{\"32\":3,\"57\":1,\"100\":1,\"113\":1,\"142\":1,\"157\":2}}],[\"使用自定义锚点\",{\"2\":{\"18\":2}}],[\"0>\",{\"2\":{\"279\":2,\"282\":1}}],[\"0代表等待所有\",{\"2\":{\"279\":1}}],[\"0zw​=0\",{\"2\":{\"271\":1}}],[\"0h0​\",{\"2\":{\"255\":1}}],[\"0的结果\",{\"2\":{\"205\":2}}],[\"0001\",{\"2\":{\"181\":1,\"193\":1}}],[\"0​​\",{\"2\":{\"151\":1}}],[\"0四个浮点数\",{\"2\":{\"151\":1}}],[\"0∇⋅b=0\",{\"2\":{\"128\":1}}],[\"0a=0\",{\"2\":{\"128\":1}}],[\"0$\",{\"2\":{\"128\":2}}],[\"0⋅∑k=1nexk−exi+xj\",{\"2\":{\"123\":1}}],[\"090b5e7e70c295757f55df93cb0a180b9691891a\",{\"2\":{\"117\":1}}],[\"02\",{\"2\":{\"103\":1,\"151\":2}}],[\"03\",{\"2\":{\"88\":2,\"151\":2}}],[\"0b0​\",{\"2\":{\"88\":1}}],[\"0w0​\",{\"2\":{\"88\":1}}],[\"0^\",{\"2\":{\"78\":1,\"151\":1}}],[\"0x0​=0\",{\"2\":{\"151\":1}}],[\"0x0​点的梯度\",{\"2\":{\"151\":1}}],[\"0x0​点的值\",{\"2\":{\"151\":1}}],[\"0x0​的requires\",{\"2\":{\"151\":1}}],[\"0x0​作为初始值\",{\"2\":{\"151\":1}}],[\"0x0​\",{\"2\":{\"78\":1,\"88\":1,\"151\":3}}],[\"01\",{\"2\":{\"51\":1,\"88\":3,\"103\":2,\"151\":2,\"152\":2,\"255\":1}}],[\"05\",{\"2\":{\"51\":1,\"63\":1}}],[\"0\",{\"2\":{\"48\":4,\"51\":5,\"59\":2,\"63\":4,\"67\":4,\"75\":1,\"78\":4,\"81\":1,\"86\":4,\"88\":12,\"95\":18,\"96\":4,\"97\":1,\"103\":5,\"108\":3,\"112\":3,\"113\":1,\"115\":4,\"117\":4,\"123\":1,\"124\":5,\"128\":4,\"130\":6,\"140\":11,\"150\":4,\"151\":18,\"152\":18,\"166\":10,\"167\":2,\"173\":4,\"174\":28,\"176\":3,\"178\":1,\"181\":3,\"187\":2,\"188\":2,\"191\":3,\"193\":11,\"202\":2,\"203\":3,\"205\":2,\"220\":3,\"229\":3,\"247\":6,\"251\":3,\"254\":10,\"255\":2,\"260\":6,\"261\":1,\"262\":1,\"268\":6,\"269\":13,\"270\":3,\"273\":11,\"279\":8,\"282\":7,\"283\":4,\"285\":5}}],[\"=t\",{\"2\":{\"278\":1}}],[\"=t=1∏t​p\",{\"2\":{\"103\":2,\"131\":1}}],[\"=fgelu​\",{\"2\":{\"278\":2}}],[\"=fgelu\",{\"2\":{\"278\":2}}],[\"=r\",{\"2\":{\"254\":8,\"273\":2}}],[\"=h\",{\"2\":{\"254\":2}}],[\"=1+2+1=4=1+2+1=4=1+2+1=4\",{\"2\":{\"268\":1}}],[\"=1\",{\"2\":{\"229\":1}}],[\"=1y\",{\"2\":{\"229\":1}}],[\"=12πexp⁡\",{\"2\":{\"51\":1}}],[\"=12m∑i=1m\",{\"2\":{\"48\":1}}],[\"=−128−round\",{\"2\":{\"262\":2}}],[\"=−lnpt​\",{\"2\":{\"137\":1}}],[\"=−lnptloss\",{\"2\":{\"137\":1}}],[\"=−i=1∑n​yi​⋅lnpi​\",{\"2\":{\"137\":1}}],[\"=−∑i=1nyi⋅lnpiloss\",{\"2\":{\"137\":1}}],[\"=p\",{\"2\":{\"103\":3,\"131\":2}}],[\"=∏t=1tp\",{\"2\":{\"103\":2,\"131\":1}}],[\"=d​q⊤k​\",{\"2\":{\"91\":1}}],[\"=q⊤kd\",{\"2\":{\"91\":1}}],[\"=θi−αddθij\",{\"2\":{\"88\":1}}],[\"=θ0​+θ1​x\",{\"2\":{\"48\":1}}],[\"=θ0+θ1xh\",{\"2\":{\"48\":1}}],[\"=wv⊤​tanh\",{\"2\":{\"81\":1}}],[\"=wv⊤tanh⁡\",{\"2\":{\"81\":1}}],[\"=x\",{\"2\":{\"278\":3}}],[\"=x02​+x12​\",{\"2\":{\"78\":1}}],[\"=x02+x12f\",{\"2\":{\"78\":1}}],[\"=x2\",{\"2\":{\"78\":1}}],[\"=x2f\",{\"2\":{\"78\":1}}],[\"=∑t=1tα\",{\"2\":{\"115\":1}}],[\"=∑xtp\",{\"2\":{\"103\":3}}],[\"=∑j=1m​exp\",{\"2\":{\"70\":1}}],[\"=∑i=1mα\",{\"2\":{\"70\":1}}],[\"=∑i=1nsoftmax\",{\"2\":{\"51\":1,\"59\":1}}],[\"=∑i=1nexp⁡\",{\"2\":{\"51\":1,\"59\":1}}],[\"=∑i=1nα\",{\"2\":{\"51\":2,\"59\":1}}],[\"=∑i=1nk\",{\"2\":{\"51\":1}}],[\"=exp⁡\",{\"2\":{\"70\":1}}],[\"=softmax\",{\"2\":{\"70\":2,\"108\":2,\"278\":2}}],[\"=i=1∑m​α\",{\"2\":{\"70\":1}}],[\"=i=1∑n​softmax\",{\"2\":{\"51\":1,\"59\":1}}],[\"=i=1∑n​∑j=1n​exp\",{\"2\":{\"51\":1,\"59\":1}}],[\"=i=1∑n​∑j=1n​k\",{\"2\":{\"51\":1}}],[\"=i=1∑n​α\",{\"2\":{\"51\":2,\"59\":1}}],[\"==简洁美观==\",{\"2\":{\"142\":1}}],[\"==\",{\"2\":{\"61\":1,\"70\":1,\"96\":2,\"97\":1,\"103\":1,\"117\":3,\"130\":1,\"142\":2,\"152\":1,\"181\":1,\"193\":2,\"229\":2,\"247\":4,\"269\":2,\"270\":1,\"273\":3,\"279\":4,\"282\":5,\"285\":3}}],[\"=2\",{\"2\":{\"264\":1}}],[\"=224lbsh^2\",{\"2\":{\"264\":1}}],[\"=20bytes\",{\"2\":{\"246\":2}}],[\"=28\",{\"2\":{\"151\":1}}],[\"=28x\",{\"2\":{\"151\":1}}],[\"=2xtx\",{\"2\":{\"151\":2}}],[\"=2xtxf\",{\"2\":{\"151\":2}}],[\"=2x\",{\"2\":{\"78\":2}}],[\"=2π​1​exp\",{\"2\":{\"51\":1}}],[\"=2m1​i=1∑m​\",{\"2\":{\"48\":1}}],[\"=\",{\"2\":{\"48\":2,\"49\":2,\"51\":11,\"59\":19,\"61\":11,\"63\":11,\"70\":7,\"71\":6,\"75\":1,\"78\":7,\"79\":2,\"81\":14,\"82\":4,\"86\":6,\"88\":33,\"91\":5,\"95\":2,\"96\":19,\"97\":18,\"100\":10,\"103\":22,\"108\":4,\"110\":3,\"112\":1,\"115\":14,\"117\":17,\"122\":4,\"123\":23,\"124\":5,\"128\":12,\"130\":16,\"131\":3,\"135\":14,\"137\":8,\"138\":9,\"139\":1,\"140\":24,\"144\":8,\"145\":1,\"150\":3,\"151\":12,\"152\":20,\"153\":13,\"154\":5,\"159\":2,\"166\":10,\"167\":24,\"173\":19,\"174\":3,\"176\":7,\"178\":4,\"181\":15,\"186\":1,\"187\":1,\"188\":12,\"191\":6,\"193\":87,\"197\":6,\"202\":8,\"203\":9,\"205\":10,\"213\":1,\"217\":1,\"220\":10,\"222\":7,\"229\":11,\"230\":4,\"232\":3,\"243\":3,\"246\":1,\"247\":18,\"248\":1,\"252\":3,\"255\":27,\"259\":18,\"261\":5,\"262\":5,\"264\":3,\"265\":1,\"266\":7,\"267\":4,\"268\":1,\"269\":23,\"270\":13,\"271\":3,\"272\":1,\"273\":27,\"277\":11,\"278\":8,\"279\":4,\"280\":4,\"282\":4,\"283\":19,\"285\":18}}],[\"目前感觉这俩就够用了\",{\"2\":{\"169\":1}}],[\"目标均是将一个由\",{\"2\":{\"202\":1}}],[\"目标嵌入\",{\"2\":{\"143\":1}}],[\"目标类别\",{\"2\":{\"137\":1}}],[\"目标是为了确定一个模型函数h\",{\"2\":{\"48\":1}}],[\"目录表\",{\"0\":{\"69\":1}}],[\"目录开始\",{\"2\":{\"32\":1}}],[\"计算输出映射以及一个droupout操作\",{\"2\":{\"272\":1}}],[\"计算输出o\",{\"2\":{\"255\":1}}],[\"计算梯度时需要用到层的输入\",{\"2\":{\"272\":1}}],[\"计算交叉熵损失\",{\"2\":{\"270\":1}}],[\"计算loss\",{\"2\":{\"270\":1}}],[\"计算端到端训练的gpu利用率时\",{\"2\":{\"268\":1}}],[\"计算方式为\",{\"2\":{\"259\":1}}],[\"计算h\",{\"2\":{\"255\":1}}],[\"计算bwd\",{\"2\":{\"252\":1}}],[\"计算fwd\",{\"2\":{\"252\":1}}],[\"计算得到float16的梯度\",{\"2\":{\"246\":1}}],[\"计算的\",{\"2\":{\"222\":1}}],[\"计算完attention之后还会进行一次线性变换\",{\"2\":{\"225\":1}}],[\"计算完梯度之后完全释放\",{\"2\":{\"213\":2}}],[\"计算完bwd之后完全释放\",{\"2\":{\"213\":1}}],[\"计算出abs\",{\"2\":{\"223\":1}}],[\"计算出input\",{\"2\":{\"213\":1}}],[\"计算出grad\",{\"2\":{\"140\":1}}],[\"计算复杂度为\",{\"2\":{\"202\":1}}],[\"计算操作\",{\"0\":{\"191\":1}}],[\"计算每个参数的梯度\",{\"2\":{\"180\":1}}],[\"计算这个标量相对于模型参数的梯度\",{\"2\":{\"180\":1}}],[\"计算预测正确的数量\",{\"2\":{\"152\":1}}],[\"计算yyy\",{\"2\":{\"151\":1}}],[\"计算yyy的函数h\",{\"2\":{\"88\":1}}],[\"计算注意力权重\",{\"2\":{\"143\":1}}],[\"计算密集型任务\",{\"2\":{\"133\":2,\"177\":1}}],[\"计算通道维度上的均值和方差\",{\"2\":{\"96\":1}}],[\"计算特征维度上的均值和方差\",{\"2\":{\"96\":1}}],[\"计算损失函数l\",{\"2\":{\"88\":1}}],[\"计算次数\",{\"2\":{\"55\":1}}],[\"计算量与参数量关联\",{\"0\":{\"264\":1}}],[\"计算量flops估计\",{\"0\":{\"259\":1},\"1\":{\"264\":1,\"268\":1}}],[\"计算量为\",{\"2\":{\"55\":1,\"259\":1}}],[\"计算量\",{\"2\":{\"55\":2,\"212\":1}}],[\"计算与\",{\"2\":{\"272\":1}}],[\"计算与通信相重叠\",{\"2\":{\"47\":1}}],[\"计算与访存相重叠\",{\"2\":{\"47\":1}}],[\"计算效率\",{\"2\":{\"47\":1}}],[\"取决于访存延迟和带宽\",{\"2\":{\"47\":1}}],[\"取决于硬件的算力\",{\"2\":{\"47\":1}}],[\"宏观上\",{\"2\":{\"47\":1}}],[\"自动的邮件链接也很类似\",{\"2\":{\"199\":1}}],[\"自动链接\",{\"0\":{\"199\":1}}],[\"自动微分对向量的兼容\",{\"0\":{\"166\":1}}],[\"自注意力\",{\"2\":{\"186\":1}}],[\"自注意力和位置编码\",{\"0\":{\"186\":1},\"1\":{\"202\":1}}],[\"自然\",{\"2\":{\"156\":1}}],[\"自左而右滑动计算\",{\"2\":{\"144\":1}}],[\"自始至终没有出现过\",{\"2\":{\"103\":1}}],[\"自回归模型\",{\"2\":{\"103\":1}}],[\"自定义对齐\",{\"0\":{\"172\":1}}],[\"自定义标题\",{\"0\":{\"100\":1}}],[\"自定义容器可以通过它们的类型\",{\"2\":{\"80\":1}}],[\"自定义容器\",{\"0\":{\"80\":1},\"1\":{\"90\":1,\"100\":1},\"2\":{\"100\":2}}],[\"自定义锚点\",{\"0\":{\"18\":1}}],[\"自主性被称为查询\",{\"2\":{\"43\":1}}],[\"引来ub\",{\"2\":{\"150\":1}}],[\"引用折叠\",{\"2\":{\"146\":1}}],[\"引用\",{\"2\":{\"119\":1}}],[\"引言的块内也可以使用其他的\",{\"2\":{\"57\":1}}],[\"引言内的引言\",{\"2\":{\"57\":1}}],[\"引言写法看起来就真的像是引用一段文字\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"引入一个\",{\"2\":{\"108\":1}}],[\"引入\",{\"0\":{\"43\":1,\"95\":1}}],[\"1≤l≤l\",{\"2\":{\"278\":2}}],[\"1≤i≤n\",{\"2\":{\"278\":2}}],[\"1d\",{\"2\":{\"265\":2}}],[\"1d或2d张量\",{\"2\":{\"70\":1}}],[\"1k\",{\"2\":{\"256\":1}}],[\"1m+1\",{\"2\":{\"256\":1}}],[\"1n∑t=1n−log⁡p\",{\"2\":{\"249\":1}}],[\"1n−1\",{\"2\":{\"217\":1}}],[\"1f1b调度的精髓是当一个micro\",{\"2\":{\"252\":1}}],[\"1f1b有non\",{\"2\":{\"252\":1}}],[\"1f\",{\"2\":{\"247\":1,\"270\":2,\"285\":1}}],[\"1y\",{\"2\":{\"229\":1}}],[\"1$\",{\"2\":{\"225\":1}}],[\"1a\",{\"2\":{\"222\":1}}],[\"1卷积没有这个作用\",{\"2\":{\"203\":1}}],[\"1卷积层通常用于调整网络层的通道数量和控制模型复杂性\",{\"2\":{\"203\":1}}],[\"1卷积层的全连接层实现\",{\"2\":{\"203\":1}}],[\"1卷积层\",{\"0\":{\"203\":1},\"2\":{\"203\":1}}],[\"1>\",{\"2\":{\"154\":1}}],[\"1pw​=kw​−1\",{\"2\":{\"144\":1}}],[\"1ph​=kh​−1\",{\"2\":{\"144\":1}}],[\"14\",{\"2\":{\"135\":1}}],[\"144\",{\"2\":{\"86\":1}}],[\"1ci​\",{\"2\":{\"174\":1}}],[\"1ci​=1\",{\"2\":{\"174\":1}}],[\"1c\",{\"2\":{\"128\":2,\"174\":1}}],[\"12lh^2\",{\"2\":{\"264\":1}}],[\"12lh2×bs\",{\"2\":{\"264\":2}}],[\"12lh212lh^212lh2\",{\"2\":{\"236\":1,\"264\":1}}],[\"127\",{\"2\":{\"262\":5}}],[\"127scale\",{\"2\":{\"262\":2}}],[\"12h^2\",{\"2\":{\"236\":1}}],[\"12h2+13h\",{\"2\":{\"236\":2}}],[\"12h2+13h12h^2\",{\"2\":{\"236\":1}}],[\"120\",{\"2\":{\"199\":2,\"247\":2}}],[\"12\",{\"2\":{\"150\":1,\"151\":1,\"166\":3}}],[\"123\",{\"2\":{\"135\":8}}],[\"12∥∂p∂x∥1=12∑i\",{\"2\":{\"123\":1}}],[\"128b\",{\"2\":{\"269\":2}}],[\"128\",{\"2\":{\"61\":1,\"63\":2,\"86\":6,\"197\":3,\"262\":2}}],[\"11bsh+5bs2a11bsh\",{\"2\":{\"272\":1}}],[\"111\",{\"2\":{\"199\":2}}],[\"115\",{\"2\":{\"199\":4}}],[\"11\",{\"2\":{\"117\":1,\"169\":3}}],[\"112\",{\"2\":{\"86\":1}}],[\"1t−1\",{\"2\":{\"217\":1}}],[\"1t\",{\"2\":{\"115\":1}}],[\"1都会被转化为\",{\"2\":{\"112\":1}}],[\"1∼t1\",{\"2\":{\"103\":1}}],[\"13h\",{\"2\":{\"236\":1}}],[\"13h12h2+13h\",{\"2\":{\"236\":1}}],[\"13\",{\"2\":{\"100\":1}}],[\"176\",{\"2\":{\"113\":1}}],[\"17\",{\"2\":{\"100\":1}}],[\"1e\",{\"2\":{\"203\":1}}],[\"1e9\",{\"2\":{\"97\":1,\"193\":1}}],[\"1e6\",{\"2\":{\"70\":1}}],[\"1x1\",{\"2\":{\"203\":2}}],[\"1x1​\",{\"2\":{\"88\":1,\"151\":2}}],[\"1xh\",{\"2\":{\"48\":1}}],[\"16bit\",{\"2\":{\"254\":1}}],[\"160\",{\"2\":{\"86\":2}}],[\"16\",{\"2\":{\"86\":2,\"100\":1,\"103\":1,\"199\":1,\"229\":1,\"247\":2,\"269\":2}}],[\"19bsh19bsh19bsh\",{\"2\":{\"272\":1}}],[\"19th\",{\"2\":{\"157\":1}}],[\"19^th^\",{\"2\":{\"157\":1}}],[\"192\",{\"2\":{\"86\":3}}],[\"1986\",{\"2\":{\"68\":2}}],[\"1^\",{\"2\":{\"78\":1,\"151\":1}}],[\"109\",{\"2\":{\"199\":4}}],[\"101\",{\"2\":{\"199\":2}}],[\"10为类别数目\",{\"2\":{\"152\":1}}],[\"1024\",{\"2\":{\"86\":1}}],[\"10\",{\"2\":{\"59\":5,\"61\":2,\"63\":2,\"75\":1,\"81\":2,\"88\":2,\"100\":2,\"103\":2,\"112\":10,\"113\":4,\"114\":2,\"118\":2,\"122\":1,\"130\":1,\"152\":5,\"220\":1,\"247\":2,\"255\":1,\"261\":1,\"270\":2,\"285\":2}}],[\"10000d2j​i​\",{\"2\":{\"202\":2}}],[\"10000^\",{\"2\":{\"202\":2}}],[\"10000\",{\"2\":{\"124\":1,\"193\":1,\"202\":1}}],[\"1000\",{\"2\":{\"88\":1,\"103\":1}}],[\"100\",{\"2\":{\"58\":1,\"181\":2,\"185\":2,\"193\":2}}],[\"1θ0​\",{\"2\":{\"48\":1,\"67\":2}}],[\"1\",{\"0\":{\"43\":1,\"52\":1,\"67\":1,\"93\":1,\"95\":1,\"97\":1,\"115\":1,\"130\":1,\"163\":1,\"164\":1,\"203\":1,\"217\":1,\"219\":1,\"225\":1,\"229\":1,\"245\":1,\"246\":2,\"251\":1,\"253\":1,\"256\":1,\"264\":1,\"275\":1,\"277\":1,\"284\":1},\"1\":{\"129\":1,\"143\":1,\"178\":1,\"191\":1,\"230\":1,\"236\":1,\"241\":1,\"246\":1,\"249\":1,\"253\":1},\"2\":{\"48\":3,\"49\":3,\"51\":4,\"55\":1,\"57\":2,\"59\":33,\"61\":3,\"63\":4,\"67\":2,\"68\":6,\"70\":11,\"75\":3,\"78\":6,\"79\":4,\"81\":11,\"86\":2,\"88\":11,\"91\":2,\"95\":10,\"96\":6,\"97\":4,\"100\":1,\"103\":28,\"108\":4,\"112\":13,\"113\":4,\"114\":5,\"115\":11,\"117\":3,\"118\":2,\"119\":1,\"123\":6,\"124\":3,\"130\":16,\"131\":4,\"137\":2,\"140\":10,\"144\":9,\"145\":1,\"151\":7,\"152\":7,\"154\":1,\"159\":2,\"166\":11,\"167\":9,\"170\":1,\"173\":9,\"174\":5,\"176\":4,\"178\":4,\"181\":7,\"186\":4,\"187\":1,\"188\":6,\"191\":2,\"193\":23,\"200\":2,\"202\":14,\"203\":9,\"205\":5,\"215\":1,\"217\":5,\"220\":6,\"222\":6,\"229\":11,\"230\":2,\"232\":3,\"247\":9,\"249\":6,\"252\":4,\"254\":10,\"255\":2,\"259\":1,\"260\":4,\"261\":5,\"264\":1,\"266\":4,\"267\":2,\"269\":5,\"270\":7,\"273\":6,\"277\":3,\"278\":7,\"279\":1,\"282\":2,\"283\":7,\"285\":15}}],[\"还要考虑cpu加载数据\",{\"2\":{\"268\":1}}],[\"还与gpu利用率有关\",{\"2\":{\"268\":1}}],[\"还有一些中间结果\",{\"2\":{\"253\":1}}],[\"还会进入embedding层\",{\"2\":{\"225\":1}}],[\"还是使用交叉熵\",{\"2\":{\"285\":1}}],[\"还是多线程\",{\"2\":{\"231\":1}}],[\"还是\",{\"2\":{\"213\":1}}],[\"还没有办法指定图片的宽高\",{\"2\":{\"156\":1}}],[\"还可以指定多个单行\",{\"2\":{\"100\":1}}],[\"还更好阅读\",{\"2\":{\"40\":1}}],[\"还得转换网址内的\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"式的\",{\"2\":{\"40\":1}}],[\"或梯度\",{\"2\":{\"275\":1}}],[\"或缓存未及时同步\",{\"2\":{\"205\":1}}],[\"或\",{\"2\":{\"100\":2,\"127\":2,\"173\":1,\"229\":1}}],[\"或两者均指定\",{\"2\":{\"100\":1}}],[\"或者是抛弃某些已经无用的像素信息\",{\"2\":{\"216\":1}}],[\"或者模板类型推导的时候容易发生错误\",{\"2\":{\"125\":1}}],[\"或者\",{\"2\":{\"91\":1}}],[\"或斜线\",{\"2\":{\"40\":1}}],[\"或是文件结尾\",{\"2\":{\"79\":1}}],[\"或是你懒一点都写作\",{\"2\":{\"68\":1}}],[\"或是空白来缩进\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"或是\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"允许寄存器或内存\",{\"2\":{\"248\":1}}],[\"允许重排序\",{\"2\":{\"205\":1}}],[\"允许注意力机制组合使用查询\",{\"2\":{\"159\":1}}],[\"允许我们自定义计算图节点\",{\"2\":{\"140\":1}}],[\"允许段落内的强迫断行\",{\"2\":{\"40\":1}}],[\"允许你直接使用这些符号\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"若某一行只包含空白和\",{\"2\":{\"40\":1}}],[\"比onehot更加精准\",{\"2\":{\"283\":1}}],[\"比较有用的用法就是\",{\"2\":{\"260\":1}}],[\"比较推荐\",{\"2\":{\"251\":1}}],[\"比较反直觉\",{\"2\":{\"205\":1}}],[\"比较难受的是\",{\"2\":{\"169\":1}}],[\"比较一下上面的范例\",{\"2\":{\"113\":1}}],[\"比方说\",{\"2\":{\"40\":1}}],[\"比如在fwd和bwd的时候\",{\"2\":{\"263\":1}}],[\"比如在这里\",{\"2\":{\"140\":1}}],[\"比如cv中的通道数\",{\"2\":{\"257\":1}}],[\"比如cuda\",{\"2\":{\"169\":1}}],[\"比如6b以上的llm\",{\"2\":{\"251\":1}}],[\"比如绝大部分的cv模型\",{\"2\":{\"251\":1}}],[\"比如int8的0就是0\",{\"2\":{\"251\":1}}],[\"比如int8\",{\"2\":{\"251\":1}}],[\"比如at\",{\"2\":{\"169\":1}}],[\"比如linear层的weight矩阵\",{\"2\":{\"140\":1}}],[\"比如上述的卷积核可能特征就是具体物体的特征\",{\"2\":{\"82\":1}}],[\"比如unsqueeze\",{\"2\":{\"59\":1}}],[\"比如对于\",{\"2\":{\"55\":1}}],[\"比如\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1,\"252\":1,\"272\":1,\"278\":1}}],[\"分割\",{\"2\":{\"220\":1}}],[\"分别表示输入和输出通道的数目\",{\"2\":{\"187\":1}}],[\"分别初始化成1和0\",{\"2\":{\"96\":1}}],[\"分析gil锁的释放条件\",{\"2\":{\"177\":1}}],[\"分析得到\",{\"2\":{\"51\":1}}],[\"分类精度\",{\"2\":{\"152\":1}}],[\"分类任务\",{\"2\":{\"137\":1}}],[\"分布\",{\"2\":{\"137\":1}}],[\"分布的时候\",{\"2\":{\"123\":1}}],[\"分布式训练框架的经典\",{\"2\":{\"1\":1}}],[\"分隔线\",{\"0\":{\"89\":1}}],[\"分子分母除以\",{\"2\":{\"38\":1}}],[\"容易超过float32的最大表示范围\",{\"2\":{\"38\":1}}],[\"为每个transformer层生成key\",{\"2\":{\"278\":1}}],[\"为每个进程持有\",{\"2\":{\"163\":1}}],[\"为输出层的权重参数\",{\"2\":{\"230\":1}}],[\"为输出维度\",{\"2\":{\"230\":1}}],[\"为隐藏层权重参数\",{\"2\":{\"230\":1}}],[\"为固定形状窗口\",{\"2\":{\"229\":1}}],[\"为图片添加属性\",{\"2\":{\"185\":1}}],[\"为此\",{\"2\":{\"159\":1}}],[\"为计算量\",{\"2\":{\"158\":1}}],[\"为数据集大小\",{\"2\":{\"158\":1}}],[\"为一个长度为4的一维张量\",{\"2\":{\"151\":1}}],[\"为\",{\"2\":{\"145\":1,\"255\":1,\"272\":3,\"283\":2}}],[\"为中心\",{\"2\":{\"144\":1}}],[\"为模型性能\",{\"2\":{\"158\":1}}],[\"为模型参数量\",{\"2\":{\"158\":1}}],[\"为模型的输入\",{\"2\":{\"137\":1}}],[\"为模型函数\",{\"2\":{\"137\":1}}],[\"为了和其他阶段区分\",{\"2\":{\"260\":1}}],[\"为了和文献中一致\",{\"2\":{\"130\":1}}],[\"为了多个handler并行处理\",{\"2\":{\"256\":1}}],[\"为了多注意力头的并行计算而变换形状\",{\"2\":{\"173\":1}}],[\"为了使用gpu\",{\"2\":{\"247\":1}}],[\"为了适应急剧增长的model\",{\"2\":{\"235\":1}}],[\"为了更好地利用l2\",{\"2\":{\"197\":1}}],[\"为了避免计算代价和参数代价的大幅增长\",{\"2\":{\"173\":1}}],[\"为了训练语言模型\",{\"2\":{\"131\":1}}],[\"为卷积核kernel\",{\"2\":{\"130\":1}}],[\"为原本图像\",{\"2\":{\"130\":1}}],[\"为确保无论向量长度如何\",{\"2\":{\"91\":1}}],[\"为键值对\",{\"2\":{\"51\":1}}],[\"为查询\",{\"2\":{\"51\":1}}],[\"为什么反向传播的起点需要是一个标量呢\",{\"2\":{\"180\":1}}],[\"为什么multi\",{\"2\":{\"175\":1}}],[\"为什么python中多线程的效率这么差\",{\"0\":{\"147\":1},\"1\":{\"163\":1,\"177\":1}}],[\"为什么需要move\",{\"0\":{\"132\":1}}],[\"为什么\",{\"0\":{\"38\":1}}],[\"为im2col\",{\"2\":{\"23\":1}}],[\"然而当\",{\"2\":{\"174\":1}}],[\"然而\",{\"2\":{\"93\":1,\"229\":1}}],[\"然而最大灵感来源其实是纯文字的电子邮件格式\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"然后广播一下\",{\"2\":{\"283\":1}}],[\"然后第\",{\"2\":{\"278\":1}}],[\"然后最后输出一个预测的token\",{\"2\":{\"278\":1}}],[\"然后启动tma\",{\"2\":{\"265\":1}}],[\"然后使用cp\",{\"2\":{\"269\":1}}],[\"然后使用\",{\"2\":{\"265\":1}}],[\"然后使用async\",{\"2\":{\"256\":1}}],[\"然后我们有个输入\",{\"2\":{\"283\":1}}],[\"然后我们会开\",{\"2\":{\"256\":1}}],[\"然后我们对输入的token进行转发\",{\"2\":{\"61\":1}}],[\"然后一步一步更新小批量数据的隐状态\",{\"2\":{\"255\":1}}],[\"然后设置rnn中的各种权重\",{\"2\":{\"255\":1}}],[\"然后异步send\",{\"2\":{\"252\":1}}],[\"然后异步去send\",{\"2\":{\"252\":1}}],[\"然后send出去\",{\"2\":{\"252\":1}}],[\"然后send出去结果\",{\"2\":{\"252\":1}}],[\"然后计算\",{\"2\":{\"252\":2}}],[\"然后释放显存\",{\"2\":{\"252\":1}}],[\"然后backward按逆序逐层传递梯度\",{\"2\":{\"252\":1}}],[\"然后均匀地将fp32等映射到现在指定的值域上\",{\"2\":{\"251\":1}}],[\"然后利用交叉熵损失计算模型输出和标签之间的误差\",{\"2\":{\"241\":1}}],[\"然后在训练过程中\",{\"2\":{\"241\":1}}],[\"然后在每行的最前面加上\",{\"2\":{\"57\":1}}],[\"然后做softmax\",{\"2\":{\"225\":1}}],[\"然后返回响应\",{\"2\":{\"219\":1}}],[\"然后通过bwd计算出了input\",{\"2\":{\"213\":1}}],[\"然后根据当前阶段的input\",{\"2\":{\"213\":1}}],[\"然后获得output\",{\"2\":{\"213\":1}}],[\"然后完整地进行一次batch的fwd和bwd\",{\"2\":{\"213\":1}}],[\"然后诸如此类\",{\"2\":{\"173\":1}}],[\"然后如此复制第二项\",{\"2\":{\"173\":1}}],[\"然后将不同的行为作为知识组合起来\",{\"2\":{\"159\":1}}],[\"然后将token进行dispatch\",{\"2\":{\"61\":1}}],[\"然后每行都除以它对应行的和\",{\"2\":{\"152\":1}}],[\"然后定义了fwd和bwd的操作\",{\"2\":{\"126\":1}}],[\"然后定义链接内容\",{\"2\":{\"113\":1}}],[\"然后实现属于自己的forward逻辑\",{\"2\":{\"126\":1}}],[\"然后实参与param\",{\"2\":{\"122\":1}}],[\"然后内部嵌入若干子module\",{\"2\":{\"126\":1}}],[\"然后内部不断地嵌套\",{\"2\":{\"126\":1}}],[\"然后\",{\"2\":{\"122\":1,\"159\":1}}],[\"然后对于原值\",{\"2\":{\"262\":1}}],[\"然后对于第一维中的每个矩阵\",{\"2\":{\"59\":1}}],[\"然后对标量调用backward\",{\"2\":{\"166\":1}}],[\"然后对每个单词按照出现频率排序\",{\"2\":{\"117\":1}}],[\"然后接着定义链接\",{\"2\":{\"113\":1}}],[\"然后从图片中提取出4个特征\",{\"2\":{\"95\":1}}],[\"然后反向传播计算梯度\",{\"2\":{\"88\":1}}],[\"然后选择最高的topk个\",{\"2\":{\"72\":1}}],[\"然后进行计算\",{\"2\":{\"255\":1}}],[\"然后进行量化\",{\"2\":{\"223\":1}}],[\"然后进行移动构造\",{\"2\":{\"132\":1}}],[\"然后进行all2all通信\",{\"2\":{\"72\":1}}],[\"然后进行批量矩阵乘法\",{\"2\":{\"59\":1}}],[\"然后再求平均值\",{\"2\":{\"270\":1}}],[\"然后再求zero\",{\"2\":{\"262\":1}}],[\"然后再下沉到transformer\",{\"2\":{\"263\":1}}],[\"然后再将隐藏层权重用为输出\",{\"2\":{\"230\":1}}],[\"然后再对通道\",{\"2\":{\"174\":1}}],[\"然后再反向传播\",{\"2\":{\"166\":1}}],[\"然后再按照匹配程度分配到一些专属的experts上\",{\"2\":{\"72\":1}}],[\"然后再寻找最适合的local\",{\"2\":{\"61\":1}}],[\"然后任其自由向\",{\"2\":{\"67\":1}}],[\"然后按照列来逐个处理block\",{\"2\":{\"197\":1}}],[\"然后按\",{\"2\":{\"40\":1}}],[\"然后讲解\",{\"2\":{\"35\":1}}],[\"渲染为\",{\"2\":{\"32\":1}}],[\"$2\",{\"2\":{\"253\":1}}],[\"$4h$\",{\"2\":{\"225\":2}}],[\"$h$\",{\"2\":{\"225\":2}}],[\"$w\",{\"2\":{\"225\":6}}],[\"$v$\",{\"2\":{\"225\":1}}],[\"$k$\",{\"2\":{\"225\":1}}],[\"$q$\",{\"2\":{\"225\":1}}],[\"$$\",{\"2\":{\"128\":4}}],[\"$a\",{\"2\":{\"128\":1}}],[\"$markdown\",{\"2\":{\"57\":1}}],[\"$input\",{\"2\":{\"57\":1}}],[\"$1\",{\"2\":{\"50\":2}}],[\"$12\",{\"2\":{\"50\":2}}],[\"$1600\",{\"2\":{\"50\":2}}],[\"$\",{\"2\":{\"32\":1,\"128\":12,\"143\":4,\"225\":2,\"253\":1,\"264\":1}}],[\"表明在这个点上\",{\"2\":{\"151\":2}}],[\"表达式\",{\"2\":{\"119\":1}}],[\"表示为\",{\"2\":{\"278\":1}}],[\"表示浮点数运算次数\",{\"2\":{\"259\":1}}],[\"表示操作数在ptx中是output\",{\"2\":{\"248\":1}}],[\"表示整个输出的\",{\"2\":{\"180\":1}}],[\"表示当前模型的表现好坏\",{\"2\":{\"180\":1}}],[\"表示当前解码步骤的对源句子的主要关注部分\",{\"2\":{\"143\":1}}],[\"表示该点f\",{\"2\":{\"151\":1}}],[\"表示第\",{\"2\":{\"103\":1}}],[\"表示鸡鸭鹅这种类别数据的一种简单方式是onehot编码\",{\"2\":{\"95\":1}}],[\"表示的代码库\",{\"2\":{\"79\":1}}],[\"表示按行复制n\",{\"2\":{\"59\":1}}],[\"表示模型计算到底需要存取多少\",{\"2\":{\"55\":1}}],[\"表示从\",{\"2\":{\"32\":1}}],[\"表格\",{\"0\":{\"238\":1},\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"绝对路径\",{\"2\":{\"32\":1}}],[\"bs2abs^2abs2a\",{\"2\":{\"272\":1}}],[\"bsbsh\",{\"2\":{\"272\":2}}],[\"bsbsbs\",{\"2\":{\"264\":1,\"272\":1}}],[\"bsh+2bsbsh\",{\"2\":{\"272\":1}}],[\"bsh\",{\"2\":{\"272\":2}}],[\"bshbshbsh\",{\"2\":{\"272\":5}}],[\"bsh^23∗2∗bsh2\",{\"2\":{\"259\":1}}],[\"bs\",{\"2\":{\"264\":1,\"272\":1}}],[\"bwd的overlap上\",{\"2\":{\"263\":1}}],[\"bwd的时候\",{\"2\":{\"126\":1}}],[\"bwd\",{\"2\":{\"263\":1}}],[\"b64\",{\"2\":{\"260\":6,\"279\":1}}],[\"b∈rb×c\",{\"2\":{\"259\":1}}],[\"b∈rb×cb\",{\"2\":{\"259\":1}}],[\"b∈r10∗10\",{\"2\":{\"152\":2}}],[\"b32\",{\"2\":{\"254\":1}}],[\"b16意思是每次load\",{\"2\":{\"254\":1}}],[\"b16\",{\"2\":{\"254\":8}}],[\"bf16\",{\"2\":{\"254\":6}}],[\"bf16>\",{\"2\":{\"254\":1}}],[\"bbb\",{\"2\":{\"212\":1,\"275\":3}}],[\"bbedit\",{\"2\":{\"57\":1}}],[\"bmatrix\",{\"2\":{\"151\":2,\"159\":2,\"222\":2}}],[\"bmm\",{\"2\":{\"59\":2,\"81\":1,\"91\":2}}],[\"b⃗\",{\"2\":{\"128\":2}}],[\"b^2\",{\"2\":{\"128\":2}}],[\"bx\",{\"2\":{\"128\":2}}],[\"bulk操作\",{\"2\":{\"279\":1}}],[\"bulk的时候\",{\"2\":{\"265\":1}}],[\"bulk\",{\"2\":{\"265\":11,\"269\":3,\"273\":8,\"279\":3}}],[\"bushi\",{\"2\":{\"263\":1}}],[\"bubbles\",{\"2\":{\"263\":1}}],[\"bubble比也降低为原来的virtual\",{\"2\":{\"252\":1}}],[\"bubble\",{\"2\":{\"252\":1}}],[\"bubbleall=p−1m+p−1\",{\"2\":{\"252\":1}}],[\"buffer\",{\"2\":{\"124\":1,\"193\":1}}],[\"but\",{\"2\":{\"100\":2}}],[\"by\",{\"2\":{\"97\":2,\"110\":1,\"127\":1,\"138\":1,\"193\":4,\"222\":1,\"260\":1,\"263\":1}}],[\"bytes\",{\"2\":{\"55\":3,\"246\":1,\"253\":1,\"260\":1,\"265\":3,\"269\":2,\"273\":3,\"279\":4,\"282\":2}}],[\"bos>\",{\"2\":{\"285\":1}}],[\"bos\",{\"2\":{\"285\":2}}],[\"bold\",{\"2\":{\"228\":1}}],[\"both\",{\"2\":{\"153\":1,\"193\":1}}],[\"box\",{\"2\":{\"90\":4}}],[\"bool\",{\"2\":{\"59\":2,\"112\":2,\"150\":3,\"167\":1,\"193\":1,\"269\":1,\"273\":1}}],[\"b0b\",{\"2\":{\"88\":1}}],[\"b为我们要回归的两个参数\",{\"2\":{\"88\":1}}],[\"bidirectional\",{\"2\":{\"277\":1}}],[\"bits\",{\"2\":{\"267\":1}}],[\"bits=8\",{\"2\":{\"267\":1}}],[\"billion\",{\"0\":{\"222\":1}}],[\"bin\",{\"2\":{\"169\":1}}],[\"bin目录等重组在一起\",{\"2\":{\"169\":1}}],[\"bias=bias\",{\"2\":{\"173\":4}}],[\"bias=false\",{\"2\":{\"81\":3,\"130\":1,\"173\":1}}],[\"bias\",{\"2\":{\"88\":1,\"130\":2,\"140\":1}}],[\"bird\",{\"2\":{\"68\":4}}],[\"b=true为了交换keys的最后两个维度\",{\"2\":{\"91\":1}}],[\"b=\",{\"2\":{\"71\":1}}],[\"b​=\",{\"2\":{\"71\":1}}],[\"b​\",{\"2\":{\"71\":5}}],[\"b\",{\"2\":{\"71\":15,\"82\":14,\"88\":16,\"95\":4,\"112\":2,\"119\":1,\"128\":14,\"152\":7,\"185\":2,\"191\":3,\"205\":4,\"220\":3,\"228\":1,\"230\":4,\"238\":1,\"243\":3,\"254\":1,\"255\":8,\"259\":31,\"266\":2,\"272\":9,\"278\":1}}],[\"bert微调所需的\",{\"2\":{\"247\":1}}],[\"believable\",{\"2\":{\"127\":1}}],[\"begin\",{\"2\":{\"123\":3,\"137\":1,\"151\":1,\"159\":1,\"222\":1,\"255\":2,\"261\":1,\"270\":1,\"277\":1}}],[\"beta$\",{\"2\":{\"225\":1}}],[\"betas=\",{\"2\":{\"181\":1,\"193\":1}}],[\"beta\",{\"2\":{\"96\":4}}],[\"beep\",{\"2\":{\"79\":2}}],[\"be\",{\"2\":{\"61\":1,\"260\":1}}],[\"ba×b\",{\"2\":{\"259\":1}}],[\"bahdanau注意力模型\",{\"0\":{\"115\":1},\"1\":{\"129\":1,\"143\":1}}],[\"baz\",{\"2\":{\"100\":2}}],[\"barrier\",{\"0\":{\"260\":1},\"2\":{\"260\":9}}],[\"bar\",{\"0\":{\"260\":1},\"2\":{\"100\":2,\"260\":3,\"269\":2,\"273\":2,\"279\":4,\"282\":2}}],[\"ba\",{\"2\":{\"71\":2}}],[\"base\",{\"2\":{\"213\":1}}],[\"baseschedulestrategy\",{\"2\":{\"213\":1}}],[\"based\",{\"2\":{\"153\":1,\"193\":1}}],[\"basemoe\",{\"2\":{\"61\":2}}],[\"basicexpert\",{\"2\":{\"61\":2}}],[\"basic\",{\"0\":{\"61\":1},\"2\":{\"61\":3,\"100\":1}}],[\"backends\",{\"2\":{\"255\":1}}],[\"background\",{\"2\":{\"169\":1}}],[\"backtick\",{\"2\":{\"141\":6}}],[\"backward这一\",{\"2\":{\"213\":1}}],[\"backward返回的值其实就对应了forward的input\",{\"2\":{\"140\":1}}],[\"backward的return值的数量要和forward中\",{\"2\":{\"140\":1}}],[\"backward\",{\"2\":{\"59\":1,\"88\":2,\"103\":1,\"130\":1,\"140\":2,\"151\":2,\"166\":7,\"181\":1,\"193\":1,\"207\":1,\"213\":2,\"247\":1,\"263\":3,\"270\":2,\"285\":1}}],[\"back\",{\"2\":{\"57\":1,\"97\":1,\"193\":1}}],[\"bath\",{\"2\":{\"61\":1}}],[\"bathnorm由哪些小算子构成\",{\"0\":{\"38\":1}}],[\"batch1的fwd执行完毕\",{\"2\":{\"252\":1}}],[\"batch1\",{\"2\":{\"252\":1}}],[\"batch也进一步划分为若干micro\",{\"2\":{\"245\":1}}],[\"batches\",{\"2\":{\"176\":2,\"188\":2,\"247\":4}}],[\"batch\",{\"0\":{\"96\":1,\"284\":1},\"2\":{\"61\":6,\"63\":2,\"81\":6,\"88\":15,\"91\":5,\"96\":2,\"97\":6,\"103\":2,\"115\":9,\"129\":2,\"152\":2,\"167\":4,\"173\":10,\"176\":8,\"188\":9,\"193\":10,\"245\":2,\"252\":2,\"255\":6,\"261\":1,\"270\":8,\"277\":4,\"283\":19,\"285\":7}}],[\"batchnorm精度问题\",{\"2\":{\"38\":1}}],[\"batchnorm和softmax在什么情况下计算结果可能会出现精度问题\",{\"0\":{\"38\":1}}],[\"batchnorm\",{\"2\":{\"23\":1,\"96\":1}}],[\"blog\",{\"2\":{\"240\":1}}],[\"blocks\",{\"2\":{\"63\":3,\"197\":5}}],[\"block\",{\"2\":{\"63\":2,\"75\":4,\"79\":2,\"90\":2,\"197\":15,\"245\":1}}],[\"blockquote\",{\"2\":{\"57\":3,\"68\":2}}],[\"blockquotes\",{\"0\":{\"57\":1}}],[\"block的模型结构\",{\"0\":{\"30\":1}}],[\"blink\",{\"2\":{\"141\":1}}],[\"blink>`\",{\"2\":{\"141\":1}}],[\"blue\",{\"2\":{\"68\":3,\"271\":1}}],[\"blank\",{\"2\":{\"41\":1}}],[\"bra\",{\"2\":{\"260\":2}}],[\"break\",{\"2\":{\"117\":1}}],[\"breaks\",{\"2\":{\"40\":1}}],[\"broadcasting\",{\"2\":{\"97\":1,\"193\":1}}],[\"br\",{\"2\":{\"40\":4}}],[\"中间激活占用的显存会远远超过模型参数显存\",{\"2\":{\"275\":1}}],[\"中间激活占用的显存会同步增大\",{\"2\":{\"275\":1}}],[\"中间激活近似估计为\",{\"2\":{\"272\":1}}],[\"中间激活\",{\"2\":{\"253\":1}}],[\"中间激活的显存占用后面会详细介绍\",{\"2\":{\"246\":1}}],[\"中间激活值一般是float16或者bfloat16数据类型的\",{\"2\":{\"272\":1}}],[\"中间激活值分析\",{\"0\":{\"272\":1},\"1\":{\"275\":1}}],[\"中间激活值\",{\"2\":{\"212\":1}}],[\"中考虑\",{\"2\":{\"213\":1}}],[\"中每个元素相对于\",{\"2\":{\"166\":1}}],[\"中所有元素的和\",{\"2\":{\"166\":1}}],[\"中的一个上下文管理器\",{\"2\":{\"88\":1}}],[\"中建立代码块很简单\",{\"2\":{\"79\":1}}],[\"中并不适合\",{\"2\":{\"40\":1}}],[\"中\",{\"2\":{\"25\":1,\"40\":1}}],[\"主要解决的就是expert之间的all2all通信问题\",{\"2\":{\"263\":1}}],[\"主要存在round误差和clip误差这两种误差\",{\"2\":{\"262\":1}}],[\"主要需要理解\",{\"2\":{\"245\":1}}],[\"主要就介绍的是相对于当时gpipe的tensor\",{\"2\":{\"222\":1}}],[\"主要参考是megatron\",{\"2\":{\"213\":1}}],[\"主要有俩方面\",{\"2\":{\"169\":1}}],[\"主要讲解了如何配置一个cuda舒服的开发环境\",{\"2\":{\"169\":1}}],[\"主要的用途是自定义函数\",{\"2\":{\"140\":1}}],[\"主要的算子\",{\"2\":{\"23\":1}}],[\"主要是以下几种模板定义以及三种实参定义的全连接组合\",{\"2\":{\"122\":1}}],[\"主要还是几个规则的记忆\",{\"2\":{\"122\":1}}],[\"主题\",{\"2\":{\"100\":2,\"142\":2}}],[\"主题默认对每个\",{\"2\":{\"25\":1}}],[\"才能在\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"才能放到链接标签的\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"都无法实现真正意义上的并行\",{\"2\":{\"231\":1}}],[\"都要求满足\",{\"2\":{\"87\":1}}],[\"都会被初始化为int\",{\"2\":{\"135\":1}}],[\"都会被\",{\"2\":{\"115\":1}}],[\"都会被移除\",{\"2\":{\"79\":1}}],[\"都会帮你处理\",{\"2\":{\"79\":1}}],[\"都可以有效果\",{\"2\":{\"49\":1}}],[\"都可以直接在文件里面用\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"都转换为\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"写操作\",{\"2\":{\"205\":2}}],[\"写为const\",{\"2\":{\"104\":1}}],[\"写出batchnorm和softmax的公式\",{\"0\":{\"38\":1}}],[\"写\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"将第一个warp的sync放到下一次循环的开头\",{\"2\":{\"282\":1}}],[\"将第一项\",{\"2\":{\"173\":1}}],[\"将dispatcher和combiner这两个all2all通信算子\",{\"2\":{\"263\":1}}],[\"将reg0中16bit数据存入smem1\",{\"2\":{\"254\":1}}],[\"将不同的层划分到不同的机器上\",{\"2\":{\"245\":1}}],[\"将不会对这段文字做修改\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"将内存模型分为三类relaxd\",{\"2\":{\"205\":1}}],[\"将各个库的lib目录\",{\"2\":{\"169\":1}}],[\"将这些索引直接输入神经网络会导致没什么意义\",{\"2\":{\"255\":1}}],[\"将这\",{\"2\":{\"159\":1}}],[\"将上下文向量\",{\"2\":{\"143\":1}}],[\"将其类型转化为std\",{\"2\":{\"154\":1}}],[\"将其输入\",{\"2\":{\"143\":1}}],[\"将其对应到该属于的experts中\",{\"2\":{\"72\":1}}],[\"将输出映射为概率分布\",{\"2\":{\"137\":1}}],[\"将输入序列\",{\"2\":{\"129\":1}}],[\"将t\",{\"2\":{\"119\":1}}],[\"将亡值\",{\"2\":{\"119\":2}}],[\"将词元列表展平成一个列表\",{\"2\":{\"117\":1}}],[\"将词元映射为数字\",{\"2\":{\"117\":1}}],[\"将文本转换为数字索引序列\",{\"2\":{\"117\":1}}],[\"将文本作为字符串加载到内存中\",{\"2\":{\"117\":1}}],[\"将拆分的词元映射到数字索引\",{\"2\":{\"117\":1}}],[\"将字符串拆分为词元\",{\"2\":{\"117\":1}}],[\"将x变形为\",{\"2\":{\"115\":1}}],[\"将某层的输出\",{\"2\":{\"108\":1}}],[\"将过去四个时间点作为数据\",{\"2\":{\"103\":1}}],[\"将moving\",{\"2\":{\"96\":1}}],[\"将mlp层变化为多个expert\",{\"2\":{\"61\":1}}],[\"将两个向量映射为标量\",{\"2\":{\"70\":1}}],[\"将选择引导至感官输入\",{\"2\":{\"43\":1}}],[\"将会把它转换为\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"5bs^2a\",{\"2\":{\"272\":1}}],[\"5bs^2a11bsh+5bs2a\",{\"2\":{\"272\":1}}],[\"5d\",{\"2\":{\"269\":3,\"273\":2}}],[\"55\",{\"2\":{\"268\":3}}],[\"528\",{\"2\":{\"86\":1}}],[\"512\",{\"2\":{\"61\":1,\"63\":2,\"86\":3,\"181\":1,\"193\":1,\"255\":1}}],[\"5000\",{\"2\":{\"181\":2,\"193\":2}}],[\"50\",{\"2\":{\"51\":1,\"232\":1,\"270\":1}}],[\"5\",{\"0\":{\"92\":1,\"153\":1,\"162\":1,\"243\":1},\"1\":{\"176\":1,\"188\":1},\"2\":{\"24\":2,\"36\":2,\"37\":2,\"42\":2,\"49\":1,\"51\":2,\"59\":3,\"63\":2,\"75\":1,\"88\":1,\"96\":1,\"100\":1,\"103\":1,\"114\":1,\"144\":2,\"152\":1,\"174\":2,\"191\":2,\"220\":2,\"232\":2,\"247\":3,\"255\":1,\"267\":1,\"269\":2,\"273\":2}}],[\"4bsh4bsh4bsh\",{\"2\":{\"272\":1}}],[\"4bsh2∗2∗bsh=4bsh\",{\"2\":{\"272\":1}}],[\"4bs^2h\",{\"2\":{\"259\":1}}],[\"4bs^2h24bsh2+4bs2h\",{\"2\":{\"259\":1}}],[\"4h\",{\"2\":{\"259\":12}}],[\"4h2+6h\",{\"2\":{\"225\":1}}],[\"4h2+6h4h^2\",{\"2\":{\"225\":1}}],[\"4有四个元素\",{\"2\":{\"254\":1}}],[\"4>\",{\"2\":{\"254\":1}}],[\"4+4\",{\"2\":{\"246\":2}}],[\"4f\",{\"2\":{\"181\":1,\"193\":1}}],[\"496012402\",{\"2\":{\"175\":1}}],[\"4δ4\",{\"2\":{\"151\":1}}],[\"4xi4x\",{\"2\":{\"151\":1}}],[\"4x\",{\"2\":{\"151\":4,\"166\":1}}],[\"4x3​\",{\"2\":{\"151\":1}}],[\"4x3\",{\"2\":{\"151\":1}}],[\"4x2​\",{\"2\":{\"151\":1}}],[\"4x2\",{\"2\":{\"151\":1}}],[\"4x1​=4\",{\"2\":{\"151\":1}}],[\"4x1​\",{\"2\":{\"151\":1}}],[\"4x1\",{\"2\":{\"151\":1}}],[\"4x0​\",{\"2\":{\"151\":1}}],[\"4x0\",{\"2\":{\"151\":1}}],[\"4ac\",{\"2\":{\"128\":2}}],[\"4表示卷积层\",{\"2\":{\"96\":1}}],[\"48\",{\"2\":{\"86\":2}}],[\"480\",{\"2\":{\"86\":1}}],[\"40\",{\"2\":{\"81\":1,\"100\":1}}],[\"4096\",{\"2\":{\"63\":4}}],[\"4\",{\"0\":{\"70\":1,\"82\":1,\"131\":1,\"137\":1,\"138\":1,\"203\":1,\"232\":1,\"270\":1},\"1\":{\"81\":1,\"91\":1,\"145\":1},\"2\":{\"24\":2,\"36\":2,\"37\":2,\"42\":2,\"49\":1,\"63\":1,\"68\":1,\"79\":2,\"81\":1,\"86\":1,\"88\":3,\"95\":1,\"96\":1,\"100\":4,\"103\":2,\"114\":1,\"128\":4,\"143\":1,\"151\":3,\"166\":5,\"174\":3,\"191\":2,\"197\":2,\"220\":9,\"229\":2,\"232\":1,\"243\":2,\"246\":4,\"254\":11,\"260\":1,\"269\":2,\"273\":2,\"282\":2,\"283\":1}}],[\"那就是seq2seq模型\",{\"2\":{\"283\":1}}],[\"那就是序列往往很长\",{\"2\":{\"162\":1}}],[\"那就是如果你有更好的exp实现方式\",{\"2\":{\"140\":1}}],[\"那就是一个二维图像一般需要三维表达\",{\"2\":{\"82\":1}}],[\"那什么情况不会创建节点呢\",{\"2\":{\"140\":1}}],[\"那也不一定需要\",{\"2\":{\"68\":1}}],[\"那会看起来像是你强迫断行\",{\"2\":{\"57\":1}}],[\"那么这一部分我们就可以缓存下来\",{\"2\":{\"278\":1}}],[\"那么这样的话整个序列的估计值都将通过以下的方式获得\",{\"2\":{\"103\":1}}],[\"那么\",{\"2\":{\"259\":1,\"283\":1}}],[\"那么如果某个词元为\",{\"2\":{\"255\":1}}],[\"那么如果我的自变量是二维的呢\",{\"2\":{\"78\":1}}],[\"那么gpu0被分配到的层会变为0\",{\"2\":{\"252\":1}}],[\"那么梯度元素数量为\",{\"2\":{\"246\":1}}],[\"那么梯度会一直存在\",{\"2\":{\"137\":1}}],[\"那么参数量为\",{\"2\":{\"225\":1}}],[\"那么当前多输入输出卷积层的weight就会有多个卷积核张量\",{\"2\":{\"187\":1}}],[\"那么当\",{\"2\":{\"174\":1}}],[\"那么当二者很相近的时候\",{\"2\":{\"38\":1}}],[\"那么卷积核的输入通道数也为\",{\"2\":{\"174\":1}}],[\"那么卷积层的实现也简单起来\",{\"2\":{\"130\":1}}],[\"那么对于计算密集型就会有很好的表现\",{\"2\":{\"231\":1}}],[\"那么对于io任务就会有很好的表现\",{\"2\":{\"231\":1}}],[\"那么对于y\",{\"2\":{\"166\":1}}],[\"那么对于一个未知对象使用传值通常会造成不必要的拷贝\",{\"2\":{\"150\":1}}],[\"那么各个线程之间其实无法实现真正意义上的并行\",{\"2\":{\"163\":1}}],[\"那么你还需要返回一个weight的梯度\",{\"2\":{\"140\":1}}],[\"那么右值引用其实就是对右值的引用\",{\"2\":{\"119\":1}}],[\"那么解码时间步\",{\"2\":{\"115\":1}}],[\"那么具有bahdanau注意力的rnn\",{\"2\":{\"115\":1}}],[\"那么就会采用uint8量化的activation和int8量化的weight\",{\"2\":{\"271\":1}}],[\"那么就可以将模型表示为如下的结构\",{\"2\":{\"95\":1}}],[\"那么就代表我们的\",{\"2\":{\"71\":1}}],[\"那么查询为\",{\"2\":{\"91\":1}}],[\"那么两个向量的点积的均值为0\",{\"2\":{\"91\":1}}],[\"那么θ\",{\"2\":{\"88\":1}}],[\"那么权重就会变为四维张量\",{\"2\":{\"82\":1}}],[\"那么操作也应该是将三原色拟合为一个通道\",{\"2\":{\"82\":1}}],[\"那么我们的输出其实就是输入往后移一位\",{\"2\":{\"241\":1}}],[\"那么我们可以得知\",{\"2\":{\"230\":1}}],[\"那么我们可以得到计算公式\",{\"2\":{\"230\":1}}],[\"那么我们需要每一次保存前一个时间步的隐藏变量\",{\"2\":{\"230\":1}}],[\"那么我们需要为每个输出通道创建一个\",{\"2\":{\"187\":1}}],[\"那么我们增加了隐藏层状态该如何理解呢\",{\"2\":{\"230\":1}}],[\"那么我们一般这样计算\",{\"2\":{\"230\":1}}],[\"那么我们如何使用cuda来实现一版gemm呢\",{\"2\":{\"197\":1}}],[\"那么我们通常会使用tuple将其存起来\",{\"2\":{\"154\":1}}],[\"那么我们希望通过\",{\"2\":{\"137\":1}}],[\"那么我们求梯度的过程其实是对其求偏导\",{\"2\":{\"123\":1}}],[\"那么我们就有了限域和非限域两种写法\",{\"2\":{\"154\":1}}],[\"那么我们就需要不断地计算这样的概率\",{\"2\":{\"131\":1}}],[\"那么我们就可以观察很短的一个历史\",{\"2\":{\"103\":1}}],[\"那么我们就称这个序列满足马尔科夫条件\",{\"2\":{\"103\":1}}],[\"那么我们每次预测\",{\"2\":{\"103\":1}}],[\"那么我们\",{\"2\":{\"82\":1}}],[\"那么其实这里就会将query和key连结\",{\"2\":{\"81\":1}}],[\"那么其实∇f\",{\"2\":{\"78\":1}}],[\"那么它的梯度也为一维向量\",{\"2\":{\"78\":1}}],[\"那么注意力汇聚函数就可以表示为值的加权和\",{\"2\":{\"70\":1}}],[\"那么分配给这个键对应的\",{\"2\":{\"51\":1}}],[\"那\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1,\"68\":1}}],[\"支持在下面这些符号前面加上反斜线来帮助插入普通的符号\",{\"2\":{\"214\":1}}],[\"支持比较简短的自动链接形式来处理网址和电子邮件信箱\",{\"2\":{\"199\":1}}],[\"支持两种形式的链接语法\",{\"2\":{\"113\":1}}],[\"支持两种标题的语法\",{\"2\":{\"49\":1}}],[\"支持多种编程语言\",{\"2\":{\"100\":1}}],[\"支持有序列表和无序列表\",{\"2\":{\"68\":1}}],[\"支持\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"因其在计算机视觉任务中的高效性能而受到广泛关注\",{\"2\":{\"247\":1}}],[\"因为已经调用了mean函数\",{\"2\":{\"270\":1}}],[\"因为在当今训练中\",{\"2\":{\"263\":1}}],[\"因为在此期间模型会自我更新\",{\"2\":{\"261\":1}}],[\"因为在c++中有规定\",{\"2\":{\"112\":1}}],[\"因为mbarrier可以同时用来同步threads\",{\"2\":{\"260\":1}}],[\"因为只需要区分上一个phase\",{\"2\":{\"260\":1}}],[\"因为这是一个很好的衡量\",{\"2\":{\"249\":1}}],[\"因为这是python操作\",{\"2\":{\"140\":1}}],[\"因为是基于单线程的事件循环\",{\"2\":{\"231\":1}}],[\"因为网络io也是一个比较慢的操作\",{\"2\":{\"219\":1}}],[\"因为由下一个stage的input\",{\"2\":{\"213\":1}}],[\"因为对于inference来说\",{\"2\":{\"213\":1}}],[\"因为调度策略分为很多\",{\"2\":{\"213\":1}}],[\"因为rnn是分层的\",{\"2\":{\"202\":1}}],[\"因为gil锁的粒度为进程\",{\"2\":{\"190\":1}}],[\"因为gil机制下\",{\"2\":{\"177\":1}}],[\"因为每个通道不是独立学习的\",{\"2\":{\"187\":1}}],[\"因为它提供了一个单一的度量\",{\"2\":{\"180\":1}}],[\"因为线程的切换也是会产生开销的\",{\"2\":{\"177\":1}}],[\"因为cudatoolkit已经被打乱重组到环境中了\",{\"2\":{\"169\":1}}],[\"因为conda\",{\"2\":{\"169\":1}}],[\"因为const承诺不会修改对象\",{\"2\":{\"119\":1}}],[\"因为我们执行计算的时候\",{\"2\":{\"267\":1}}],[\"因为我们的0\",{\"2\":{\"262\":1}}],[\"因为我们的目标是根据过去和当前的词元预测下一个词元\",{\"2\":{\"241\":1}}],[\"因为我们模型生成的语言需要是更为符合语义\",{\"2\":{\"249\":1}}],[\"因为我们是cuda项目\",{\"2\":{\"169\":1}}],[\"因为我们不能保证释放锁的时候一定完成了某个操作数据的语句\",{\"2\":{\"163\":1}}],[\"因为该语句不一定是原子操作\",{\"2\":{\"163\":1}}],[\"因为一次训练多条数据\",{\"2\":{\"152\":1}}],[\"因为右值无法绑定到左值上\",{\"2\":{\"150\":1}}],[\"因为返回一个引用允许用户来修改容器\",{\"2\":{\"150\":1}}],[\"因为卷积核是从数据中学习到的\",{\"2\":{\"130\":1}}],[\"因为他告诉了我们一种方式\",{\"2\":{\"151\":1}}],[\"因为他表达的运算其实是互相关运算\",{\"2\":{\"130\":1}}],[\"因为他可以被视为一个输入映射到下一层的空间维度的转换器\",{\"2\":{\"92\":1}}],[\"因为0和null会被推断为int和整形\",{\"2\":{\"125\":1}}],[\"因为可能存在风险\",{\"2\":{\"100\":2}}],[\"因为反向传播计算的是总损失\",{\"2\":{\"88\":1}}],[\"因为同时不除的话效果等价\",{\"2\":{\"88\":1}}],[\"因为\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"因此将上述中间激活相加\",{\"2\":{\"272\":1}}],[\"因此前向传递\",{\"2\":{\"268\":1}}],[\"因此高度和宽度都减少了4个像素\",{\"2\":{\"247\":1}}],[\"因此有\",{\"2\":{\"202\":1}}],[\"因此有很多人用它写博客\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"因此计算复杂度为\",{\"2\":{\"202\":1}}],[\"因此被称为\",{\"2\":{\"186\":1}}],[\"因此我们在处理数据时需要解决这个问题\",{\"2\":{\"162\":1}}],[\"因此其可学习的参数\",{\"2\":{\"159\":1}}],[\"因此这一篇文章的目标就是深入了解pytorch梯度计算的代码实现与内部原理\",{\"2\":{\"136\":1}}],[\"因此这种类型不方便模型使用\",{\"2\":{\"117\":1}}],[\"因此下面两个链接是一样的\",{\"2\":{\"113\":1}}],[\"因此从形状中移除最后那个维度\",{\"2\":{\"81\":1}}],[\"因此float32类型下的计算量单位为flops\",{\"2\":{\"55\":1}}],[\"因此\",{\"2\":{\"6\":1,\"10\":1,\"13\":1,\"14\":1,\"19\":1,\"21\":1,\"22\":1,\"26\":1,\"87\":1,\"93\":1,\"159\":1,\"180\":1,\"187\":1,\"246\":1,\"249\":2,\"264\":1,\"272\":1}}],[\"就使用的是cp\",{\"2\":{\"273\":1}}],[\"就自动减一\",{\"2\":{\"260\":1,\"265\":1}}],[\"就这样我们完成了权重的更新\",{\"2\":{\"241\":1}}],[\"就如同当前时间步下神经网络的状态和记忆一样\",{\"2\":{\"230\":1}}],[\"就只需要理解这张图\",{\"2\":{\"222\":1}}],[\"就得扩大\",{\"2\":{\"217\":1}}],[\"就越大\",{\"2\":{\"216\":1}}],[\"就被破坏\",{\"2\":{\"211\":1}}],[\"就提供了一个明确的\",{\"2\":{\"180\":1}}],[\"就为\",{\"2\":{\"173\":1}}],[\"就无法作为左值来使用\",{\"2\":{\"150\":1}}],[\"就形成了encoder\",{\"2\":{\"138\":1}}],[\"就要用什么符号结束\",{\"2\":{\"127\":1}}],[\"就正常推导\",{\"2\":{\"122\":1}}],[\"就像是注解一样\",{\"2\":{\"113\":1}}],[\"就需要构建概率的分布\",{\"2\":{\"95\":1}}],[\"就需要缩进\",{\"2\":{\"68\":1}}],[\"就很难理解文章原始的意思\",{\"2\":{\"93\":1}}],[\"就可以了\",{\"2\":{\"169\":1}}],[\"就可以返回\",{\"2\":{\"150\":1}}],[\"就可以计算下去\",{\"2\":{\"103\":1}}],[\"就可以\",{\"2\":{\"79\":1}}],[\"就是用encoder和decoder都使用rnn来实现\",{\"2\":{\"283\":1}}],[\"就是在问\",{\"2\":{\"180\":1}}],[\"就是通过enum将名字和字段编号关联起来以避免上述按标号的晦涩访问\",{\"2\":{\"154\":1}}],[\"就是int之类的变量或者表达式的静态属性\",{\"2\":{\"119\":1}}],[\"就是一种通用的解决方案\",{\"2\":{\"95\":1}}],[\"就是将一个\",{\"2\":{\"95\":1}}],[\"就是对其求偏导\",{\"2\":{\"78\":1}}],[\"就是列表\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"就视为不需要掩蔽\",{\"2\":{\"70\":1}}],[\"就会继续往下选择\",{\"2\":{\"271\":1}}],[\"就会开始执行bwd\",{\"2\":{\"252\":1}}],[\"就会自动把它转成链接\",{\"2\":{\"199\":1}}],[\"就会缺乏一个统一的量度来衡量整体的变化\",{\"2\":{\"180\":1}}],[\"就会较为冗余\",{\"2\":{\"154\":1}}],[\"就会发现我们需要使用自己预测出来的数据来预测\",{\"2\":{\"103\":1}}],[\"就会使得weight变为\",{\"2\":{\"59\":1}}],[\"就会出现精度损失\",{\"2\":{\"38\":1}}],[\"就会将它转为\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"但与输入数据的大小无关\",{\"2\":{\"275\":1}}],[\"但包含了dropout操作需要用到的mask矩阵\",{\"2\":{\"272\":1}}],[\"但不用\",{\"2\":{\"214\":1}}],[\"但并无法全部挡下来\",{\"2\":{\"199\":1}}],[\"但有时候为了高效计算\",{\"2\":{\"144\":1}}],[\"但会修改原始张量\",{\"2\":{\"140\":1}}],[\"但我们建议你显式指定\",{\"2\":{\"114\":1}}],[\"但依旧获得高效用的模型\",{\"2\":{\"102\":1}}],[\"但是bytes占用为1\",{\"2\":{\"272\":1}}],[\"但是注意activation不使用per\",{\"2\":{\"271\":1}}],[\"但是第二项由于包含activation\",{\"2\":{\"271\":1}}],[\"但是不会进行预测\",{\"2\":{\"261\":1}}],[\"但是不生成任何输出\",{\"2\":{\"261\":1}}],[\"但是不声明的话\",{\"2\":{\"154\":1}}],[\"但是为了处理方便\",{\"2\":{\"255\":1}}],[\"但是带来的好处是\",{\"2\":{\"252\":1}}],[\"但是chunk变了\",{\"2\":{\"252\":1}}],[\"但是c++14可以自动推导lambda表达式返回值\",{\"2\":{\"150\":1}}],[\"但是仍然不能和async的性能作比较\",{\"2\":{\"231\":1}}],[\"但是多线程是创建更多的线程来分别去执行任务\",{\"2\":{\"231\":1}}],[\"但是多进程有诸多缺点\",{\"2\":{\"190\":1}}],[\"但是从如今的视角来看\",{\"2\":{\"222\":1}}],[\"但是无需做一次sync\",{\"2\":{\"222\":1}}],[\"但是需要在gelu前做一次sync\",{\"2\":{\"222\":1}}],[\"但是模型的参数会指数增长\",{\"2\":{\"217\":1}}],[\"但是我们需要做一些改进\",{\"2\":{\"285\":1}}],[\"但是我们可以看出\",{\"2\":{\"278\":1}}],[\"但是我们仍然需要其grad\",{\"2\":{\"213\":1}}],[\"但是我们忽略了图像的另外一个特点\",{\"2\":{\"82\":1}}],[\"但是经由mutable修饰的成员变量\",{\"2\":{\"211\":1}}],[\"但是十分流行的卷积层\",{\"2\":{\"203\":1}}],[\"但是self\",{\"2\":{\"202\":1}}],[\"但是实际上会受限于sm的数量和资源\",{\"2\":{\"197\":1}}],[\"但是有了注意力机制后\",{\"2\":{\"186\":1}}],[\"但是有的时候我们会有其他的要求\",{\"2\":{\"126\":1}}],[\"但是优点是环境干净隔离\",{\"2\":{\"169\":1}}],[\"但是一般cuda开发都需要ssh\",{\"2\":{\"169\":1}}],[\"但是提供了一个与\",{\"2\":{\"166\":1}}],[\"但是其实我们也可以提供一个与\",{\"2\":{\"166\":1}}],[\"但是其实也可以缩进\",{\"2\":{\"68\":1}}],[\"但是由于cpython\",{\"2\":{\"163\":1}}],[\"但是python中却不同\",{\"2\":{\"163\":1}}],[\"但是更一般化地\",{\"2\":{\"154\":1}}],[\"但是对于ctx\",{\"2\":{\"213\":1}}],[\"但是对于第一种\",{\"2\":{\"154\":1}}],[\"但是对于取值的时候\",{\"2\":{\"154\":1}}],[\"但是对于表格和图像数据\",{\"2\":{\"93\":1}}],[\"但是并不总是这样\",{\"2\":{\"154\":1}}],[\"但是并不区分大小写\",{\"2\":{\"113\":1}}],[\"但是decltype也会产生一些意想不到的结果\",{\"2\":{\"150\":1}}],[\"但是目前可以知道的是\",{\"2\":{\"150\":1}}],[\"但是通过实验发现\",{\"2\":{\"145\":1}}],[\"但是typedef不行\",{\"2\":{\"139\":1}}],[\"但是auto类型推导假定花括号初始化代表std\",{\"2\":{\"135\":1}}],[\"但是auto就不行\",{\"2\":{\"135\":1}}],[\"但是也有一些不同\",{\"2\":{\"135\":1,\"231\":1}}],[\"但是这种数据的保存\",{\"2\":{\"213\":1}}],[\"但是这样存在诸多局限性\",{\"2\":{\"168\":1}}],[\"但是这样其实忽略了单词本来的意义\",{\"2\":{\"131\":1}}],[\"但是这里带来了一些问题\",{\"2\":{\"150\":1}}],[\"但是这个\",{\"2\":{\"68\":1}}],[\"但是用行内形式的链接却会增加到\",{\"2\":{\"113\":1}}],[\"但是可以通过指针来改变其指向的对象t的属性\",{\"2\":{\"104\":1}}],[\"但是如果我们持续预测下去\",{\"2\":{\"103\":1}}],[\"但是如果你的\",{\"2\":{\"127\":1}}],[\"但是如果你很懒\",{\"2\":{\"68\":1}}],[\"但是如果你是写\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"但是如果你这样写\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"但是点积操作要求查询和键具有相同的长度\",{\"2\":{\"91\":1}}],[\"但是在之前的auto推导中我们得知\",{\"2\":{\"150\":1}}],[\"但是在处理图像数据的时候\",{\"2\":{\"52\":1}}],[\"但是在计算机实现上我们有更加有趣的方法\",{\"2\":{\"48\":1}}],[\"但是\",{\"2\":{\"40\":1,\"87\":1}}],[\"但是你要小心跳脱字元的使用\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"但在一些语法和渲染效果上有改动\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"h​tq\",{\"2\":{\"278\":1}}],[\"h​qkt​\",{\"2\":{\"259\":1}}],[\"hn​=ϕ\",{\"2\":{\"266\":1}}],[\"hn=ϕ\",{\"2\":{\"266\":1}}],[\"hh\",{\"2\":{\"230\":2,\"255\":4}}],[\"hhh\",{\"2\":{\"71\":2,\"81\":2,\"103\":1,\"159\":5,\"212\":1,\"236\":1,\"264\":1,\"272\":1}}],[\"hq\",{\"2\":{\"230\":3,\"255\":4}}],[\"hw\",{\"2\":{\"230\":1}}],[\"h=ϕ\",{\"2\":{\"230\":2}}],[\"h∈rn⋅h\",{\"2\":{\"230\":1}}],[\"h∈rn⋅hh\",{\"2\":{\"230\":1}}],[\"hvhvhv\",{\"2\":{\"225\":1}}],[\"hooks\",{\"2\":{\"213\":1}}],[\"hook\",{\"2\":{\"197\":1}}],[\"hook=pre\",{\"2\":{\"197\":1}}],[\"hook=none\",{\"2\":{\"197\":1}}],[\"hopper架构下\",{\"2\":{\"260\":1}}],[\"hopper的新特性\",{\"2\":{\"197\":1}}],[\"hopper\",{\"2\":{\"179\":1,\"260\":1}}],[\"hot\",{\"2\":{\"123\":1,\"255\":1,\"277\":1}}],[\"hp\",{\"2\":{\"159\":1}}],[\"hph​\",{\"2\":{\"144\":1}}],[\"h~2~o\",{\"2\":{\"157\":1}}],[\"hub\",{\"2\":{\"117\":1}}],[\"hint\",{\"2\":{\"254\":2,\"269\":1,\"273\":1}}],[\"hi​=f\",{\"2\":{\"159\":1}}],[\"hi=f\",{\"2\":{\"159\":1}}],[\"hih\",{\"2\":{\"159\":1}}],[\"highlight\",{\"2\":{\"100\":3}}],[\"highlighted\",{\"2\":{\"100\":8}}],[\"hidden\",{\"2\":{\"81\":1,\"115\":9,\"129\":2,\"230\":1,\"277\":1}}],[\"hiddens=16\",{\"2\":{\"283\":2}}],[\"hiddens=num\",{\"2\":{\"115\":1,\"255\":1}}],[\"hiddens=8\",{\"2\":{\"81\":1}}],[\"hiddens\",{\"2\":{\"81\":5,\"115\":14,\"173\":15,\"202\":4,\"255\":15,\"277\":6,\"283\":16}}],[\"handle\",{\"2\":{\"269\":1,\"273\":1}}],[\"hardware\",{\"0\":{\"179\":1}}],[\"has\",{\"2\":{\"113\":2,\"263\":1}}],[\"have\",{\"2\":{\"97\":2,\"193\":2}}],[\"hat和y\",{\"2\":{\"270\":1}}],[\"hat的shape为\",{\"2\":{\"270\":1}}],[\"hat\",{\"2\":{\"88\":3,\"96\":3,\"130\":2,\"152\":14,\"247\":3,\"270\":2,\"285\":2}}],[\"height\",{\"2\":{\"269\":1,\"273\":1}}],[\"heavy\",{\"2\":{\"263\":1}}],[\"heads次\",{\"2\":{\"173\":1}}],[\"heads\",{\"2\":{\"97\":19,\"138\":2,\"153\":3,\"167\":3,\"173\":22,\"181\":2,\"193\":29}}],[\"header\",{\"2\":{\"49\":6,\"57\":1,\"169\":1}}],[\"head\",{\"0\":{\"45\":1,\"97\":1},\"2\":{\"87\":1,\"97\":3,\"110\":1,\"138\":1,\"153\":2,\"159\":1,\"175\":1,\"193\":6,\"259\":6}}],[\"helps\",{\"2\":{\"110\":1,\"193\":1}}],[\"hello\",{\"2\":{\"100\":7,\"122\":1,\"135\":1}}],[\"here\",{\"2\":{\"57\":1,\"79\":1,\"113\":7,\"141\":2}}],[\"hendrerit\",{\"2\":{\"57\":2,\"68\":3}}],[\"h6\",{\"2\":{\"49\":1}}],[\"h5\",{\"2\":{\"49\":1}}],[\"h4\",{\"2\":{\"49\":1}}],[\"h3\",{\"2\":{\"49\":1}}],[\"h2o\",{\"2\":{\"157\":1}}],[\"h2\",{\"2\":{\"49\":2}}],[\"h1⋮hh\",{\"2\":{\"159\":1}}],[\"h1\",{\"2\":{\"49\":2}}],[\"h\",{\"2\":{\"48\":3,\"55\":6,\"71\":12,\"81\":3,\"82\":9,\"88\":2,\"103\":2,\"115\":2,\"130\":5,\"144\":5,\"159\":7,\"173\":1,\"174\":2,\"187\":2,\"203\":3,\"217\":3,\"229\":4,\"230\":7,\"248\":1,\"254\":2,\"255\":9,\"259\":19,\"266\":2,\"272\":6,\"278\":3}}],[\"href=\",{\"2\":{\"113\":5,\"199\":2}}],[\"href\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"ht=ϕ\",{\"2\":{\"230\":1}}],[\"ht=f\",{\"2\":{\"217\":1}}],[\"ht=g\",{\"2\":{\"103\":1}}],[\"ht\",{\"2\":{\"115\":2}}],[\"ht−1h\",{\"2\":{\"217\":1,\"230\":1,\"255\":1}}],[\"ht−1​\",{\"2\":{\"103\":1,\"217\":2,\"230\":1,\"255\":1}}],[\"ht−1\",{\"2\":{\"103\":1,\"217\":1}}],[\"ht​=ϕ\",{\"2\":{\"230\":1}}],[\"ht​=f\",{\"2\":{\"217\":1}}],[\"ht​=g\",{\"2\":{\"103\":1}}],[\"ht​\",{\"2\":{\"103\":1,\"115\":2}}],[\"hth\",{\"2\":{\"103\":2,\"115\":1}}],[\"http\",{\"2\":{\"24\":2,\"36\":2,\"37\":2,\"42\":2,\"113\":24,\"199\":2}}],[\"https\",{\"2\":{\"15\":2,\"100\":3,\"106\":4,\"175\":1,\"273\":2}}],[\"html\",{\"0\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1},\"2\":{\"6\":2,\"13\":2,\"14\":2,\"17\":5,\"19\":2,\"24\":13,\"28\":5,\"29\":5,\"33\":5,\"36\":13,\"37\":13,\"40\":1,\"42\":13,\"68\":3,\"79\":2,\"113\":3,\"141\":2,\"199\":1,\"273\":2}}],[\"n​\",{\"2\":{\"275\":1}}],[\"n+1\",{\"2\":{\"266\":2,\"278\":1}}],[\"n1​t=1∑n​−logp\",{\"2\":{\"249\":1}}],[\"n−1n\",{\"2\":{\"217\":1}}],[\"n^2d\",{\"2\":{\"202\":1}}],[\"n2d\",{\"2\":{\"202\":2}}],[\"n∗dn\",{\"2\":{\"202\":1}}],[\"nd^2\",{\"2\":{\"202\":1}}],[\"nd2\",{\"2\":{\"202\":2}}],[\"ny1​\",{\"2\":{\"186\":1}}],[\"nx1​\",{\"2\":{\"186\":1}}],[\"nvidia\",{\"2\":{\"169\":1,\"273\":2}}],[\"nvcc\",{\"2\":{\"169\":2}}],[\"nh\",{\"2\":{\"266\":1}}],[\"nh​−kh​+ph​+1\",{\"2\":{\"144\":1}}],[\"nh​−kh​+1\",{\"2\":{\"130\":1}}],[\"nh−kh+ph+1\",{\"2\":{\"144\":1}}],[\"nh−kh+1\",{\"2\":{\"130\":1}}],[\"nw​−kw​+pw​+1\",{\"2\":{\"144\":1}}],[\"nw​−kw​+1\",{\"2\":{\"130\":1}}],[\"nw−kw+pw+1\",{\"2\":{\"144\":1}}],[\"nw−kw+1\",{\"2\":{\"130\":1}}],[\"nwkernelregression\",{\"2\":{\"59\":2}}],[\"nullptr\",{\"0\":{\"125\":1},\"2\":{\"125\":1}}],[\"num的话\",{\"2\":{\"260\":1}}],[\"numel\",{\"2\":{\"152\":1,\"191\":1,\"247\":1,\"270\":2}}],[\"numpy\",{\"2\":{\"88\":1}}],[\"num\",{\"2\":{\"63\":6,\"81\":7,\"88\":10,\"96\":7,\"97\":9,\"115\":19,\"129\":2,\"138\":2,\"152\":10,\"153\":3,\"167\":6,\"173\":37,\"176\":11,\"181\":4,\"188\":16,\"193\":24,\"197\":7,\"202\":4,\"213\":1,\"247\":10,\"254\":1,\"255\":22,\"260\":1,\"261\":2,\"270\":7,\"277\":15,\"282\":2,\"283\":33,\"285\":9}}],[\"number=2\",{\"2\":{\"61\":1}}],[\"number\",{\"2\":{\"61\":5,\"97\":2,\"193\":2,\"279\":1}}],[\"num=30\",{\"2\":{\"24\":2,\"36\":2,\"37\":2,\"42\":2}}],[\"np\",{\"2\":{\"88\":1}}],[\"ni​∝iα1​\",{\"2\":{\"145\":1}}],[\"ni∝1iαn\",{\"2\":{\"145\":1}}],[\"nin\",{\"0\":{\"75\":1},\"2\":{\"75\":4,\"145\":1}}],[\"nisl\",{\"2\":{\"57\":2,\"68\":3}}],[\"native\",{\"2\":{\"208\":1}}],[\"nas\",{\"2\":{\"208\":1}}],[\"nabla\",{\"2\":{\"78\":3,\"128\":8}}],[\"names\",{\"2\":{\"285\":1}}],[\"name\",{\"2\":{\"61\":1,\"86\":1,\"100\":2,\"135\":3,\"181\":1,\"193\":1}}],[\"nadaraya\",{\"2\":{\"51\":2}}],[\"nnn\",{\"2\":{\"91\":1,\"95\":2,\"108\":1,\"123\":2,\"130\":1,\"137\":1,\"158\":1,\"202\":4,\"217\":3,\"230\":1,\"249\":1,\"255\":3,\"266\":1,\"278\":1}}],[\"nn\",{\"2\":{\"59\":4,\"61\":6,\"63\":16,\"70\":2,\"75\":14,\"81\":5,\"86\":33,\"88\":4,\"91\":2,\"96\":5,\"97\":5,\"103\":7,\"110\":4,\"115\":3,\"117\":2,\"124\":1,\"126\":5,\"130\":4,\"138\":4,\"144\":4,\"152\":1,\"153\":5,\"167\":7,\"173\":5,\"181\":1,\"193\":29,\"202\":2,\"229\":4,\"247\":19,\"266\":1,\"270\":3,\"277\":6,\"280\":3,\"283\":5,\"285\":5}}],[\"neighbor\",{\"2\":{\"273\":8}}],[\"neural\",{\"2\":{\"138\":1,\"153\":1,\"158\":1,\"193\":2}}],[\"ne\",{\"2\":{\"128\":2}}],[\"neq\",{\"2\":{\"123\":3,\"137\":1}}],[\"new和\",{\"2\":{\"283\":1}}],[\"new\",{\"2\":{\"104\":2,\"118\":2,\"255\":1,\"283\":2}}],[\"next\",{\"2\":{\"100\":2,\"140\":1,\"247\":1,\"282\":1}}],[\"networks\",{\"0\":{\"110\":1},\"2\":{\"110\":1,\"193\":1}}],[\"network\",{\"2\":{\"87\":1,\"138\":1,\"153\":1,\"193\":2,\"225\":1}}],[\"net\",{\"2\":{\"59\":3,\"63\":2,\"75\":1,\"88\":9,\"103\":11,\"113\":3,\"152\":6,\"247\":14,\"255\":3,\"261\":5,\"266\":4,\"270\":12,\"285\":7}}],[\"nested\",{\"2\":{\"57\":1}}],[\"nec\",{\"2\":{\"57\":2,\"68\":3}}],[\"neat\",{\"2\":{\"50\":2}}],[\"n×c×h×wn\",{\"2\":{\"55\":1}}],[\"n\",{\"2\":{\"51\":4,\"55\":5,\"59\":23,\"91\":2,\"103\":3,\"108\":2,\"118\":2,\"123\":10,\"130\":2,\"137\":1,\"144\":2,\"145\":1,\"152\":2,\"158\":1,\"166\":3,\"186\":2,\"197\":6,\"202\":11,\"230\":2,\"249\":2,\"254\":6,\"260\":13,\"266\":4,\"267\":2,\"269\":11,\"273\":12,\"275\":5,\"278\":2,\"279\":9,\"282\":4,\"283\":1}}],[\"node\",{\"2\":{\"263\":1}}],[\"nopeak\",{\"2\":{\"167\":2,\"193\":2}}],[\"noexcept也是同理\",{\"2\":{\"182\":1}}],[\"noexcept\",{\"0\":{\"182\":1},\"2\":{\"154\":3,\"182\":1}}],[\"nonlinearity\",{\"2\":{\"222\":1}}],[\"non\",{\"0\":{\"282\":1},\"2\":{\"122\":1,\"269\":1,\"282\":2}}],[\"none\",{\"2\":{\"59\":1,\"70\":1,\"97\":1,\"103\":1,\"117\":2,\"173\":1,\"193\":1,\"247\":3,\"270\":2,\"285\":3}}],[\"notimplementederror\",{\"2\":{\"115\":1,\"280\":3}}],[\"not\",{\"2\":{\"96\":1,\"97\":1,\"114\":1,\"117\":3,\"173\":1,\"193\":1,\"247\":1,\"260\":1,\"270\":1,\"277\":2}}],[\"note\",{\"2\":{\"90\":3,\"100\":2,\"260\":1}}],[\"notes\",{\"0\":{\"15\":1}}],[\"no\",{\"2\":{\"88\":3,\"113\":2,\"140\":1,\"152\":1,\"247\":2,\"285\":1}}],[\"norm层\",{\"2\":{\"272\":1}}],[\"norm3\",{\"2\":{\"153\":2,\"193\":2}}],[\"norm2\",{\"2\":{\"138\":2,\"153\":2,\"193\":4}}],[\"norm1\",{\"2\":{\"138\":2,\"153\":2,\"193\":4}}],[\"norm\",{\"2\":{\"96\":2,\"266\":3}}],[\"normalization\",{\"0\":{\"96\":1},\"2\":{\"87\":1,\"138\":1,\"153\":1,\"193\":2,\"225\":2,\"272\":2}}],[\"normal\",{\"2\":{\"51\":1,\"79\":2,\"81\":1,\"88\":4,\"103\":1,\"110\":1,\"152\":2,\"178\":1,\"193\":1,\"203\":2,\"255\":4,\"269\":1,\"273\":1}}],[\"noreferrer\",{\"2\":{\"41\":1}}],[\"像是星号便只是星号\",{\"2\":{\"79\":1}}],[\"像是下面这样的写法\",{\"2\":{\"68\":1}}],[\"像是\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"像是在文字两旁加上星号\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"你用什么符号开启标签\",{\"2\":{\"127\":1}}],[\"你就可以将其替换掉\",{\"2\":{\"140\":1}}],[\"你就可以增加链接而不让文章的阅读感觉被打断\",{\"2\":{\"113\":1}}],[\"你就知道怎么在\",{\"2\":{\"57\":1}}],[\"你还可以通过\",{\"2\":{\"100\":1}}],[\"你还可以指定高亮显示的次数\",{\"2\":{\"100\":1}}],[\"你也可以这样写\",{\"2\":{\"141\":1}}],[\"你也可以把它放在文件最后面\",{\"2\":{\"113\":1}}],[\"你也可以把\",{\"2\":{\"113\":1}}],[\"你也可以在星号中间插入空白\",{\"2\":{\"89\":1}}],[\"你也可以通过\",{\"2\":{\"25\":1}}],[\"你都会得到完全相同的\",{\"2\":{\"68\":1}}],[\"你在列表标记上使用的数字并不会影响输出的\",{\"2\":{\"68\":1}}],[\"你可以用多个反引号来开启和结束行内代码\",{\"2\":{\"141\":1}}],[\"你可以用反引号把它包起来\",{\"2\":{\"141\":1}}],[\"你可以用反斜线\",{\"2\":{\"127\":1}}],[\"你可以随便用你喜欢的样式\",{\"2\":{\"127\":1}}],[\"你可以随时修改它们\",{\"2\":{\"25\":1}}],[\"你可以使用特殊标记为\",{\"2\":{\"185\":1}}],[\"你可以使用普通的\",{\"2\":{\"156\":1}}],[\"你可以使用下面的语法\",{\"2\":{\"114\":1}}],[\"你可以使用相对路径\",{\"2\":{\"113\":1}}],[\"你可以简化成\",{\"2\":{\"113\":1}}],[\"你可以把这个标签的链接内容定义出来\",{\"2\":{\"113\":1}}],[\"你可以把内容用固定的缩进整理好\",{\"2\":{\"68\":1}}],[\"你可以在星号的前面加上反斜线\",{\"2\":{\"214\":1}}],[\"你可以在一行中用三个或以上的星号\",{\"2\":{\"89\":1}}],[\"你可以在句点前面加上反斜线\",{\"2\":{\"68\":1}}],[\"你可以进行嵌套\",{\"2\":{\"79\":1}}],[\"你可以完全不用在意数字的正确性\",{\"2\":{\"68\":1}}],[\"你可以让\",{\"2\":{\"68\":1}}],[\"你可以选取文字后然后从选单中选择增加引言阶层\",{\"2\":{\"57\":1}}],[\"你可以这样写\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"你要把所有的\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"你必须要把网址转成\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"你必须要写成\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"你必须要使用实体的形式\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"你无法在\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"有16层\",{\"2\":{\"252\":1}}],[\"有隐状态的循环神经网络\",{\"0\":{\"230\":1}}],[\"有两种tensor切割方式\",{\"2\":{\"222\":1}}],[\"有两个字元需要特殊处理\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"有\",{\"2\":{\"202\":1}}],[\"有时称为汇聚窗口\",{\"2\":{\"229\":1}}],[\"有时间再完善实现的笔记\",{\"2\":{\"152\":1}}],[\"有时在应用多层卷积的时候\",{\"2\":{\"144\":1}}],[\"有的时候我们bwd的时候\",{\"2\":{\"213\":1}}],[\"有的时候我们创建的节点会覆盖当前的节点\",{\"2\":{\"140\":1}}],[\"有的时候我们还想捕捉边界特征等一些其他特征\",{\"2\":{\"82\":1}}],[\"有持久身份的对象\",{\"2\":{\"119\":1}}],[\"有一个问题\",{\"2\":{\"285\":1}}],[\"有一个已知的问题是\",{\"2\":{\"113\":1}}],[\"有一条性质比较好用\",{\"2\":{\"118\":1}}],[\"有天然的免疫性\",{\"2\":{\"112\":1}}],[\"有什么区别\",{\"2\":{\"104\":1}}],[\"有助于用户更顺利达成目标的建议性信息\",{\"2\":{\"100\":2}}],[\"有序列表则使用数字接着一个英文句点\",{\"2\":{\"68\":1}}],[\"有如下核心结构\",{\"2\":{\"61\":1}}],[\"有三种方式来使用内部链接\",{\"2\":{\"32\":1}}],[\"有关web框架\",{\"2\":{\"1\":1}}],[\"算子融合\",{\"2\":{\"66\":1}}],[\"算子优化\",{\"2\":{\"66\":1}}],[\"算子operator层面优化\",{\"2\":{\"23\":1}}],[\"算法入门笔记\",{\"2\":{\"1\":1}}],[\"而中间激活值与输入数据的大小\",{\"2\":{\"275\":1}}],[\"而输入的均值和方差分别包含了\",{\"2\":{\"272\":1}}],[\"而dualpipev采取了v形调度\",{\"2\":{\"263\":1}}],[\"而多进程是在网络框架中实现的\",{\"2\":{\"256\":1}}],[\"而多线程因为每个线程都需要一定的内存和资源\",{\"2\":{\"231\":1}}],[\"而隐状态形态保持不变\",{\"2\":{\"255\":1}}],[\"而任何实际模型都必须超越这个上限\",{\"2\":{\"249\":1}}],[\"而协程则是因为他的本质是基于epoll的io让渡\",{\"2\":{\"231\":1}}],[\"而每一维的隐藏层权重都需要上一维来更新\",{\"2\":{\"230\":1}}],[\"而现实可能更为复杂一些\",{\"2\":{\"187\":1}}],[\"而只有成员函数可被标记为private\",{\"2\":{\"168\":1}}],[\"而y是标准答案\",{\"2\":{\"152\":1}}],[\"而我们梯度下降的方式也很简单\",{\"2\":{\"137\":1}}],[\"而模板类型推导就不行\",{\"2\":{\"135\":1}}],[\"而模型需要的输入是数字\",{\"2\":{\"117\":1}}],[\"而是替换其数据字段为一个标量\",{\"2\":{\"213\":1}}],[\"而是为了共同使用而优化的\",{\"2\":{\"187\":1}}],[\"而是分析这种机制\",{\"2\":{\"163\":1}}],[\"而是它比较好读\",{\"2\":{\"113\":1}}],[\"而是照原来的样子显示\",{\"2\":{\"79\":1}}],[\"而在pp维度其实care的是更加上层的调度\",{\"2\":{\"213\":1}}],[\"而在多维情况下\",{\"2\":{\"180\":1}}],[\"而在第二个方括号里面要填入用以辨识链接的标签\",{\"2\":{\"113\":1}}],[\"而在其它情形下\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"而键和值来自整个编码器的输出\",{\"2\":{\"87\":1}}],[\"而不需要在意handler的并行处理的原因\",{\"2\":{\"256\":1}}],[\"而不是模型参数\",{\"2\":{\"275\":1}}],[\"而不是元素个数\",{\"2\":{\"272\":1}}],[\"而不是\",{\"2\":{\"272\":1}}],[\"而不是拷贝一份之后再操作\",{\"2\":{\"267\":1}}],[\"而不是像卷积层一样在通道上对输入进行汇总\",{\"2\":{\"229\":1}}],[\"而不是链接期\",{\"2\":{\"168\":1}}],[\"而不是声明\",{\"2\":{\"154\":1}}],[\"而不是卷积运算\",{\"2\":{\"130\":1}}],[\"而不是默认的\",{\"2\":{\"18\":1}}],[\"而不在乎它的位置\",{\"2\":{\"102\":1}}],[\"而不变性蕴含在二维空间中\",{\"2\":{\"82\":1}}],[\"而非自主性提示被称之为键\",{\"2\":{\"43\":1}}],[\"而一个以上的空行则会切分出不同的段落\",{\"2\":{\"40\":1}}],[\"而且输出层的权重矩阵通常与词嵌入矩阵是参数共享的\",{\"2\":{\"225\":1}}],[\"而且self\",{\"2\":{\"202\":1}}],[\"而且c++14的lambda函数也允许在形参声明中使用auto\",{\"2\":{\"135\":1}}],[\"而且我们最后训练出来的\",{\"2\":{\"130\":1}}],[\"而且因为卷积核发生了堆叠\",{\"2\":{\"82\":1}}],[\"而且存在累加\",{\"2\":{\"38\":1}}],[\"而且这些\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"而且功能比纯文本更强\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"这俩真可以算loss吗\",{\"2\":{\"285\":1}}],[\"这被称为预热期\",{\"2\":{\"261\":1}}],[\"这类量化其实就是每个刻度对应一个固定的gap\",{\"2\":{\"251\":1}}],[\"这类库是使用虚拟环境内的pip安装的\",{\"2\":{\"169\":1}}],[\"这组数据\",{\"2\":{\"205\":1}}],[\"这段字串会变成一个可以点击的\",{\"2\":{\"199\":1}}],[\"这段语法会产生\",{\"2\":{\"141\":1}}],[\"这将是我们能做的最好的编码方式\",{\"2\":{\"249\":1}}],[\"这将被渲染为\",{\"2\":{\"185\":1}}],[\"这将为图片添加\",{\"2\":{\"185\":1}}],[\"这需要有一个清晰定义的输出方向来应用\",{\"2\":{\"180\":1}}],[\"这可以表示为\",{\"2\":{\"166\":1}}],[\"这可以为我们的设计提供参考\",{\"2\":{\"46\":1}}],[\"这\",{\"2\":{\"159\":1}}],[\"这意味着\",{\"2\":{\"229\":1}}],[\"这意味着每个元素的梯度权重都是1\",{\"2\":{\"166\":1}}],[\"这意味着pytorch将会追踪对x0x\",{\"2\":{\"151\":1}}],[\"这意味着我们无法给函数传递右值容器\",{\"2\":{\"150\":1}}],[\"这意味着对于\",{\"2\":{\"71\":1}}],[\"这也就是为什么上述的对于矩阵block的re\",{\"2\":{\"197\":1}}],[\"这也是官方文档给出的例子\",{\"2\":{\"140\":1}}],[\"这也可能是\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"这表示源句子的编码表示\",{\"2\":{\"129\":1}}],[\"这表示你可以很容易地以\",{\"2\":{\"79\":1}}],[\"这使得我们需要一个可以自己定义fwd和bwd逻辑\",{\"2\":{\"126\":1}}],[\"这在函数重载\",{\"2\":{\"125\":1}}],[\"这说明如果\",{\"2\":{\"123\":1}}],[\"这是const语义保证的\",{\"2\":{\"211\":1}}],[\"这是对应l2\",{\"2\":{\"197\":1}}],[\"这是为什么呢\",{\"2\":{\"166\":1}}],[\"这是因为我们的模型还没训练\",{\"2\":{\"261\":1}}],[\"这是因为cpp会为每个enum选择一个底层的类型用来表示它\",{\"2\":{\"154\":1}}],[\"这是因为还没有进行任何梯度的计算\",{\"2\":{\"151\":1}}],[\"这是通过将上下文变量视为加性注意力池化的输出来实现的\",{\"2\":{\"115\":1}}],[\"这是一种朴素的并行策略\",{\"2\":{\"245\":1}}],[\"这是一种很好的性质\",{\"2\":{\"103\":1}}],[\"这是一篇杂谈\",{\"2\":{\"169\":1}}],[\"这是一个单词维度统计的频率\",{\"2\":{\"145\":1}}],[\"这是一个从0开始实现的例子\",{\"2\":{\"88\":1}}],[\"这是一个一维自变量和一维因变量的函数\",{\"2\":{\"78\":1}}],[\"这两种写法的区别在于const修饰语义\",{\"2\":{\"104\":1}}],[\"这叫\",{\"2\":{\"103\":1}}],[\"这让我们知道了\",{\"2\":{\"92\":1}}],[\"这种优化针对的是system\",{\"2\":{\"284\":1}}],[\"这种方式减少的其实是中间激活占用的显存\",{\"2\":{\"275\":1}}],[\"这种方式提供了一个重要的上限\",{\"2\":{\"249\":1}}],[\"这种计算就像不断循环一样\",{\"2\":{\"230\":1}}],[\"这种就被称之为隐状态\",{\"2\":{\"230\":1}}],[\"这种作法虽然可以混淆不少的机器人\",{\"2\":{\"199\":1}}],[\"这种机制由解释器实现\",{\"2\":{\"163\":1}}],[\"这种设计被称为多头注意力\",{\"2\":{\"159\":1}}],[\"这种操作一般不会在cpu上执行\",{\"2\":{\"133\":1}}],[\"这种操作可以使得x\",{\"2\":{\"59\":1}}],[\"这种情形下\",{\"2\":{\"113\":1}}],[\"这种掩蔽\",{\"2\":{\"87\":1}}],[\"这样zw=0z\",{\"2\":{\"271\":1}}],[\"这样overlap收益不高\",{\"2\":{\"252\":1}}],[\"这样做的坏处是\",{\"2\":{\"252\":1}}],[\"这样做可以有效地避免不必要的内存开销和计算\",{\"2\":{\"88\":1}}],[\"这样fwd的顺序会变为\",{\"2\":{\"252\":1}}],[\"这样也会产生切换开销\",{\"2\":{\"231\":1}}],[\"这样重新排列一下\",{\"2\":{\"220\":1}}],[\"这样随着我们在神经网络中层叠的上升\",{\"2\":{\"216\":1}}],[\"这样会避免多block调度和创建的开销\",{\"2\":{\"197\":1}}],[\"这样会给我们的代码带来更快的运行效率\",{\"2\":{\"194\":1}}],[\"这样会比较容易插入\",{\"2\":{\"141\":1}}],[\"这样会比较好看\",{\"2\":{\"113\":1}}],[\"这样对于值的语义并不直观\",{\"2\":{\"154\":1}}],[\"这样可以显著降低显存占用\",{\"2\":{\"252\":1}}],[\"这样可以使得编译器选取最小的类型来表示这个枚举\",{\"2\":{\"154\":1}}],[\"这样可以保证传入的参数c具有之前的左值or右值的特性\",{\"2\":{\"150\":1}}],[\"这样你就可以在区段的一开始就插入反引号\",{\"2\":{\"141\":1}}],[\"这样就无法进行量化\",{\"2\":{\"271\":1}}],[\"这样就实现了一个web框架的高效运转\",{\"2\":{\"256\":1}}],[\"这样就实现了通信和计算的overlap\",{\"2\":{\"252\":1}}],[\"这样就可以并行的处理请求\",{\"2\":{\"256\":1}}],[\"这样就可以实现你自己定制的exp函数\",{\"2\":{\"140\":1}}],[\"这样就不可能导向a\",{\"2\":{\"205\":1}}],[\"这样就会使得偏差越来越大\",{\"2\":{\"103\":1}}],[\"这样我们可以采用batch\",{\"2\":{\"284\":1}}],[\"这样我们可以方便的迭代外围时间步数\",{\"2\":{\"255\":1}}],[\"这样我们就可以顾及到前面所有的单词\",{\"2\":{\"217\":1}}],[\"这样我们就可以实现并行\",{\"2\":{\"190\":1}}],[\"这样我们就可以将所有的答案输出概率select出来\",{\"2\":{\"152\":1}}],[\"这样我们在使用模板的时候\",{\"2\":{\"139\":1}}],[\"这样我们的输出就会有多个通道\",{\"2\":{\"82\":1}}],[\"这样\",{\"2\":{\"137\":1}}],[\"这样最后梯度的形态应该是一个\",{\"2\":{\"123\":1}}],[\"这样便构建了概率分布\",{\"2\":{\"108\":1}}],[\"这样的话就会出现梯度爆炸或者梯度消失现象\",{\"2\":{\"266\":1}}],[\"这样的话\",{\"2\":{\"211\":1}}],[\"这样的话每次输出\",{\"2\":{\"202\":1}}],[\"这样的话我们需要填充的行和列均为偶数\",{\"2\":{\"144\":1}}],[\"这样的话我们可以固定训练的参数数量\",{\"2\":{\"103\":1}}],[\"这样的格式可以混淆一些不好的信箱地址收集机器人\",{\"2\":{\"199\":1}}],[\"这样的方式让你非常容易使用\",{\"2\":{\"79\":1}}],[\"这样是一个生成数据的函数\",{\"2\":{\"88\":1}}],[\"这时使用\",{\"2\":{\"112\":1}}],[\"这时候该怎么办呢\",{\"2\":{\"82\":1}}],[\"这时会恢复为\",{\"2\":{\"25\":1}}],[\"这就\",{\"2\":{\"256\":1}}],[\"这就需要通过各种不同的方法\",{\"2\":{\"223\":1}}],[\"这就会使得以下的语句只能被解析为函数声明\",{\"2\":{\"112\":1}}],[\"这就获得了某种意义上的\",{\"2\":{\"71\":1}}],[\"这就是中间激活\",{\"2\":{\"272\":1}}],[\"这就是int8量化算子的执行过程\",{\"2\":{\"267\":1}}],[\"这就是我们使用django或者flask等应用框架的时候只需要实现url到handler的映射\",{\"2\":{\"256\":1}}],[\"这就是我们熟知的分词操作\",{\"2\":{\"117\":1}}],[\"这就是为什么反向传播通常需要从一个标量开始的原因\",{\"2\":{\"180\":1}}],[\"这就是pytorch的自动微分机制\",{\"2\":{\"151\":1}}],[\"这就是torch\",{\"2\":{\"126\":1}}],[\"这就是一个自定义的torch\",{\"2\":{\"126\":1}}],[\"这就是ep并行策略\",{\"2\":{\"61\":1}}],[\"这就是最朴素的moe\",{\"2\":{\"61\":1}}],[\"这就不是我们想看到的\",{\"2\":{\"52\":1}}],[\"这里shape\",{\"2\":{\"285\":1}}],[\"这里写的有点问题\",{\"2\":{\"278\":1}}],[\"这里1和2是ffn层的全连接层\",{\"2\":{\"278\":1}}],[\"这里放一个sync版本的store\",{\"2\":{\"273\":1}}],[\"这里简单追踪一下张量shape的变化便于理解\",{\"2\":{\"270\":1}}],[\"这里clamp\",{\"2\":{\"267\":1}}],[\"这里和之前算子不同的是\",{\"2\":{\"267\":1}}],[\"这里不大懂\",{\"2\":{\"266\":1}}],[\"这里就是属于deepep的部分了\",{\"2\":{\"263\":1}}],[\"这里就不过多赘述\",{\"2\":{\"87\":1}}],[\"这里大部分的操作均为异步\",{\"2\":{\"263\":1}}],[\"这里上文中也提到\",{\"2\":{\"263\":1}}],[\"这里使用了cp\",{\"2\":{\"269\":1}}],[\"这里使用tanh作为激活函数\",{\"2\":{\"255\":1}}],[\"这里使用nn包中的卷积层\",{\"2\":{\"130\":1}}],[\"这里需要区分是否使用tma\",{\"2\":{\"273\":1}}],[\"这里需要区分bar\",{\"2\":{\"260\":1}}],[\"这里需要注意kphasebit\",{\"2\":{\"260\":1}}],[\"这里需要重点讲解一下为什么会有一个for循环\",{\"2\":{\"255\":1}}],[\"这里需要recv一个tensor\",{\"2\":{\"252\":1}}],[\"这里同样需要recv一个tensor\",{\"2\":{\"252\":1}}],[\"这里着重分析参数\",{\"2\":{\"246\":1}}],[\"这里我本人是使用mac本地训练\",{\"2\":{\"255\":1}}],[\"这里我认为可以将二维的神经网络堆叠成三维\",{\"2\":{\"230\":1}}],[\"这里我们介绍一种encoder\",{\"2\":{\"283\":1}}],[\"这里我们初始化为全0张量\",{\"2\":{\"255\":1}}],[\"这里我们其实有一个名为困惑度的量\",{\"2\":{\"249\":1}}],[\"这里我们可以使用信息论\",{\"2\":{\"249\":1}}],[\"这里我们可以构建一个词表\",{\"2\":{\"117\":1}}],[\"这里我们在gpu上训练\",{\"2\":{\"247\":1}}],[\"这里我们就介绍汇聚层\",{\"2\":{\"216\":1}}],[\"这里我们就得到了\",{\"2\":{\"151\":1}}],[\"这里我们讨论train的pp\",{\"2\":{\"213\":1}}],[\"这里我们假定当前的虚拟环境叫dev\",{\"2\":{\"169\":1}}],[\"这里我们假设xxx是一个二维向量\",{\"2\":{\"88\":1}}],[\"这里我们并不知道container中的类型是什么\",{\"2\":{\"150\":1}}],[\"这里我们处理数据简单分为以下步骤\",{\"2\":{\"117\":1}}],[\"这里是直接设置3\",{\"2\":{\"229\":1}}],[\"这里\",{\"2\":{\"217\":1,\"279\":1}}],[\"这里其实有一个点要注意一下\",{\"2\":{\"213\":1}}],[\"这里input\",{\"2\":{\"213\":1}}],[\"这里选择先使用triton来示范如何写一个当前业界较为先进的一版gemm\",{\"2\":{\"197\":1}}],[\"这里先放一个链接\",{\"2\":{\"175\":1}}],[\"这里直接对\",{\"2\":{\"166\":1}}],[\"这里直接将图片展平\",{\"2\":{\"152\":1}}],[\"这里介绍两种对序列进行分割的方法\",{\"2\":{\"162\":1}}],[\"这里介绍一种损失函数\",{\"2\":{\"137\":1}}],[\"这里介绍一种比较简单的例子\",{\"2\":{\"51\":1}}],[\"这里研究decode\",{\"2\":{\"158\":1}}],[\"这里num\",{\"2\":{\"152\":1}}],[\"这里相当于\",{\"2\":{\"144\":1}}],[\"这里也解释了我们为什么通常将kernel的长宽均设置为奇数\",{\"2\":{\"144\":1}}],[\"这里允许我们实现自己的\",{\"2\":{\"140\":1}}],[\"这里补充一些会创建节点的操作\",{\"2\":{\"140\":1}}],[\"这里要区分右值引用和通用引用\",{\"2\":{\"119\":1}}],[\"这里要区分值类型type和值类别value\",{\"2\":{\"119\":1}}],[\"这里有三条准则\",{\"2\":{\"119\":1}}],[\"这里首先定义输入小批量样本\",{\"2\":{\"230\":1}}],[\"这里首先计算\",{\"2\":{\"166\":1}}],[\"这里首先为了简化之后的训练\",{\"2\":{\"117\":1}}],[\"这里首先引入一个torch的简便操作\",{\"2\":{\"59\":1}}],[\"这里只实现这两种简单的词元分割\",{\"2\":{\"117\":1}}],[\"这里仍然使用d2l的库\",{\"2\":{\"117\":1}}],[\"这里类比vector就可以理解\",{\"2\":{\"112\":1}}],[\"这里采用均方损失\",{\"2\":{\"103\":1}}],[\"这里采取小批量随机梯度下降\",{\"2\":{\"88\":1}}],[\"这里如果尝试使用全连接来拟合数据\",{\"2\":{\"103\":1}}],[\"这里可以参考deep\",{\"2\":{\"197\":1}}],[\"这里可以发现\",{\"2\":{\"137\":1}}],[\"这里可以使用pytorch的批量矩阵乘法\",{\"2\":{\"97\":1}}],[\"这里可以找到\",{\"2\":{\"58\":1}}],[\"这里假设我有一张禽类图片\",{\"2\":{\"95\":1}}],[\"这里变成了squared\",{\"2\":{\"88\":1}}],[\"这里会通过广播机制扩散\",{\"2\":{\"88\":1}}],[\"这里的激活不包含模型参数和优化器状态\",{\"2\":{\"272\":1}}],[\"这里的激活\",{\"2\":{\"272\":1}}],[\"这里的目的就是转换输出形态\",{\"2\":{\"255\":1}}],[\"这里的通信与计算的overlap是这样做的\",{\"2\":{\"252\":1}}],[\"这里的y\",{\"2\":{\"152\":1}}],[\"这里的tokens是1d列表或2d列表\",{\"2\":{\"117\":1}}],[\"这里的问题主要是const\",{\"2\":{\"104\":1}}],[\"这里的缩进\",{\"2\":{\"79\":1}}],[\"这里的\",{\"2\":{\"71\":1}}],[\"这个隐状态就是encoder出来的固定状态\",{\"2\":{\"283\":1}}],[\"这个范式trick了一下\",{\"2\":{\"282\":1}}],[\"这个kittens中放到了warpgroup下\",{\"2\":{\"282\":1}}],[\"这个bar会帮我们做好同步的事情\",{\"2\":{\"279\":1}}],[\"这个对应的0其实是值域的中点\",{\"2\":{\"251\":1}}],[\"这个输出的每个元素可能依赖于输入的不同部分\",{\"2\":{\"180\":1}}],[\"这个里面包含了lib和nvcc编译器\",{\"2\":{\"169\":1}}],[\"这个参数指定了张量\",{\"2\":{\"166\":1}}],[\"这个点上\",{\"2\":{\"151\":1}}],[\"这个公式有一个前提\",{\"2\":{\"145\":1}}],[\"这个就是步幅\",{\"2\":{\"144\":1}}],[\"这个函数比较关键\",{\"2\":{\"279\":1}}],[\"这个函数可以实现一个需求\",{\"2\":{\"140\":1}}],[\"这个函数会返回词元索引列表\",{\"2\":{\"117\":1}}],[\"这个类型可以隐式地转化为指向任何内置类型的指针\",{\"2\":{\"125\":1}}],[\"这个单元可以是字符单元\",{\"2\":{\"117\":1}}],[\"这个不会被高亮显示\",{\"2\":{\"100\":2}}],[\"这个时候output就是我们要的答案结果\",{\"2\":{\"283\":1}}],[\"这个时候传入decoder的rnn网络\",{\"2\":{\"283\":1}}],[\"这个时候通常采用激活重计算技术来减少中间激活\",{\"2\":{\"275\":1}}],[\"这个时候可以使用epoll来完成异步接受\",{\"2\":{\"256\":1}}],[\"这个时候micro\",{\"2\":{\"252\":1}}],[\"这个时候bubble为\",{\"2\":{\"252\":1}}],[\"这个时候一般如何写并行代码呢\",{\"2\":{\"250\":1}}],[\"这个时候一个卷积核一般只能提取一个特性\",{\"2\":{\"82\":1}}],[\"这个时候\",{\"2\":{\"222\":1}}],[\"这个时候epoll应运而生\",{\"2\":{\"219\":1}}],[\"这个时候对于单个进程来说\",{\"2\":{\"219\":1}}],[\"这个时候下一个线程就可以获得锁然后去占用cpu\",{\"2\":{\"177\":1}}],[\"这个时候互相关运算的计算策略为\",{\"2\":{\"174\":1}}],[\"这个时候有一个比较好用的方法\",{\"2\":{\"154\":1}}],[\"这个时候我们就需要梯度裁剪来稳定地训练\",{\"2\":{\"266\":1}}],[\"这个时候我们就需要使用decltype\",{\"2\":{\"150\":1}}],[\"这个时候我们必须得去sync一下\",{\"2\":{\"263\":1}}],[\"这个时候我们c\",{\"2\":{\"150\":1}}],[\"这个时候我们的图像大小进一步缩小\",{\"2\":{\"144\":1}}],[\"这个时候我们通常使用\",{\"2\":{\"95\":1}}],[\"这个时候会发生类型转换\",{\"2\":{\"112\":1}}],[\"这个特性可以帮助我们限制\",{\"2\":{\"71\":1}}],[\"这个特性和其他大部分的\",{\"2\":{\"40\":1}}],[\"这个权重将分配给每一个值\",{\"2\":{\"51\":1}}],[\"这一阶段我们会进行通信与计算的overlap\",{\"2\":{\"263\":1}}],[\"这一特点并没有被我们所利用\",{\"2\":{\"52\":1}}],[\"这一章主要是讲一些现代设计的卷积神经网络模型以及一些技术\",{\"2\":{\"46\":1}}],[\"这一节我们将学习卷积神经网络\",{\"2\":{\"35\":1}}],[\"这确实需要花比较多功夫来插入\",{\"2\":{\"40\":1}}],[\"这句话其实暗示了\",{\"2\":{\"40\":1}}],[\"这项特性让你可以很容易地用\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"这允许将标题链接为\",{\"2\":{\"18\":1}}],[\"这些变量\",{\"2\":{\"278\":1}}],[\"这些操作分别称为最大汇聚层\",{\"2\":{\"229\":1}}],[\"这些操作不会影响模型的梯度和参数更新\",{\"2\":{\"88\":1}}],[\"这些超参数直接影响着kernel的吞吐\",{\"2\":{\"197\":1}}],[\"这些知识的不同来源于相同的查询\",{\"2\":{\"173\":1}}],[\"这些都包含在targets\",{\"2\":{\"169\":1}}],[\"这些概率本质上就是语言模型的参数\",{\"2\":{\"131\":1}}],[\"这些值累加为1\",{\"2\":{\"108\":1}}],[\"这些衍生版本要么基于工具\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"这些功能原初的\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"请勿继续\",{\"2\":{\"100\":2}}],[\"请向标题添加后缀\",{\"2\":{\"18\":1}}],[\"请注意两边需要有空格\",{\"2\":{\"142\":1}}],[\"请注意\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1,\"92\":1,\"113\":1,\"247\":1}}],[\"要求枚举已定义\",{\"2\":{\"154\":1}}],[\"要一一对应\",{\"2\":{\"140\":1}}],[\"要用预设链接标签只要在链接文字后面加上一个空的方括号\",{\"2\":{\"113\":1}}],[\"要建立一个行内形式的链接\",{\"2\":{\"113\":1}}],[\"要在纯文字应用中设计一个\",{\"2\":{\"156\":1}}],[\"要在\",{\"2\":{\"79\":1}}],[\"要避免这样的状况\",{\"2\":{\"68\":1}}],[\"要让列表看起来更漂亮\",{\"2\":{\"68\":1}}],[\"要为标题指定自定义锚点而不是使用自动生成的锚点\",{\"2\":{\"18\":1}}],[\"要么基于网站\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"块引言可以有阶层\",{\"2\":{\"57\":1}}],[\"块引言\",{\"2\":{\"40\":1}}],[\"块元素\",{\"0\":{\"31\":1},\"1\":{\"40\":1,\"49\":1,\"57\":1,\"68\":1,\"79\":1,\"89\":1}}],[\"块内使用\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"块标签中将不会被进行处理\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"xo\",{\"2\":{\"278\":2}}],[\"xout\",{\"2\":{\"278\":4}}],[\"xout​w1​\",{\"2\":{\"259\":1}}],[\"xout​=softmax\",{\"2\":{\"259\":1}}],[\"xoutw1\",{\"2\":{\"259\":1}}],[\"xout=softmax\",{\"2\":{\"259\":1}}],[\"xq\",{\"2\":{\"278\":5}}],[\"xv\",{\"2\":{\"278\":8}}],[\"xk\",{\"2\":{\"278\":10}}],[\"xh\",{\"2\":{\"255\":4}}],[\"xa2​\",{\"2\":{\"222\":1}}],[\"xa2\",{\"2\":{\"222\":1}}],[\"xa1​\",{\"2\":{\"222\":1}}],[\"xa1\",{\"2\":{\"222\":1}}],[\"xa\",{\"2\":{\"222\":5}}],[\"xavier\",{\"2\":{\"103\":1,\"247\":1,\"285\":4}}],[\"x+p\",{\"2\":{\"202\":2}}],[\"x+c\",{\"2\":{\"108\":2}}],[\"x∈rn⋅d\",{\"2\":{\"230\":1}}],[\"x∈rn⋅dx\",{\"2\":{\"230\":1}}],[\"x∈rn∗dx\",{\"2\":{\"283\":1}}],[\"x∈rn∗d\",{\"2\":{\"202\":2,\"283\":1}}],[\"x∈rd\",{\"2\":{\"87\":2}}],[\"x70\",{\"2\":{\"199\":2}}],[\"x72\",{\"2\":{\"199\":2}}],[\"x74\",{\"2\":{\"199\":1}}],[\"x65\",{\"2\":{\"199\":2}}],[\"x64\",{\"2\":{\"199\":4}}],[\"x6f\",{\"2\":{\"199\":1}}],[\"x6c\",{\"2\":{\"199\":3}}],[\"x61\",{\"2\":{\"199\":5}}],[\"x6d\",{\"2\":{\"199\":1}}],[\"xs\",{\"2\":{\"188\":5}}],[\"x86\",{\"2\":{\"169\":2}}],[\"xcuda来让clang知道这是cuda代码\",{\"2\":{\"169\":1}}],[\"xcuda\",{\"2\":{\"169\":1}}],[\"x以及auto\",{\"2\":{\"119\":1}}],[\"xnx\",{\"2\":{\"186\":1}}],[\"xn​\",{\"2\":{\"108\":1,\"186\":3}}],[\"xn\",{\"2\":{\"108\":1,\"186\":2}}],[\"x=fgelu​\",{\"2\":{\"259\":1}}],[\"x=fgelu\",{\"2\":{\"259\":1}}],[\"x=\",{\"2\":{\"108\":1,\"222\":2}}],[\"xenium\",{\"2\":{\"106\":1}}],[\"xtwdh+ht−1whh+bh\",{\"2\":{\"230\":1}}],[\"xt∣ht−1\",{\"2\":{\"217\":1}}],[\"xt∣xt−1\",{\"2\":{\"103\":4,\"131\":1,\"217\":1,\"249\":2}}],[\"xt+1​∣xt​\",{\"2\":{\"103\":2}}],[\"xt+1​∣xt−1​\",{\"2\":{\"103\":2}}],[\"xt+1​\",{\"2\":{\"103\":1}}],[\"xt+1∣xt\",{\"2\":{\"103\":2}}],[\"xt+1∣xt−1\",{\"2\":{\"103\":2}}],[\"xt+1\",{\"2\":{\"103\":1}}],[\"xt\",{\"2\":{\"103\":4,\"131\":1,\"217\":1}}],[\"xt−1​\",{\"2\":{\"103\":6}}],[\"xt−1\",{\"2\":{\"103\":6}}],[\"xt​wdh​+ht−1​whh​+bh​\",{\"2\":{\"230\":1}}],[\"xt​∣ht−1​\",{\"2\":{\"217\":1}}],[\"xt​∣xt−1​\",{\"2\":{\"103\":4,\"131\":1,\"217\":1,\"249\":2}}],[\"xt​\",{\"2\":{\"103\":4,\"131\":1,\"217\":1}}],[\"xt​∼p\",{\"2\":{\"103\":1}}],[\"xt∼p\",{\"2\":{\"103\":1}}],[\"xtx\",{\"2\":{\"103\":3,\"217\":1,\"249\":1,\"255\":1}}],[\"x4​\",{\"2\":{\"95\":1}}],[\"x4\",{\"2\":{\"95\":1,\"135\":2,\"254\":2}}],[\"x3x\",{\"2\":{\"151\":1}}],[\"x3​\",{\"2\":{\"95\":1,\"151\":2}}],[\"x3\",{\"2\":{\"95\":1,\"135\":2,\"151\":1}}],[\"x3c\",{\"2\":{\"17\":6,\"24\":1,\"28\":6,\"29\":6,\"33\":6,\"36\":1,\"37\":1,\"42\":1,\"68\":24,\"79\":18,\"100\":9,\"112\":1,\"113\":16,\"114\":3,\"117\":2,\"118\":8,\"119\":1,\"122\":5,\"127\":8,\"135\":5,\"139\":12,\"141\":27,\"150\":7,\"154\":17,\"185\":2,\"199\":6,\"203\":1,\"254\":5,\"260\":1,\"269\":27,\"273\":28,\"279\":3,\"282\":2,\"285\":2}}],[\"xwdh​+bh​\",{\"2\":{\"230\":1}}],[\"xwdh+bh\",{\"2\":{\"230\":1}}],[\"xw\",{\"2\":{\"88\":1,\"230\":1,\"259\":3}}],[\"x1a1+x2a2\",{\"2\":{\"222\":1}}],[\"x1=4x\",{\"2\":{\"151\":1}}],[\"x1∣x0\",{\"2\":{\"103\":1}}],[\"x1−xt−1x\",{\"2\":{\"103\":1}}],[\"x1x\",{\"2\":{\"88\":1,\"151\":2}}],[\"x1​a1​+x2​a2​\",{\"2\":{\"222\":1}}],[\"x1​∣x0​\",{\"2\":{\"103\":1}}],[\"x1​−xt−1​\",{\"2\":{\"103\":1}}],[\"x1​\",{\"2\":{\"78\":4,\"95\":1,\"103\":5,\"108\":1,\"131\":2,\"151\":1,\"186\":2,\"217\":1,\"222\":1,\"249\":2}}],[\"x1\",{\"2\":{\"78\":4,\"95\":1,\"103\":5,\"108\":1,\"131\":2,\"135\":2,\"151\":1,\"186\":3,\"217\":1,\"222\":1,\"249\":2}}],[\"x0x\",{\"2\":{\"151\":3}}],[\"x0=0x\",{\"2\":{\"151\":1}}],[\"x0=\",{\"2\":{\"151\":1,\"166\":1}}],[\"x02​+x12​+x22​+x32​\",{\"2\":{\"151\":1}}],[\"x02+x12+x22+x32\",{\"2\":{\"151\":1}}],[\"x0​=\",{\"2\":{\"166\":1}}],[\"x0​=​0\",{\"2\":{\"151\":1}}],[\"x0​\",{\"2\":{\"78\":4,\"151\":1}}],[\"x0\",{\"2\":{\"78\":4,\"151\":9}}],[\"xj​\",{\"2\":{\"108\":1}}],[\"xj​=xj−1​−α∇f\",{\"2\":{\"78\":1}}],[\"xjp\",{\"2\":{\"108\":1}}],[\"xj−1​\",{\"2\":{\"78\":1}}],[\"xj−1\",{\"2\":{\"78\":1}}],[\"xj=xj−1−α∇f\",{\"2\":{\"78\":1}}],[\"xlim=\",{\"2\":{\"59\":1,\"247\":1,\"270\":1,\"285\":1}}],[\"xlabel=\",{\"2\":{\"59\":1,\"247\":1,\"270\":1,\"285\":1}}],[\"xxx\",{\"2\":{\"51\":2,\"71\":2,\"82\":1,\"92\":2,\"144\":1,\"151\":4,\"163\":1,\"166\":1,\"169\":1,\"205\":1,\"222\":2,\"229\":1,\"265\":2,\"272\":2,\"280\":1,\"283\":2}}],[\"x−xj​\",{\"2\":{\"51\":2,\"59\":1}}],[\"x−xj\",{\"2\":{\"51\":2,\"59\":1}}],[\"x−xi​\",{\"2\":{\"51\":3,\"59\":2}}],[\"x−xi\",{\"2\":{\"51\":3,\"59\":2}}],[\"x^\",{\"2\":{\"278\":17}}],[\"x^i\",{\"2\":{\"48\":1}}],[\"x^2f\",{\"2\":{\"78\":1}}],[\"x^2\",{\"2\":{\"38\":1}}],[\"xil​\",{\"2\":{\"278\":1}}],[\"xil\",{\"2\":{\"278\":1}}],[\"xint​\",{\"2\":{\"271\":1}}],[\"xint​−zx​\",{\"2\":{\"271\":1}}],[\"xintx\",{\"2\":{\"271\":1}}],[\"xint−zx\",{\"2\":{\"271\":1}}],[\"xinshuowang\",{\"2\":{\"15\":1}}],[\"xi∈rdx\",{\"2\":{\"186\":1}}],[\"xix\",{\"2\":{\"51\":1,\"151\":1}}],[\"xi​∈rd\",{\"2\":{\"186\":1}}],[\"xi​\",{\"2\":{\"51\":3,\"59\":1,\"186\":1}}],[\"xi\",{\"2\":{\"48\":2,\"51\":3,\"59\":1,\"143\":2,\"186\":1}}],[\"x较大时\",{\"2\":{\"38\":1}}],[\"x2e\",{\"2\":{\"199\":2}}],[\"x2​\",{\"2\":{\"95\":1,\"103\":1,\"108\":1,\"131\":1,\"151\":1,\"186\":1,\"222\":1}}],[\"x27\",{\"2\":{\"78\":1,\"88\":1,\"115\":6,\"283\":1}}],[\"x2\",{\"2\":{\"38\":2,\"95\":1,\"103\":1,\"108\":1,\"131\":1,\"135\":2,\"151\":2,\"186\":1,\"222\":1}}],[\"x26\",{\"2\":{\"24\":5,\"36\":5,\"37\":5,\"42\":5,\"79\":6,\"104\":1,\"118\":1,\"119\":4,\"122\":19,\"135\":17,\"141\":6,\"150\":13,\"167\":1,\"193\":1,\"199\":41,\"254\":28,\"269\":16,\"273\":13,\"279\":2}}],[\"x\",{\"2\":{\"38\":6,\"48\":3,\"51\":36,\"59\":18,\"61\":10,\"70\":7,\"71\":12,\"78\":22,\"82\":9,\"86\":9,\"87\":4,\"88\":12,\"95\":5,\"96\":17,\"97\":7,\"103\":45,\"108\":15,\"110\":2,\"112\":4,\"115\":8,\"117\":2,\"122\":5,\"123\":32,\"124\":3,\"128\":2,\"130\":12,\"131\":6,\"135\":4,\"137\":17,\"138\":10,\"140\":21,\"144\":10,\"150\":8,\"151\":37,\"152\":16,\"153\":14,\"166\":10,\"173\":20,\"174\":6,\"176\":2,\"178\":4,\"186\":7,\"187\":3,\"188\":2,\"191\":8,\"193\":36,\"200\":1,\"202\":11,\"203\":8,\"205\":4,\"207\":2,\"217\":5,\"220\":7,\"222\":5,\"229\":23,\"230\":1,\"232\":3,\"247\":15,\"249\":6,\"255\":9,\"259\":3,\"267\":9,\"269\":4,\"270\":4,\"271\":13,\"273\":3,\"277\":4,\"278\":13,\"280\":6,\"283\":22,\"285\":10}}],[\"i+1\",{\"2\":{\"278\":6}}],[\"i+1i+1i+1\",{\"2\":{\"266\":1}}],[\"i++\",{\"2\":{\"269\":1,\"273\":1}}],[\"i+a\",{\"2\":{\"71\":6,\"82\":6}}],[\"i100002jd\",{\"2\":{\"202\":2}}],[\"ici​\",{\"2\":{\"174\":2}}],[\"i$\",{\"2\":{\"169\":1}}],[\"ihi​\",{\"2\":{\"159\":1}}],[\"ignore\",{\"2\":{\"153\":2,\"193\":2}}],[\"i4xi​\",{\"2\":{\"151\":1}}],[\"iii\",{\"2\":{\"145\":1,\"255\":2,\"266\":1,\"278\":3}}],[\"io密集型任务会使得当前线程释放锁\",{\"2\":{\"177\":1}}],[\"io密集型任务\",{\"2\":{\"133\":2}}],[\"i≠j\",{\"2\":{\"123\":1}}],[\"i≠ji\",{\"2\":{\"123\":1}}],[\"ipython\",{\"2\":{\"152\":1}}],[\"ip\",{\"2\":{\"123\":1}}],[\"ipsum\",{\"2\":{\"57\":4,\"68\":7,\"100\":2}}],[\"il\",{\"2\":{\"112\":1}}],[\"it\",{\"2\":{\"110\":1,\"124\":1,\"138\":1,\"153\":1,\"193\":4,\"263\":1}}],[\"iter=false\",{\"2\":{\"270\":1}}],[\"iter中\",{\"2\":{\"255\":1}}],[\"iterator\",{\"2\":{\"117\":1,\"176\":1,\"188\":1}}],[\"iter\",{\"2\":{\"63\":4,\"88\":4,\"103\":5,\"152\":4,\"176\":1,\"188\":9,\"247\":10,\"255\":1,\"270\":7,\"285\":2}}],[\"items\",{\"2\":{\"117\":1}}],[\"item\",{\"2\":{\"57\":2,\"68\":6,\"181\":1,\"193\":1}}],[\"i​=∑j=1n​exj​exi​​\",{\"2\":{\"108\":1}}],[\"i=j−pipj\",{\"2\":{\"123\":1}}],[\"i=ji\",{\"2\":{\"123\":1}}],[\"i=exi∑j=1nexjp\",{\"2\":{\"108\":1}}],[\"i=1\",{\"2\":{\"48\":1,\"51\":5,\"59\":3,\"70\":1,\"159\":2}}],[\"i^2yi​=2xi2​\",{\"2\":{\"166\":1}}],[\"i^2\",{\"2\":{\"123\":3}}],[\"i^\",{\"2\":{\"88\":1,\"123\":1,\"145\":1,\"159\":6}}],[\"iki​\",{\"2\":{\"70\":1}}],[\"if\",{\"2\":{\"61\":1,\"70\":2,\"96\":4,\"97\":2,\"103\":1,\"117\":9,\"130\":1,\"150\":1,\"152\":2,\"173\":1,\"181\":1,\"188\":1,\"193\":3,\"229\":1,\"247\":5,\"255\":1,\"266\":3,\"269\":4,\"270\":5,\"273\":5,\"277\":2,\"279\":4,\"282\":4,\"285\":4}}],[\"image\",{\"2\":{\"156\":1}}],[\"images\",{\"2\":{\"24\":4,\"36\":4,\"37\":4,\"42\":4}}],[\"img\",{\"2\":{\"156\":3}}],[\"importantly\",{\"2\":{\"263\":1}}],[\"important\",{\"2\":{\"100\":2}}],[\"import\",{\"2\":{\"61\":2,\"88\":5,\"100\":4,\"117\":8,\"151\":1,\"152\":3,\"193\":6}}],[\"id为0\",{\"2\":{\"252\":1}}],[\"ids\",{\"2\":{\"213\":2}}],[\"id=\",{\"2\":{\"185\":1}}],[\"ide这里使用的是vscode\",{\"2\":{\"169\":1}}],[\"idx\",{\"2\":{\"117\":13,\"152\":2,\"261\":1,\"269\":12,\"273\":9}}],[\"id\",{\"2\":{\"57\":2,\"68\":3,\"100\":2,\"113\":5,\"156\":3,\"197\":2,\"260\":5,\"282\":13}}],[\"inval\",{\"2\":{\"260\":1}}],[\"invalidate\",{\"2\":{\"260\":1}}],[\"include之中\",{\"2\":{\"169\":1}}],[\"include\",{\"2\":{\"169\":6,\"248\":1,\"265\":1}}],[\"inception\",{\"2\":{\"86\":11}}],[\"instr\",{\"2\":{\"273\":2}}],[\"instructions\",{\"2\":{\"273\":2}}],[\"instruction\",{\"2\":{\"254\":1}}],[\"insertion=never\",{\"2\":{\"169\":1}}],[\"inside\",{\"2\":{\"68\":1}}],[\"ini​\",{\"2\":{\"145\":1}}],[\"initiates\",{\"2\":{\"265\":3}}],[\"initiated\",{\"2\":{\"260\":1}}],[\"initial\",{\"2\":{\"135\":2,\"176\":7}}],[\"initializer\",{\"2\":{\"112\":2,\"135\":4}}],[\"initialize\",{\"2\":{\"97\":1,\"193\":1,\"213\":2}}],[\"init\",{\"2\":{\"59\":2,\"61\":4,\"81\":2,\"86\":4,\"91\":2,\"96\":2,\"97\":2,\"103\":3,\"110\":2,\"115\":5,\"117\":1,\"124\":2,\"126\":2,\"130\":2,\"135\":1,\"138\":2,\"152\":1,\"153\":2,\"167\":2,\"173\":2,\"188\":1,\"193\":12,\"202\":2,\"213\":1,\"247\":3,\"255\":7,\"260\":2,\"277\":2,\"280\":8,\"282\":2,\"283\":6,\"285\":4}}],[\"inject\",{\"2\":{\"124\":1,\"193\":1}}],[\"inline\",{\"2\":{\"113\":2,\"228\":1,\"254\":10,\"269\":3,\"273\":3,\"279\":4,\"282\":1}}],[\"inputs\",{\"2\":{\"152\":4,\"255\":4,\"277\":2}}],[\"input返回出去\",{\"2\":{\"140\":1}}],[\"input\",{\"2\":{\"97\":4,\"124\":1,\"126\":2,\"138\":1,\"140\":4,\"153\":2,\"193\":8,\"213\":4,\"261\":3,\"282\":5,\"285\":2}}],[\"information\",{\"2\":{\"113\":1,\"124\":1,\"193\":1}}],[\"info\",{\"2\":{\"90\":3}}],[\"infra的学习笔记\",{\"2\":{\"0\":1}}],[\"index>\",{\"2\":{\"150\":5}}],[\"index\",{\"2\":{\"117\":2,\"150\":5,\"169\":1,\"273\":2}}],[\"indent\",{\"2\":{\"68\":1}}],[\"indices包含子序列的随机起始索引\",{\"2\":{\"176\":1}}],[\"indices\",{\"2\":{\"88\":6,\"117\":4,\"176\":6}}],[\"in=512\",{\"2\":{\"61\":1}}],[\"int4\",{\"2\":{\"269\":1,\"273\":1}}],[\"int8\",{\"2\":{\"251\":1,\"262\":1}}],[\"int8量化压缩\",{\"2\":{\"66\":1}}],[\"interpreter\",{\"2\":{\"163\":1}}],[\"interleaved调度\",{\"2\":{\"263\":1}}],[\"interleaved版本的1f1b调度中\",{\"2\":{\"252\":1}}],[\"interleaved以及interleaved两种调度策略\",{\"2\":{\"252\":1}}],[\"interleaved\",{\"0\":{\"252\":1},\"2\":{\"213\":1,\"235\":1}}],[\"interleave\",{\"2\":{\"59\":1,\"70\":1,\"173\":1}}],[\"introduced\",{\"2\":{\"263\":1}}],[\"introduce\",{\"2\":{\"143\":2}}],[\"int>\",{\"2\":{\"135\":2,\"150\":1}}],[\"int\",{\"2\":{\"63\":4,\"75\":5,\"104\":6,\"112\":10,\"118\":8,\"122\":30,\"130\":2,\"135\":14,\"150\":7,\"176\":3,\"188\":3,\"205\":4,\"213\":2,\"229\":2,\"255\":6,\"260\":4,\"261\":1,\"269\":12,\"271\":7,\"273\":13,\"279\":2,\"282\":2}}],[\"into\",{\"2\":{\"61\":1,\"97\":2,\"138\":1,\"153\":1,\"193\":4,\"273\":1}}],[\"in\",{\"2\":{\"57\":2,\"59\":1,\"61\":9,\"63\":9,\"68\":5,\"70\":3,\"75\":2,\"81\":6,\"86\":10,\"87\":2,\"88\":6,\"91\":4,\"96\":1,\"100\":2,\"103\":3,\"108\":2,\"110\":1,\"115\":1,\"117\":13,\"124\":1,\"130\":4,\"138\":1,\"141\":4,\"144\":1,\"152\":4,\"159\":9,\"167\":4,\"174\":3,\"176\":3,\"181\":1,\"186\":2,\"187\":4,\"188\":1,\"193\":8,\"197\":8,\"202\":2,\"203\":3,\"229\":2,\"230\":2,\"247\":4,\"255\":2,\"259\":3,\"260\":1,\"261\":3,\"266\":3,\"270\":3,\"273\":3,\"278\":1,\"282\":1,\"283\":1,\"285\":5}}],[\"ixi​\",{\"2\":{\"51\":1,\"151\":1}}],[\"iyi​\",{\"2\":{\"51\":3}}],[\"i\",{\"2\":{\"51\":12,\"59\":6,\"70\":5,\"71\":31,\"82\":12,\"88\":5,\"103\":4,\"104\":6,\"108\":5,\"112\":4,\"113\":4,\"117\":2,\"118\":6,\"123\":27,\"130\":7,\"137\":3,\"144\":6,\"145\":3,\"150\":15,\"159\":2,\"166\":6,\"169\":5,\"174\":3,\"176\":3,\"186\":3,\"187\":3,\"188\":5,\"199\":1,\"202\":4,\"203\":3,\"228\":1,\"229\":22,\"247\":4,\"248\":1,\"260\":2,\"261\":2,\"269\":3,\"273\":3,\"278\":140}}],[\"is∣deep\",{\"2\":{\"131\":2}}],[\"isinstance\",{\"2\":{\"117\":3,\"152\":1,\"247\":2,\"266\":1,\"270\":4,\"277\":1}}],[\"isn\",{\"2\":{\"100\":2}}],[\"is\",{\"2\":{\"17\":2,\"28\":2,\"29\":2,\"33\":2,\"49\":2,\"50\":4,\"57\":7,\"61\":6,\"68\":4,\"70\":1,\"79\":6,\"88\":1,\"90\":12,\"96\":1,\"97\":4,\"100\":2,\"103\":1,\"113\":3,\"117\":2,\"124\":1,\"127\":1,\"128\":4,\"131\":8,\"140\":1,\"141\":4,\"173\":1,\"193\":5,\"255\":1,\"260\":2,\"270\":1}}],[\"标量或者矢量\",{\"2\":{\"173\":1}}],[\"标记一个async操作\",{\"2\":{\"265\":1}}],[\"标记或达到最大长度\",{\"2\":{\"143\":1}}],[\"标记或之前生成的词\",{\"2\":{\"143\":1}}],[\"标记\",{\"0\":{\"142\":1}}],[\"标记为\",{\"2\":{\"68\":1}}],[\"标准检查所检查到的错误中\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"标签包围\",{\"2\":{\"127\":1}}],[\"标签包起来\",{\"2\":{\"68\":1}}],[\"标签比文字还要多\",{\"2\":{\"113\":1}}],[\"标签来把代码块包起来\",{\"2\":{\"79\":1}}],[\"标签的话\",{\"2\":{\"40\":1}}],[\"标签使用\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"标签\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1,\"40\":1,\"156\":1,\"214\":1}}],[\"标题和内容来定义\",{\"2\":{\"80\":1}}],[\"标题能显示出文章的结构\",{\"2\":{\"49\":1}}],[\"标题\",{\"0\":{\"49\":1}}],[\"标题会自动应用锚点\",{\"2\":{\"11\":1}}],[\"标题锚点自定义锚点链接内部链接github风格的表格emoji\",{\"2\":{\"69\":1}}],[\"标题锚点\",{\"0\":{\"11\":1},\"1\":{\"18\":1}}],[\"可减少空间维度\",{\"2\":{\"239\":1}}],[\"可见\",{\"2\":{\"205\":1}}],[\"可见对于一维因变量来说\",{\"2\":{\"78\":1}}],[\"可能在没有划分virtual\",{\"2\":{\"252\":1}}],[\"可能是有益的\",{\"2\":{\"159\":1}}],[\"可能效果会更好\",{\"2\":{\"93\":1}}],[\"可能更像是一个\",{\"2\":{\"2\":1}}],[\"可以合理利用所有的thread\",{\"2\":{\"269\":1}}],[\"可以估计所需要的训练时间\",{\"2\":{\"268\":1}}],[\"可以设置expect\",{\"2\":{\"260\":1,\"265\":1}}],[\"可以设置tma想要load的bytes\",{\"2\":{\"260\":1}}],[\"可以直接使用01交替\",{\"2\":{\"260\":1}}],[\"可以直接使用数组方式创建\",{\"2\":{\"178\":1}}],[\"可以指定当前arrive了多少次\",{\"2\":{\"260\":1}}],[\"可以指定容器的初始元素\",{\"2\":{\"112\":1}}],[\"可以作用到一个比较小的vector上\",{\"2\":{\"257\":1}}],[\"可以忽略\",{\"2\":{\"253\":1}}],[\"可以做到的overlap其实就是在loop的时候\",{\"2\":{\"252\":1}}],[\"可以做到io任务的让渡\",{\"2\":{\"231\":1}}],[\"可以有效地利用多核\",{\"2\":{\"242\":1}}],[\"可以访问和修改向量的特定部分\",{\"2\":{\"232\":1}}],[\"可以帮助我们在单个进程中快速处理网络请求\",{\"2\":{\"219\":1}}],[\"可以利用反斜线来插入一些在语法中有其它意义的符号\",{\"2\":{\"214\":1}}],[\"可以利用高效的矩阵乘法来计算\",{\"2\":{\"23\":1}}],[\"可以快速异步地搬运数据\",{\"2\":{\"197\":1}}],[\"可以视为对每个元素操作\",{\"2\":{\"191\":1}}],[\"可以视为卷积层的权重weight\",{\"2\":{\"71\":1}}],[\"可以给我们带来更小的开销\",{\"2\":{\"182\":1}}],[\"可以创建一个1\",{\"2\":{\"178\":1}}],[\"可以实现多头注意力的并行计算\",{\"2\":{\"173\":1}}],[\"可以对gemm有一个超级深刻的印象\",{\"2\":{\"170\":1}}],[\"可以在编译期检测出来\",{\"2\":{\"168\":1}}],[\"可以禁止一些模板的实例化\",{\"2\":{\"168\":1}}],[\"可以针对当前标量进行反向传播求梯度\",{\"2\":{\"166\":1}}],[\"可以进行一系列操作\",{\"2\":{\"164\":1}}],[\"可以理解为多维数组\",{\"2\":{\"164\":1}}],[\"可以理解为w2函数declaration\",{\"2\":{\"112\":1}}],[\"可以得知\",{\"2\":{\"260\":1}}],[\"可以得出\",{\"2\":{\"163\":1,\"177\":1}}],[\"可以得到更简洁的实现\",{\"2\":{\"88\":1}}],[\"可以得到以下结果\",{\"2\":{\"51\":1}}],[\"可以被前置声明\",{\"2\":{\"154\":1}}],[\"可以减少命名污染\",{\"2\":{\"154\":1}}],[\"可以正常推导\",{\"2\":{\"135\":1}}],[\"可以绑定到​​左值或右值​​\",{\"2\":{\"119\":1}}],[\"可以让文件更像是浏览器最后产生的结果\",{\"2\":{\"113\":1}}],[\"可以避免\",{\"2\":{\"112\":1}}],[\"可以避免在块标签前后加上没有必要的\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"可以用单引号\",{\"2\":{\"113\":1}}],[\"可以用于为非静态数据成员指定默认初始值\",{\"2\":{\"112\":1}}],[\"可以用来持续加速深层网络的收敛速度\",{\"2\":{\"96\":1}}],[\"可以解决单标签多分类问题\",{\"2\":{\"108\":1}}],[\"可以通过以下途径来预测\",{\"2\":{\"103\":1}}],[\"可以通过在容器的\",{\"2\":{\"100\":1}}],[\"可以像这样对多个代码块进行分组\",{\"2\":{\"100\":1}}],[\"可以使用hopper写出一个超过cublas的gemm\",{\"2\":{\"170\":1}}],[\"可以使用数据来训练我们的权重和偏差\",{\"2\":{\"130\":1}}],[\"可以使用\",{\"2\":{\"100\":1,\"112\":1}}],[\"可以使用加性注意力作为评分函数\",{\"2\":{\"81\":1}}],[\"可以找到\",{\"2\":{\"100\":1}}],[\"可以按照batch\",{\"2\":{\"88\":1}}],[\"可以更有效地利用硬件资源\",{\"2\":{\"88\":1}}],[\"可以发现会出现多个参数矩阵连乘的现象\",{\"2\":{\"266\":1}}],[\"可以发现在量化中\",{\"2\":{\"262\":1}}],[\"可以发现它唯一的计算就在通道上\",{\"2\":{\"203\":1}}],[\"可以发现w其实包含了所有注意力头的子线性空间\",{\"2\":{\"173\":1}}],[\"可以发现最后的输出会变为\",{\"2\":{\"130\":1}}],[\"可以发现\",{\"2\":{\"71\":1,\"264\":1}}],[\"可以知道w∈r784∗10\",{\"2\":{\"152\":1}}],[\"可以知道\",{\"2\":{\"71\":1}}],[\"可以看出来我们last\",{\"2\":{\"263\":1}}],[\"可以看出dualpipev主要有以下的一些关键点\",{\"2\":{\"263\":1}}],[\"可以看出这个fp8e4m3\",{\"2\":{\"254\":1}}],[\"可以看出这个结构很适合parallel并行\",{\"2\":{\"61\":1}}],[\"可以看出这种方式\",{\"2\":{\"222\":1}}],[\"可以看出\",{\"2\":{\"59\":1,\"95\":1,\"108\":1,\"112\":1,\"260\":1,\"263\":1,\"271\":1}}],[\"可以注意到\",{\"2\":{\"52\":1}}],[\"──\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"只考虑激活占用显存的大头\",{\"2\":{\"272\":1}}],[\"只使用一个warp来load或者store数据\",{\"2\":{\"260\":1}}],[\"只保留了计算图信息\",{\"2\":{\"213\":1}}],[\"只是\",{\"2\":{\"199\":1}}],[\"只是创建新视图\",{\"2\":{\"140\":1}}],[\"只能绑定到​​右值​​\",{\"2\":{\"119\":1}}],[\"只能绑定到​​左值​​\",{\"2\":{\"119\":1}}],[\"只有一个线程会执行当前执行到的python字节码\",{\"2\":{\"163\":1}}],[\"只有唯一的标签\",{\"2\":{\"152\":1}}],[\"只有三种\",{\"2\":{\"119\":1}}],[\"只有块元素\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"只读\",{\"2\":{\"118\":1}}],[\"只需要分治做gelu即可\",{\"2\":{\"222\":1}}],[\"只需要执行fwd的过程\",{\"2\":{\"213\":1}}],[\"只需要上下\",{\"2\":{\"144\":1}}],[\"只需要水平和垂直翻转二维卷积核张量\",{\"2\":{\"130\":1}}],[\"只需要依赖于\",{\"2\":{\"103\":1}}],[\"只需要复制粘贴\",{\"2\":{\"79\":1}}],[\"只要是用方括号包起来\",{\"2\":{\"199\":1}}],[\"只要两者不相等\",{\"2\":{\"137\":1}}],[\"只要在网址后面\",{\"2\":{\"113\":1}}],[\"只要在方块括号后面马上接着括号并插入网址链接即可\",{\"2\":{\"113\":1}}],[\"只要我们能够找到一个时间跨度\",{\"2\":{\"103\":1}}],[\"只要简单地缩进\",{\"2\":{\"79\":1}}],[\"只要根据层数加上不同数量的\",{\"2\":{\"57\":1}}],[\"只要直接加标签就可以了\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"撰写\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"涵盖范围之外的标签\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"不断地生成答案\",{\"2\":{\"283\":1}}],[\"不断沿梯度改变θ0\",{\"2\":{\"67\":1}}],[\"不知道是什么用途\",{\"2\":{\"273\":1}}],[\"不仅要考虑前向传递和后向传递的计算时间\",{\"2\":{\"268\":1}}],[\"不仅跟gpu类型有关\",{\"2\":{\"268\":1}}],[\"不难发现\",{\"2\":{\"266\":1}}],[\"不然就会出现内存泄露的情况\",{\"2\":{\"263\":1}}],[\"不然拿不到compute需要的input\",{\"2\":{\"263\":1}}],[\"不论是多进程\",{\"2\":{\"231\":1}}],[\"不论是行内还是块\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"不同于卷积层中的输入与卷积核之间的互相关计算\",{\"2\":{\"229\":1}}],[\"不同os对多进程的支持不同\",{\"2\":{\"190\":1}}],[\"不能让每个part之间产生计算图的依赖\",{\"2\":{\"263\":1}}],[\"不能随意更改传入的参数和返回值的type\",{\"2\":{\"224\":1}}],[\"不能通过该指针来改变对象的属性\",{\"2\":{\"104\":1}}],[\"不管是input\",{\"2\":{\"213\":1}}],[\"不管是哪一种\",{\"2\":{\"113\":1}}],[\"不是del\",{\"2\":{\"213\":1}}],[\"不接受荒谬的隐式类型转换\",{\"2\":{\"154\":1}}],[\"不改变张量数据的操作\",{\"2\":{\"140\":1}}],[\"不会创建节点\",{\"2\":{\"140\":4}}],[\"不涉及梯度的操作\",{\"2\":{\"140\":1}}],[\"不建议\",{\"2\":{\"68\":1}}],[\"不需要占用cpu资源\",{\"2\":{\"133\":1}}],[\"不需要过度在意相隔较远的区域之间的联系\",{\"2\":{\"60\":1}}],[\"不需要额外标注这是\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"不变性\",{\"2\":{\"60\":1,\"108\":1}}],[\"不但更好用\",{\"2\":{\"40\":1}}],[\"不过这部分占用的显存是很小的\",{\"2\":{\"253\":1}}],[\"不过这样也比什么都不做好些\",{\"2\":{\"199\":1}}],[\"不过较少\",{\"2\":{\"55\":1}}],[\"不过需要注意的是\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"不过最需要强调的便是它的可读性\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"不用说也知道这很容易忘记\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"不可以用\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"不在\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"q^\",{\"2\":{\"278\":3}}],[\"q=xwq​\",{\"2\":{\"259\":1}}],[\"q=xwq\",{\"2\":{\"259\":1}}],[\"q=larry+bird\",{\"2\":{\"24\":2,\"36\":2,\"37\":2,\"42\":2}}],[\"qp⋅q\",{\"2\":{\"229\":2}}],[\"q$\",{\"2\":{\"225\":1}}],[\"qktqk^tqkt\",{\"2\":{\"259\":1,\"272\":3}}],[\"qkth\",{\"2\":{\"259\":1}}],[\"qk^t\",{\"2\":{\"259\":1}}],[\"qkv函数的操作\",{\"2\":{\"173\":1}}],[\"qkv\",{\"2\":{\"173\":4}}],[\"qk⊤d\",{\"2\":{\"91\":1}}],[\"q∈rdq​\",{\"2\":{\"159\":1}}],[\"q∈rdq\",{\"2\":{\"159\":1}}],[\"q∈rn∗d\",{\"2\":{\"91\":2}}],[\"q∈rq\",{\"2\":{\"70\":1,\"81\":1}}],[\"qqq\",{\"2\":{\"70\":1,\"230\":1,\"259\":1,\"272\":1}}],[\"quantize\",{\"2\":{\"267\":1}}],[\"quant\",{\"2\":{\"251\":5,\"262\":2}}],[\"queries的形状\",{\"2\":{\"81\":1,\"91\":1}}],[\"queries和attention\",{\"2\":{\"59\":1}}],[\"queries\",{\"2\":{\"59\":4,\"81\":6,\"91\":3,\"173\":5,\"202\":1}}],[\"query的形状为\",{\"2\":{\"115\":1}}],[\"querys被调整为\",{\"2\":{\"59\":1}}],[\"query\",{\"2\":{\"43\":1,\"51\":1,\"81\":4,\"115\":3,\"169\":2,\"173\":2,\"278\":1}}],[\"quoting\",{\"2\":{\"57\":1}}],[\"quot\",{\"2\":{\"2\":2,\"41\":4,\"72\":2,\"100\":2,\"113\":2,\"115\":2,\"118\":2,\"129\":2,\"140\":2,\"143\":4,\"150\":2,\"213\":2,\"248\":2,\"263\":2,\"279\":4}}],[\"q\",{\"0\":{\"16\":1},\"1\":{\"23\":1,\"30\":1,\"38\":1,\"47\":1,\"55\":1,\"66\":1},\"2\":{\"70\":19,\"81\":10,\"91\":6,\"97\":10,\"159\":12,\"173\":3,\"193\":10,\"230\":2,\"255\":4,\"259\":1,\"267\":10,\"272\":1,\"278\":5}}],[\"v形调度\",{\"2\":{\"263\":1}}],[\"v3\",{\"2\":{\"263\":2}}],[\"v=xwv​\",{\"2\":{\"259\":1}}],[\"v=xwvq\",{\"2\":{\"259\":1}}],[\"v4\",{\"2\":{\"254\":1}}],[\"vh\",{\"2\":{\"236\":1}}],[\"v$\",{\"2\":{\"225\":1}}],[\"v要先经过一层linear\",{\"2\":{\"175\":1}}],[\"vscode\",{\"2\":{\"169\":1}}],[\"vdots\",{\"2\":{\"159\":1}}],[\"volatile\",{\"2\":{\"122\":1,\"248\":1,\"254\":7,\"260\":6,\"269\":5,\"273\":7,\"279\":5,\"282\":1}}],[\"volatile实参会被认为是non\",{\"2\":{\"122\":1}}],[\"vocab\",{\"2\":{\"115\":4,\"117\":5,\"167\":5,\"181\":7,\"188\":1,\"193\":12,\"255\":11,\"261\":5,\"270\":3,\"277\":6,\"283\":9,\"285\":4}}],[\"void\",{\"2\":{\"104\":2,\"122\":5,\"135\":2,\"254\":10,\"269\":3,\"273\":6,\"279\":5,\"282\":1}}],[\"variable\",{\"2\":{\"254\":3}}],[\"var\",{\"2\":{\"96\":16}}],[\"val\",{\"2\":{\"154\":4}}],[\"value\",{\"0\":{\"119\":1},\"2\":{\"119\":1,\"173\":2,\"260\":2,\"269\":1,\"278\":1,\"285\":1}}],[\"value=0\",{\"2\":{\"285\":1}}],[\"value=\",{\"2\":{\"70\":1}}],[\"values都是\",{\"2\":{\"202\":1}}],[\"values的小批量\",{\"2\":{\"81\":1}}],[\"values的形状\",{\"2\":{\"59\":1,\"81\":1,\"91\":1,\"173\":1}}],[\"values的形状为\",{\"2\":{\"59\":1}}],[\"values\",{\"2\":{\"59\":7,\"81\":4,\"91\":2,\"97\":1,\"173\":5,\"193\":1}}],[\"valid\",{\"2\":{\"70\":9,\"81\":4,\"91\":3,\"115\":5,\"173\":6,\"285\":11}}],[\"v∈rdv​\",{\"2\":{\"159\":1}}],[\"v∈rdv\",{\"2\":{\"159\":1}}],[\"v∈rn×v\",{\"2\":{\"91\":2}}],[\"v∈rm∗v\",{\"2\":{\"91\":1}}],[\"v仅有一个输出\",{\"2\":{\"81\":1}}],[\"v^\",{\"2\":{\"81\":1,\"278\":3}}],[\"vvv\",{\"2\":{\"71\":2,\"91\":1,\"212\":1,\"259\":2,\"272\":3}}],[\"v\",{\"2\":{\"70\":5,\"71\":16,\"81\":3,\"82\":12,\"91\":4,\"97\":10,\"100\":2,\"112\":1,\"150\":2,\"159\":14,\"173\":3,\"193\":10,\"259\":9,\"278\":6}}],[\"vm​\",{\"2\":{\"70\":2}}],[\"vm\",{\"2\":{\"70\":2}}],[\"v1​\",{\"2\":{\"70\":2}}],[\"v1\",{\"2\":{\"70\":2}}],[\"vgg网络的超参数\",{\"2\":{\"63\":1}}],[\"vgg以块为一个单元\",{\"2\":{\"63\":1}}],[\"vgg\",{\"0\":{\"63\":1},\"2\":{\"63\":4}}],[\"visible\",{\"2\":{\"260\":1}}],[\"visit\",{\"2\":{\"113\":1}}],[\"virtual\",{\"2\":{\"252\":1}}],[\"vitepress\",{\"2\":{\"100\":4}}],[\"vitae\",{\"2\":{\"57\":2,\"68\":3}}],[\"view\",{\"2\":{\"97\":2,\"140\":1,\"181\":2,\"193\":4,\"220\":1}}],[\"vi​∈rv\",{\"2\":{\"70\":1}}],[\"vi∈rv\",{\"2\":{\"70\":1}}],[\"viverra\",{\"2\":{\"57\":2,\"68\":3}}],[\"vec\",{\"2\":{\"128\":22,\"254\":2}}],[\"vector\",{\"2\":{\"112\":1,\"150\":1,\"257\":1}}],[\"vexing\",{\"2\":{\"112\":1}}],[\"velit\",{\"2\":{\"57\":2,\"68\":3}}],[\"vestibulum\",{\"2\":{\"57\":2,\"68\":3}}],[\"verl\",{\"2\":{\"15\":1,\"77\":1}}],[\"vuepress\",{\"2\":{\"25\":1,\"41\":1,\"100\":4,\"142\":2}}],[\"vllm\",{\"2\":{\"1\":1}}],[\"+t\",{\"2\":{\"278\":1}}],[\"+zp\",{\"2\":{\"262\":2}}],[\"+2bshv\",{\"2\":{\"259\":1}}],[\"+2bshvl\",{\"2\":{\"259\":1}}],[\"+21​i=j∑​pi​pj​=1−i∑​pi2​\",{\"2\":{\"123\":1}}],[\"+vh\",{\"2\":{\"236\":1}}],[\"+vhl\",{\"2\":{\"236\":1}}],[\"+x\",{\"2\":{\"151\":3,\"278\":1}}],[\"+12∑i≠jpipj=1−∑ipi2\",{\"2\":{\"123\":1}}],[\"++\",{\"2\":{\"100\":3}}],[\"+=\",{\"2\":{\"88\":1}}],[\"+\",{\"2\":{\"15\":2,\"48\":1,\"51\":2,\"55\":1,\"59\":2,\"71\":4,\"78\":1,\"81\":2,\"82\":2,\"88\":7,\"95\":1,\"96\":5,\"103\":4,\"108\":1,\"112\":4,\"115\":1,\"117\":4,\"119\":1,\"123\":2,\"124\":1,\"128\":7,\"130\":9,\"138\":2,\"140\":1,\"144\":5,\"145\":1,\"152\":3,\"153\":3,\"176\":3,\"187\":2,\"188\":6,\"193\":6,\"197\":1,\"202\":2,\"214\":1,\"222\":1,\"225\":2,\"228\":2,\"229\":10,\"230\":5,\"235\":2,\"236\":3,\"246\":9,\"247\":4,\"252\":1,\"255\":3,\"256\":1,\"259\":6,\"260\":1,\"262\":1,\"263\":1,\"264\":2,\"266\":2,\"268\":2,\"269\":6,\"270\":2,\"271\":1,\"272\":4,\"273\":5,\"278\":4,\"283\":1,\"285\":2}}],[\"l×\",{\"2\":{\"259\":2,\"272\":2}}],[\"ldg\",{\"2\":{\"254\":2}}],[\"ldsm4\",{\"2\":{\"254\":1}}],[\"lds\",{\"2\":{\"254\":2,\"273\":2}}],[\"ld\",{\"2\":{\"254\":6,\"273\":1}}],[\"ldmatrix\",{\"2\":{\"254\":4,\"273\":1}}],[\"ldots\",{\"2\":{\"103\":4,\"131\":2,\"249\":2}}],[\"llm\",{\"2\":{\"251\":1}}],[\"lll\",{\"2\":{\"158\":2,\"212\":1,\"225\":1,\"236\":1,\"272\":1}}],[\"lm2\",{\"0\":{\"235\":1},\"1\":{\"245\":1,\"252\":1,\"258\":1},\"2\":{\"235\":1}}],[\"lm的paper\",{\"2\":{\"222\":1}}],[\"lm\",{\"0\":{\"222\":1,\"235\":1},\"1\":{\"245\":1,\"252\":1,\"258\":1},\"2\":{\"222\":1}}],[\"lm中\",{\"2\":{\"213\":1}}],[\"lm中的distribute\",{\"2\":{\"213\":1}}],[\"l2\",{\"2\":{\"197\":2,\"269\":3,\"273\":1}}],[\"lcudart是cuda运行时编译选项\",{\"2\":{\"169\":1}}],[\"lcudart\",{\"2\":{\"169\":1}}],[\"lstm以元组作为隐状态\",{\"2\":{\"277\":1}}],[\"lstm\",{\"2\":{\"277\":1}}],[\"lstm或对于我们从零开始实现的模型是个张量\",{\"2\":{\"270\":1}}],[\"ls\",{\"2\":{\"139\":2}}],[\"lw1\",{\"2\":{\"139\":1}}],[\"lw\",{\"2\":{\"139\":1}}],[\"ln\",{\"2\":{\"137\":1}}],[\"lnp\",{\"2\":{\"137\":2}}],[\"l1l1l1\",{\"2\":{\"123\":1}}],[\"l​\",{\"2\":{\"71\":2}}],[\"lr=lr\",{\"2\":{\"247\":1,\"285\":1}}],[\"lr=0\",{\"2\":{\"59\":1,\"181\":1,\"193\":1}}],[\"lr为步长\",{\"2\":{\"88\":1}}],[\"lr\",{\"2\":{\"63\":2,\"88\":5,\"103\":2,\"130\":2,\"247\":3,\"270\":3,\"285\":1}}],[\"l\",{\"2\":{\"59\":4,\"71\":5,\"88\":8,\"103\":2,\"130\":3,\"236\":2,\"247\":6,\"248\":1,\"254\":2,\"266\":1,\"269\":5,\"270\":4,\"272\":1,\"273\":3,\"278\":2,\"285\":3}}],[\"lock\",{\"2\":{\"163\":1}}],[\"local\",{\"2\":{\"61\":1}}],[\"lower\",{\"2\":{\"117\":1}}],[\"longish\",{\"2\":{\"113\":1}}],[\"long\",{\"2\":{\"112\":2,\"270\":1,\"277\":1,\"283\":1}}],[\"longleftrightarrow\",{\"2\":{\"108\":1}}],[\"logni​=−αlogi+c\",{\"2\":{\"145\":1}}],[\"log⁡ni=−αlog⁡i+c\",{\"2\":{\"145\":1}}],[\"log\",{\"2\":{\"100\":6,\"124\":1,\"145\":2,\"152\":2,\"193\":1,\"249\":2}}],[\"loads\",{\"2\":{\"282\":1}}],[\"load\",{\"0\":{\"254\":1,\"269\":1},\"2\":{\"63\":1,\"88\":2,\"103\":1,\"117\":1,\"152\":1,\"188\":1,\"205\":2,\"254\":2,\"260\":1,\"265\":2,\"269\":8,\"273\":6,\"279\":1,\"282\":6}}],[\"losslossloss\",{\"2\":{\"137\":2}}],[\"loss\",{\"2\":{\"59\":4,\"88\":11,\"103\":7,\"130\":1,\"137\":5,\"181\":4,\"193\":4,\"247\":4,\"266\":1,\"270\":4,\"285\":8}}],[\"lorem\",{\"2\":{\"57\":2,\"68\":4,\"100\":2}}],[\"luctus\",{\"2\":{\"57\":2,\"68\":3}}],[\"literal\",{\"2\":{\"127\":1,\"141\":2,\"214\":1}}],[\"lib等\",{\"2\":{\"169\":1}}],[\"lib\",{\"2\":{\"106\":1,\"169\":3}}],[\"libero\",{\"2\":{\"57\":2,\"68\":3}}],[\"li\",{\"2\":{\"100\":2}}],[\"like\",{\"2\":{\"97\":1,\"140\":1,\"193\":1,\"285\":1}}],[\"li>magic\",{\"2\":{\"68\":1}}],[\"li>mchale\",{\"2\":{\"68\":1}}],[\"li>parish\",{\"2\":{\"68\":1}}],[\"li>\",{\"2\":{\"68\":9,\"100\":2}}],[\"li>bird\",{\"2\":{\"68\":2}}],[\"liststruct1\",{\"2\":{\"139\":1}}],[\"liststruct\",{\"2\":{\"139\":1}}],[\"list\",{\"2\":{\"57\":2,\"61\":2,\"63\":2,\"68\":6,\"88\":1,\"112\":2,\"117\":5,\"135\":7,\"139\":2,\"176\":2,\"188\":1,\"213\":2,\"247\":1}}],[\"link起来\",{\"2\":{\"169\":1}}],[\"linkage\",{\"2\":{\"169\":1}}],[\"link\",{\"2\":{\"113\":7}}],[\"linreg\",{\"2\":{\"88\":2}}],[\"lines\",{\"2\":{\"117\":9}}],[\"lines>\",{\"2\":{\"100\":1}}],[\"line\",{\"2\":{\"40\":1,\"68\":1,\"100\":2,\"117\":10}}],[\"linear\",{\"0\":{\"20\":1,\"39\":1},\"1\":{\"48\":1,\"56\":1,\"67\":1,\"78\":1,\"88\":1},\"2\":{\"61\":5,\"63\":3,\"81\":3,\"86\":1,\"88\":1,\"97\":6,\"103\":3,\"110\":2,\"115\":1,\"140\":1,\"159\":1,\"167\":1,\"173\":4,\"193\":9,\"247\":4,\"277\":5,\"283\":1,\"285\":1}}],[\"linux\",{\"2\":{\"15\":1,\"169\":2}}],[\"laneid\",{\"2\":{\"269\":3,\"273\":4,\"279\":4,\"282\":2}}],[\"language\",{\"0\":{\"222\":1,\"235\":1},\"1\":{\"245\":1,\"252\":1,\"258\":1},\"2\":{\"158\":1}}],[\"languages\",{\"2\":{\"100\":1}}],[\"lambda\",{\"2\":{\"261\":1,\"270\":2}}],[\"label的shape是\",{\"2\":{\"285\":1}}],[\"label的形状\",{\"2\":{\"285\":1}}],[\"label\",{\"2\":{\"285\":3}}],[\"labels\",{\"2\":{\"88\":8,\"103\":2}}],[\"lab\",{\"2\":{\"260\":2}}],[\"large\",{\"0\":{\"210\":1,\"235\":1},\"1\":{\"222\":1,\"235\":1,\"245\":2,\"252\":2,\"258\":2,\"263\":1}}],[\"launch\",{\"2\":{\"197\":2}}],[\"laws\",{\"2\":{\"158\":1}}],[\"last\",{\"2\":{\"97\":2,\"193\":2}}],[\"layer上\",{\"2\":{\"263\":1}}],[\"layer进行进一步划分\",{\"2\":{\"252\":1}}],[\"layernorm\",{\"2\":{\"138\":2,\"153\":3,\"193\":5}}],[\"layer\",{\"0\":{\"138\":1,\"153\":1},\"2\":{\"86\":3,\"87\":1,\"138\":2,\"153\":4,\"167\":4,\"193\":10,\"213\":2,\"277\":2}}],[\"layers=2\",{\"2\":{\"283\":2}}],[\"layers\",{\"2\":{\"63\":5,\"97\":1,\"115\":4,\"138\":1,\"153\":2,\"167\":7,\"181\":2,\"193\":13,\"213\":1,\"277\":3,\"283\":9}}],[\"laoreet\",{\"2\":{\"57\":2,\"68\":3}}],[\"latent\",{\"0\":{\"45\":1}}],[\"latex\",{\"2\":{\"6\":1,\"10\":1,\"13\":1,\"14\":1,\"19\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"leq\",{\"2\":{\"278\":4}}],[\"legend=\",{\"2\":{\"247\":1,\"270\":1}}],[\"leaf\",{\"2\":{\"140\":1}}],[\"learning∣deep\",{\"2\":{\"131\":2}}],[\"learning\",{\"2\":{\"131\":11}}],[\"learned\",{\"2\":{\"110\":1,\"193\":1}}],[\"level中\",{\"2\":{\"273\":1}}],[\"level\",{\"2\":{\"57\":2,\"197\":1,\"254\":3,\"282\":2}}],[\"lectus\",{\"2\":{\"57\":2,\"68\":3}}],[\"leftarrow\",{\"2\":{\"266\":1,\"278\":2}}],[\"left左对齐的内容\",{\"2\":{\"172\":2}}],[\"left|\",{\"2\":{\"123\":1}}],[\"left\",{\"2\":{\"51\":4,\"59\":3,\"91\":1,\"123\":1,\"202\":2,\"249\":3,\"259\":1,\"266\":1,\"271\":2,\"278\":2}}],[\"len的形状\",{\"2\":{\"285\":1}}],[\"len从\",{\"2\":{\"285\":1}}],[\"len这个维度分割\",{\"2\":{\"258\":1}}],[\"lenet\",{\"0\":{\"247\":1},\"2\":{\"247\":1}}],[\"len=1000\",{\"2\":{\"202\":1}}],[\"lens=none\",{\"2\":{\"91\":1}}],[\"lens的形状\",{\"2\":{\"91\":1}}],[\"lens\",{\"2\":{\"70\":10,\"81\":4,\"91\":1,\"115\":5,\"173\":6}}],[\"length\",{\"2\":{\"61\":7,\"97\":6,\"124\":3,\"167\":9,\"181\":4,\"193\":22}}],[\"len\",{\"2\":{\"51\":1,\"88\":2,\"96\":2,\"117\":4,\"152\":4,\"166\":2,\"176\":1,\"188\":1,\"202\":2,\"247\":1,\"285\":11}}],[\"lt\",{\"0\":{\"254\":1},\"2\":{\"17\":5,\"24\":8,\"28\":5,\"29\":5,\"33\":5,\"36\":8,\"37\":8,\"40\":4,\"42\":8,\"68\":1,\"79\":5,\"108\":3,\"112\":1,\"127\":2,\"135\":1,\"141\":1,\"143\":2,\"156\":1,\"214\":1,\"273\":1}}],[\"dstmem\",{\"2\":{\"265\":2}}],[\"dst4\",{\"2\":{\"254\":2}}],[\"dst3\",{\"2\":{\"254\":2}}],[\"dst2\",{\"2\":{\"254\":2}}],[\"dst1\",{\"2\":{\"254\":2}}],[\"dst\",{\"2\":{\"254\":18,\"269\":20,\"273\":22}}],[\"dp将model\",{\"2\":{\"245\":1}}],[\"dp\",{\"2\":{\"245\":1}}],[\"dh\",{\"2\":{\"230\":3}}],[\"ducks\",{\"2\":{\"269\":10,\"273\":7}}],[\"during\",{\"2\":{\"263\":1}}],[\"dualpipe其实是一种和deepep深度耦合的技术\",{\"2\":{\"263\":1}}],[\"dualpipe\",{\"0\":{\"263\":1},\"2\":{\"263\":1}}],[\"dualpipev是带有virtual\",{\"2\":{\"263\":1}}],[\"dualpipev\",{\"2\":{\"213\":1}}],[\"duplicate\",{\"2\":{\"222\":1}}],[\"dn∗d\",{\"2\":{\"202\":1}}],[\"d^2\",{\"2\":{\"202\":1}}],[\"d2\",{\"2\":{\"202\":2}}],[\"d2l\",{\"2\":{\"59\":1,\"63\":3,\"70\":1,\"88\":3,\"103\":2,\"115\":1,\"117\":5,\"152\":3,\"173\":1,\"174\":1,\"247\":7,\"270\":4,\"285\":4}}],[\"d∗dd\",{\"2\":{\"202\":1}}],[\"driver设置为nvcc编译器路径\",{\"2\":{\"169\":1}}],[\"driver=\",{\"2\":{\"169\":1}}],[\"droupout需要保存mask矩阵\",{\"2\":{\"272\":1}}],[\"droupout操作\",{\"2\":{\"272\":1}}],[\"droupout\",{\"2\":{\"138\":2,\"167\":4,\"181\":2,\"193\":8}}],[\"dropout操作的mask矩阵\",{\"2\":{\"272\":1}}],[\"dropout=dropout\",{\"2\":{\"115\":2,\"283\":2}}],[\"dropout=0\",{\"2\":{\"81\":1,\"115\":1,\"283\":2}}],[\"dropout\",{\"2\":{\"63\":2,\"75\":1,\"81\":5,\"86\":1,\"91\":5,\"138\":5,\"153\":8,\"167\":4,\"173\":2,\"193\":17,\"202\":5}}],[\"dtype\",{\"2\":{\"152\":2,\"269\":4,\"273\":4}}],[\"dtype=torch\",{\"2\":{\"81\":1,\"103\":1,\"124\":1,\"193\":1,\"202\":2,\"229\":1,\"283\":1,\"285\":1}}],[\"dxd​f\",{\"2\":{\"151\":1}}],[\"dx\",{\"2\":{\"151\":1}}],[\"dd∗d\",{\"2\":{\"202\":1}}],[\"ddxf\",{\"2\":{\"151\":1}}],[\"ddd\",{\"2\":{\"91\":3,\"158\":1,\"202\":4,\"230\":1}}],[\"daringfireball\",{\"2\":{\"113\":1}}],[\"daring\",{\"2\":{\"113\":2}}],[\"dangerous\",{\"2\":{\"90\":2}}],[\"data∈rb×s\",{\"2\":{\"259\":1}}],[\"data∈rb×sdata\",{\"2\":{\"259\":1}}],[\"dataloader\",{\"2\":{\"88\":1}}],[\"dataset\",{\"2\":{\"88\":2}}],[\"data\",{\"2\":{\"63\":1,\"88\":14,\"96\":2,\"100\":12,\"106\":1,\"117\":2,\"130\":1,\"138\":1,\"152\":9,\"176\":4,\"181\":5,\"188\":6,\"193\":8,\"247\":2,\"254\":1,\"265\":1,\"269\":1,\"273\":3,\"285\":2}}],[\"d=u+∑a=−δδ∑b=−δδ∑c\",{\"2\":{\"82\":1}}],[\"d​qk⊤​\",{\"2\":{\"91\":1}}],[\"d​=u+a=−δ∑δ​b=−δ∑δ​c∑​\",{\"2\":{\"82\":1}}],[\"d​\",{\"2\":{\"82\":2,\"91\":1}}],[\"d\",{\"2\":{\"82\":5,\"87\":2,\"88\":2,\"91\":10,\"97\":22,\"110\":6,\"112\":2,\"124\":4,\"138\":7,\"151\":1,\"153\":9,\"158\":3,\"159\":6,\"167\":10,\"169\":2,\"181\":4,\"186\":1,\"193\":62,\"202\":4,\"230\":1,\"254\":1,\"269\":3,\"283\":1}}],[\"directions\",{\"2\":{\"277\":5}}],[\"directions应该是2\",{\"2\":{\"277\":1}}],[\"directly\",{\"2\":{\"260\":1}}],[\"dir=$\",{\"2\":{\"169\":1}}],[\"distributed\",{\"0\":{\"210\":1},\"1\":{\"222\":1,\"235\":1,\"245\":1,\"252\":1,\"258\":1,\"263\":1},\"2\":{\"213\":2}}],[\"display\",{\"2\":{\"152\":1}}],[\"dispatch\",{\"2\":{\"61\":1}}],[\"diagnostics\",{\"2\":{\"169\":1}}],[\"diagonal=1\",{\"2\":{\"167\":1,\"193\":1}}],[\"different\",{\"2\":{\"273\":1}}],[\"diff\",{\"2\":{\"100\":1}}],[\"dimensions\",{\"2\":{\"97\":2,\"193\":2}}],[\"dimension\",{\"2\":{\"97\":3,\"193\":3}}],[\"dims\",{\"2\":{\"96\":3}}],[\"dim\",{\"2\":{\"70\":1,\"258\":1,\"269\":4,\"273\":3}}],[\"dim=0\",{\"2\":{\"96\":2,\"115\":1,\"173\":1,\"191\":1,\"220\":2,\"255\":1}}],[\"dim=\",{\"2\":{\"70\":2,\"96\":2,\"97\":1,\"115\":1,\"193\":1}}],[\"dim=2\",{\"2\":{\"61\":1}}],[\"dim=1\",{\"2\":{\"59\":1,\"86\":2,\"115\":2,\"152\":2,\"191\":1,\"261\":1,\"285\":1}}],[\"divergence\",{\"2\":{\"128\":2}}],[\"divisible\",{\"2\":{\"97\":1,\"193\":1}}],[\"div>\",{\"2\":{\"79\":1}}],[\"div\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1,\"79\":3,\"124\":3,\"193\":3,\"267\":1}}],[\"done\",{\"2\":{\"260\":2}}],[\"donec\",{\"2\":{\"57\":2,\"68\":3}}],[\"don\",{\"2\":{\"141\":2}}],[\"downstream\",{\"2\":{\"138\":1,\"193\":1}}],[\"download\",{\"2\":{\"117\":1}}],[\"double>\",{\"2\":{\"112\":1}}],[\"double\",{\"2\":{\"112\":4,\"127\":2}}],[\"docs\",{\"2\":{\"100\":1,\"273\":2}}],[\"docbook\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"dotproductattention\",{\"2\":{\"91\":2,\"173\":1}}],[\"dot\",{\"2\":{\"91\":1,\"97\":3,\"151\":1,\"193\":3}}],[\"dots\",{\"2\":{\"70\":1,\"186\":1,\"217\":1}}],[\"dolor\",{\"2\":{\"57\":2,\"68\":4}}],[\"dequantize\",{\"2\":{\"267\":1}}],[\"devide\",{\"2\":{\"197\":1}}],[\"device=x\",{\"2\":{\"285\":1}}],[\"device=try\",{\"2\":{\"255\":1}}],[\"device=device\",{\"2\":{\"255\":4,\"261\":2,\"270\":1,\"277\":3,\"285\":1}}],[\"device=none\",{\"2\":{\"247\":1}}],[\"device之间的点对点通信次数\",{\"2\":{\"252\":1}}],[\"device\",{\"2\":{\"96\":4,\"202\":1,\"247\":12,\"254\":10,\"255\":8,\"260\":2,\"261\":1,\"269\":3,\"270\":7,\"273\":3,\"277\":1,\"279\":4,\"282\":1,\"285\":5}}],[\"dev\",{\"2\":{\"169\":7}}],[\"decode\",{\"2\":{\"278\":1}}],[\"decoder的具体实现\",{\"2\":{\"283\":1}}],[\"decoder架构\",{\"2\":{\"283\":1}}],[\"decoderlayer\",{\"2\":{\"153\":3,\"167\":1,\"193\":4}}],[\"decoder与attention机制步骤\",{\"0\":{\"143\":1}}],[\"decoder会有选择地统计输入序列的不同部分\",{\"2\":{\"115\":1}}],[\"decoder\",{\"0\":{\"153\":1,\"212\":1,\"280\":1},\"1\":{\"225\":1,\"236\":1,\"246\":1,\"253\":1,\"259\":1,\"264\":1,\"268\":1,\"272\":1,\"275\":1},\"2\":{\"87\":1,\"115\":2,\"153\":6,\"167\":4,\"193\":10,\"212\":2,\"280\":7,\"283\":5}}],[\"dec\",{\"2\":{\"167\":6,\"193\":6,\"280\":4,\"285\":2}}],[\"decltype就会返回左值引用\",{\"2\":{\"150\":1}}],[\"decltype有一个比较重要的作用就是在模板中标识返回值类型\",{\"2\":{\"150\":1}}],[\"decltype\",{\"0\":{\"150\":1},\"2\":{\"150\":15}}],[\"decimal\",{\"2\":{\"141\":2}}],[\"description\",{\"2\":{\"128\":2}}],[\"dense\",{\"2\":{\"115\":2,\"283\":2}}],[\"delimited\",{\"2\":{\"141\":2}}],[\"deleted函数不能以任何方式被调用\",{\"2\":{\"168\":1}}],[\"deleted\",{\"0\":{\"168\":1},\"2\":{\"168\":1}}],[\"delete\",{\"2\":{\"104\":1,\"118\":1}}],[\"delta4δ\",{\"2\":{\"151\":1}}],[\"delta\",{\"2\":{\"71\":4,\"82\":8,\"123\":1,\"137\":2}}],[\"deltaδ\",{\"2\":{\"71\":1,\"151\":1}}],[\"detail\",{\"2\":{\"269\":1,\"273\":1}}],[\"details\",{\"2\":{\"90\":3,\"100\":2,\"113\":1}}],[\"detach\",{\"2\":{\"140\":1,\"270\":2}}],[\"determine\",{\"2\":{\"61\":1}}],[\"defines\",{\"2\":{\"138\":1,\"153\":1,\"193\":2}}],[\"defaults\",{\"2\":{\"279\":1}}],[\"default\",{\"2\":{\"100\":18,\"269\":2,\"273\":1}}],[\"def\",{\"2\":{\"51\":1,\"59\":2,\"61\":4,\"63\":2,\"70\":1,\"75\":1,\"81\":2,\"86\":4,\"88\":6,\"91\":2,\"96\":3,\"97\":5,\"103\":3,\"110\":2,\"115\":6,\"117\":10,\"124\":2,\"126\":2,\"130\":3,\"138\":2,\"140\":3,\"144\":1,\"152\":12,\"153\":2,\"167\":3,\"173\":4,\"174\":1,\"176\":2,\"181\":1,\"187\":1,\"188\":3,\"193\":17,\"197\":2,\"202\":2,\"203\":1,\"213\":4,\"229\":1,\"247\":3,\"255\":8,\"261\":1,\"266\":1,\"267\":2,\"270\":2,\"277\":3,\"280\":7,\"283\":5,\"285\":4}}],[\"deepseek\",{\"2\":{\"263\":2}}],[\"deepep\",{\"2\":{\"15\":1}}],[\"deep\",{\"2\":{\"15\":1,\"131\":10}}],[\"极大地推进了动态可重复性研究的历史进程\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"在序列中屏蔽不相关的项\",{\"2\":{\"285\":1}}],[\"在循环神经网络模型中\",{\"2\":{\"283\":1}}],[\"在循环遍历prefix中的开始字符时\",{\"2\":{\"261\":1}}],[\"在store\",{\"2\":{\"279\":1}}],[\"在sm\",{\"2\":{\"260\":1}}],[\"在smem中\",{\"2\":{\"260\":1}}],[\"在推断阶段\",{\"2\":{\"278\":1}}],[\"在下面的分析中\",{\"2\":{\"272\":1}}],[\"在下面实现中\",{\"2\":{\"173\":1}}],[\"在分析中间激活的显存占用时\",{\"2\":{\"272\":2}}],[\"在asym下\",{\"2\":{\"271\":1}}],[\"在第一次迭代或使用随机抽样时初始化state\",{\"2\":{\"270\":1}}],[\"在给定训练tokens数\",{\"2\":{\"268\":1}}],[\"在一次前向传递中\",{\"2\":{\"264\":1}}],[\"在一次训练迭代中\",{\"2\":{\"246\":1,\"275\":1}}],[\"在dualpipev中\",{\"2\":{\"263\":1}}],[\"在1f1b调度中\",{\"2\":{\"263\":1}}],[\"在1中\",{\"2\":{\"144\":1}}],[\"在prefix后面生成新字符\",{\"2\":{\"261\":1}}],[\"在python的网络框架中\",{\"2\":{\"256\":1}}],[\"在python中网络框架和应用框架是解耦的\",{\"2\":{\"256\":1}}],[\"在python中实现多进程\",{\"2\":{\"256\":1}}],[\"在python中书写并行\",{\"0\":{\"250\":1},\"1\":{\"256\":1}}],[\"在python中\",{\"2\":{\"190\":1}}],[\"在pytorch上进行量化\",{\"2\":{\"223\":1}}],[\"在具体应用的时候\",{\"2\":{\"260\":1}}],[\"在量化的时候\",{\"2\":{\"257\":1}}],[\"在自己的进程里植入了应用框架的代码\",{\"2\":{\"256\":1}}],[\"在自回归模型中\",{\"2\":{\"103\":1}}],[\"在运行wsgi时\",{\"2\":{\"256\":1}}],[\"在train\",{\"2\":{\"255\":1}}],[\"在transformer中\",{\"2\":{\"87\":1}}],[\"在神经网络的推理阶段\",{\"2\":{\"253\":1}}],[\"在基线上\",{\"2\":{\"249\":1}}],[\"在基于位置的前馈网络中\",{\"2\":{\"110\":1}}],[\"在最坏的情况下\",{\"2\":{\"249\":1}}],[\"在最好的情况下\",{\"2\":{\"249\":1}}],[\"在最流行的神经网络架构中\",{\"2\":{\"187\":1}}],[\"在进行正向和反向传播之前\",{\"2\":{\"247\":1}}],[\"在进入transformer层之前\",{\"2\":{\"225\":1}}],[\"在整个卷积块中\",{\"2\":{\"247\":1}}],[\"在优化器更新模型参数时\",{\"2\":{\"246\":1}}],[\"在混合精度训练中\",{\"2\":{\"246\":1}}],[\"在训练神经网络的过程中\",{\"2\":{\"246\":1}}],[\"在处理多通道输入的时候\",{\"2\":{\"229\":1}}],[\"在时间步\",{\"2\":{\"217\":1}}],[\"在bwd阶段\",{\"2\":{\"213\":1}}],[\"在backward实现中\",{\"2\":{\"140\":1}}],[\"在bahdanau注意力模型中\",{\"2\":{\"115\":1}}],[\"在fwd\",{\"2\":{\"263\":1}}],[\"在fwd阶段\",{\"2\":{\"213\":1}}],[\"在functional中存在了很多torch预先帮我们设计好的函数\",{\"2\":{\"126\":1}}],[\"在matmul算子中\",{\"2\":{\"267\":1}}],[\"在megatron\",{\"2\":{\"213\":1}}],[\"在moe中我们一般会设定一个topk\",{\"2\":{\"72\":1}}],[\"在其他章节已经介绍过了\",{\"2\":{\"212\":1}}],[\"在其作用域中\",{\"2\":{\"154\":1}}],[\"在compute之前我们需要receive一下上一个stage的tensor\",{\"2\":{\"263\":1}}],[\"在cpp中\",{\"2\":{\"211\":1}}],[\"在c++98中会将其标记为private\",{\"2\":{\"168\":1}}],[\"在c++\",{\"2\":{\"163\":1}}],[\"在浏览器里面\",{\"2\":{\"199\":1}}],[\"在互相关运算中\",{\"2\":{\"187\":1}}],[\"在多核机器下\",{\"2\":{\"177\":1}}],[\"在这种情况下\",{\"2\":{\"249\":3}}],[\"在这里\",{\"2\":{\"176\":1}}],[\"在这个具体的例子中\",{\"2\":{\"151\":1}}],[\"在这个上下文中\",{\"2\":{\"88\":1}}],[\"在随机抽样的迭代过程中\",{\"2\":{\"176\":1}}],[\"在轴0\",{\"2\":{\"173\":1}}],[\"在实际的pp中\",{\"2\":{\"213\":1}}],[\"在实现过程中通常选择缩放点积注意力作为每一个注意力头\",{\"2\":{\"173\":1}}],[\"在实践中\",{\"2\":{\"159\":1}}],[\"在该项目的\",{\"2\":{\"169\":1}}],[\"在gil保证下\",{\"2\":{\"163\":1}}],[\"在gil机制中\",{\"2\":{\"163\":1}}],[\"在编译器生效\",{\"2\":{\"154\":1}}],[\"在编码器\",{\"2\":{\"87\":1}}],[\"在non\",{\"2\":{\"252\":1}}],[\"在n个变量上累加\",{\"2\":{\"152\":1}}],[\"在nn\",{\"2\":{\"126\":1,\"140\":1}}],[\"在x=\",{\"2\":{\"151\":1}}],[\"在x0x\",{\"2\":{\"151\":1}}],[\"在点\",{\"2\":{\"151\":1}}],[\"在梯度计算之后\",{\"2\":{\"151\":1}}],[\"在初始时\",{\"2\":{\"151\":1}}],[\"在数学上\",{\"2\":{\"151\":1,\"166\":1}}],[\"在数学中可以表示为一个向量\",{\"2\":{\"151\":1}}],[\"在数据科学领域\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"在前一部分讨论的auto初始化表达式类型推导的地方\",{\"2\":{\"150\":1}}],[\"在计算互相关时\",{\"2\":{\"144\":1}}],[\"在计算编码器的自注意力时\",{\"2\":{\"87\":1}}],[\"在代码中找到了一个shared\",{\"2\":{\"273\":1}}],[\"在代码码区段内\",{\"2\":{\"141\":1}}],[\"在代码块中实现行高亮\",{\"2\":{\"100\":1}}],[\"在代码块里面\",{\"2\":{\"79\":1}}],[\"在机器学习中\",{\"2\":{\"136\":1}}],[\"在二维互相关运算中\",{\"2\":{\"130\":1}}],[\"在上述例子中就是\",{\"2\":{\"205\":1}}],[\"在上述中\",{\"2\":{\"130\":1}}],[\"在上文中\",{\"2\":{\"93\":1}}],[\"在深度学习之中\",{\"2\":{\"126\":1}}],[\"在深度学习中\",{\"2\":{\"43\":1,\"123\":1,\"180\":1,\"186\":1}}],[\"在发生类型推导的前提下\",{\"2\":{\"119\":1}}],[\"在特征维度上连结\",{\"2\":{\"115\":1}}],[\"在解码的某个时间步\",{\"2\":{\"115\":1}}],[\"在解码器自注意力中\",{\"2\":{\"87\":1}}],[\"在预测词元时\",{\"2\":{\"115\":1}}],[\"在文件的任意处\",{\"2\":{\"113\":1}}],[\"在某一行添加\",{\"2\":{\"100\":2}}],[\"在某一行上添加\",{\"2\":{\"100\":1}}],[\"在卷积神经网络中\",{\"2\":{\"92\":1}}],[\"在残差连接的加法计算之后\",{\"2\":{\"87\":1}}],[\"在维度扩展后\",{\"2\":{\"81\":1}}],[\"在图像处理中\",{\"2\":{\"102\":1}}],[\"在图像任意位置扫描就可以\",{\"2\":{\"71\":1}}],[\"在图像识别中\",{\"2\":{\"60\":1}}],[\"在反向传播时会被更新\",{\"2\":{\"59\":1}}],[\"在使用换行来排版的时候\",{\"2\":{\"40\":1}}],[\"在行尾加上两个以上的空格\",{\"2\":{\"40\":1}}],[\"在\",{\"2\":{\"17\":1,\"24\":1,\"28\":1,\"29\":1,\"33\":1,\"36\":1,\"37\":1,\"42\":1,\"100\":2,\"113\":1,\"151\":1}}],[\"在语法上基本兼容\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"转置为\",{\"2\":{\"270\":1}}],[\"转义字符\",{\"0\":{\"214\":1}}],[\"转为\",{\"2\":{\"141\":1}}],[\"转化为\",{\"2\":{\"283\":2}}],[\"转化为嵌入向量\",{\"2\":{\"143\":1}}],[\"转化为嵌入向量再惯例permute一下\",{\"2\":{\"129\":1}}],[\"转化为演讲\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"转换形态为2\",{\"2\":{\"220\":2}}],[\"转换操作\",{\"0\":{\"220\":1}}],[\"转换成标量后\",{\"2\":{\"180\":1}}],[\"转换成更多的格式\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"转换为右值\",{\"2\":{\"119\":1}}],[\"转换为t\",{\"2\":{\"119\":1}}],[\"转换维一个\",{\"2\":{\"95\":1}}],[\"我可以arrive\",{\"2\":{\"260\":1}}],[\"我貌似没有get到这个和tp的区别\",{\"2\":{\"258\":1}}],[\"我需要计算一个forward\",{\"2\":{\"252\":1}}],[\"我需要保存用户的三种属性\",{\"2\":{\"154\":1}}],[\"我这里给出如下环境变量定义\",{\"2\":{\"169\":1}}],[\"我个人习惯使用vscode\",{\"2\":{\"169\":1}}],[\"我比较偏好直接放在链接出现段落的后面\",{\"2\":{\"113\":1}}],[\"我们只取最后一层\",{\"2\":{\"283\":1}}],[\"我们只需要在少数同步点上同步一下通信\",{\"2\":{\"263\":1}}],[\"我们只需要在一个规定的比较小的范围\",{\"2\":{\"71\":1}}],[\"我们只需要添加\",{\"2\":{\"144\":1}}],[\"我们只需要观测从\",{\"2\":{\"103\":1}}],[\"我们照例embedding一下并且permute一下\",{\"2\":{\"283\":1}}],[\"我们按照惯例将其permute一下\",{\"2\":{\"283\":1}}],[\"我们假如输入的\",{\"2\":{\"283\":1}}],[\"我们发现对于\",{\"2\":{\"278\":1}}],[\"我们发现这里引入了一个隐藏层参数\",{\"2\":{\"81\":1}}],[\"我们采用量化的手段将其重写为处理int8数据类型的算子\",{\"2\":{\"267\":1}}],[\"我们计算量近似为\",{\"2\":{\"264\":1}}],[\"我们经常转换输入的维度\",{\"2\":{\"255\":1}}],[\"我们看一些边界情况来更好的理解上述式子\",{\"2\":{\"249\":1}}],[\"我们尝试使用lenet来训练一下\",{\"2\":{\"247\":1}}],[\"我们对每个时间步的输出层的输出进行softmax操作\",{\"2\":{\"241\":1}}],[\"我们对上述实现的组件进行组装\",{\"2\":{\"138\":1}}],[\"我们沿着时间维度进行传播\",{\"2\":{\"230\":1}}],[\"我们希望逐渐降低隐藏表示的空间分辨率\",{\"2\":{\"216\":1}}],[\"我们希望模型可以基于相同的注意力机制学习到不同的行为\",{\"2\":{\"159\":1}}],[\"我们理解每个block是完全并行执行的\",{\"2\":{\"197\":1}}],[\"我们写出一个加载序列数据的迭代器\",{\"2\":{\"188\":1}}],[\"我们常会增加输出通道的维数\",{\"2\":{\"187\":1}}],[\"我们常常丢失边缘像素\",{\"2\":{\"144\":1}}],[\"我们通常计算汇聚窗口中所有元素的最大值或平均值\",{\"2\":{\"229\":1}}],[\"我们通常关注的是如何根据损失函数\",{\"2\":{\"180\":1}}],[\"我们通过传递引用的方式传递非常量左值引用\",{\"2\":{\"150\":1}}],[\"我们设定\",{\"2\":{\"173\":1}}],[\"我们知道计算公式如下\",{\"2\":{\"259\":1}}],[\"我们知道线程在执行了一定时间\",{\"2\":{\"231\":1}}],[\"我们知道cuda的核心开发工具包就是nv的cudatoolkit\",{\"2\":{\"169\":1}}],[\"我们知道在使用backward\",{\"2\":{\"166\":1}}],[\"我们代入具体的\",{\"2\":{\"166\":1}}],[\"我们再做一些小改动\",{\"2\":{\"247\":1}}],[\"我们再解释一下第二种计算方式y\",{\"2\":{\"166\":1}}],[\"我们再将点积除以\",{\"2\":{\"91\":1}}],[\"我们不难得出两者相等\",{\"2\":{\"166\":1}}],[\"我们不纠结具体时间\",{\"2\":{\"163\":1}}],[\"我们来探讨一个看似没啥意义\",{\"2\":{\"203\":1}}],[\"我们来对比一下这两种方式\",{\"2\":{\"166\":1}}],[\"我们来看如下代码\",{\"2\":{\"104\":1}}],[\"我们一般计算梯度是采取的y\",{\"2\":{\"166\":1}}],[\"我们一般设置\",{\"2\":{\"144\":1}}],[\"我们创建的为\",{\"2\":{\"163\":1}}],[\"我们展示多输入输出通道时\",{\"2\":{\"160\":1}}],[\"我们如果要访问的话\",{\"2\":{\"154\":1}}],[\"我们也可以重写他来制定enum的类型\",{\"2\":{\"154\":1}}],[\"我们要优先使用限域enum\",{\"2\":{\"154\":1}}],[\"我们输入需要为一个向量\",{\"2\":{\"152\":1}}],[\"我们更加通俗的解释一下\",{\"2\":{\"151\":1}}],[\"我们引入一个关于词频的定律\",{\"2\":{\"145\":1}}],[\"我们是自上而下\",{\"2\":{\"144\":1}}],[\"我们构建的模型\",{\"2\":{\"126\":1}}],[\"我们在定义空指针的时候\",{\"2\":{\"125\":1}}],[\"我们传入的x就可以根据传入类型来判断\",{\"2\":{\"119\":1}}],[\"我们选择字符词元化\",{\"2\":{\"117\":1}}],[\"我们首先回顾多层感知机的梯度消失是如何产生的\",{\"2\":{\"266\":1}}],[\"我们首先要起一个进程\",{\"2\":{\"256\":1}}],[\"我们首先要高效的接受请求\",{\"2\":{\"256\":1}}],[\"我们首先要对分类问题有基本的认知\",{\"2\":{\"95\":1}}],[\"我们首先看无隐状态的神经网络\",{\"2\":{\"230\":1}}],[\"我们首先会定义一些超参数\",{\"2\":{\"197\":1}}],[\"我们首先创建一个一维张量x0x\",{\"2\":{\"151\":1}}],[\"我们首先进行推导\",{\"2\":{\"123\":1}}],[\"我们首先可以统计不同的词元数目\",{\"2\":{\"117\":1}}],[\"我们这里探讨一下如何处理序列数据\",{\"2\":{\"117\":1}}],[\"我们会多一步\",{\"2\":{\"262\":1}}],[\"我们会不断地将隐状态传递到下一个时间步\",{\"2\":{\"261\":1}}],[\"我们会不断地接受请求\",{\"2\":{\"219\":1}}],[\"我们会将这个固定状态拿去投入另外一个rnn\",{\"2\":{\"283\":1}}],[\"我们会将每个索引映射为互不相同的单位向量\",{\"2\":{\"255\":1}}],[\"我们会将一组在一个gpu上的连续的transformer\",{\"2\":{\"252\":1}}],[\"我们会对调度的block进行重排\",{\"2\":{\"197\":1}}],[\"我们会对multi\",{\"2\":{\"110\":1}}],[\"我们会启动sm个block\",{\"2\":{\"197\":1}}],[\"我们会使用tensor\",{\"2\":{\"197\":1}}],[\"我们会根据这个结构来对tokens进行分发\",{\"2\":{\"72\":1}}],[\"我们找到了生成一串序列的方法\",{\"2\":{\"103\":1}}],[\"我们现在有三种方式\",{\"2\":{\"202\":1}}],[\"我们现在有了数据\",{\"2\":{\"131\":1}}],[\"我们现在有一连串随时间变化的股票数据\",{\"2\":{\"103\":1}}],[\"我们现在解决了如何预测的问题\",{\"2\":{\"103\":1}}],[\"我们预测的其实是一个概率\",{\"2\":{\"103\":1}}],[\"我们还可以分配一些索引给未知或者已删除的词元\",{\"2\":{\"117\":1}}],[\"我们还可以快速将\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"我们还想有一个网络架构来对其进行计算\",{\"2\":{\"95\":1}}],[\"我们需要执行矩阵乘法操作\",{\"2\":{\"267\":1}}],[\"我们需要精细的控制计算图\",{\"2\":{\"263\":1}}],[\"我们需要一个手段来评估我们的模型生成的语言的质量\",{\"2\":{\"249\":1}}],[\"我们需要一个损失函数\",{\"2\":{\"137\":1}}],[\"我们需要将每一小批数据移动到我们指定的设备上\",{\"2\":{\"247\":1}}],[\"我们需要将input\",{\"2\":{\"213\":1}}],[\"我们需要将若干禽类数据划分到三种类别下\",{\"2\":{\"95\":1}}],[\"我们需要的是上一个阶段传来的output\",{\"2\":{\"213\":1}}],[\"我们需要的是上一个阶段的input\",{\"2\":{\"213\":1}}],[\"我们需要对其进行分割\",{\"2\":{\"162\":1}}],[\"我们需要通过1\",{\"2\":{\"154\":1}}],[\"我们需要计算单词的概率\",{\"2\":{\"131\":1}}],[\"我们需要更好的模型\",{\"2\":{\"103\":1}}],[\"我们需要这个值来估计损失\",{\"2\":{\"88\":1}}],[\"我们使用交叉熵和小批量随机梯度下降来计算\",{\"2\":{\"247\":1}}],[\"我们使用卷积神经网络来提取图像的空间特征\",{\"2\":{\"93\":1}}],[\"我们使用库的话\",{\"2\":{\"88\":1}}],[\"我们先将前面的常用词作为例外消除之后\",{\"2\":{\"145\":1}}],[\"我们先定义两个真正的true\",{\"2\":{\"88\":1}}],[\"我们先生成一下训练和测试样本\",{\"2\":{\"51\":1}}],[\"我们想要将一个函数标记为无法使用\",{\"2\":{\"168\":1}}],[\"我们想去用梯度下降法\",{\"2\":{\"88\":1}}],[\"我们想提取边缘性或者其他特性\",{\"2\":{\"82\":1}}],[\"我们上面得知了一个二维图像的卷积形式\",{\"2\":{\"82\":1}}],[\"我们完成了二维卷积层conv2d的大致推导\",{\"2\":{\"71\":1}}],[\"我们拿着这个固定的方框\",{\"2\":{\"71\":1}}],[\"我们都有\",{\"2\":{\"71\":1}}],[\"我们将state\",{\"2\":{\"283\":1}}],[\"我们将推理过程优化为如下过程\",{\"2\":{\"278\":1}}],[\"我们将其拆解\",{\"2\":{\"263\":1}}],[\"我们将其归一化\",{\"2\":{\"71\":1}}],[\"我们将创建一个长度为\",{\"2\":{\"255\":1}}],[\"我们将比较cnn\",{\"2\":{\"202\":1}}],[\"我们将词元序列输入注意力池化中\",{\"2\":{\"186\":1}}],[\"我们将高斯核带入注意力汇聚公式\",{\"2\":{\"51\":1}}],[\"我们可以对比一下non\",{\"2\":{\"269\":1}}],[\"我们可以写出这样的代码\",{\"2\":{\"267\":1}}],[\"我们可以看到输出的维度为\",{\"2\":{\"255\":1}}],[\"我们可以看出\",{\"2\":{\"230\":1}}],[\"我们可以看出两点性质\",{\"2\":{\"108\":1}}],[\"我们可以想到独热编码\",{\"2\":{\"255\":1}}],[\"我们可以从每一层的shape中看出是怎么处理的\",{\"2\":{\"247\":1}}],[\"我们可以指定汇聚层的填充和步幅\",{\"2\":{\"239\":1}}],[\"我们可以近似看为\",{\"2\":{\"236\":1}}],[\"我们可以使用全连接层来实现\",{\"2\":{\"203\":1}}],[\"我们可以使用动态规划来精确地计算结果\",{\"2\":{\"103\":1}}],[\"我们可以在输入表示中添加位置编码来注入绝对的或者相对的位置信息\",{\"2\":{\"202\":1}}],[\"我们可以直接使用triton\",{\"2\":{\"197\":1}}],[\"我们可以直接返回这个枚举的底层类型\",{\"2\":{\"154\":1}}],[\"我们可以更清晰地使用链式法则来逐步回溯\",{\"2\":{\"180\":1}}],[\"我们可以用独立学习得到的\",{\"2\":{\"159\":1}}],[\"我们可以实现一个constexpr函数\",{\"2\":{\"154\":1}}],[\"我们可以实现如下softmax函数\",{\"2\":{\"152\":1}}],[\"我们可以通过下面的方法来访问数据\",{\"2\":{\"154\":1}}],[\"我们可以求得它的梯度\",{\"2\":{\"137\":1}}],[\"我们可以将其推理理解为\",{\"2\":{\"278\":1}}],[\"我们可以将其看做是在每个像素位置应用的\",{\"2\":{\"203\":1}}],[\"我们可以将其划分为两种类型\",{\"2\":{\"133\":1}}],[\"我们可以将每个通道看作对不同特征的响应\",{\"2\":{\"187\":1}}],[\"我们可以将\",{\"2\":{\"137\":1}}],[\"我们可以自己定制属于自己的torch\",{\"2\":{\"126\":1}}],[\"我们可以计算一下它的梯度\",{\"2\":{\"123\":1}}],[\"我们可以发现\",{\"2\":{\"103\":1}}],[\"我们可以构建一个更深的网络\",{\"2\":{\"92\":1}}],[\"我们可以把通道想象成一个特征\",{\"2\":{\"82\":1}}],[\"我们可以简单利用下标的变换获得下面的公式\",{\"2\":{\"71\":1}}],[\"我们可以利用上述两个特点来改进多层感知机\",{\"2\":{\"71\":1}}],[\"我们有如下公式\",{\"2\":{\"71\":1}}],[\"我们就可以使用梯度下降法\",{\"2\":{\"67\":1}}],[\"我们的b一般就是weight\",{\"2\":{\"263\":1}}],[\"我们的上下文变量\",{\"2\":{\"115\":1}}],[\"我们的目的仍然是计算scale\",{\"2\":{\"223\":1}}],[\"我们的目的是图像识别\",{\"2\":{\"82\":1}}],[\"我们的目标就是让j\",{\"2\":{\"48\":1}}],[\"我们的特征现在是平移不变的\",{\"2\":{\"71\":1}}],[\"我们的神经网络应该对其具有相似的\",{\"2\":{\"60\":1}}],[\"我们以图像识别为例\",{\"2\":{\"60\":1}}],[\"我们给出一个注意力权重\",{\"2\":{\"51\":1}}],[\"我们调整一下\",{\"2\":{\"51\":1}}],[\"我会去记录我学习过程中的一些困惑\",{\"2\":{\"2\":1}}],[\"w^\",{\"2\":{\"278\":4}}],[\"w^x=swsxwintxint−swzwsxxint−swsxzxwint+swzwsxzx\",{\"2\":{\"271\":1}}],[\"w^x=sw\",{\"2\":{\"271\":1}}],[\"wx​=sw​sx​wint​xint​−sw​zw​sx​xint​−sw​sx​zx​wint​+sw​zw​sx​zx​\",{\"2\":{\"271\":1}}],[\"wx​=sw​\",{\"2\":{\"271\":1}}],[\"wn​hn−1​+bn​\",{\"2\":{\"266\":1}}],[\"wnhn−1+bn\",{\"2\":{\"266\":1}}],[\"wn×c×h×w\",{\"2\":{\"55\":1}}],[\"wsgi\",{\"2\":{\"256\":2}}],[\"wsgi的master进程先通过unix\",{\"2\":{\"256\":1}}],[\"wdh​\",{\"2\":{\"230\":1}}],[\"wdhw\",{\"2\":{\"230\":1}}],[\"wco​⋅ci​⋅kh​⋅kw​\",{\"2\":{\"187\":1}}],[\"wci​⋅kh​⋅kw​\",{\"2\":{\"174\":1,\"187\":1}}],[\"wgmma\",{\"0\":{\"183\":1},\"2\":{\"197\":1}}],[\"wow\",{\"2\":{\"225\":1,\"259\":1}}],[\"wo​​h1​⋮hh​​​∈rpo​\",{\"2\":{\"159\":1}}],[\"wo​∈rpo​∗hpv​\",{\"2\":{\"159\":1}}],[\"wo\",{\"2\":{\"159\":1}}],[\"wo∈rpo∗hpvw\",{\"2\":{\"159\":1}}],[\"worker接受到unix\",{\"2\":{\"256\":1}}],[\"worker进程在启动的时候调了run函数\",{\"2\":{\"256\":1}}],[\"worker进程\",{\"2\":{\"256\":1}}],[\"workspacefolder\",{\"2\":{\"169\":2}}],[\"world\",{\"2\":{\"100\":4,\"122\":1,\"135\":1}}],[\"word\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1,\"100\":3,\"117\":2}}],[\"wordpress\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"w∈r784∗10\",{\"2\":{\"152\":1}}],[\"wpw​\",{\"2\":{\"144\":1}}],[\"w4\",{\"2\":{\"112\":3}}],[\"w3\",{\"2\":{\"112\":2}}],[\"w2​+xout​\",{\"2\":{\"259\":1}}],[\"w2+xoutx\",{\"2\":{\"259\":1}}],[\"w2先于r2\",{\"2\":{\"205\":1}}],[\"w2\",{\"2\":{\"112\":3,\"205\":2,\"278\":2}}],[\"w1先于r1\",{\"2\":{\"205\":1}}],[\"w1\",{\"2\":{\"112\":3,\"205\":2,\"278\":2}}],[\"whh​\",{\"2\":{\"230\":1}}],[\"whhw\",{\"2\":{\"230\":1}}],[\"whq​\",{\"2\":{\"230\":1}}],[\"whqw\",{\"2\":{\"230\":1}}],[\"white\",{\"2\":{\"179\":2}}],[\"where\",{\"2\":{\"140\":1}}],[\"when\",{\"2\":{\"103\":3,\"128\":2}}],[\"wha\",{\"2\":{\"128\":2}}],[\"what\",{\"2\":{\"68\":2}}],[\"writing\",{\"2\":{\"100\":3}}],[\"wv\",{\"2\":{\"278\":2}}],[\"wv​∈rh\",{\"2\":{\"81\":1}}],[\"wv∈rh\",{\"2\":{\"81\":1}}],[\"wk\",{\"2\":{\"278\":2}}],[\"wk​∈rh∗k\",{\"2\":{\"81\":1}}],[\"wk∈rh∗k\",{\"2\":{\"81\":1}}],[\"wq\",{\"2\":{\"278\":2}}],[\"wq​∈rh∗q\",{\"2\":{\"81\":1}}],[\"wq​q+wk​k\",{\"2\":{\"81\":1}}],[\"wq∈rh∗q\",{\"2\":{\"81\":1}}],[\"wqq+wkk\",{\"2\":{\"81\":1}}],[\"www\",{\"2\":{\"71\":1}}],[\"w是一个可学习的标量参数\",{\"2\":{\"59\":1}}],[\"wint​−zw​\",{\"2\":{\"271\":1}}],[\"wint−zw\",{\"2\":{\"271\":1}}],[\"wint8=clip\",{\"2\":{\"262\":2}}],[\"wint8=round\",{\"2\":{\"262\":2}}],[\"wint8\",{\"2\":{\"262\":2}}],[\"widehat\",{\"2\":{\"271\":2}}],[\"width=\",{\"2\":{\"185\":1}}],[\"width\",{\"2\":{\"185\":3,\"269\":1,\"273\":1}}],[\"widget\",{\"2\":{\"112\":17}}],[\"wi\",{\"2\":{\"159\":12}}],[\"wise\",{\"0\":{\"110\":1},\"2\":{\"110\":1,\"138\":1,\"153\":1,\"193\":3}}],[\"wisi\",{\"2\":{\"57\":2,\"68\":3}}],[\"without\",{\"2\":{\"263\":1}}],[\"within\",{\"2\":{\"110\":1,\"193\":1,\"260\":1}}],[\"with\",{\"0\":{\"183\":1,\"279\":1},\"2\":{\"57\":2,\"68\":3,\"88\":3,\"100\":1,\"117\":1,\"138\":1,\"140\":1,\"152\":1,\"153\":1,\"185\":2,\"193\":2,\"247\":2,\"263\":1,\"285\":1}}],[\"wikipedia\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"we\",{\"2\":{\"263\":1,\"269\":2,\"273\":2}}],[\"weak\",{\"2\":{\"254\":2}}],[\"weighted\",{\"2\":{\"285\":2}}],[\"weight和activation经过量化后\",{\"2\":{\"271\":1}}],[\"weight与activation的分离\",{\"2\":{\"263\":1}}],[\"weightscale\",{\"2\":{\"262\":2}}],[\"weights的形状\",{\"2\":{\"81\":1}}],[\"weights的形状为\",{\"2\":{\"59\":2}}],[\"weights\",{\"2\":{\"59\":4,\"61\":5,\"81\":2,\"91\":2,\"103\":2,\"115\":6,\"247\":2,\"285\":7}}],[\"weight\",{\"2\":{\"55\":1,\"59\":1,\"88\":1,\"103\":1,\"130\":6,\"140\":1,\"223\":1,\"247\":2,\"262\":14,\"271\":2,\"285\":2}}],[\"welford算法\",{\"2\":{\"38\":1}}],[\"w\",{\"2\":{\"55\":5,\"59\":11,\"71\":3,\"81\":13,\"88\":16,\"95\":4,\"97\":8,\"130\":5,\"144\":5,\"152\":7,\"159\":7,\"173\":8,\"174\":1,\"193\":8,\"197\":1,\"203\":3,\"229\":4,\"230\":1,\"255\":12,\"259\":3,\"266\":2,\"269\":2,\"271\":14,\"273\":2,\"278\":13}}],[\"waits\",{\"2\":{\"282\":1}}],[\"wait其实就是check当前这个phase是否结束\",{\"2\":{\"260\":1}}],[\"waiting\",{\"2\":{\"260\":1}}],[\"wait\",{\"2\":{\"252\":1,\"260\":5,\"265\":2,\"279\":6,\"282\":12}}],[\"warm\",{\"2\":{\"261\":1}}],[\"warpgourp\",{\"2\":{\"282\":1}}],[\"warpgroup\",{\"2\":{\"260\":1,\"282\":16}}],[\"warpid\",{\"2\":{\"282\":2}}],[\"warps>\",{\"2\":{\"260\":1}}],[\"warps=w\",{\"2\":{\"197\":1}}],[\"warp\",{\"2\":{\"248\":1,\"260\":1,\"265\":1,\"269\":2,\"273\":2,\"282\":5}}],[\"warning\",{\"2\":{\"90\":5,\"100\":9}}],[\"watson核回归是一个非参数模型\",{\"2\":{\"51\":1}}],[\"waston核回归\",{\"2\":{\"51\":1}}],[\"世界上最流行的博客平台\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"用流程图来表示就是下面这样\",{\"2\":{\"278\":1}}],[\"用作nginx\",{\"2\":{\"256\":1}}],[\"用gpu训练模型\",{\"2\":{\"247\":1}}],[\"用encoder的最终隐状态初始化decoder的隐状态\",{\"2\":{\"143\":1}}],[\"用两个\",{\"2\":{\"127\":1}}],[\"用双引号把\",{\"2\":{\"113\":1}}],[\"用\",{\"2\":{\"103\":1,\"187\":1}}],[\"用当前的均值和方差做标准化\",{\"2\":{\"96\":1}}],[\"用来获得输入序列中每个词元的特征向量\",{\"2\":{\"283\":1}}],[\"用来解决变长输入输出问题\",{\"2\":{\"283\":1}}],[\"用来表示上一层到这一层的变化\",{\"2\":{\"230\":1}}],[\"用来不断地返回训练数据\",{\"2\":{\"188\":1}}],[\"用来构建单标签多分类任务的输出\",{\"2\":{\"137\":1}}],[\"用来生成数据\",{\"2\":{\"88\":1}}],[\"用来作为一种网络内容的写作用语言\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"用一个卷积核来识别\",{\"2\":{\"82\":1}}],[\"用于序列到序列学习的循环神经网络解码器\",{\"2\":{\"283\":1}}],[\"用于序列到序列学习的循环神经网络编码器\",{\"2\":{\"283\":1}}],[\"用于当我们只关心和的梯度的时候\",{\"2\":{\"166\":1}}],[\"用于在其代码块内关闭梯度计算\",{\"2\":{\"88\":1}}],[\"用于在指定的维度上插入一维\",{\"2\":{\"59\":1}}],[\"用于编写说明文档\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"用于扩展\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"用途\",{\"0\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1},\"1\":{\"17\":1,\"24\":1,\"28\":1,\"29\":1,\"33\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"内异步接受请求\",{\"2\":{\"256\":1}}],[\"内观察到的实际词元\",{\"2\":{\"249\":1}}],[\"内存操作数\",{\"2\":{\"248\":1}}],[\"内存模型可以通过操作可见性顺序\",{\"2\":{\"205\":1}}],[\"内存一致性模型其实是存在于cpp中的概念\",{\"2\":{\"205\":1}}],[\"内存占用低\",{\"2\":{\"88\":1}}],[\"内存占用是模型运行时\",{\"2\":{\"55\":1}}],[\"内存占用\",{\"2\":{\"55\":2}}],[\"内容\",{\"2\":{\"113\":1}}],[\"内容水印\",{\"0\":{\"9\":1},\"1\":{\"14\":1,\"22\":1,\"29\":1,\"37\":1}}],[\"内聚合特征即可\",{\"2\":{\"71\":1}}],[\"内部链接\",{\"0\":{\"32\":1},\"1\":{\"41\":1}}],[\"内部和外部链接都会被特殊处理\",{\"2\":{\"25\":1}}],[\"内嵌\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"内嵌入训练\",{\"2\":{\"1\":1}}],[\"扩展\",{\"0\":{\"7\":1},\"1\":{\"11\":1,\"18\":1,\"25\":1,\"32\":1,\"41\":1,\"50\":1,\"58\":1,\"69\":1,\"80\":1,\"90\":1,\"100\":1,\"114\":1,\"128\":1,\"142\":1,\"157\":1,\"172\":1,\"185\":1,\"200\":1,\"215\":1}}],[\"gl\",{\"2\":{\"269\":12,\"273\":8}}],[\"global\",{\"2\":{\"163\":1,\"254\":2,\"265\":10,\"269\":4,\"273\":2,\"282\":4}}],[\"g←min\",{\"2\":{\"266\":1}}],[\"g←min⁡\",{\"2\":{\"266\":1}}],[\"gqa\",{\"0\":{\"198\":1}}],[\"gil是一种粗粒度的锁\",{\"2\":{\"163\":1}}],[\"gil\",{\"2\":{\"163\":1}}],[\"github风格的表格\",{\"0\":{\"50\":1}}],[\"github\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"15\":2,\"19\":1,\"100\":6,\"106\":4}}],[\"g\",{\"2\":{\"103\":1,\"248\":1,\"266\":5}}],[\"generic\",{\"2\":{\"269\":3,\"273\":6,\"279\":1}}],[\"generate\",{\"2\":{\"153\":1,\"167\":2,\"193\":3}}],[\"gelu\",{\"2\":{\"222\":7,\"259\":1,\"278\":2}}],[\"get模板实参所需要的\",{\"2\":{\"154\":1}}],[\"getvalue\",{\"2\":{\"118\":4}}],[\"getitem\",{\"2\":{\"117\":2,\"152\":1}}],[\"getting\",{\"2\":{\"100\":1}}],[\"get\",{\"2\":{\"100\":1,\"103\":2,\"113\":4,\"117\":1,\"154\":4,\"197\":2,\"213\":2,\"255\":4,\"261\":3,\"269\":1,\"273\":1}}],[\"gemm的实现\",{\"2\":{\"197\":1}}],[\"gemm\",{\"0\":{\"169\":1,\"170\":1,\"183\":1,\"197\":1},\"1\":{\"183\":1,\"197\":1},\"2\":{\"15\":4,\"197\":7}}],[\"gather\",{\"2\":{\"245\":1}}],[\"gate\",{\"2\":{\"61\":2}}],[\"gamma$\",{\"2\":{\"225\":1}}],[\"gamma\",{\"2\":{\"96\":4}}],[\"gpu只支持int8\",{\"2\":{\"271\":1}}],[\"gpu利用率\",{\"2\":{\"268\":1}}],[\"gpu利用率一般在\",{\"2\":{\"268\":1}}],[\"gpu峰值flops\",{\"2\":{\"268\":1}}],[\"gpu数\",{\"2\":{\"268\":1}}],[\"gpu3\",{\"2\":{\"252\":2}}],[\"gpu2\",{\"2\":{\"252\":1}}],[\"gpu1\",{\"2\":{\"252\":1}}],[\"gpu0\",{\"2\":{\"252\":2}}],[\"gpu环境机器上可以run起来\",{\"2\":{\"169\":1}}],[\"gpu机器\",{\"2\":{\"169\":1}}],[\"gpu算子加速库\",{\"2\":{\"66\":1}}],[\"gpu\",{\"0\":{\"235\":1},\"1\":{\"245\":1,\"252\":1,\"258\":1},\"2\":{\"63\":1,\"66\":1,\"247\":3}}],[\"guide2\",{\"2\":{\"197\":1}}],[\"guide\",{\"2\":{\"32\":1,\"197\":2}}],[\"googlenet\",{\"0\":{\"86\":1},\"2\":{\"86\":2}}],[\"google\",{\"2\":{\"24\":2,\"36\":2,\"37\":2,\"42\":2,\"113\":17}}],[\"gru以张量作为隐状态\",{\"2\":{\"277\":1}}],[\"gru是个张量\",{\"2\":{\"270\":1}}],[\"gru\",{\"2\":{\"115\":1,\"283\":2,\"285\":1}}],[\"grutatext\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"great\",{\"2\":{\"68\":2}}],[\"green\",{\"2\":{\"68\":3}}],[\"grad本身也就没用了\",{\"2\":{\"213\":1}}],[\"grad=4∗\",{\"2\":{\"166\":2}}],[\"grad=true\",{\"2\":{\"59\":1,\"88\":2,\"140\":8,\"151\":1,\"152\":4}}],[\"gradient\",{\"2\":{\"166\":3}}],[\"grad就会等于\",{\"2\":{\"151\":1}}],[\"grad之中\",{\"2\":{\"151\":1}}],[\"grad这个字段就会存储x0的梯度\",{\"2\":{\"151\":1}}],[\"grad为none\",{\"2\":{\"151\":1}}],[\"grad默认为false\",{\"2\":{\"140\":1}}],[\"grad\",{\"2\":{\"59\":1,\"88\":6,\"96\":1,\"103\":1,\"130\":2,\"140\":6,\"151\":5,\"152\":1,\"166\":1,\"181\":1,\"193\":1,\"207\":1,\"213\":5,\"247\":3,\"252\":1,\"255\":1,\"266\":4,\"270\":3,\"285\":3}}],[\"graph层面可以做一些算子fusion\",{\"2\":{\"23\":1}}],[\"graph计算图层面优化\",{\"2\":{\"23\":1}}],[\"group来等待\",{\"2\":{\"282\":1}}],[\"groups\",{\"2\":{\"279\":1,\"282\":1}}],[\"groupgemm\",{\"2\":{\"61\":1}}],[\"group\",{\"2\":{\"15\":1,\"197\":12,\"257\":1,\"265\":6,\"269\":1,\"273\":3,\"279\":6,\"282\":1}}],[\"gt\",{\"0\":{\"254\":1},\"2\":{\"15\":5,\"17\":5,\"28\":5,\"29\":5,\"33\":5,\"40\":4,\"57\":3,\"68\":2,\"79\":5,\"108\":6,\"112\":1,\"127\":2,\"135\":1,\"141\":1,\"143\":2,\"156\":1,\"174\":3,\"214\":1,\"251\":2,\"262\":2,\"265\":1,\"272\":6,\"273\":2}}],[\"p1\",{\"2\":{\"260\":3}}],[\"p⋅qp\",{\"2\":{\"229\":2}}],[\"p∈rn∗d\",{\"2\":{\"202\":2}}],[\"png\",{\"2\":{\"185\":1}}],[\"pq​=pk​=pv​=ho​po​​\",{\"2\":{\"173\":1}}],[\"pq=pk=pv=pohop\",{\"2\":{\"173\":1}}],[\"py\",{\"2\":{\"169\":1}}],[\"pytorch模型量化\",{\"0\":{\"223\":1}}],[\"pytorch常用函数以及方法\",{\"0\":{\"134\":1},\"1\":{\"148\":1,\"164\":1,\"178\":1,\"191\":1,\"207\":1,\"220\":1,\"232\":1,\"243\":1}}],[\"pytorch中的梯度计算\",{\"0\":{\"136\":1},\"1\":{\"151\":1,\"166\":1,\"180\":1}}],[\"pytorch中的梯度\",{\"2\":{\"88\":1}}],[\"pytorch\",{\"0\":{\"121\":1,\"126\":1},\"1\":{\"140\":1},\"2\":{\"1\":1,\"88\":1}}],[\"python中\",{\"2\":{\"231\":1}}],[\"python中多线程和async\",{\"0\":{\"120\":1},\"1\":{\"133\":1,\"147\":1,\"163\":1,\"177\":1,\"190\":1,\"206\":1,\"219\":1,\"231\":1,\"242\":1,\"250\":1,\"256\":1}}],[\"python多线程的表现甚至差于串行\",{\"2\":{\"177\":1}}],[\"python的多线程对于io密集型任务较为友好\",{\"2\":{\"177\":1}}],[\"python3\",{\"2\":{\"169\":3}}],[\"python八股速记\",{\"2\":{\"1\":1}}],[\"python\",{\"0\":{\"111\":1},\"2\":{\"1\":1}}],[\"pw=kw−1p\",{\"2\":{\"144\":1}}],[\"pwp\",{\"2\":{\"144\":1}}],[\"phase\",{\"2\":{\"282\":4}}],[\"phases\",{\"2\":{\"263\":1}}],[\"phi20ϕ\",{\"2\":{\"246\":1}}],[\"phi2ϕ\",{\"2\":{\"246\":1}}],[\"phiϕ\",{\"2\":{\"246\":2}}],[\"phi\",{\"2\":{\"230\":2,\"253\":1,\"266\":1}}],[\"ph=kh−1p\",{\"2\":{\"144\":1}}],[\"php\",{\"2\":{\"144\":1}}],[\"ptx内联的形式\",{\"2\":{\"248\":1}}],[\"ptx\",{\"0\":{\"240\":1},\"1\":{\"248\":1,\"254\":1,\"260\":1,\"265\":1,\"269\":1,\"273\":1,\"276\":1,\"279\":1,\"282\":1}}],[\"ptp\",{\"2\":{\"137\":1}}],[\"ptr\",{\"2\":{\"104\":5,\"118\":5,\"122\":2,\"254\":1,\"260\":6,\"269\":16,\"273\":21,\"279\":4}}],[\"p=softmax\",{\"2\":{\"137\":2}}],[\"p=0\",{\"2\":{\"86\":1}}],[\"pm\",{\"2\":{\"128\":2}}],[\"pe\",{\"2\":{\"124\":6,\"193\":6}}],[\"perplexity\",{\"2\":{\"270\":1}}],[\"per\",{\"2\":{\"176\":3,\"257\":5,\"259\":6,\"267\":1,\"269\":7,\"273\":7}}],[\"performs\",{\"2\":{\"279\":1}}],[\"perform\",{\"2\":{\"97\":1,\"193\":1}}],[\"permute之后shape是\",{\"2\":{\"285\":1}}],[\"permute之后会将step提到前面\",{\"2\":{\"283\":1}}],[\"permute\",{\"2\":{\"61\":1,\"115\":4,\"173\":2,\"220\":1,\"283\":3,\"285\":1}}],[\"permalink\",{\"2\":{\"25\":1,\"32\":1}}],[\"persistent\",{\"2\":{\"15\":1,\"197\":1}}],[\"plume\",{\"2\":{\"142\":2,\"185\":1}}],[\"please\",{\"2\":{\"141\":1}}],[\"pl\",{\"2\":{\"113\":1}}],[\"pj​−1\",{\"2\":{\"137\":1}}],[\"pj​⟺xi​\",{\"2\":{\"108\":1}}],[\"pj−1\",{\"2\":{\"137\":1}}],[\"pj⟺xi\",{\"2\":{\"108\":1}}],[\"px4\",{\"2\":{\"106\":1}}],[\"public\",{\"2\":{\"104\":1,\"112\":2,\"118\":1}}],[\"p>please\",{\"2\":{\"141\":1}}],[\"p>a\",{\"2\":{\"141\":2}}],[\"p>use\",{\"2\":{\"141\":1}}],[\"p>here\",{\"2\":{\"79\":1}}],[\"p>this\",{\"2\":{\"79\":1}}],[\"p>magic\",{\"2\":{\"68\":1}}],[\"p>\",{\"2\":{\"68\":2,\"79\":2,\"113\":6,\"141\":8,\"185\":1}}],[\"p>bird\",{\"2\":{\"68\":1}}],[\"policy>\",{\"2\":{\"269\":1,\"273\":1}}],[\"policy\",{\"2\":{\"254\":2,\"269\":5,\"273\":5}}],[\"pool\",{\"2\":{\"229\":2}}],[\"pool2d\",{\"2\":{\"229\":7}}],[\"pooling层输出通道与输入通道相同\",{\"2\":{\"229\":1}}],[\"pooling\",{\"2\":{\"23\":1,\"229\":2}}],[\"pow\",{\"2\":{\"202\":1}}],[\"pop\",{\"2\":{\"173\":1}}],[\"pos\",{\"2\":{\"176\":3}}],[\"positionalencoding\",{\"2\":{\"124\":2,\"167\":1,\"193\":3,\"202\":2}}],[\"positional\",{\"0\":{\"124\":1},\"2\":{\"124\":1,\"167\":3,\"193\":4}}],[\"position\",{\"0\":{\"110\":1},\"2\":{\"110\":1,\"124\":4,\"138\":1,\"153\":1,\"193\":7}}],[\"positionwisefeedforward\",{\"2\":{\"110\":2,\"138\":1,\"153\":1,\"193\":4}}],[\"positionwise\",{\"2\":{\"87\":1}}],[\"posuere\",{\"2\":{\"57\":2,\"68\":3}}],[\"point\",{\"2\":{\"55\":1,\"150\":1,\"223\":1,\"251\":1,\"259\":1,\"262\":1}}],[\"pipeline\",{\"2\":{\"263\":2}}],[\"pipline\",{\"0\":{\"213\":1},\"2\":{\"213\":3}}],[\"pid\",{\"2\":{\"197\":3}}],[\"pi​−pi2​\",{\"2\":{\"123\":2}}],[\"pi​=softmax\",{\"2\":{\"108\":1}}],[\"pi−pi2\",{\"2\":{\"123\":3}}],[\"pi=softmax\",{\"2\":{\"108\":1}}],[\"pi\",{\"2\":{\"51\":1,\"108\":1,\"128\":4,\"202\":4}}],[\"p\",{\"2\":{\"17\":2,\"28\":2,\"29\":2,\"33\":2,\"68\":1,\"103\":32,\"108\":1,\"123\":23,\"131\":17,\"137\":6,\"144\":2,\"159\":6,\"173\":3,\"175\":1,\"185\":3,\"202\":8,\"217\":4,\"229\":8,\"249\":2,\"252\":2,\"254\":1,\"266\":5}}],[\"pragma\",{\"2\":{\"269\":1,\"273\":1}}],[\"private\",{\"2\":{\"104\":1,\"112\":1,\"118\":1,\"260\":1}}],[\"printf\",{\"2\":{\"269\":1}}],[\"prints\",{\"2\":{\"100\":2}}],[\"print\",{\"2\":{\"59\":1,\"61\":1,\"81\":1,\"86\":1,\"88\":2,\"103\":1,\"117\":2,\"130\":2,\"140\":3,\"144\":1,\"151\":3,\"174\":1,\"181\":1,\"187\":1,\"193\":1,\"229\":1,\"247\":4,\"255\":1,\"261\":1,\"267\":1,\"270\":4,\"283\":2,\"285\":1}}],[\"prompt\",{\"2\":{\"284\":1}}],[\"prompt的场景\",{\"2\":{\"284\":1}}],[\"prompting的技术\",{\"2\":{\"284\":1}}],[\"prompting\",{\"0\":{\"284\":1}}],[\"processes\",{\"2\":{\"263\":1}}],[\"processing\",{\"2\":{\"110\":1,\"193\":1}}],[\"projections\",{\"2\":{\"159\":1}}],[\"propto\",{\"2\":{\"145\":1}}],[\"proportional\",{\"2\":{\"128\":2}}],[\"property\",{\"2\":{\"115\":2,\"117\":2}}],[\"proxy\",{\"2\":{\"106\":1,\"273\":2,\"279\":1}}],[\"prod\",{\"2\":{\"103\":2,\"131\":1}}],[\"product\",{\"2\":{\"91\":1,\"97\":3,\"193\":3}}],[\"probs\",{\"2\":{\"97\":2,\"193\":2}}],[\"probabilities\",{\"2\":{\"97\":1,\"193\":1}}],[\"provided\",{\"2\":{\"97\":1,\"193\":1}}],[\"profile方法\",{\"2\":{\"15\":1}}],[\"prev\",{\"2\":{\"282\":1}}],[\"previous\",{\"2\":{\"279\":1,\"282\":1}}],[\"preventing\",{\"2\":{\"97\":1,\"193\":1}}],[\"pred的形状\",{\"2\":{\"285\":1}}],[\"preds步\",{\"2\":{\"261\":1}}],[\"preds\",{\"2\":{\"261\":2}}],[\"predict\",{\"2\":{\"261\":2,\"270\":5}}],[\"prediction\",{\"0\":{\"62\":1}}],[\"pred\",{\"2\":{\"260\":1,\"285\":3}}],[\"prefill阶段\",{\"2\":{\"278\":1}}],[\"prefix\",{\"2\":{\"261\":4,\"270\":2}}],[\"prefix=\",{\"2\":{\"169\":1}}],[\"prefetch\",{\"2\":{\"254\":1,\"265\":1}}],[\"pre>\",{\"2\":{\"79\":6}}],[\"pre\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1,\"79\":1,\"197\":2}}],[\"ppl\",{\"2\":{\"270\":3}}],[\"pp来说\",{\"2\":{\"252\":1}}],[\"pp调度\",{\"2\":{\"252\":2}}],[\"ppp\",{\"2\":{\"249\":1}}],[\"pp进一步拆分transformer\",{\"2\":{\"245\":1}}],[\"pp\",{\"2\":{\"245\":1,\"252\":4,\"263\":1}}],[\"pp的混合并行策略\",{\"2\":{\"235\":1}}],[\"pp部分\",{\"2\":{\"213\":1}}],[\"ppo\",{\"0\":{\"65\":1,\"77\":1},\"1\":{\"77\":1},\"2\":{\"15\":1}}],[\"ppt\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"pass\",{\"2\":{\"213\":4}}],[\"paper\",{\"0\":{\"179\":1},\"2\":{\"179\":2,\"222\":1,\"235\":1,\"263\":1}}],[\"paper阅读记录\",{\"0\":{\"158\":1}}],[\"papers\",{\"0\":{\"155\":1,\"208\":1}}],[\"path=\",{\"2\":{\"169\":1}}],[\"path的方法可能不适用\",{\"2\":{\"169\":1}}],[\"path\",{\"2\":{\"113\":1,\"156\":2,\"169\":3}}],[\"page\",{\"0\":{\"201\":1},\"2\":{\"113\":1}}],[\"padding主要依照kernel\",{\"2\":{\"144\":1}}],[\"padding代表上下左右都添加1行\",{\"2\":{\"144\":1}}],[\"padding=\",{\"2\":{\"144\":1,\"229\":1}}],[\"padding=3\",{\"2\":{\"86\":1}}],[\"padding=2\",{\"2\":{\"75\":1,\"86\":1,\"247\":2}}],[\"padding=0\",{\"2\":{\"75\":1}}],[\"padding=1\",{\"2\":{\"63\":1,\"75\":1,\"86\":5,\"144\":2,\"229\":2}}],[\"padding\",{\"2\":{\"75\":2,\"97\":1,\"193\":1}}],[\"parity\",{\"2\":{\"260\":1}}],[\"parish\",{\"2\":{\"68\":2}}],[\"part3\",{\"2\":{\"183\":1}}],[\"part2\",{\"2\":{\"183\":1}}],[\"part1\",{\"2\":{\"183\":1}}],[\"part\",{\"2\":{\"138\":1,\"153\":1,\"193\":2}}],[\"partial\",{\"2\":{\"123\":14,\"128\":8,\"137\":4,\"166\":8}}],[\"parts\",{\"2\":{\"97\":1,\"153\":2,\"193\":3}}],[\"parse\",{\"2\":{\"112\":1}}],[\"param都会成为它的一份copy\",{\"2\":{\"122\":1}}],[\"param\",{\"2\":{\"88\":4,\"122\":20,\"135\":1,\"255\":2,\"266\":2,\"285\":3}}],[\"params=get\",{\"2\":{\"255\":1}}],[\"params\",{\"2\":{\"88\":2,\"255\":12,\"266\":5,\"270\":1}}],[\"parameter参与计算\",{\"2\":{\"140\":1}}],[\"parameters\",{\"2\":{\"59\":1,\"88\":1,\"103\":1,\"181\":1,\"193\":1,\"247\":2,\"266\":1,\"270\":1,\"285\":2}}],[\"parameter\",{\"0\":{\"222\":1},\"2\":{\"59\":1,\"96\":4,\"130\":2}}],[\"paragraphs\",{\"2\":{\"57\":2,\"68\":2}}],[\"paragraph\",{\"2\":{\"17\":2,\"28\":2,\"29\":2,\"33\":2,\"68\":1,\"79\":2}}],[\"parallel已经是时代的眼泪了\",{\"2\":{\"222\":1}}],[\"parallel策略\",{\"2\":{\"222\":1}}],[\"parallel的基石\",{\"2\":{\"222\":1}}],[\"parallel如何实现\",{\"2\":{\"213\":1}}],[\"parallelism\",{\"0\":{\"210\":1},\"1\":{\"222\":1,\"235\":1,\"245\":1,\"252\":1,\"258\":1,\"263\":1},\"2\":{\"263\":3}}],[\"parallel\",{\"0\":{\"245\":1,\"258\":1},\"2\":{\"15\":1,\"61\":1,\"213\":2,\"235\":3,\"245\":1,\"273\":2}}],[\"pair\",{\"2\":{\"63\":3}}],[\"packages\",{\"2\":{\"169\":3}}],[\"package\",{\"2\":{\"15\":1}}],[\"pandoc\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"如高度和宽度\",{\"2\":{\"239\":1}}],[\"如图中橙色映射关系\",{\"2\":{\"230\":1}}],[\"如下是一个作用于3个输入通道与一个输出通道的例子\",{\"2\":{\"203\":1}}],[\"如变量\",{\"2\":{\"119\":1}}],[\"如单词和字符\",{\"2\":{\"117\":1}}],[\"如上图所示\",{\"2\":{\"95\":1}}],[\"如上述例子\",{\"2\":{\"166\":1}}],[\"如上述\",{\"2\":{\"23\":1}}],[\"如果未提及状态\",{\"2\":{\"283\":1}}],[\"如果rnn是双向的\",{\"2\":{\"277\":1}}],[\"如果精度不达标的话\",{\"2\":{\"271\":1}}],[\"如果超出的话就取设定的上下界的值\",{\"2\":{\"262\":1}}],[\"如果设置的bytes数量到达\",{\"2\":{\"260\":1,\"265\":1}}],[\"如果当前mbarrier设置的是warp\",{\"2\":{\"260\":1}}],[\"如果使用tma的话\",{\"2\":{\"273\":1}}],[\"如果使用kv\",{\"2\":{\"253\":1}}],[\"如果使用float16来进行推理\",{\"2\":{\"253\":1}}],[\"如果可以做到多核并行\",{\"2\":{\"231\":1}}],[\"如果没有使用tma\",{\"2\":{\"273\":1}}],[\"如果没有显式声明\",{\"2\":{\"224\":1}}],[\"如果没有内存一致性模型约束\",{\"2\":{\"205\":1}}],[\"如果没有传入valid\",{\"2\":{\"70\":1}}],[\"如果维度不同则广播机制\",{\"2\":{\"191\":1}}],[\"如果直接从这样的结构开始反向传播\",{\"2\":{\"180\":1}}],[\"如果卷积核的窗口形状是\",{\"2\":{\"174\":1}}],[\"如果不满足广播机制就报错\",{\"2\":{\"191\":1}}],[\"如果不使用多进程来运行\",{\"2\":{\"163\":1}}],[\"如果不是所有输入词元都是相关的\",{\"2\":{\"115\":1}}],[\"如果改变了定义\",{\"2\":{\"154\":1}}],[\"如果改成用链接名称的方式写\",{\"2\":{\"113\":1}}],[\"如果\",{\"2\":{\"151\":1}}],[\"如果要标记一小段行内代码\",{\"2\":{\"141\":1}}],[\"如果要在代码内插入反引号\",{\"2\":{\"141\":1}}],[\"如果要在文字前后直接插入普通的星号或底线\",{\"2\":{\"127\":1}}],[\"如果要在列表项目内放进引言\",{\"2\":{\"68\":1}}],[\"如果expr是右值\",{\"2\":{\"122\":1}}],[\"如果expr是左值\",{\"2\":{\"122\":1}}],[\"如果形参是通用引用\",{\"2\":{\"122\":1}}],[\"如果形参是ref\",{\"2\":{\"122\":2}}],[\"如果是用纯\",{\"2\":{\"113\":1}}],[\"如果正常的构造函数\",{\"2\":{\"112\":1}}],[\"如果x不在内存上\",{\"2\":{\"96\":1}}],[\"如果我改变这个参数一点点\",{\"2\":{\"180\":1}}],[\"如果我们的程序不能支持并行\",{\"2\":{\"250\":1}}],[\"如果我们在没有任何压缩的情况下存储序列\",{\"2\":{\"249\":1}}],[\"如果我们当前代码运行机制\",{\"2\":{\"231\":1}}],[\"如果我们使用限域enum来进行声明的话\",{\"2\":{\"154\":1}}],[\"如果我们目标类别是\",{\"2\":{\"137\":1}}],[\"如果我们想让函数接受右值\",{\"2\":{\"150\":1}}],[\"如果我们想生成\",{\"2\":{\"131\":1}}],[\"如果我们想获得软性类别\",{\"2\":{\"95\":1}}],[\"如果我钦定一个x0x\",{\"2\":{\"78\":1}}],[\"如果顺序被随机地重排\",{\"2\":{\"93\":1}}],[\"如果对于pytorch的梯度计算有疑问可以看我的另外一篇文章\",{\"2\":{\"88\":1}}],[\"如果列表项目间用空行分开\",{\"2\":{\"68\":1}}],[\"如果键\",{\"2\":{\"51\":1}}],[\"如果通过\",{\"2\":{\"38\":1}}],[\"如果你已经掌握了单机单卡简单使用pytorch训练model之后\",{\"2\":{\"222\":1}}],[\"如果你想要用星号加在文字旁边的方式来做出强调效果\",{\"2\":{\"214\":1}}],[\"如果你想要在代码块里输入用\",{\"2\":{\"79\":1}}],[\"如果你需要的话\",{\"2\":{\"156\":1}}],[\"如果你有更好的exp实现方式\",{\"2\":{\"140\":1}}],[\"如果你只想导入这个文件的一部分\",{\"2\":{\"114\":1}}],[\"如果你只是想要使用这些符号\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"如果你还想要加上链接的\",{\"2\":{\"113\":1}}],[\"如果你很懒惰\",{\"2\":{\"68\":1}}],[\"如果你很熟悉如何在\",{\"2\":{\"57\":1}}],[\"如果你每行都有缩进\",{\"2\":{\"68\":1}}],[\"如果你的列表标记写成\",{\"2\":{\"68\":1}}],[\"如果你真的想要插入\",{\"2\":{\"40\":1}}],[\"如果你是要链接到同样主机的资源\",{\"2\":{\"113\":1}}],[\"如果你是使用\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"如果你是在\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"如果你要让\",{\"2\":{\"113\":1}}],[\"如果你要链接到\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"如果你要打\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"如何选择\",{\"0\":{\"271\":1}}],[\"如何做量化\",{\"0\":{\"257\":1},\"1\":{\"262\":1}}],[\"如何实现真正意义上的并行\",{\"0\":{\"190\":1}}],[\"如何理解\",{\"0\":{\"78\":1}}],[\"如何解决\",{\"0\":{\"38\":1}}],[\"如何分析整理\",{\"2\":{\"15\":1}}],[\"如\",{\"2\":{\"6\":2,\"13\":2,\"14\":2,\"19\":2}}],[\"如表格\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"等到达之后tx\",{\"2\":{\"260\":1}}],[\"等价于x0=torch\",{\"2\":{\"151\":1}}],[\"等价于\",{\"2\":{\"144\":1}}],[\"等标签\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"等\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1,\"144\":1}}],[\"等等\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"efficient\",{\"0\":{\"235\":1},\"1\":{\"245\":1,\"252\":1,\"258\":1},\"2\":{\"263\":1}}],[\"e>>\",{\"2\":{\"154\":2}}],[\"e>\",{\"2\":{\"154\":6}}],[\"equivalent\",{\"2\":{\"141\":2}}],[\"equation\",{\"2\":{\"128\":2}}],[\"equations\",{\"2\":{\"128\":2}}],[\"e⃗\",{\"2\":{\"128\":1}}],[\"each\",{\"2\":{\"124\":1,\"193\":1,\"213\":1,\"269\":1,\"273\":1}}],[\"eigen\",{\"2\":{\"106\":1}}],[\"error\",{\"2\":{\"100\":7,\"112\":2}}],[\"evaluate\",{\"2\":{\"103\":1,\"152\":1,\"247\":2}}],[\"eval\",{\"2\":{\"81\":1,\"152\":1,\"247\":1,\"283\":2}}],[\"elem\",{\"2\":{\"269\":5,\"273\":5}}],[\"elif\",{\"2\":{\"117\":1,\"229\":1}}],[\"elit\",{\"2\":{\"57\":2,\"68\":4}}],[\"else\",{\"2\":{\"70\":2,\"96\":3,\"117\":1,\"188\":1,\"247\":1,\"255\":1,\"266\":1,\"269\":3,\"270\":4,\"273\":2,\"277\":2,\"282\":1}}],[\"etc\",{\"2\":{\"66\":1}}],[\"ettext\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"eye\",{\"2\":{\"59\":2}}],[\"eye可以生成单位矩阵\",{\"2\":{\"59\":1}}],[\"emphasize\",{\"2\":{\"228\":1}}],[\"em>\",{\"2\":{\"127\":2}}],[\"em>single\",{\"2\":{\"127\":2}}],[\"em\",{\"2\":{\"127\":1,\"214\":1}}],[\"embedded\",{\"2\":{\"167\":4,\"193\":4}}],[\"embedding层的参数量也相同\",{\"2\":{\"225\":1}}],[\"embedding\",{\"2\":{\"115\":3,\"167\":6,\"193\":6,\"225\":1,\"283\":6}}],[\"embed\",{\"2\":{\"115\":5,\"129\":1,\"283\":14}}],[\"emoji\",{\"0\":{\"58\":1},\"2\":{\"58\":1}}],[\"email\",{\"2\":{\"40\":1,\"57\":3}}],[\"emax\",{\"2\":{\"38\":2}}],[\"echo\",{\"2\":{\"57\":1}}],[\"enabling\",{\"2\":{\"263\":1}}],[\"enable\",{\"2\":{\"169\":1}}],[\"enables\",{\"2\":{\"153\":1,\"193\":1}}],[\"enabled\",{\"2\":{\"96\":1}}],[\"envs\",{\"2\":{\"169\":7}}],[\"enumerator\",{\"2\":{\"154\":6}}],[\"enumerate\",{\"2\":{\"117\":1,\"247\":1}}],[\"enum\",{\"0\":{\"154\":1},\"2\":{\"154\":2}}],[\"entropy\",{\"2\":{\"152\":2}}],[\"enter\",{\"2\":{\"40\":1}}],[\"encapsulates\",{\"2\":{\"138\":1,\"193\":1}}],[\"encoded\",{\"2\":{\"141\":2}}],[\"encoderdecoder\",{\"2\":{\"280\":2}}],[\"encoderlayer\",{\"2\":{\"138\":3,\"167\":1,\"193\":4}}],[\"encoder步骤\",{\"0\":{\"129\":1}}],[\"encoder和decoder的运行步骤如下\",{\"2\":{\"115\":1}}],[\"encoder\",{\"0\":{\"30\":1,\"138\":1,\"280\":1},\"2\":{\"87\":1,\"115\":1,\"138\":4,\"153\":5,\"167\":4,\"193\":13,\"212\":1,\"280\":6,\"283\":5}}],[\"encoding\",{\"0\":{\"124\":1},\"2\":{\"124\":1,\"167\":3,\"193\":4}}],[\"enc\",{\"2\":{\"115\":12,\"153\":4,\"167\":6,\"193\":10,\"280\":5,\"283\":2}}],[\"en\",{\"2\":{\"100\":1}}],[\"ensure\",{\"2\":{\"97\":1,\"193\":1}}],[\"end\",{\"2\":{\"79\":2,\"123\":3,\"137\":1,\"143\":1,\"151\":1,\"159\":1,\"222\":1}}],[\"enim\",{\"2\":{\"57\":2,\"68\":3}}],[\"e^\",{\"2\":{\"38\":1,\"108\":2,\"123\":19}}],[\"existing\",{\"2\":{\"263\":1}}],[\"exi∑k=1nexk\",{\"2\":{\"123\":1}}],[\"exi∑k=1nexk−\",{\"2\":{\"123\":1}}],[\"exi∑k=1nexk−e2xi\",{\"2\":{\"123\":1}}],[\"execution\",{\"2\":{\"273\":2}}],[\"exec\",{\"2\":{\"57\":1}}],[\"exe^xex\",{\"2\":{\"38\":1}}],[\"examples\",{\"2\":{\"88\":6,\"247\":1}}],[\"example\",{\"2\":{\"57\":1,\"79\":2,\"113\":13,\"199\":5}}],[\"expected\",{\"2\":{\"279\":1}}],[\"expect\",{\"2\":{\"260\":2,\"279\":2,\"282\":1}}],[\"expert结构最初应该是出现在qwen2\",{\"2\":{\"72\":1}}],[\"experts和local\",{\"2\":{\"72\":1}}],[\"experts\",{\"0\":{\"72\":1},\"2\":{\"61\":7,\"72\":2}}],[\"expert\",{\"2\":{\"61\":20,\"263\":1}}],[\"exp⁡\",{\"2\":{\"249\":1}}],[\"expr\",{\"2\":{\"122\":1}}],[\"export\",{\"2\":{\"100\":20,\"169\":1}}],[\"exp\",{\"2\":{\"51\":4,\"59\":3,\"70\":3,\"124\":1,\"140\":2,\"152\":8,\"193\":1,\"249\":2,\"270\":1}}],[\"extra\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"e\",{\"2\":{\"38\":4,\"128\":9,\"154\":3,\"199\":2}}],[\"eps=1e\",{\"2\":{\"96\":1,\"181\":1,\"193\":1}}],[\"eps\",{\"2\":{\"96\":3}}],[\"epochs\",{\"2\":{\"63\":2,\"88\":4,\"103\":2,\"247\":6,\"270\":3,\"285\":3}}],[\"epoch\",{\"2\":{\"59\":5,\"88\":6,\"103\":3,\"130\":1,\"181\":3,\"193\":3,\"247\":4,\"270\":6,\"285\":4}}],[\"ep\",{\"2\":{\"15\":1}}],[\"它应该允许我们在压缩序列时花费更少的比特\",{\"2\":{\"249\":1}}],[\"它是最早发布的卷积神经网络之一\",{\"2\":{\"247\":1}}],[\"它对应着\",{\"2\":{\"159\":1}}],[\"它的作用有如下两点\",{\"2\":{\"216\":1}}],[\"它的梯度正好是目标分布与预测分布之差\",{\"2\":{\"137\":1}}],[\"它的\",{\"2\":{\"123\":1}}],[\"它的元素可正可负\",{\"2\":{\"108\":1}}],[\"它可以包含多个卷积层\",{\"2\":{\"102\":1}}],[\"它可以使普通文本内容具有一定的格式\",{\"2\":{\"5\":1}}],[\"它们俩的共同点就是\",{\"2\":{\"231\":1}}],[\"它们最大的区别就是\",{\"2\":{\"231\":1}}],[\"它们也存在诸多共同点\",{\"2\":{\"231\":1}}],[\"它们就只会被当成普通的符号\",{\"2\":{\"127\":1}}],[\"它们和\",{\"2\":{\"100\":1}}],[\"它们能让\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"它则会被转换成\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"它不会被转换\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1}}],[\"它能让文件更容易阅读\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"尚不具备\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"脚注\",{\"0\":{\"215\":1},\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"嗯\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"是在每次循环的最后\",{\"2\":{\"282\":1}}],[\"是成正相关的\",{\"2\":{\"275\":1}}],[\"是pytorch中的函数\",{\"2\":{\"267\":1}}],[\"是用户提供的一个包含多个字符的字符串\",{\"2\":{\"261\":1}}],[\"是关于数据搬运的\",{\"2\":{\"254\":1}}],[\"是上述式子的指数形式\",{\"2\":{\"249\":1}}],[\"是时间步\",{\"2\":{\"249\":1}}],[\"是可以被const成员函数改变的\",{\"2\":{\"211\":1}}],[\"是因为我们需要考虑标签\",{\"2\":{\"176\":1}}],[\"是图片参考的名称\",{\"2\":{\"156\":1}}],[\"是int\",{\"2\":{\"150\":2}}],[\"是通过以输入\",{\"2\":{\"144\":1}}],[\"是否是叶子节点\",{\"2\":{\"140\":1}}],[\"是对应给右值的一种静态类型\",{\"2\":{\"119\":1}}],[\"是指不会修改所属类的成员变量的函数\",{\"2\":{\"118\":1}}],[\"是离散值时\",{\"2\":{\"103\":1}}],[\"是从\",{\"2\":{\"103\":1}}],[\"是一种更直接的方法\",{\"2\":{\"166\":1}}],[\"是一种可以使用普通文本编辑器编写的标记语言\",{\"2\":{\"5\":1}}],[\"是一个\",{\"2\":{\"142\":2}}],[\"是一类特殊的神经网络\",{\"2\":{\"102\":1}}],[\"是偏置量\",{\"2\":{\"95\":1}}],[\"是\",{\"2\":{\"88\":1}}],[\"是query与key之间的关系建模\",{\"2\":{\"51\":1}}],[\"是的\",{\"2\":{\"40\":1}}],[\"是为了让它们看起来就像所要表达的意思\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"并在后向传递过程中需要用到的所有张量\",{\"2\":{\"272\":1}}],[\"并将第\",{\"2\":{\"255\":1}}],[\"并将这些偏导数加和\",{\"2\":{\"166\":1}}],[\"并将这个梯度存储在x0\",{\"2\":{\"151\":1}}],[\"并对应2个优化器状态\",{\"2\":{\"246\":1}}],[\"并用混合精度训练来加速训练\",{\"2\":{\"246\":1}}],[\"并用argmax或采样选择下一个单词\",{\"2\":{\"143\":1}}],[\"并非会变成完全意义上的并行\",{\"2\":{\"197\":1}}],[\"并非带有\",{\"2\":{\"119\":1}}],[\"并发也是会导致数据竞争问题\",{\"2\":{\"163\":1}}],[\"并不会直接出现在文件之中\",{\"2\":{\"113\":1}}],[\"并保存在对应的\",{\"2\":{\"25\":1}}],[\"并且编为onehot\",{\"2\":{\"255\":1}}],[\"并且可以做到通信的overlap\",{\"2\":{\"252\":1}}],[\"并且可以在计算图之中创建一个节点\",{\"2\":{\"126\":1}}],[\"并且引入一个新的权重\",{\"2\":{\"230\":1}}],[\"并且gradient\",{\"2\":{\"166\":1}}],[\"并且通过另一个可以学习的线性投影进行变换\",{\"2\":{\"159\":1}}],[\"并且自己来优化对应的函数\",{\"2\":{\"140\":1}}],[\"并且都满足零均值和单位方差\",{\"2\":{\"91\":1}}],[\"并且层中使用了残差连接和层规范化\",{\"2\":{\"87\":1}}],[\"并且禁用偏置项\",{\"2\":{\"81\":1}}],[\"并且给出具体的代码实现\",{\"2\":{\"20\":1}}],[\"并且以\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"并且看起来不会像是由许多标签或是格式指令所构成\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"并经过严谨慎选\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"的shape\",{\"2\":{\"283\":1}}],[\"的tokens\",{\"2\":{\"278\":1}}],[\"的type就是右值引用\",{\"2\":{\"119\":1}}],[\"的逐渐增大\",{\"2\":{\"275\":1}}],[\"的增大\",{\"2\":{\"275\":1}}],[\"的基础指令\",{\"2\":{\"273\":1}}],[\"的线性映射为\",{\"2\":{\"259\":1}}],[\"的加权以及之后\",{\"2\":{\"259\":1}}],[\"的加权平均\",{\"2\":{\"51\":1}}],[\"的全0向量\",{\"2\":{\"255\":1}}],[\"的ptx指令\",{\"2\":{\"254\":1}}],[\"的工具\",{\"2\":{\"249\":1}}],[\"的汇聚层被称之为\",{\"2\":{\"229\":1}}],[\"的条件概率仅取决于前面\",{\"2\":{\"217\":1}}],[\"的写操作\",{\"2\":{\"205\":1}}],[\"的矩阵\",{\"2\":{\"202\":1}}],[\"的权重\",{\"2\":{\"272\":1}}],[\"的权重矩阵\",{\"2\":{\"202\":1}}],[\"的权重就会更大\",{\"2\":{\"51\":1}}],[\"的卷积层\",{\"2\":{\"202\":1}}],[\"的卷积核三维张量\",{\"2\":{\"187\":1}}],[\"的三维张量\",{\"2\":{\"174\":1}}],[\"的形状为\",{\"2\":{\"272\":1}}],[\"的形状\",{\"2\":{\"173\":2,\"283\":2}}],[\"的时候\",{\"2\":{\"166\":1}}],[\"的缘故\",{\"2\":{\"163\":1}}],[\"的计算方式为\",{\"2\":{\"159\":1}}],[\"的偏导数\",{\"2\":{\"151\":1,\"166\":1}}],[\"的变化率\",{\"2\":{\"151\":1}}],[\"的导数在\",{\"2\":{\"151\":1}}],[\"的所有操作\",{\"2\":{\"151\":1}}],[\"的所有元素\",{\"2\":{\"92\":1}}],[\"的英文翻译\",{\"2\":{\"143\":1}}],[\"的运算\",{\"2\":{\"140\":1}}],[\"的组合\",{\"2\":{\"126\":1}}],[\"的梯度为\",{\"2\":{\"123\":1}}],[\"的类型转换表达式\",{\"2\":{\"119\":1}}],[\"的函数调用\",{\"2\":{\"119\":1}}],[\"的行为\",{\"2\":{\"118\":1}}],[\"的上下文变量是注意力集中的输出\",{\"2\":{\"115\":1}}],[\"的参考式链接\",{\"2\":{\"113\":1}}],[\"的更新我们可以递推地使用\",{\"2\":{\"103\":1}}],[\"的代码仓库中\",{\"2\":{\"100\":1}}],[\"的渲染方式相同\",{\"2\":{\"100\":1}}],[\"的索引就应该更新为\",{\"2\":{\"82\":1}}],[\"的模型结构中\",{\"2\":{\"72\":1}}],[\"的范围\",{\"2\":{\"71\":1}}],[\"的值相同与否\",{\"2\":{\"229\":2}}],[\"的值\",{\"2\":{\"71\":1,\"108\":1}}],[\"的注意力权重是通过注意力评分函数\",{\"2\":{\"70\":1}}],[\"的数据中保留的特征\",{\"2\":{\"103\":1}}],[\"的数据\",{\"2\":{\"55\":1,\"103\":1}}],[\"的float32\",{\"2\":{\"55\":2}}],[\"的方法在\",{\"2\":{\"40\":1}}],[\"的默认行为\",{\"2\":{\"25\":1}}],[\"的\",{\"2\":{\"25\":1,\"40\":1,\"142\":2,\"185\":1,\"273\":1}}],[\"的解析器有智慧型判断\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"的开始与结尾标签\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"的文件名保存在软件的目录下面\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"的格式语法只涵盖纯文字可以涵盖的范围\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"的重点在于\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"的语法来插入图片是有一定难度的\",{\"2\":{\"156\":1}}],[\"的语法简洁明了\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"的语法有个主要的目的\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"的语法全由标点符号所组成\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"的功能\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"的列表看起来\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"的目标是实现\",{\"2\":{\"5\":1}}],[\"和序列长度\",{\"2\":{\"275\":1}}],[\"和方差\",{\"2\":{\"272\":1}}],[\"和方括号都会被转成\",{\"2\":{\"141\":1}}],[\"和cp\",{\"2\":{\"265\":1}}],[\"和其余的computation\",{\"2\":{\"263\":1}}],[\"和平均汇聚层\",{\"2\":{\"229\":1}}],[\"和缩放参数\",{\"2\":{\"225\":1}}],[\"和self\",{\"2\":{\"202\":1}}],[\"和值\",{\"2\":{\"159\":1}}],[\"和当前嵌入向量结合\",{\"2\":{\"143\":1}}],[\"和底线\",{\"2\":{\"127\":1}}],[\"和右值引用int\",{\"2\":{\"119\":1}}],[\"和一个\",{\"2\":{\"88\":1}}],[\"和代码相关的写作或是标签语言原始码通常会有已经排版好的代码块\",{\"2\":{\"79\":1}}],[\"和键\",{\"2\":{\"70\":1}}],[\"和多段落的\",{\"2\":{\"40\":1}}],[\"和\",{\"2\":{\"6\":2,\"13\":2,\"14\":2,\"19\":2,\"24\":5,\"36\":5,\"37\":5,\"42\":5,\"49\":3,\"70\":1,\"71\":1,\"79\":2,\"88\":3,\"100\":1,\"112\":2,\"127\":1,\"156\":1,\"212\":1,\"223\":1,\"225\":1,\"229\":2,\"271\":1,\"275\":1}}],[\"run\",{\"2\":{\"269\":1,\"273\":1}}],[\"runtime等等\",{\"2\":{\"169\":1}}],[\"runtime\",{\"2\":{\"169\":1}}],[\"runtime层面主要是运行时对程序进行系统层面的优化\",{\"2\":{\"23\":1}}],[\"rmda实现\",{\"2\":{\"263\":1}}],[\"r^\",{\"2\":{\"230\":2,\"259\":3,\"278\":1,\"283\":1}}],[\"r^qq∈rq\",{\"2\":{\"70\":1}}],[\"round\",{\"2\":{\"262\":5,\"267\":2,\"269\":1,\"273\":1}}],[\"router是一个核心网络结构\",{\"2\":{\"72\":1}}],[\"router\",{\"0\":{\"0\":1,\"72\":1},\"1\":{\"1\":1,\"2\":1},\"2\":{\"61\":1}}],[\"rows\",{\"2\":{\"269\":1,\"273\":1}}],[\"row\",{\"2\":{\"222\":2,\"269\":15,\"273\":12}}],[\"r2\",{\"2\":{\"205\":2}}],[\"r1\",{\"2\":{\"205\":2}}],[\"rho∇×b−c1​∂t∂e​=c4π​j​∇⋅e=4πρ\",{\"2\":{\"128\":1}}],[\"rho$\",{\"2\":{\"128\":1}}],[\"rnn网络\",{\"2\":{\"283\":2}}],[\"rnn的作用是根据输入来计算出隐状态\",{\"2\":{\"283\":1}}],[\"rnn的引入是为了解决序列信息引入的模型架构\",{\"2\":{\"93\":1}}],[\"rnnmodel\",{\"2\":{\"277\":2}}],[\"rnnmodelscratch\",{\"2\":{\"255\":2}}],[\"rnn在时间步过长的时候\",{\"2\":{\"266\":1}}],[\"rnn介绍\",{\"0\":{\"204\":1},\"1\":{\"217\":1,\"230\":1,\"241\":1,\"249\":1,\"255\":1,\"261\":1,\"266\":1,\"270\":1}}],[\"rnn和self\",{\"2\":{\"202\":1}}],[\"rnn\",{\"2\":{\"115\":2,\"202\":2,\"255\":3,\"277\":10,\"283\":4}}],[\"rnn引入\",{\"0\":{\"83\":1},\"1\":{\"93\":1,\"103\":1,\"117\":1,\"131\":1,\"145\":1,\"162\":1,\"176\":1,\"188\":1}}],[\"r\",{\"2\":{\"70\":2,\"81\":6,\"87\":2,\"91\":4,\"108\":2,\"117\":1,\"152\":2,\"159\":9,\"186\":2,\"202\":2,\"248\":1,\"254\":10,\"260\":10,\"269\":14,\"273\":18,\"279\":2}}],[\"ralyattention\",{\"0\":{\"286\":1}}],[\"rate\",{\"2\":{\"128\":2}}],[\"ratio\",{\"2\":{\"63\":2}}],[\"raise\",{\"2\":{\"115\":1,\"280\":3}}],[\"ray分布式训练\",{\"2\":{\"77\":1}}],[\"rank\",{\"2\":{\"263\":1}}],[\"rank做完stage1的forward的时候\",{\"2\":{\"263\":1}}],[\"range\",{\"2\":{\"59\":1,\"61\":1,\"63\":1,\"88\":4,\"103\":2,\"117\":1,\"130\":3,\"152\":2,\"167\":2,\"176\":2,\"181\":1,\"188\":1,\"193\":3,\"229\":2,\"247\":1,\"261\":1,\"270\":1,\"285\":1}}],[\"randint\",{\"2\":{\"176\":1,\"181\":2,\"188\":1,\"193\":2}}],[\"random\",{\"2\":{\"88\":1,\"117\":2,\"176\":3,\"188\":4,\"270\":4}}],[\"rand\",{\"2\":{\"59\":1,\"61\":1,\"130\":1,\"144\":1,\"178\":1}}],[\"randn\",{\"2\":{\"51\":1,\"191\":2,\"243\":2,\"255\":1}}],[\"risus\",{\"2\":{\"57\":2,\"68\":3}}],[\"right右对齐的内容\",{\"2\":{\"172\":2}}],[\"right|\",{\"2\":{\"123\":1}}],[\"right\",{\"2\":{\"50\":2,\"51\":4,\"59\":3,\"91\":1,\"123\":1,\"202\":2,\"249\":3,\"259\":1,\"266\":1,\"271\":2,\"278\":2}}],[\"rl介绍\",{\"0\":{\"227\":1}}],[\"rl\",{\"2\":{\"15\":1}}],[\"rdma\",{\"2\":{\"15\":3}}],[\"remaining\",{\"2\":{\"279\":1}}],[\"removed\",{\"2\":{\"100\":2}}],[\"remove\",{\"2\":{\"100\":2}}],[\"reinterpret\",{\"2\":{\"269\":1,\"273\":1}}],[\"recv的就是上一轮异步send的tensor\",{\"2\":{\"252\":1}}],[\"recv\",{\"2\":{\"252\":1}}],[\"recv一个tensor\",{\"2\":{\"252\":1}}],[\"representations\",{\"2\":{\"153\":1,\"193\":1}}],[\"representation\",{\"2\":{\"138\":1,\"159\":1,\"193\":1}}],[\"repeats=self\",{\"2\":{\"173\":1}}],[\"repeat\",{\"2\":{\"59\":4,\"70\":1,\"81\":1,\"173\":1,\"283\":1}}],[\"reverse=true\",{\"2\":{\"117\":1}}],[\"reading\",{\"2\":{\"282\":1}}],[\"ready\",{\"2\":{\"282\":3}}],[\"read不知道是啥意思\",{\"2\":{\"279\":1}}],[\"readlines\",{\"2\":{\"117\":1}}],[\"read\",{\"2\":{\"117\":3,\"279\":2,\"282\":1}}],[\"readme\",{\"0\":{\"192\":1,\"209\":1,\"218\":1,\"226\":1,\"237\":1},\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"ref实参会去掉ref\",{\"2\":{\"122\":1}}],[\"reference\",{\"2\":{\"113\":1}}],[\"ref\",{\"2\":{\"106\":1,\"122\":13}}],[\"required\",{\"2\":{\"68\":1}}],[\"requires\",{\"2\":{\"59\":1,\"88\":2,\"140\":10,\"151\":2,\"152\":4,\"255\":1,\"266\":1}}],[\"re\",{\"2\":{\"68\":1,\"117\":2,\"197\":2}}],[\"reduce来获得结果\",{\"2\":{\"245\":1}}],[\"reduce\",{\"2\":{\"245\":1,\"265\":1}}],[\"reduction=\",{\"2\":{\"59\":1,\"103\":1,\"285\":1}}],[\"red\",{\"2\":{\"68\":3,\"271\":1}}],[\"res\",{\"2\":{\"282\":1}}],[\"reset\",{\"2\":{\"152\":1}}],[\"reserved\",{\"2\":{\"117\":4}}],[\"resource\",{\"2\":{\"113\":1}}],[\"resnet系列\",{\"2\":{\"251\":1}}],[\"resnet\",{\"0\":{\"109\":1}}],[\"results\",{\"2\":{\"97\":1,\"193\":1}}],[\"residual\",{\"2\":{\"87\":1,\"138\":2,\"153\":1,\"193\":3}}],[\"resize=224\",{\"2\":{\"63\":1}}],[\"reshapes\",{\"2\":{\"97\":1,\"193\":1}}],[\"reshape\",{\"2\":{\"59\":5,\"70\":3,\"81\":1,\"88\":2,\"97\":2,\"103\":1,\"130\":2,\"144\":2,\"152\":2,\"173\":4,\"188\":2,\"193\":2,\"202\":1,\"203\":3,\"220\":1,\"229\":1,\"255\":1,\"261\":2,\"270\":1,\"277\":1,\"285\":1}}],[\"restructuredtext\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"return\",{\"2\":{\"51\":1,\"57\":1,\"59\":1,\"61\":2,\"63\":2,\"70\":2,\"75\":1,\"81\":1,\"86\":1,\"88\":4,\"91\":1,\"96\":2,\"97\":4,\"100\":12,\"103\":1,\"110\":1,\"115\":3,\"117\":12,\"118\":2,\"119\":2,\"124\":1,\"126\":1,\"130\":2,\"138\":1,\"140\":3,\"144\":1,\"150\":7,\"152\":9,\"153\":1,\"154\":3,\"167\":2,\"169\":1,\"173\":3,\"174\":1,\"176\":1,\"187\":1,\"188\":1,\"193\":10,\"197\":1,\"202\":1,\"203\":1,\"229\":1,\"247\":1,\"255\":7,\"260\":1,\"261\":1,\"267\":2,\"270\":1,\"277\":3,\"280\":1,\"283\":3,\"285\":2}}],[\"relaxed\",{\"2\":{\"205\":1}}],[\"relationships\",{\"2\":{\"138\":1,\"193\":1}}],[\"release语义可以实现上述的内存一致性约束\",{\"2\":{\"205\":1}}],[\"release\",{\"2\":{\"205\":6,\"260\":2}}],[\"rel=\",{\"2\":{\"41\":1}}],[\"relu\",{\"2\":{\"23\":1,\"63\":3,\"75\":3,\"86\":8,\"103\":1,\"110\":3,\"126\":1,\"140\":1,\"193\":3}}],[\"reg\",{\"2\":{\"260\":1,\"282\":1}}],[\"register\",{\"2\":{\"124\":1,\"193\":1,\"254\":1}}],[\"regressive\",{\"2\":{\"87\":1}}],[\"regression\",{\"0\":{\"20\":1,\"39\":1},\"1\":{\"48\":1,\"56\":1,\"67\":1,\"78\":1,\"88\":1}}],[\"regular\",{\"2\":{\"17\":2,\"28\":2,\"29\":2,\"33\":2}}],[\"格式中\",{\"2\":{\"113\":1}}],[\"格式来写\",{\"2\":{\"113\":1}}],[\"格式不一样\",{\"2\":{\"40\":1}}],[\"格式的影响\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"格式撰写的文件应该可以直接以纯文字发佈\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"t​​\",{\"2\":{\"278\":1}}],[\"tq\",{\"2\":{\"278\":3}}],[\"t^\",{\"2\":{\"278\":5}}],[\"tn​\",{\"2\":{\"278\":1}}],[\"tn+1​\",{\"2\":{\"278\":1}}],[\"tn+1\",{\"2\":{\"278\":1}}],[\"tn\",{\"2\":{\"278\":1}}],[\"tmp\",{\"2\":{\"273\":6}}],[\"tma无法做到async\",{\"2\":{\"282\":1}}],[\"tma的load\",{\"2\":{\"279\":1}}],[\"tma的版本下\",{\"2\":{\"269\":1}}],[\"tma的版本\",{\"2\":{\"269\":2}}],[\"tma\",{\"0\":{\"279\":1,\"282\":1},\"2\":{\"183\":1,\"197\":1,\"265\":1,\"269\":14,\"273\":14,\"279\":2,\"282\":9}}],[\"tc0\",{\"2\":{\"265\":2}}],[\"tx\",{\"2\":{\"260\":3,\"265\":4,\"269\":2,\"273\":1,\"279\":1,\"282\":4}}],[\"txt来导出compile\",{\"2\":{\"169\":1}}],[\"txt\",{\"2\":{\"117\":1}}],[\"txt​\",{\"2\":{\"103\":3,\"217\":1,\"249\":1,\"255\":1}}],[\"tp聚焦于节点内部\",{\"2\":{\"245\":1}}],[\"tp之间的\",{\"2\":{\"245\":1}}],[\"tp\",{\"2\":{\"235\":1,\"263\":1}}],[\"tpt​\",{\"2\":{\"137\":1}}],[\"tw\",{\"2\":{\"230\":2}}],[\"two\",{\"2\":{\"57\":2,\"68\":2,\"128\":2}}],[\"t−1t\",{\"2\":{\"217\":1}}],[\"t是std\",{\"2\":{\"154\":1}}],[\"tgt\",{\"2\":{\"153\":3,\"167\":21,\"181\":7,\"193\":31,\"285\":2}}],[\"tyt​\",{\"2\":{\"137\":1}}],[\"typically\",{\"2\":{\"138\":1,\"153\":1,\"193\":2}}],[\"typing\",{\"2\":{\"117\":1}}],[\"types\",{\"2\":{\"254\":1}}],[\"type>\",{\"2\":{\"154\":1,\"269\":1,\"273\":1}}],[\"type用于获取枚举类型的底层数据类型\",{\"2\":{\"154\":1}}],[\"typedef\",{\"2\":{\"139\":1}}],[\"type都会被推导为左值引用\",{\"2\":{\"122\":1}}],[\"type进行模式匹配来决定t\",{\"2\":{\"122\":1}}],[\"typename\",{\"2\":{\"122\":5,\"135\":2,\"139\":5,\"150\":10,\"154\":5,\"254\":1,\"269\":4,\"273\":4}}],[\"type\",{\"2\":{\"59\":2,\"100\":5,\"103\":1,\"119\":1,\"122\":1,\"139\":3,\"152\":2,\"154\":6,\"169\":1,\"247\":2,\"254\":3,\"255\":1,\"260\":1,\"267\":1,\"285\":2}}],[\"t和param\",{\"2\":{\"122\":1}}],[\"t>>\",{\"2\":{\"139\":2}}],[\"t>\",{\"2\":{\"122\":5,\"135\":3,\"139\":6,\"154\":2,\"254\":1,\"269\":6,\"273\":8,\"279\":1}}],[\"t2\",{\"2\":{\"112\":1,\"118\":2}}],[\"t1​\",{\"2\":{\"278\":1}}],[\"t1\",{\"2\":{\"112\":1,\"118\":2,\"278\":1}}],[\"t1∼t\",{\"2\":{\"103\":1}}],[\"t代表的t是一个常量指针\",{\"2\":{\"104\":1}}],[\"t+1\",{\"2\":{\"103\":5}}],[\"t=1\",{\"2\":{\"103\":1,\"115\":1,\"249\":2}}],[\"ttt\",{\"2\":{\"103\":2,\"115\":1,\"137\":1,\"217\":1,\"230\":1,\"249\":1}}],[\"ts\",{\"2\":{\"100\":2}}],[\"tuple的连接操作\",{\"2\":{\"144\":1}}],[\"tuple\",{\"2\":{\"63\":1,\"96\":1,\"117\":3,\"130\":1,\"154\":1,\"176\":1,\"188\":1,\"229\":1,\"255\":1,\"270\":1}}],[\"ti∈rb×1×h\",{\"2\":{\"278\":1}}],[\"ti∈rb×1×ht^i\",{\"2\":{\"278\":1}}],[\"title=\",{\"2\":{\"113\":4}}],[\"title\",{\"2\":{\"113\":15,\"156\":3}}],[\"timer\",{\"2\":{\"247\":5,\"270\":3,\"285\":3}}],[\"timemachine\",{\"2\":{\"117\":1}}],[\"time\",{\"2\":{\"103\":2,\"117\":6,\"188\":1,\"261\":1,\"269\":1,\"270\":2,\"273\":1,\"283\":8}}],[\"times\",{\"2\":{\"55\":8,\"91\":1,\"113\":4,\"128\":4,\"259\":11,\"264\":1,\"268\":4,\"272\":1,\"278\":2}}],[\"tip\",{\"2\":{\"90\":3,\"100\":2}}],[\"tile的主对角线元素被移除\",{\"2\":{\"59\":1}}],[\"tile的形状\",{\"2\":{\"59\":2}}],[\"tile\",{\"2\":{\"59\":4,\"265\":1,\"269\":7,\"273\":6}}],[\"targets\",{\"2\":{\"169\":1}}],[\"target\",{\"2\":{\"153\":2,\"193\":2}}],[\"target=\",{\"2\":{\"41\":1}}],[\"taking\",{\"2\":{\"153\":1,\"193\":1}}],[\"tags\",{\"2\":{\"141\":2}}],[\"tasks\",{\"2\":{\"138\":1,\"193\":1}}],[\"tau\",{\"2\":{\"103\":6}}],[\"tauτ\",{\"2\":{\"103\":3}}],[\"tanh\",{\"2\":{\"81\":2,\"255\":1}}],[\"tada\",{\"2\":{\"58\":1}}],[\"tabs\",{\"2\":{\"100\":2}}],[\"tab\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1,\"40\":1,\"68\":2,\"79\":2,\"100\":5,\"113\":1}}],[\"tables\",{\"2\":{\"50\":2}}],[\"table>\",{\"2\":{\"17\":2,\"28\":2,\"29\":2,\"33\":2}}],[\"table\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"threadblocks\",{\"2\":{\"273\":1}}],[\"threadidx\",{\"2\":{\"269\":2,\"273\":1}}],[\"threads>\",{\"2\":{\"269\":2,\"273\":1}}],[\"threads\",{\"2\":{\"260\":2,\"269\":5,\"273\":5}}],[\"thread2\",{\"2\":{\"205\":3}}],[\"thread1\",{\"2\":{\"205\":1}}],[\"thread\",{\"2\":{\"205\":2,\"260\":2,\"269\":1,\"273\":2}}],[\"th\",{\"2\":{\"124\":1,\"193\":1,\"278\":2}}],[\"than\",{\"2\":{\"113\":4}}],[\"that\",{\"2\":{\"97\":1,\"153\":1,\"193\":2,\"260\":2}}],[\"tht​\",{\"2\":{\"103\":2,\"115\":1}}],[\"them\",{\"2\":{\"138\":1,\"193\":1,\"260\":1,\"279\":1}}],[\"theme\",{\"2\":{\"25\":1,\"142\":2}}],[\"these\",{\"2\":{\"138\":1,\"193\":1}}],[\"they\",{\"2\":{\"128\":2}}],[\"thereby\",{\"2\":{\"263\":2}}],[\"there\",{\"2\":{\"128\":2}}],[\"the\",{\"2\":{\"57\":4,\"61\":1,\"68\":4,\"97\":10,\"100\":2,\"110\":4,\"124\":1,\"128\":2,\"138\":5,\"141\":4,\"153\":16,\"193\":36,\"213\":3,\"260\":1,\"263\":3,\"265\":1,\"269\":1,\"279\":1}}],[\"thetaθ的变化公式为\",{\"2\":{\"88\":1}}],[\"theta\",{\"2\":{\"48\":8,\"67\":8,\"88\":5,\"266\":4}}],[\"this\",{\"2\":{\"17\":2,\"28\":2,\"29\":2,\"33\":2,\"49\":2,\"57\":7,\"68\":4,\"79\":2,\"90\":12,\"97\":2,\"100\":4,\"113\":4,\"118\":3,\"127\":1,\"153\":1,\"193\":3,\"260\":1,\"269\":1,\"273\":1}}],[\"t\",{\"0\":{\"254\":1},\"2\":{\"24\":4,\"36\":4,\"37\":4,\"42\":4,\"100\":2,\"103\":37,\"104\":19,\"115\":14,\"118\":9,\"119\":7,\"122\":18,\"125\":1,\"128\":4,\"131\":5,\"135\":1,\"137\":9,\"139\":2,\"141\":2,\"143\":2,\"150\":1,\"154\":5,\"217\":8,\"230\":4,\"249\":4,\"254\":24,\"255\":5,\"260\":1,\"269\":5,\"270\":1,\"273\":10,\"277\":1,\"278\":15,\"279\":2}}],[\"td>\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"td>foo\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"triu\",{\"2\":{\"167\":1,\"193\":1}}],[\"triton\",{\"2\":{\"15\":1,\"197\":7}}],[\"tree\",{\"2\":{\"106\":1}}],[\"true\",{\"2\":{\"88\":10,\"112\":5,\"119\":1,\"140\":1,\"151\":1,\"255\":2}}],[\"truth\",{\"2\":{\"51\":1}}],[\"try\",{\"2\":{\"63\":1,\"247\":1,\"255\":3,\"260\":2,\"261\":1}}],[\"traveller\",{\"2\":{\"261\":1,\"270\":3}}],[\"traffic\",{\"2\":{\"113\":4}}],[\"transfer\",{\"2\":{\"273\":1}}],[\"transform\",{\"2\":{\"138\":1,\"193\":1}}],[\"transformation\",{\"2\":{\"97\":1,\"193\":1}}],[\"transformations\",{\"2\":{\"97\":1,\"193\":1}}],[\"transforming\",{\"2\":{\"97\":1,\"110\":1,\"193\":2}}],[\"transformer模型加速推断的一个常用策略就是使用\",{\"2\":{\"278\":1}}],[\"transformer模型由\",{\"2\":{\"225\":1}}],[\"transformer论文\",{\"0\":{\"161\":1},\"1\":{\"175\":1}}],[\"transformer论文解析\",{\"2\":{\"87\":1}}],[\"transformer解码器也是由多个相同的层叠加而成的\",{\"2\":{\"87\":1}}],[\"transformer编码器都将输出一个维表示向量\",{\"2\":{\"87\":1}}],[\"transformer的编码器是由多个相同的层叠加而成的\",{\"2\":{\"87\":1}}],[\"transformer是如此的重要\",{\"2\":{\"76\":1}}],[\"transformer架构\",{\"0\":{\"76\":1},\"1\":{\"87\":1,\"97\":1,\"110\":1,\"124\":1,\"138\":1,\"153\":1,\"167\":1,\"181\":1,\"193\":1}}],[\"transformer\",{\"0\":{\"30\":1,\"167\":1},\"2\":{\"110\":1,\"138\":2,\"153\":2,\"167\":2,\"181\":5,\"193\":12}}],[\"transaction\",{\"2\":{\"260\":1,\"265\":1}}],[\"transpose\",{\"2\":{\"91\":1,\"97\":4,\"173\":6,\"193\":4}}],[\"trans\",{\"2\":{\"61\":1,\"254\":1}}],[\"training\",{\"0\":{\"222\":1,\"235\":1},\"1\":{\"245\":1,\"252\":1,\"258\":1},\"2\":{\"247\":1,\"263\":1}}],[\"train=true\",{\"2\":{\"88\":1,\"103\":1}}],[\"trainer\",{\"2\":{\"59\":3,\"88\":3,\"103\":3}}],[\"train次\",{\"2\":{\"59\":1}}],[\"train\",{\"2\":{\"51\":6,\"59\":23,\"63\":3,\"88\":4,\"103\":10,\"152\":1,\"181\":3,\"193\":3,\"247\":16,\"255\":1,\"263\":1,\"270\":8,\"285\":2}}],[\"tr>\",{\"2\":{\"17\":2,\"28\":2,\"29\":2,\"33\":2}}],[\"tout\",{\"2\":{\"278\":4}}],[\"toutype\",{\"2\":{\"154\":4}}],[\"total\",{\"2\":{\"269\":2,\"273\":2}}],[\"tolist\",{\"2\":{\"140\":1}}],[\"together\",{\"2\":{\"138\":1,\"193\":1}}],[\"top\",{\"2\":{\"81\":1,\"91\":2}}],[\"toc\",{\"2\":{\"69\":1}}],[\"tokens数\",{\"2\":{\"268\":1}}],[\"tokens=\",{\"2\":{\"117\":1}}],[\"tokens=none\",{\"2\":{\"117\":2}}],[\"tokens\",{\"2\":{\"117\":24,\"188\":5,\"285\":3}}],[\"token=\",{\"2\":{\"117\":1}}],[\"tokenize\",{\"2\":{\"117\":3}}],[\"tokenizer\",{\"2\":{\"117\":1}}],[\"token\",{\"0\":{\"62\":1},\"2\":{\"117\":30,\"124\":1,\"193\":1,\"257\":1,\"261\":1}}],[\"torch\",{\"0\":{\"140\":1,\"148\":1},\"1\":{\"164\":1,\"178\":1,\"191\":1,\"207\":1,\"220\":1,\"232\":1,\"243\":1},\"2\":{\"51\":5,\"59\":11,\"61\":4,\"70\":1,\"81\":6,\"86\":2,\"88\":16,\"91\":2,\"96\":13,\"97\":3,\"103\":5,\"115\":4,\"117\":4,\"124\":6,\"126\":2,\"130\":8,\"140\":16,\"144\":3,\"151\":3,\"152\":25,\"166\":2,\"167\":2,\"169\":3,\"173\":1,\"174\":5,\"176\":4,\"178\":4,\"181\":2,\"187\":5,\"188\":4,\"191\":3,\"193\":17,\"202\":6,\"203\":7,\"220\":7,\"229\":5,\"232\":2,\"243\":3,\"247\":3,\"255\":13,\"261\":1,\"266\":2,\"267\":2,\"270\":2,\"277\":4,\"283\":2,\"285\":6}}],[\"todos\",{\"2\":{\"100\":2}}],[\"todo\",{\"0\":{\"15\":1},\"2\":{\"100\":6,\"152\":1,\"266\":1,\"278\":1,\"279\":1}}],[\"to\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1,\"40\":1,\"57\":1,\"68\":1,\"96\":2,\"97\":7,\"113\":1,\"117\":12,\"122\":1,\"124\":1,\"128\":4,\"138\":2,\"153\":6,\"156\":3,\"169\":2,\"193\":16,\"202\":1,\"247\":6,\"254\":1,\"255\":1,\"260\":1,\"261\":1,\"263\":1,\"265\":3,\"269\":4,\"270\":2,\"273\":7,\"277\":1,\"279\":3,\"282\":3,\"285\":2}}],[\"term\",{\"2\":{\"124\":3,\"193\":3}}],[\"template\",{\"2\":{\"122\":5,\"135\":2,\"139\":4,\"150\":5,\"154\":3,\"254\":3,\"260\":1,\"269\":10,\"273\":8,\"279\":2,\"282\":1}}],[\"tell\",{\"2\":{\"79\":3}}],[\"tensor来load\",{\"2\":{\"273\":1}}],[\"tensor来保存\",{\"2\":{\"213\":1}}],[\"tensor就可以满足精度要求\",{\"2\":{\"271\":1}}],[\"tensormap3\",{\"2\":{\"265\":1}}],[\"tensormap0\",{\"2\":{\"265\":1}}],[\"tensor的async\",{\"2\":{\"273\":1}}],[\"tensor的生成\",{\"2\":{\"220\":1}}],[\"tensor的data一般不会释放\",{\"2\":{\"213\":1}}],[\"tensor的data\",{\"2\":{\"213\":1}}],[\"tensor的数据其实已经不需要了\",{\"2\":{\"213\":1}}],[\"tensor等的data信息来计算梯度\",{\"2\":{\"213\":1}}],[\"tensor等等\",{\"2\":{\"169\":1}}],[\"tensor中的grad取出来\",{\"2\":{\"213\":1}}],[\"tensor中\",{\"2\":{\"213\":1}}],[\"tensor已经经过伪释放\",{\"2\":{\"213\":1}}],[\"tensor都应该压入栈中等待fwd\",{\"2\":{\"213\":1}}],[\"tensor和output\",{\"2\":{\"213\":3}}],[\"tensor发送给下一个stage作为input\",{\"2\":{\"213\":1}}],[\"tensors\",{\"2\":{\"140\":1}}],[\"tensordataset\",{\"2\":{\"88\":1}}],[\"tensor\",{\"0\":{\"148\":1},\"1\":{\"164\":1,\"178\":1,\"191\":1,\"207\":1,\"220\":1,\"232\":1,\"243\":1},\"2\":{\"55\":1,\"81\":1,\"86\":1,\"88\":2,\"96\":6,\"97\":2,\"126\":1,\"130\":4,\"140\":12,\"144\":2,\"152\":11,\"174\":5,\"176\":4,\"178\":1,\"187\":3,\"188\":4,\"191\":3,\"193\":2,\"203\":3,\"213\":17,\"220\":9,\"222\":1,\"229\":2,\"232\":3,\"255\":1,\"257\":1,\"261\":1,\"263\":1,\"265\":4,\"267\":3,\"269\":4,\"271\":1,\"273\":2,\"285\":1}}],[\"tensor相加\",{\"2\":{\"55\":1}}],[\"tensorflow\",{\"2\":{\"1\":1}}],[\"test\",{\"2\":{\"51\":4,\"63\":2,\"152\":1,\"247\":8,\"260\":1}}],[\"textile\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"text\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1,\"40\":1,\"51\":1,\"59\":1,\"70\":1,\"91\":1,\"100\":2,\"103\":1,\"113\":2,\"127\":1,\"156\":3,\"228\":2,\"259\":2,\"268\":6,\"271\":6}}],[\"易读易写\",{\"2\":{\"5\":1}}],[\"muμ\",{\"2\":{\"272\":1}}],[\"mul\",{\"2\":{\"191\":1}}],[\"multihead\",{\"2\":{\"159\":1}}],[\"multiheadattention\",{\"2\":{\"97\":2,\"138\":1,\"153\":2,\"173\":2,\"193\":5}}],[\"multiple\",{\"2\":{\"138\":1,\"153\":1,\"193\":2}}],[\"multiply\",{\"2\":{\"97\":1,\"193\":1}}],[\"multi\",{\"0\":{\"45\":1,\"62\":1,\"97\":1,\"222\":1},\"2\":{\"87\":1,\"97\":2,\"138\":1,\"153\":2,\"174\":2,\"187\":3,\"193\":5,\"203\":3}}],[\"multimarkdown\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"mul等\",{\"2\":{\"23\":1}}],[\"mbar0\",{\"2\":{\"265\":1}}],[\"mbar\",{\"2\":{\"260\":3,\"265\":1,\"269\":3}}],[\"mbarrier对象是不透明的\",{\"2\":{\"260\":1}}],[\"mbarrier\",{\"0\":{\"260\":1},\"2\":{\"260\":14,\"265\":3,\"269\":2,\"273\":7,\"279\":1}}],[\"m+1m\",{\"2\":{\"256\":1}}],[\"mps\",{\"2\":{\"255\":6,\"261\":1}}],[\"mpoeter\",{\"2\":{\"106\":1}}],[\"m8n8意思是8x8的matrix\",{\"2\":{\"254\":1}}],[\"m8n8\",{\"2\":{\"254\":2}}],[\"mma\",{\"2\":{\"254\":1}}],[\"mm\",{\"2\":{\"203\":1,\"243\":1,\"255\":3}}],[\"mmm\",{\"2\":{\"70\":1,\"91\":1,\"256\":2}}],[\"mqa优化技术\",{\"0\":{\"198\":1}}],[\"mha\",{\"0\":{\"198\":1}}],[\"mlp\",{\"2\":{\"110\":1,\"193\":1}}],[\"msn\",{\"2\":{\"113\":12}}],[\"msg\",{\"2\":{\"100\":12}}],[\"mseloss\",{\"2\":{\"59\":1,\"88\":1,\"103\":1}}],[\"memcpy\",{\"2\":{\"269\":8,\"273\":8}}],[\"memory和reg等\",{\"2\":{\"197\":1}}],[\"memory\",{\"0\":{\"189\":1,\"205\":1},\"1\":{\"205\":1},\"2\":{\"205\":7,\"248\":1,\"254\":1,\"260\":7,\"263\":1,\"265\":2,\"269\":5,\"273\":5,\"275\":1,\"279\":3,\"282\":12}}],[\"medium=social\",{\"2\":{\"175\":1}}],[\"meticulously\",{\"2\":{\"263\":1}}],[\"metadata\",{\"2\":{\"197\":1}}],[\"metadata=\",{\"2\":{\"197\":1}}],[\"metric\",{\"2\":{\"152\":4,\"247\":11,\"270\":5,\"285\":7}}],[\"methods\",{\"2\":{\"263\":1}}],[\"method\",{\"2\":{\"97\":2,\"193\":2}}],[\"mechanism\",{\"2\":{\"138\":1,\"153\":2,\"193\":3,\"265\":1}}],[\"mechanisms\",{\"2\":{\"110\":1,\"193\":1}}],[\"meaningful\",{\"2\":{\"153\":1,\"193\":1}}],[\"mean和moving\",{\"2\":{\"96\":2}}],[\"mean=0\",{\"2\":{\"88\":1}}],[\"mean\",{\"2\":{\"88\":1,\"96\":21,\"191\":1,\"229\":1,\"270\":1,\"285\":1}}],[\"megatronv2提出了更加完备的并行策略\",{\"2\":{\"235\":1}}],[\"megatron\",{\"0\":{\"222\":1,\"235\":2},\"1\":{\"245\":2,\"252\":2,\"258\":2},\"2\":{\"1\":1,\"222\":1,\"235\":1}}],[\"mchale\",{\"2\":{\"68\":2}}],[\"mnist\",{\"2\":{\"63\":1,\"152\":1}}],[\"mix\",{\"0\":{\"245\":1},\"2\":{\"235\":1}}],[\"micro\",{\"2\":{\"252\":1}}],[\"micromamba在下载lib的时候\",{\"2\":{\"169\":1}}],[\"microsoft\",{\"2\":{\"106\":1}}],[\"mid\",{\"2\":{\"103\":9,\"131\":1,\"217\":2,\"249\":2}}],[\"min=1e\",{\"2\":{\"267\":1}}],[\"mini\",{\"2\":{\"245\":1}}],[\"min\",{\"2\":{\"88\":1,\"117\":2,\"197\":1,\"262\":3,\"266\":1}}],[\"mi\",{\"2\":{\"57\":2,\"68\":3}}],[\"more\",{\"2\":{\"113\":5,\"254\":1,\"263\":1}}],[\"most\",{\"2\":{\"112\":1}}],[\"motd\",{\"2\":{\"100\":2}}],[\"momentum=0\",{\"2\":{\"96\":1}}],[\"momentum\",{\"2\":{\"96\":5}}],[\"movement\",{\"2\":{\"273\":2}}],[\"move将当前的值转化为将亡值\",{\"2\":{\"132\":1}}],[\"move\",{\"0\":{\"105\":1,\"254\":1},\"1\":{\"119\":1,\"132\":1,\"146\":1},\"2\":{\"119\":1,\"254\":3,\"269\":1,\"273\":4}}],[\"moving\",{\"2\":{\"96\":21}}],[\"movabletype\",{\"2\":{\"40\":1}}],[\"mode\",{\"2\":{\"229\":2}}],[\"mode=\",{\"2\":{\"229\":1}}],[\"models\",{\"0\":{\"222\":1},\"2\":{\"158\":1}}],[\"model\",{\"0\":{\"189\":1,\"205\":1,\"210\":1,\"235\":1},\"1\":{\"205\":1,\"222\":1,\"235\":1,\"245\":2,\"252\":2,\"258\":2,\"263\":1},\"2\":{\"86\":2,\"97\":19,\"110\":3,\"124\":4,\"138\":6,\"153\":8,\"167\":7,\"181\":4,\"193\":51}}],[\"module中调用\",{\"2\":{\"140\":1}}],[\"module中充当一个计算点的工具\",{\"2\":{\"126\":1}}],[\"modulelist\",{\"2\":{\"61\":1,\"167\":2,\"193\":2}}],[\"module\",{\"2\":{\"59\":1,\"61\":2,\"63\":1,\"81\":1,\"86\":2,\"91\":1,\"96\":1,\"97\":1,\"110\":1,\"124\":1,\"126\":4,\"130\":1,\"138\":1,\"152\":1,\"153\":1,\"167\":1,\"173\":1,\"193\":6,\"202\":1,\"247\":1,\"266\":1,\"270\":2,\"277\":1,\"280\":3}}],[\"moe的核心思想是\",{\"2\":{\"61\":1}}],[\"moe\",{\"0\":{\"61\":1},\"2\":{\"61\":2}}],[\"moe架构按照顺序的话\",{\"2\":{\"61\":1}}],[\"moe架构\",{\"0\":{\"53\":1},\"1\":{\"61\":1,\"72\":1}}],[\"m\",{\"2\":{\"48\":1,\"70\":4,\"91\":2,\"103\":3,\"197\":10,\"247\":4,\"248\":1,\"252\":1,\"256\":1,\"285\":6}}],[\"many\",{\"2\":{\"269\":1,\"273\":1}}],[\"make\",{\"2\":{\"269\":1,\"273\":1}}],[\"making\",{\"2\":{\"260\":1}}],[\"mapa\",{\"2\":{\"273\":4}}],[\"map\",{\"2\":{\"265\":1,\"269\":1}}],[\"machine\",{\"2\":{\"117\":6,\"188\":1}}],[\"mask=none\",{\"2\":{\"97\":2,\"193\":2}}],[\"mask\",{\"2\":{\"70\":1,\"97\":4,\"138\":2,\"153\":8,\"167\":17,\"193\":31,\"285\":3}}],[\"maskedsoftmaxceloss\",{\"2\":{\"285\":3}}],[\"masked\",{\"2\":{\"70\":1,\"81\":1,\"87\":1,\"91\":1,\"97\":2,\"193\":2}}],[\"matrices\",{\"2\":{\"254\":1}}],[\"matrix\",{\"2\":{\"197\":1}}],[\"math\",{\"2\":{\"91\":1,\"97\":1,\"124\":1,\"193\":3,\"270\":1}}],[\"mathbb\",{\"2\":{\"70\":2,\"81\":6,\"87\":2,\"91\":4,\"108\":2,\"152\":2,\"159\":9,\"186\":2,\"202\":2}}],[\"mathbf\",{\"2\":{\"70\":17,\"71\":7,\"81\":12,\"82\":4,\"87\":2,\"91\":10,\"95\":7,\"108\":4,\"115\":3,\"123\":3,\"128\":22,\"137\":8,\"143\":2,\"152\":2,\"159\":16,\"186\":6,\"202\":4,\"266\":3,\"271\":16}}],[\"matmul\",{\"2\":{\"23\":1,\"88\":2,\"97\":2,\"152\":2,\"193\":2,\"243\":1}}],[\"magic\",{\"2\":{\"68\":2}}],[\"main\",{\"2\":{\"61\":1,\"106\":1,\"122\":1,\"181\":1,\"193\":1}}],[\"maxlen\",{\"2\":{\"285\":4}}],[\"maximum\",{\"2\":{\"229\":1,\"279\":1}}],[\"maxwell\",{\"2\":{\"128\":2}}],[\"maxpool2d\",{\"2\":{\"63\":1,\"75\":2,\"86\":5,\"229\":4}}],[\"max\",{\"2\":{\"38\":1,\"117\":3,\"124\":3,\"167\":2,\"181\":4,\"188\":2,\"193\":9,\"202\":3,\"223\":2,\"229\":3,\"262\":4,\"267\":5}}],[\"maruku\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"markdown基础\",{\"2\":{\"32\":1}}],[\"markdown\",{\"0\":{\"5\":1,\"7\":1},\"1\":{\"6\":1,\"10\":1,\"11\":1,\"17\":1,\"18\":1,\"24\":1,\"25\":1,\"31\":1,\"32\":1,\"40\":1,\"41\":1,\"49\":1,\"50\":1,\"57\":1,\"58\":1,\"68\":1,\"69\":1,\"79\":1,\"80\":1,\"89\":1,\"90\":1,\"99\":1,\"100\":1,\"113\":1,\"114\":1,\"127\":1,\"128\":1,\"141\":1,\"142\":1,\"156\":1,\"157\":1,\"171\":1,\"172\":1,\"184\":1,\"185\":1,\"199\":1,\"200\":1,\"214\":1,\"215\":1,\"228\":1,\"238\":1},\"2\":{\"5\":2,\"6\":10,\"10\":7,\"13\":10,\"14\":10,\"17\":6,\"19\":10,\"21\":7,\"22\":7,\"24\":7,\"26\":7,\"28\":6,\"29\":6,\"32\":5,\"33\":6,\"36\":7,\"37\":7,\"40\":3,\"42\":7,\"49\":1,\"57\":4,\"68\":4,\"79\":9,\"100\":1,\"113\":4,\"127\":1,\"141\":1,\"156\":2,\"185\":1,\"199\":5,\"214\":2,\"228\":1}}],[\"myexp\",{\"2\":{\"140\":2}}],[\"myalloc\",{\"2\":{\"139\":2}}],[\"myalloclist1\",{\"2\":{\"139\":3}}],[\"myalloclist\",{\"2\":{\"139\":3}}],[\"mystruct>\",{\"2\":{\"139\":2}}],[\"mystruct\",{\"2\":{\"139\":1}}],[\"myrelu\",{\"2\":{\"126\":2}}],[\"mycomponent\",{\"2\":{\"100\":2}}],[\"my\",{\"2\":{\"18\":2,\"113\":1,\"140\":1}}],[\"mdash\",{\"2\":{\"141\":2}}],[\"md\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"25\":2,\"26\":1,\"32\":3}}],[\"友情链接\",{\"0\":{\"3\":1}}],[\"希望这个项目也会变得更加完善\",{\"2\":{\"2\":1}}],[\"以评估模式运行\",{\"2\":{\"283\":1}}],[\"以上是dualpipev的schedule以及和1f1b的bubble等数据的对比\",{\"2\":{\"263\":1}}],[\"以求在更少的device上有更低的bubble率\",{\"2\":{\"263\":1}}],[\"以wsgi网络框架举例\",{\"2\":{\"256\":1}}],[\"以流水线的形式进行forward与backward\",{\"2\":{\"245\":1}}],[\"以0为基准\",{\"2\":{\"178\":1}}],[\"以产生最终输出\",{\"2\":{\"159\":1}}],[\"以产生\",{\"2\":{\"141\":1}}],[\"以下一些和模板类型推导一致\",{\"2\":{\"135\":1}}],[\"以便同一组词元同时充当查询\",{\"2\":{\"186\":1}}],[\"以便与输入进行互相关运算\",{\"2\":{\"174\":1}}],[\"以便我们更好的训练模型\",{\"2\":{\"117\":1}}],[\"以便满足残差连接\",{\"2\":{\"87\":1}}],[\"以至于我们需要单开一章来重点讲解\",{\"2\":{\"76\":1}}],[\"以利与内容区隔\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1}}],[\"以此来对抗自己的知识遗忘\",{\"2\":{\"2\":1}}],[\"以及cp\",{\"2\":{\"265\":1}}],[\"以及同步aync\",{\"2\":{\"260\":1}}],[\"以及平均汇聚层\",{\"2\":{\"247\":1}}],[\"以及多个通道\",{\"2\":{\"229\":1}}],[\"以及偏置\",{\"2\":{\"225\":1}}],[\"以及拼接分割\",{\"2\":{\"220\":1}}],[\"以及计算图的保存问题\",{\"2\":{\"213\":1}}],[\"以及计算的持续而不被打断\",{\"2\":{\"47\":1}}],[\"以及\",{\"2\":{\"202\":1,\"223\":1,\"272\":1}}],[\"以及一个\",{\"2\":{\"185\":1}}],[\"以及一些可以出现的短语\",{\"2\":{\"131\":1}}],[\"以及一些难点\",{\"2\":{\"2\":1}}],[\"以及构造析构函数的时候\",{\"2\":{\"182\":1}}],[\"以及代表注意力汇聚的函数\",{\"2\":{\"159\":1}}],[\"以及广播机制\",{\"2\":{\"152\":1}}],[\"以及给定前面几个单词后\",{\"2\":{\"131\":1}}],[\"以及是否设置偏差conv2d的weight参数会被随机初始化\",{\"2\":{\"130\":1}}],[\"以及函数返回的非引用对象\",{\"2\":{\"119\":1}}],[\"以及词表\",{\"2\":{\"117\":1}}],[\"以及键\",{\"2\":{\"81\":1,\"91\":1,\"159\":1}}],[\"以及运行时runtime层面优化\",{\"2\":{\"23\":1}}],[\"以及python基础知识的学习\",{\"2\":{\"1\":1}}],[\"以及llm\",{\"2\":{\"0\":1}}],[\"面试速记\",{\"2\":{\"2\":1}}],[\"本质上是时间换空间\",{\"2\":{\"275\":1}}],[\"本质上都是在一个进程中运行\",{\"2\":{\"231\":1}}],[\"本节主要就伪代码来演示pipline\",{\"2\":{\"213\":1}}],[\"本章先分析decoder\",{\"2\":{\"212\":1}}],[\"本身const成员函数就肩负着的线程安全的逻辑意义\",{\"2\":{\"211\":1}}],[\"本身博客包含了一些其他作者的博客\",{\"2\":{\"170\":1}}],[\"本专题的初衷是学习机器学习以及深度学习相关的算法\",{\"2\":{\"20\":1}}],[\"本文主要研究dualpipev\",{\"2\":{\"263\":1}}],[\"本文主要包含了使用主题的过程中可能会遇到的常见问题与解决方法\",{\"2\":{\"4\":1}}],[\"本文你可以当做\",{\"2\":{\"1\":1}}],[\"本项目会长期更新\",{\"2\":{\"2\":1}}],[\"本项目其实并不会像小林coding一样\",{\"2\":{\"2\":1}}],[\"一句话简单概括\",{\"2\":{\"283\":1}}],[\"一次推理只会生成一个token\",{\"2\":{\"278\":1}}],[\"一次训练迭代中\",{\"2\":{\"264\":1}}],[\"一次训练迭代包含了前向传递和后向传递\",{\"2\":{\"264\":1}}],[\"一次训练迭代的计算量为\",{\"2\":{\"259\":1}}],[\"一次训练中\",{\"2\":{\"259\":1}}],[\"一次前向+一次反向\",{\"2\":{\"158\":1}}],[\"一共四块gpu\",{\"2\":{\"252\":1}}],[\"一篇论文\",{\"2\":{\"251\":1}}],[\"一篇讲gpipe和pipedream的文章\",{\"2\":{\"213\":1}}],[\"一篇超级赞的博客\",{\"2\":{\"170\":1}}],[\"一组数据到内存中\",{\"2\":{\"205\":1}}],[\"一款高吞吐的gemm\",{\"2\":{\"197\":1}}],[\"一行结束时输入两个空格\",{\"2\":{\"171\":1}}],[\"一种是进入io阻塞状态\",{\"2\":{\"163\":1}}],[\"一阶马尔科夫模型\",{\"2\":{\"145\":1}}],[\"一阶马尔科夫模型如下\",{\"2\":{\"103\":1}}],[\"一些不可拷贝对象\",{\"2\":{\"112\":1}}],[\"一些想法\",{\"0\":{\"2\":1}}],[\"一般和tma的load\",{\"2\":{\"279\":1}}],[\"一般选择per\",{\"2\":{\"271\":1}}],[\"一般来讲\",{\"2\":{\"268\":1}}],[\"一般来说\",{\"2\":{\"81\":1}}],[\"一般都会开启virtual\",{\"2\":{\"263\":1}}],[\"一般这个时候会使用multiprocessing库中的pool创建进程池来实现多进程的管理\",{\"2\":{\"256\":1}}],[\"一般比较适用于llm\",{\"2\":{\"251\":1}}],[\"一般放到torch\",{\"2\":{\"213\":1}}],[\"一般通过conda\",{\"2\":{\"169\":1}}],[\"一般需要将其sum\",{\"2\":{\"166\":1}}],[\"一般作为神经网络的一层\",{\"2\":{\"137\":1}}],[\"一般是使用梯度下降来优化损失函数\",{\"2\":{\"136\":1}}],[\"一般的\",{\"2\":{\"79\":1,\"225\":1}}],[\"一般的段落不需要用空白或断行缩进\",{\"2\":{\"40\":1}}],[\"一个接一个地生成词\",{\"2\":{\"278\":1}}],[\"一个典型的大模型生成式推断包含了两个阶段\",{\"2\":{\"278\":1}}],[\"一个sigmod激活函数\",{\"2\":{\"247\":1}}],[\"一个完善的卷积神经网络自然不会只有卷积层\",{\"2\":{\"216\":1}}],[\"一个包含文字的段落\",{\"2\":{\"185\":2}}],[\"一个\",{\"2\":{\"185\":1}}],[\"一个标量\",{\"2\":{\"180\":1}}],[\"一个是你的vscode需要识别到你的clangd\",{\"2\":{\"169\":1}}],[\"一个进程内多个线程竞争一把锁\",{\"2\":{\"163\":1}}],[\"一个普通括号\",{\"2\":{\"156\":1}}],[\"一个方括号\",{\"2\":{\"156\":1}}],[\"一个惊叹号\",{\"2\":{\"156\":1}}],[\"一个简单的梯度计算例子\",{\"0\":{\"151\":1}}],[\"一个以上的空白或\",{\"2\":{\"113\":1}}],[\"一个以上相连接的行句组成\",{\"2\":{\"40\":1}}],[\"一个代码块会一直持续到没有缩进的那一行\",{\"2\":{\"79\":1}}],[\"一个段落是由一个以上相连接的行句组成\",{\"2\":{\"40\":1}}],[\"一\",{\"0\":{\"34\":1,\"44\":1,\"48\":1,\"54\":1,\"83\":1,\"85\":1,\"87\":1,\"104\":1,\"112\":1,\"119\":1,\"122\":1,\"133\":1,\"148\":1,\"205\":1,\"212\":1,\"233\":1,\"248\":1},\"1\":{\"43\":1,\"51\":1,\"52\":1,\"59\":1,\"60\":1,\"70\":1,\"71\":1,\"81\":1,\"82\":1,\"91\":1,\"92\":1,\"93\":1,\"95\":1,\"97\":1,\"102\":1,\"103\":1,\"108\":1,\"110\":1,\"117\":1,\"123\":1,\"124\":1,\"131\":1,\"137\":1,\"138\":1,\"145\":1,\"147\":1,\"153\":1,\"162\":1,\"163\":1,\"164\":1,\"167\":1,\"176\":1,\"177\":1,\"178\":1,\"188\":1,\"190\":1,\"191\":1,\"207\":1,\"220\":1,\"225\":1,\"232\":1,\"236\":1,\"243\":1,\"246\":1,\"253\":1,\"254\":1,\"259\":1,\"260\":1,\"264\":1,\"265\":1,\"268\":1,\"269\":1,\"272\":1,\"273\":1,\"275\":1,\"276\":1,\"279\":1,\"282\":1}}],[\"一份使用\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"一份涵盖了llm算法\",{\"2\":{\"0\":1}}],[\"aync\",{\"2\":{\"279\":1}}],[\"a×b×ca\",{\"2\":{\"259\":1}}],[\"a×ba\",{\"2\":{\"259\":1}}],[\"a∈ra×b\",{\"2\":{\"259\":1}}],[\"a∈ra×ba\",{\"2\":{\"259\":1}}],[\"affine\",{\"2\":{\"251\":1}}],[\"available\",{\"2\":{\"255\":1}}],[\"avg\",{\"2\":{\"229\":1}}],[\"avgpool2d\",{\"2\":{\"86\":1,\"247\":2}}],[\"average\",{\"2\":{\"229\":1}}],[\"a2​\",{\"2\":{\"222\":1}}],[\"a2\",{\"2\":{\"222\":1}}],[\"a1​\",{\"2\":{\"222\":1}}],[\"a1​a2​​\",{\"2\":{\"222\":1}}],[\"a1\",{\"2\":{\"222\":1}}],[\"a1a2\",{\"2\":{\"222\":1}}],[\"aaaa\",{\"2\":{\"238\":2}}],[\"aaaaaaaaa\",{\"2\":{\"238\":1}}],[\"aaa\",{\"2\":{\"212\":1,\"222\":2}}],[\"abc\",{\"2\":{\"213\":1}}],[\"absmax\",{\"2\":{\"267\":1}}],[\"abstractmethod\",{\"2\":{\"213\":3}}],[\"abs\",{\"2\":{\"203\":1,\"223\":1,\"262\":4,\"267\":1}}],[\"about\",{\"2\":{\"113\":2}}],[\"api\",{\"2\":{\"169\":1}}],[\"approx\",{\"2\":{\"217\":1}}],[\"appropriate\",{\"2\":{\"138\":1,\"193\":1}}],[\"applied\",{\"2\":{\"97\":1,\"138\":1,\"193\":2}}],[\"application\",{\"2\":{\"79\":2}}],[\"apply\",{\"2\":{\"97\":3,\"103\":1,\"140\":1,\"193\":3,\"247\":1,\"285\":1}}],[\"applescript\",{\"2\":{\"79\":2}}],[\"append\",{\"2\":{\"63\":4,\"115\":2,\"117\":1,\"255\":1,\"261\":2}}],[\"across\",{\"2\":{\"263\":1}}],[\"acquire的协同作用可以视为内存屏障机制\",{\"2\":{\"205\":1}}],[\"acquire\",{\"2\":{\"205\":6}}],[\"accessed\",{\"2\":{\"260\":1}}],[\"acc\",{\"2\":{\"247\":10}}],[\"account\",{\"2\":{\"153\":1,\"193\":1}}],[\"accumulator\",{\"2\":{\"152\":2,\"247\":2,\"270\":1,\"285\":1}}],[\"accuracy\",{\"2\":{\"152\":3,\"247\":4}}],[\"activations\",{\"2\":{\"272\":1}}],[\"activation可以使用uint8类型的量化\",{\"2\":{\"271\":1}}],[\"activation的backward\",{\"2\":{\"263\":1}}],[\"activation\",{\"2\":{\"223\":1,\"271\":2}}],[\"active\",{\"2\":{\"100\":1}}],[\"acting\",{\"2\":{\"110\":1,\"193\":1}}],[\"authandaccess\",{\"2\":{\"150\":5}}],[\"autotune\",{\"2\":{\"197\":2}}],[\"auto的类型推导\",{\"2\":{\"150\":1}}],[\"auto类型推导通常和模板类型推导相同\",{\"2\":{\"135\":1}}],[\"auto类型推导有很多和模板类型推导一致\",{\"2\":{\"135\":1}}],[\"auto类型推导\",{\"0\":{\"135\":1}}],[\"autograd之中实现的功能\",{\"2\":{\"126\":1}}],[\"autograd\",{\"0\":{\"126\":1,\"140\":1},\"1\":{\"140\":1},\"2\":{\"140\":2,\"213\":1}}],[\"auto\",{\"2\":{\"87\":1,\"135\":13,\"150\":8,\"154\":6}}],[\"autofrontmatter\",{\"2\":{\"25\":1}}],[\"axis>\",{\"2\":{\"269\":6,\"273\":5}}],[\"axis\",{\"2\":{\"269\":4,\"273\":4}}],[\"axis=1\",{\"2\":{\"152\":1}}],[\"ax2+bx+c=0\",{\"2\":{\"128\":2}}],[\"ax^2\",{\"2\":{\"128\":2}}],[\"a≠0a\",{\"2\":{\"128\":1}}],[\"await处理\",{\"2\":{\"256\":1}}],[\"await异步编程\",{\"0\":{\"206\":1},\"1\":{\"219\":1,\"231\":1,\"242\":1}}],[\"await异步\",{\"0\":{\"120\":1},\"1\":{\"133\":1,\"147\":1,\"163\":1,\"177\":1,\"190\":1,\"206\":1,\"219\":1,\"231\":1,\"242\":1,\"250\":1,\"256\":1}}],[\"awq\",{\"2\":{\"251\":1}}],[\"awesome\",{\"2\":{\"100\":2}}],[\"a>\",{\"2\":{\"113\":5,\"199\":1}}],[\"assume\",{\"2\":{\"269\":2,\"273\":2}}],[\"assert\",{\"2\":{\"96\":1,\"97\":1,\"193\":1,\"203\":1}}],[\"asym\",{\"2\":{\"271\":1}}],[\"asymmetric\",{\"2\":{\"251\":1,\"262\":1}}],[\"async一起使用\",{\"2\":{\"279\":1}}],[\"async一样\",{\"2\":{\"265\":1}}],[\"async之前一般加上这么一句\",{\"2\":{\"279\":1}}],[\"async的实现是使用的\",{\"2\":{\"273\":1}}],[\"async貌似只能用来load\",{\"2\":{\"273\":1}}],[\"async来异步搬运数据\",{\"2\":{\"269\":1}}],[\"asynchronous\",{\"2\":{\"260\":2,\"265\":3,\"279\":1}}],[\"async其实是在一个线程中运行\",{\"2\":{\"231\":1}}],[\"async协程其实本质上也是在单进程中写并发代码\",{\"2\":{\"219\":1}}],[\"async\",{\"0\":{\"206\":1,\"265\":1,\"269\":1,\"273\":1},\"1\":{\"219\":1,\"231\":1,\"242\":1,\"269\":1,\"273\":1,\"276\":1,\"279\":1,\"282\":1},\"2\":{\"106\":1,\"265\":16,\"269\":12,\"273\":16,\"279\":9,\"282\":12}}],[\"asm\",{\"2\":{\"248\":1,\"254\":7,\"260\":6,\"269\":5,\"273\":7,\"279\":5,\"282\":1}}],[\"asterisks\",{\"2\":{\"127\":5,\"214\":1}}],[\"asio\",{\"2\":{\"106\":1}}],[\"as\",{\"2\":{\"88\":2,\"110\":1,\"117\":3,\"138\":1,\"152\":1,\"153\":1,\"193\":6}}],[\"a=\",{\"2\":{\"71\":1,\"82\":2,\"222\":4}}],[\"adamw优化器元素数量为\",{\"2\":{\"246\":1}}],[\"adam优化器梯度的一阶动量和二阶动量\",{\"2\":{\"246\":1}}],[\"adam\",{\"2\":{\"103\":1,\"181\":1,\"193\":1,\"285\":1}}],[\"adaptiveavgpool2d\",{\"2\":{\"75\":1}}],[\"addr\",{\"2\":{\"273\":7}}],[\"addressing\",{\"2\":{\"263\":1}}],[\"addressable\",{\"2\":{\"254\":2}}],[\"address\",{\"2\":{\"199\":2}}],[\"additional\",{\"2\":{\"110\":1,\"193\":1}}],[\"additiveattention\",{\"2\":{\"81\":3,\"115\":1}}],[\"added\",{\"2\":{\"100\":2}}],[\"add\",{\"2\":{\"59\":1,\"100\":2,\"140\":1,\"152\":2,\"169\":1,\"247\":4,\"270\":2,\"285\":2}}],[\"adipiscing\",{\"2\":{\"57\":4,\"68\":7}}],[\"amet\",{\"2\":{\"57\":6,\"68\":10}}],[\"ampare\",{\"2\":{\"179\":1}}],[\"amp\",{\"2\":{\"24\":18,\"36\":18,\"37\":18,\"42\":18,\"79\":2,\"119\":17,\"123\":12,\"141\":3,\"150\":1,\"175\":1,\"197\":1,\"263\":3}}],[\"along\",{\"2\":{\"222\":3}}],[\"allbubble​=m+p−1p−1​\",{\"2\":{\"252\":1}}],[\"all\",{\"2\":{\"213\":1,\"245\":1,\"252\":1,\"269\":6,\"273\":4}}],[\"allow\",{\"2\":{\"138\":1,\"193\":1}}],[\"alt\",{\"2\":{\"156\":3}}],[\"alerts\",{\"2\":{\"100\":1}}],[\"alexnet\",{\"0\":{\"54\":1}}],[\"align=\",{\"2\":{\"185\":1}}],[\"align=center\",{\"2\":{\"185\":1}}],[\"aligned\",{\"2\":{\"50\":2,\"123\":4,\"254\":3,\"269\":2,\"273\":2}}],[\"aliquam\",{\"2\":{\"57\":4,\"68\":6}}],[\"alphaα又被成为步长\",{\"2\":{\"78\":1}}],[\"alphaα\",{\"2\":{\"51\":1,\"70\":1,\"115\":1}}],[\"alpha\",{\"2\":{\"51\":2,\"59\":1,\"70\":2,\"78\":1,\"88\":1,\"115\":1,\"145\":2}}],[\"arguments\",{\"2\":{\"169\":1}}],[\"argmax\",{\"2\":{\"152\":1,\"261\":1}}],[\"args\",{\"2\":{\"115\":1,\"152\":2,\"213\":3,\"280\":5,\"283\":2}}],[\"arrived\",{\"2\":{\"282\":5}}],[\"arrive\",{\"2\":{\"260\":4,\"279\":1,\"282\":2}}],[\"arr2\",{\"2\":{\"135\":1}}],[\"arr1\",{\"2\":{\"135\":1}}],[\"arrays\",{\"2\":{\"88\":2}}],[\"array\",{\"2\":{\"88\":2,\"103\":1}}],[\"arch\",{\"2\":{\"63\":6,\"179\":2}}],[\"arange\",{\"2\":{\"51\":1,\"59\":1,\"81\":1,\"103\":1,\"124\":2,\"151\":2,\"193\":2,\"202\":2,\"220\":2,\"229\":1,\"255\":1,\"285\":1}}],[\"are\",{\"2\":{\"50\":4,\"100\":2,\"128\":4,\"138\":1,\"153\":1,\"193\":2}}],[\"atomic\",{\"2\":{\"112\":1}}],[\"attr=\",{\"2\":{\"185\":2}}],[\"attribute\",{\"2\":{\"113\":2,\"156\":1}}],[\"attends\",{\"2\":{\"153\":1,\"193\":1}}],[\"atten\",{\"2\":{\"97\":2,\"138\":2,\"193\":4}}],[\"attention块计算量估计\",{\"2\":{\"259\":1}}],[\"attention层\",{\"2\":{\"225\":1}}],[\"attention层和ffn层的中间激活\",{\"2\":{\"272\":1}}],[\"attention层和ffn层\",{\"2\":{\"225\":1}}],[\"attention使用序列的顺序信息而设计的\",{\"2\":{\"202\":1}}],[\"attention的计算复杂度和序列长度成平方关系\",{\"2\":{\"202\":1}}],[\"attention的最大路径长度最短\",{\"2\":{\"202\":1}}],[\"attention的输出应用一层mlp\",{\"2\":{\"110\":1}}],[\"attention都有并行计算的优势\",{\"2\":{\"202\":1}}],[\"attention三种架构的计算复杂性\",{\"2\":{\"202\":1}}],[\"attention中q\",{\"2\":{\"175\":1}}],[\"attention计算\",{\"2\":{\"143\":1}}],[\"attentiondecoder\",{\"2\":{\"115\":3}}],[\"attention\",{\"0\":{\"45\":1,\"97\":1,\"195\":1,\"201\":1},\"2\":{\"59\":2,\"81\":6,\"87\":2,\"91\":3,\"97\":8,\"110\":2,\"115\":9,\"138\":1,\"153\":2,\"159\":1,\"173\":2,\"186\":1,\"193\":13,\"202\":1,\"208\":1,\"225\":1,\"272\":1}}],[\"attn\",{\"2\":{\"97\":6,\"138\":2,\"153\":8,\"193\":16}}],[\"at\",{\"2\":{\"24\":4,\"36\":4,\"37\":4,\"42\":4}}],[\"atx\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1,\"49\":2}}],[\"any\",{\"2\":{\"141\":2,\"260\":1}}],[\"animator\",{\"2\":{\"59\":3,\"247\":4,\"270\":3,\"285\":3}}],[\"an\",{\"2\":{\"49\":2,\"79\":2,\"90\":2,\"110\":1,\"113\":3,\"143\":2,\"193\":1,\"254\":2,\"260\":1,\"265\":3}}],[\"answer\",{\"2\":{\"23\":1,\"30\":1,\"38\":1,\"47\":1,\"55\":1,\"66\":1}}],[\"anchor\",{\"2\":{\"18\":2}}],[\"another\",{\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1,\"68\":1,\"265\":3}}],[\"and\",{\"0\":{\"72\":1},\"2\":{\"1\":1,\"61\":2,\"97\":3,\"100\":4,\"128\":2,\"138\":2,\"152\":1,\"153\":3,\"166\":3,\"193\":8,\"260\":2,\"263\":2,\"270\":1,\"273\":2,\"279\":1,\"282\":1,\"283\":2}}],[\"a\",{\"0\":{\"16\":1},\"1\":{\"23\":1,\"30\":1,\"38\":1,\"47\":1,\"55\":1,\"66\":1},\"2\":{\"17\":1,\"28\":1,\"29\":1,\"33\":1,\"57\":3,\"61\":2,\"68\":8,\"70\":9,\"71\":21,\"79\":6,\"81\":3,\"82\":12,\"90\":10,\"91\":3,\"97\":2,\"110\":1,\"113\":7,\"119\":7,\"138\":4,\"141\":8,\"152\":2,\"153\":5,\"185\":2,\"191\":3,\"193\":12,\"199\":3,\"205\":2,\"220\":3,\"222\":7,\"238\":1,\"243\":3,\"254\":3,\"259\":10,\"260\":3,\"269\":1,\"272\":9,\"273\":1,\"279\":1}}],[\"ai领域的优化分为三类\",{\"2\":{\"23\":1}}],[\"ai\",{\"0\":{\"0\":1},\"1\":{\"1\":1,\"2\":1}}],[\"框架熟悉\",{\"2\":{\"1\":1}}],[\"sx​\",{\"2\":{\"271\":1}}],[\"sx\",{\"2\":{\"271\":1}}],[\"skipping\",{\"2\":{\"269\":1}}],[\"smem3\",{\"2\":{\"265\":1}}],[\"smem0\",{\"2\":{\"265\":1}}],[\"small\",{\"2\":{\"63\":2}}],[\"ss\",{\"2\":{\"254\":3}}],[\"sss\",{\"2\":{\"212\":1,\"275\":2}}],[\"srcmem\",{\"2\":{\"265\":2}}],[\"src4\",{\"2\":{\"254\":2}}],[\"src3\",{\"2\":{\"254\":2}}],[\"src2\",{\"2\":{\"254\":2}}],[\"src1\",{\"2\":{\"254\":2}}],[\"src\",{\"2\":{\"153\":3,\"167\":18,\"181\":5,\"193\":26,\"254\":14,\"269\":11,\"273\":22}}],[\"sym\",{\"2\":{\"271\":1}}],[\"symmetric\",{\"2\":{\"251\":1,\"262\":1}}],[\"syncwarp\",{\"2\":{\"279\":3}}],[\"synchronizing\",{\"2\":{\"260\":1}}],[\"sync\",{\"2\":{\"254\":3,\"282\":1}}],[\"syntax\",{\"2\":{\"100\":1}}],[\"synthetic\",{\"2\":{\"88\":3}}],[\"system\",{\"0\":{\"149\":1}}],[\"speed\",{\"2\":{\"270\":2}}],[\"space\",{\"2\":{\"254\":2,\"265\":3}}],[\"spaces\",{\"2\":{\"185\":2}}],[\"sparse\",{\"2\":{\"208\":1}}],[\"span\",{\"2\":{\"141\":4}}],[\"splits\",{\"2\":{\"220\":1}}],[\"split\",{\"2\":{\"97\":5,\"117\":1,\"193\":5,\"220\":1,\"222\":3}}],[\"saved\",{\"2\":{\"140\":1}}],[\"save\",{\"2\":{\"117\":2,\"140\":1,\"152\":1,\"202\":1,\"213\":2,\"247\":2,\"255\":1,\"261\":1,\"266\":1}}],[\"same\",{\"2\":{\"68\":1}}],[\"snippet\",{\"2\":{\"114\":6}}],[\"swap\",{\"2\":{\"97\":1,\"193\":1}}],[\"schedule\",{\"0\":{\"252\":1},\"2\":{\"213\":2,\"235\":1}}],[\"schedule的选择是通过get\",{\"2\":{\"213\":1}}],[\"scalescales\",{\"2\":{\"267\":1}}],[\"scales\",{\"2\":{\"267\":6}}],[\"scalemin\",{\"2\":{\"262\":1}}],[\"scale的分母就会变成255\",{\"2\":{\"262\":1}}],[\"scaleweight​\",{\"2\":{\"262\":2}}],[\"scale=127abs\",{\"2\":{\"262\":1}}],[\"scale=127max\",{\"2\":{\"262\":1}}],[\"scale=abs\",{\"2\":{\"262\":1}}],[\"scale=max\",{\"2\":{\"262\":1}}],[\"scale\",{\"0\":{\"235\":1},\"1\":{\"245\":1,\"252\":1,\"258\":1},\"2\":{\"251\":1,\"262\":4}}],[\"scaled\",{\"2\":{\"91\":1,\"97\":3,\"193\":3}}],[\"scaling\",{\"2\":{\"158\":1}}],[\"scoped\",{\"0\":{\"154\":1}}],[\"scores\",{\"2\":{\"81\":2,\"91\":2,\"97\":5,\"193\":5}}],[\"scores的形状\",{\"2\":{\"81\":1}}],[\"script\",{\"2\":{\"57\":1}}],[\"sq\",{\"2\":{\"255\":3}}],[\"squared\",{\"2\":{\"88\":2}}],[\"squeeze\",{\"2\":{\"61\":1,\"81\":1}}],[\"sqrt\",{\"2\":{\"51\":1,\"91\":4,\"96\":2,\"97\":1,\"128\":2,\"193\":1,\"259\":1,\"266\":1,\"275\":1,\"278\":2}}],[\"st>\",{\"2\":{\"269\":1,\"273\":1}}],[\"st>>\",{\"2\":{\"269\":2,\"273\":1}}],[\"stmatrix\",{\"2\":{\"254\":1,\"273\":1}}],[\"stg\",{\"2\":{\"254\":2,\"273\":2}}],[\"stsm4\",{\"2\":{\"254\":1}}],[\"sts\",{\"2\":{\"254\":2,\"269\":1}}],[\"stop\",{\"2\":{\"247\":1,\"270\":1,\"285\":1}}],[\"stop危险区域\",{\"2\":{\"100\":2}}],[\"store的时候\",{\"2\":{\"282\":1}}],[\"stores\",{\"2\":{\"279\":1}}],[\"store两个方法\",{\"2\":{\"265\":1}}],[\"store\",{\"0\":{\"254\":1,\"273\":1},\"2\":{\"205\":2,\"254\":2,\"260\":1,\"265\":1,\"273\":9,\"279\":6,\"282\":9}}],[\"stage的dualpipe\",{\"2\":{\"263\":1}}],[\"stage的时候\",{\"2\":{\"252\":1}}],[\"stage之后计算成本\",{\"2\":{\"252\":1}}],[\"stage倍\",{\"2\":{\"252\":2}}],[\"stage\",{\"2\":{\"213\":2,\"252\":2,\"263\":1}}],[\"stages=s\",{\"2\":{\"197\":1}}],[\"stack\",{\"2\":{\"187\":2,\"220\":1}}],[\"stacked\",{\"2\":{\"138\":1,\"153\":1,\"193\":2}}],[\"start\",{\"2\":{\"143\":1,\"247\":1}}],[\"started\",{\"2\":{\"100\":2}}],[\"staticmethod\",{\"2\":{\"140\":2}}],[\"static\",{\"2\":{\"119\":1,\"154\":4,\"254\":10,\"269\":6,\"273\":8,\"279\":5,\"282\":1}}],[\"state的形状\",{\"2\":{\"283\":2}}],[\"state的形状为\",{\"2\":{\"115\":2}}],[\"state对于nn\",{\"2\":{\"270\":2}}],[\"state共用一套量化参数\",{\"2\":{\"257\":1}}],[\"state=init\",{\"2\":{\"255\":1}}],[\"states\",{\"2\":{\"129\":1}}],[\"state\",{\"2\":{\"115\":10,\"230\":1,\"254\":2,\"255\":15,\"261\":6,\"265\":3,\"270\":9,\"277\":5,\"280\":5,\"283\":14}}],[\"st\",{\"2\":{\"115\":4,\"254\":7,\"269\":14,\"273\":10}}],[\"std=c++20\",{\"2\":{\"169\":1}}],[\"std=0\",{\"2\":{\"88\":1}}],[\"std\",{\"2\":{\"112\":3,\"118\":2,\"119\":1,\"135\":3,\"139\":2,\"150\":6,\"154\":15,\"205\":7}}],[\"str\",{\"2\":{\"247\":1,\"255\":3,\"270\":1,\"285\":1}}],[\"strategy\",{\"2\":{\"213\":2}}],[\"strategies\",{\"0\":{\"210\":1},\"1\":{\"222\":1,\"235\":1,\"245\":1,\"252\":1,\"258\":1,\"263\":1},\"2\":{\"213\":1}}],[\"struct\",{\"2\":{\"139\":4,\"150\":1,\"254\":3,\"260\":2}}],[\"structure\",{\"2\":{\"106\":1}}],[\"strong>\",{\"2\":{\"127\":2}}],[\"strong>double\",{\"2\":{\"127\":2}}],[\"strong\",{\"2\":{\"127\":1}}],[\"string\",{\"2\":{\"141\":2,\"150\":4,\"154\":2}}],[\"strip\",{\"2\":{\"117\":1}}],[\"stripes\",{\"2\":{\"50\":2}}],[\"stride\",{\"2\":{\"144\":1,\"269\":4,\"273\":4}}],[\"stride=\",{\"2\":{\"229\":1}}],[\"stride=1\",{\"2\":{\"86\":2}}],[\"stride=2\",{\"2\":{\"63\":1,\"75\":2,\"86\":5,\"144\":1,\"229\":2,\"247\":2}}],[\"strides=1\",{\"2\":{\"75\":2}}],[\"strides=4\",{\"2\":{\"75\":1}}],[\"strides\",{\"2\":{\"75\":2}}],[\"style=detailed\",{\"2\":{\"169\":1}}],[\"style\",{\"2\":{\"100\":1,\"113\":1}}],[\"steps的序列\",{\"2\":{\"176\":1}}],[\"steps的子序列的起始索引\",{\"2\":{\"176\":1}}],[\"steps\",{\"2\":{\"115\":4,\"129\":2,\"176\":7,\"188\":11,\"255\":2,\"270\":4,\"283\":14,\"285\":4}}],[\"step\",{\"2\":{\"59\":1,\"88\":1,\"103\":1,\"110\":1,\"181\":1,\"193\":2,\"247\":1,\"270\":1,\"285\":1}}],[\"sgd\",{\"2\":{\"59\":1,\"88\":3,\"247\":1,\"270\":2}}],[\"sglang\",{\"2\":{\"1\":1}}],[\"should\",{\"2\":{\"260\":1}}],[\"shm\",{\"2\":{\"254\":1}}],[\"shh\",{\"2\":{\"169\":1}}],[\"shikijs\",{\"2\":{\"100\":1}}],[\"shiki\",{\"2\":{\"100\":5}}],[\"shuffle=is\",{\"2\":{\"88\":1}}],[\"shuffle\",{\"2\":{\"88\":1,\"176\":1}}],[\"share\",{\"2\":{\"273\":1}}],[\"shared\",{\"0\":{\"72\":1},\"2\":{\"61\":1,\"72\":1,\"254\":8,\"260\":7,\"265\":11,\"269\":7,\"273\":14,\"279\":3,\"282\":7}}],[\"shape为\",{\"2\":{\"270\":1,\"283\":4}}],[\"shape均为\",{\"2\":{\"270\":1}}],[\"shape\",{\"2\":{\"59\":2,\"61\":8,\"70\":5,\"81\":1,\"86\":2,\"88\":2,\"91\":1,\"96\":8,\"97\":2,\"130\":5,\"144\":3,\"152\":4,\"173\":8,\"188\":1,\"193\":2,\"202\":1,\"203\":2,\"229\":4,\"247\":3,\"254\":1,\"255\":3,\"269\":1,\"270\":1,\"273\":1,\"277\":1,\"283\":4,\"285\":2}}],[\"shell\",{\"2\":{\"57\":1}}],[\"s\",{\"2\":{\"57\":1,\"97\":2,\"115\":1,\"128\":2,\"138\":1,\"150\":5,\"153\":5,\"193\":8,\"197\":1,\"232\":1,\"259\":31,\"270\":2,\"271\":10,\"272\":12,\"273\":2}}],[\"such\",{\"2\":{\"138\":1,\"193\":1}}],[\"surrounded\",{\"2\":{\"127\":1}}],[\"subset\",{\"2\":{\"260\":1}}],[\"subseqs\",{\"2\":{\"176\":3}}],[\"subspaces\",{\"2\":{\"159\":1}}],[\"sub\",{\"2\":{\"117\":1}}],[\"sublayer\",{\"2\":{\"87\":3}}],[\"suppress\",{\"2\":{\"169\":1}}],[\"supports\",{\"2\":{\"260\":1}}],[\"support\",{\"2\":{\"97\":1,\"193\":1}}],[\"super\",{\"2\":{\"59\":1,\"61\":2,\"81\":1,\"86\":2,\"91\":1,\"96\":1,\"97\":1,\"110\":1,\"115\":2,\"124\":1,\"126\":1,\"130\":1,\"138\":1,\"153\":1,\"167\":1,\"173\":1,\"193\":6,\"202\":1,\"277\":1,\"280\":3,\"283\":2,\"285\":1}}],[\"suspendisse\",{\"2\":{\"57\":2,\"68\":3}}],[\"sum\",{\"2\":{\"48\":1,\"51\":7,\"59\":7,\"70\":2,\"71\":8,\"82\":6,\"88\":1,\"103\":4,\"108\":1,\"115\":1,\"123\":14,\"130\":3,\"137\":1,\"140\":1,\"152\":3,\"166\":7,\"174\":1,\"191\":3,\"203\":1,\"247\":1,\"249\":2,\"266\":2,\"285\":3}}],[\"sigma^2σ2\",{\"2\":{\"272\":1}}],[\"sigmoid\",{\"2\":{\"247\":4}}],[\"sim\",{\"2\":{\"103\":2}}],[\"size为ppp\",{\"2\":{\"252\":1}}],[\"size决定\",{\"2\":{\"144\":1}}],[\"size+num\",{\"2\":{\"115\":1,\"283\":1}}],[\"size来获得平均损失\",{\"2\":{\"88\":1}}],[\"size来分割数据\",{\"2\":{\"88\":1}}],[\"size=8\",{\"2\":{\"283\":2}}],[\"size=x\",{\"2\":{\"270\":1}}],[\"size=len\",{\"2\":{\"255\":1}}],[\"size=shape\",{\"2\":{\"255\":1}}],[\"size=num\",{\"2\":{\"115\":2}}],[\"size=\",{\"2\":{\"88\":1,\"103\":1,\"130\":1,\"144\":3,\"152\":2,\"229\":1}}],[\"size=7\",{\"2\":{\"86\":2}}],[\"size=5\",{\"2\":{\"75\":1,\"86\":1,\"247\":3}}],[\"size=10\",{\"2\":{\"283\":2}}],[\"size=11\",{\"2\":{\"75\":1}}],[\"size=1\",{\"2\":{\"75\":2,\"86\":5,\"261\":1,\"270\":1,\"277\":1}}],[\"size=20\",{\"2\":{\"81\":1}}],[\"size=2\",{\"2\":{\"63\":1,\"81\":1,\"247\":2}}],[\"size=3\",{\"2\":{\"63\":1,\"75\":1,\"86\":7,\"144\":3}}],[\"size\",{\"2\":{\"61\":7,\"63\":2,\"75\":2,\"81\":10,\"88\":12,\"91\":5,\"97\":8,\"103\":2,\"115\":17,\"124\":1,\"129\":4,\"130\":2,\"152\":2,\"154\":5,\"167\":12,\"173\":16,\"176\":5,\"181\":7,\"188\":9,\"193\":28,\"197\":7,\"229\":2,\"235\":1,\"254\":1,\"255\":13,\"259\":6,\"265\":2,\"270\":7,\"273\":2,\"277\":10,\"283\":37,\"285\":8}}],[\"sizeof\",{\"2\":{\"55\":1,\"269\":2,\"273\":2}}],[\"site\",{\"2\":{\"169\":3}}],[\"sit\",{\"2\":{\"57\":6,\"68\":10}}],[\"single\",{\"2\":{\"97\":1,\"127\":2,\"138\":1,\"141\":2,\"153\":1,\"193\":3,\"282\":1}}],[\"sin\",{\"2\":{\"51\":1,\"103\":1,\"124\":1,\"193\":1,\"202\":2}}],[\"so\",{\"2\":{\"260\":1}}],[\"socket的请求后会调python函数handler\",{\"2\":{\"256\":1}}],[\"socket转发请求到其他wsgi\",{\"2\":{\"256\":1}}],[\"source\",{\"2\":{\"153\":2,\"193\":2}}],[\"sourcedir\",{\"2\":{\"32\":1}}],[\"solutions\",{\"2\":{\"128\":2}}],[\"sorted\",{\"2\":{\"117\":1}}],[\"sort\",{\"2\":{\"51\":1}}],[\"softmax层输出结果\",{\"2\":{\"225\":1}}],[\"softmax函数\",{\"2\":{\"152\":1}}],[\"softmaxsoftmaxsoftmax\",{\"2\":{\"95\":1,\"108\":2,\"123\":2,\"137\":1}}],[\"softmax精度问题\",{\"2\":{\"38\":1}}],[\"softmax\",{\"0\":{\"74\":1},\"1\":{\"85\":1,\"95\":1,\"108\":1,\"123\":1,\"137\":1,\"152\":1},\"2\":{\"23\":1,\"51\":1,\"59\":2,\"70\":4,\"81\":1,\"86\":1,\"91\":4,\"97\":2,\"108\":4,\"123\":3,\"137\":1,\"152\":4,\"193\":2,\"225\":1,\"259\":1,\"278\":2}}],[\"some\",{\"0\":{\"15\":1,\"208\":1},\"2\":{\"57\":1}}],[\"send之后完全释放\",{\"2\":{\"213\":1}}],[\"send出去\",{\"2\":{\"213\":1}}],[\"settings\",{\"2\":{\"169\":1}}],[\"setext\",{\"2\":{\"6\":1,\"13\":1,\"14\":1,\"19\":1,\"49\":2}}],[\"search\",{\"2\":{\"113\":16}}],[\"season\",{\"2\":{\"68\":2}}],[\"see\",{\"2\":{\"113\":1}}],[\"seq2seqdecoder\",{\"2\":{\"283\":3}}],[\"seq2seqencoder\",{\"2\":{\"283\":3}}],[\"seq2seq\",{\"0\":{\"283\":1},\"1\":{\"285\":1},\"2\":{\"285\":1}}],[\"seq2seqattentiondecoder\",{\"2\":{\"115\":2}}],[\"seqdataloader\",{\"2\":{\"188\":1,\"255\":1}}],[\"sequence\",{\"0\":{\"258\":1},\"2\":{\"70\":1,\"124\":1,\"153\":2,\"193\":3,\"235\":1,\"285\":2}}],[\"sequential\",{\"2\":{\"63\":4,\"75\":3,\"86\":4,\"88\":1,\"103\":1,\"188\":2,\"247\":1}}],[\"seq\",{\"2\":{\"61\":7,\"97\":6,\"124\":3,\"167\":9,\"176\":1,\"181\":4,\"188\":3,\"193\":22}}],[\"self\",{\"2\":{\"59\":6,\"61\":10,\"81\":14,\"86\":16,\"87\":1,\"91\":7,\"96\":17,\"97\":26,\"110\":9,\"115\":20,\"117\":22,\"124\":5,\"126\":3,\"130\":6,\"138\":17,\"152\":10,\"153\":22,\"167\":21,\"173\":18,\"186\":1,\"188\":12,\"193\":100,\"202\":10,\"213\":2,\"225\":2,\"255\":13,\"259\":1,\"272\":1,\"277\":30,\"280\":15,\"283\":17,\"285\":3}}],[\"sec\",{\"2\":{\"247\":1,\"285\":1}}],[\"second\",{\"2\":{\"57\":1,\"68\":1,\"97\":1,\"193\":1}}],[\"sections\",{\"0\":{\"1\":1}}],[\"semaphore\",{\"0\":{\"260\":1},\"2\":{\"260\":1,\"269\":1,\"273\":1,\"279\":1,\"282\":2}}],[\"sem\",{\"2\":{\"57\":2,\"68\":3}}],[\"semper\",{\"2\":{\"57\":2,\"68\":3}}],[\"server\",{\"2\":{\"15\":1}}],[\"学习率\",{\"2\":{\"130\":1}}],[\"学习容易\",{\"2\":{\"10\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"学习各种parallel策略\",{\"2\":{\"1\":1}}],[\"学习cpp可以增强自己对于底层cpu以及内存的理解\",{\"2\":{\"1\":1}}],[\"学会如何去写出性能高效的kernel\",{\"2\":{\"1\":1}}],[\"cvta\",{\"2\":{\"269\":3,\"273\":5,\"279\":1}}],[\"cg\",{\"2\":{\"265\":1,\"269\":2}}],[\"cluster\",{\"2\":{\"269\":2,\"273\":4}}],[\"clusters\",{\"0\":{\"235\":1},\"1\":{\"245\":1,\"252\":1,\"258\":1}}],[\"clipping\",{\"2\":{\"266\":1,\"270\":2,\"285\":1}}],[\"clip是一个截断操作\",{\"2\":{\"262\":1}}],[\"clip\",{\"2\":{\"262\":1}}],[\"clobber列表\",{\"2\":{\"248\":1}}],[\"cls\",{\"2\":{\"213\":2}}],[\"clamp\",{\"2\":{\"267\":2}}],[\"clangd中加上你的\",{\"2\":{\"169\":1}}],[\"clangd文件不支持访问环境变量\",{\"2\":{\"169\":1}}],[\"clangd文件来告诉clangd我的编译选项\",{\"2\":{\"169\":1}}],[\"clangd\",{\"2\":{\"169\":4}}],[\"classmethod\",{\"2\":{\"213\":2}}],[\"classes\",{\"2\":{\"86\":2}}],[\"class=\",{\"2\":{\"79\":2,\"185\":1}}],[\"class\",{\"2\":{\"59\":1,\"61\":2,\"81\":1,\"86\":3,\"91\":1,\"96\":1,\"97\":1,\"104\":1,\"110\":1,\"112\":3,\"115\":2,\"117\":1,\"118\":1,\"124\":1,\"126\":1,\"130\":1,\"138\":2,\"140\":1,\"152\":1,\"153\":2,\"154\":1,\"167\":1,\"173\":1,\"185\":1,\"188\":1,\"193\":8,\"202\":1,\"213\":2,\"255\":1,\"277\":1,\"280\":3,\"283\":2,\"285\":1}}],[\"ci⋅kh⋅kwc\",{\"2\":{\"174\":1,\"187\":1}}],[\"ci\",{\"2\":{\"174\":1,\"187\":1}}],[\"ci=1c\",{\"2\":{\"174\":1}}],[\"cic\",{\"2\":{\"174\":2}}],[\"csrc\",{\"2\":{\"169\":1}}],[\"cn\",{\"2\":{\"158\":2}}],[\"cnn\",{\"0\":{\"116\":1},\"1\":{\"130\":1,\"144\":1,\"160\":1,\"174\":1,\"187\":1,\"203\":1},\"2\":{\"55\":1,\"102\":1,\"202\":1}}],[\"c++11解决类型推断的方法是\",{\"2\":{\"154\":1}}],[\"c++14允许auto用于函数返回值并会被推导\",{\"2\":{\"135\":1}}],[\"cmp\",{\"2\":{\"152\":2}}],[\"created\",{\"2\":{\"260\":1}}],[\"criterion\",{\"2\":{\"181\":2,\"193\":2}}],[\"crossentropyloss\",{\"2\":{\"181\":1,\"193\":1,\"247\":1,\"270\":1,\"285\":1}}],[\"cross\",{\"2\":{\"152\":2,\"153\":3,\"193\":3,\"263\":1}}],[\"crx\",{\"2\":{\"122\":5,\"135\":2}}],[\"cx\",{\"2\":{\"122\":5,\"135\":2}}],[\"cta\",{\"2\":{\"254\":2,\"260\":9,\"265\":4,\"273\":11,\"279\":2}}],[\"ctrl\",{\"2\":{\"228\":2}}],[\"ctx之后的输入值的数量一致\",{\"2\":{\"140\":1}}],[\"ctx\",{\"2\":{\"140\":4}}],[\"ct\",{\"2\":{\"115\":4}}],[\"ccc\",{\"2\":{\"115\":1,\"158\":1}}],[\"center\",{\"2\":{\"185\":1}}],[\"center居中的内容\",{\"2\":{\"172\":2}}],[\"centered\",{\"2\":{\"50\":2}}],[\"certain\",{\"2\":{\"97\":1,\"153\":2,\"193\":3}}],[\"cdot\",{\"2\":{\"95\":1,\"123\":2,\"128\":4,\"130\":1,\"137\":1,\"144\":2,\"174\":2,\"187\":5,\"229\":3,\"230\":2,\"259\":2,\"278\":14}}],[\"c是一个干扰量\",{\"2\":{\"88\":1}}],[\"c4=128\",{\"2\":{\"86\":3}}],[\"c4=64\",{\"2\":{\"86\":5}}],[\"c4=32\",{\"2\":{\"86\":1}}],[\"c4\",{\"2\":{\"86\":2}}],[\"c3=\",{\"2\":{\"86\":9}}],[\"c3\",{\"2\":{\"86\":4}}],[\"c2=\",{\"2\":{\"86\":9}}],[\"c2\",{\"2\":{\"86\":4}}],[\"c1=384\",{\"2\":{\"86\":1}}],[\"c1=256\",{\"2\":{\"86\":2}}],[\"c1=112\",{\"2\":{\"86\":1}}],[\"c1=160\",{\"2\":{\"86\":1}}],[\"c1=192\",{\"2\":{\"86\":1}}],[\"c1=128\",{\"2\":{\"86\":2}}],[\"c1=64\",{\"2\":{\"86\":1}}],[\"c1\",{\"2\":{\"86\":2}}],[\"c​\",{\"2\":{\"82\":4}}],[\"cp\",{\"0\":{\"265\":1},\"1\":{\"269\":1,\"273\":1,\"276\":1,\"279\":1,\"282\":1},\"2\":{\"265\":12,\"269\":5,\"273\":7,\"279\":3,\"282\":1}}],[\"cpu\",{\"2\":{\"255\":1}}],[\"cpu算子加速库\",{\"2\":{\"66\":1}}],[\"cpp14\",{\"2\":{\"154\":1}}],[\"cpp\",{\"0\":{\"84\":1,\"106\":1},\"2\":{\"1\":2}}],[\"cuh\",{\"2\":{\"248\":1,\"265\":1}}],[\"customize\",{\"2\":{\"185\":2}}],[\"cutlass\",{\"0\":{\"183\":1}}],[\"curl\",{\"2\":{\"128\":2}}],[\"cublas\",{\"2\":{\"66\":1}}],[\"cudnn\",{\"2\":{\"66\":1}}],[\"cudnn内部采用这样计算conv2d\",{\"2\":{\"23\":1}}],[\"cuda实战01\",{\"0\":{\"234\":1}}],[\"cuda库的编译一般是使用setup\",{\"2\":{\"169\":1}}],[\"cudacc\",{\"2\":{\"169\":2}}],[\"cuda入门\",{\"2\":{\"1\":1}}],[\"cuda\",{\"0\":{\"165\":1},\"2\":{\"1\":1,\"66\":1,\"169\":3,\"273\":2}}],[\"ch8\",{\"2\":{\"261\":2,\"270\":4}}],[\"challenge\",{\"2\":{\"263\":1}}],[\"channel还是per\",{\"2\":{\"271\":1}}],[\"channel\",{\"2\":{\"257\":1,\"271\":1}}],[\"channels=1\",{\"2\":{\"130\":2,\"144\":2}}],[\"channels=192\",{\"2\":{\"86\":1}}],[\"channels=64\",{\"2\":{\"86\":4}}],[\"channels=out\",{\"2\":{\"63\":1}}],[\"channels=in\",{\"2\":{\"63\":1}}],[\"channels\",{\"2\":{\"63\":13,\"75\":8,\"86\":7}}],[\"change\",{\"2\":{\"128\":2}}],[\"char\",{\"2\":{\"117\":2,\"122\":3,\"135\":3}}],[\"chriskohlhoff\",{\"2\":{\"106\":1}}],[\"ch6\",{\"2\":{\"63\":1,\"247\":2}}],[\"ca\",{\"2\":{\"265\":1}}],[\"ca×b×c\",{\"2\":{\"259\":1}}],[\"calls\",{\"2\":{\"269\":2,\"273\":2}}],[\"call\",{\"2\":{\"213\":2,\"255\":1}}],[\"calculate\",{\"2\":{\"97\":1,\"193\":1}}],[\"cache延伸技术\",{\"0\":{\"281\":1},\"1\":{\"284\":1,\"286\":1}}],[\"cache的计算过程为\",{\"2\":{\"278\":1}}],[\"cache的re\",{\"2\":{\"197\":1}}],[\"cache和value\",{\"2\":{\"278\":2}}],[\"cache占用的显存下文会详细介绍\",{\"2\":{\"253\":1}}],[\"cache也需要占用显存\",{\"2\":{\"253\":1}}],[\"cache来加速推理过程\",{\"2\":{\"253\":1}}],[\"cache更加友好的原因\",{\"2\":{\"197\":1}}],[\"cache\",{\"0\":{\"196\":1,\"278\":1},\"1\":{\"212\":1,\"225\":1,\"236\":1,\"246\":1,\"253\":1,\"259\":1,\"264\":1,\"268\":1,\"272\":1,\"275\":1,\"278\":1,\"281\":1,\"284\":1,\"286\":1},\"2\":{\"197\":4,\"254\":4,\"269\":4,\"273\":4,\"278\":4}}],[\"capture\",{\"2\":{\"138\":1,\"193\":1}}],[\"cases\",{\"2\":{\"123\":2,\"137\":2}}],[\"cast\",{\"2\":{\"119\":1,\"154\":4,\"269\":4,\"273\":6,\"279\":1}}],[\"caution\",{\"2\":{\"90\":1,\"100\":4}}],[\"category\",{\"0\":{\"119\":1},\"2\":{\"119\":2}}],[\"cat\",{\"2\":{\"61\":1,\"86\":1,\"115\":2,\"220\":1,\"229\":1,\"255\":1,\"283\":1,\"285\":1}}],[\"can\",{\"2\":{\"61\":1,\"269\":1,\"273\":1}}],[\"c\",{\"2\":{\"55\":6,\"82\":16,\"88\":1,\"108\":2,\"115\":2,\"128\":4,\"143\":2,\"145\":1,\"150\":11,\"158\":1,\"169\":1,\"187\":2,\"191\":1,\"203\":6,\"220\":2,\"238\":1,\"243\":1,\"259\":1}}],[\"coords\",{\"2\":{\"269\":10,\"273\":10}}],[\"coordinates\",{\"2\":{\"269\":1,\"273\":1}}],[\"coord\",{\"2\":{\"269\":23,\"273\":17,\"282\":6}}],[\"cool\",{\"2\":{\"50\":2}}],[\"cop\",{\"2\":{\"254\":2}}],[\"copy到不同机器上\",{\"2\":{\"245\":1}}],[\"copy\",{\"2\":{\"24\":1,\"36\":1,\"37\":1,\"42\":1,\"79\":2,\"193\":1,\"265\":3,\"273\":1}}],[\"co⋅ci⋅kh⋅kwc\",{\"2\":{\"187\":1}}],[\"co​\",{\"2\":{\"187\":1}}],[\"coc\",{\"2\":{\"187\":1}}],[\"costly\",{\"2\":{\"263\":1}}],[\"cos\",{\"2\":{\"124\":1,\"193\":1,\"202\":2}}],[\"cout\",{\"2\":{\"118\":2}}],[\"count会自动减少\",{\"2\":{\"260\":1}}],[\"count+transaction\",{\"2\":{\"260\":2}}],[\"count\",{\"2\":{\"117\":2,\"260\":4,\"282\":4}}],[\"counter\",{\"2\":{\"117\":3}}],[\"corresponding\",{\"2\":{\"153\":1,\"193\":1}}],[\"corr2d\",{\"2\":{\"130\":3,\"174\":3,\"187\":3,\"203\":3}}],[\"corpus\",{\"2\":{\"117\":7,\"176\":5,\"188\":7,\"255\":1}}],[\"corporation\",{\"2\":{\"79\":2}}],[\"core来进行计算\",{\"2\":{\"197\":1}}],[\"core\",{\"2\":{\"15\":1}}],[\"concat\",{\"2\":{\"173\":2,\"278\":2}}],[\"concat的形状\",{\"2\":{\"173\":1}}],[\"conda\",{\"2\":{\"169\":9}}],[\"content\",{\"2\":{\"185\":2}}],[\"context\",{\"2\":{\"115\":2,\"283\":4}}],[\"context的形状为\",{\"2\":{\"115\":1}}],[\"container>\",{\"2\":{\"150\":1}}],[\"container\",{\"2\":{\"150\":10}}],[\"contiguous\",{\"2\":{\"97\":1,\"181\":2,\"193\":3}}],[\"configs=gemm\",{\"2\":{\"197\":1}}],[\"configs\",{\"2\":{\"197\":2}}],[\"config\",{\"2\":{\"100\":12,\"169\":1,\"197\":1}}],[\"connections\",{\"2\":{\"138\":1,\"153\":1,\"193\":2}}],[\"connection\",{\"2\":{\"87\":1,\"138\":1,\"193\":1}}],[\"consistency\",{\"0\":{\"205\":1}}],[\"consists\",{\"2\":{\"153\":1,\"193\":1}}],[\"console\",{\"2\":{\"100\":6}}],[\"const成员函数无法修改成员变量\",{\"2\":{\"211\":1}}],[\"const成员函数的线程安全\",{\"0\":{\"211\":1}}],[\"constexpr可以将一部分在运行时进行的计算转移到编译时进行\",{\"2\":{\"194\":1}}],[\"constexpr\",{\"0\":{\"194\":1},\"2\":{\"154\":3,\"269\":5,\"273\":5}}],[\"const修饰的函数被称为常量函数\",{\"2\":{\"118\":1}}],[\"const修饰函数\",{\"0\":{\"118\":1}}],[\"const修饰变量\",{\"0\":{\"104\":1}}],[\"const\",{\"0\":{\"94\":1},\"1\":{\"104\":1,\"118\":1},\"2\":{\"79\":2,\"100\":8,\"104\":7,\"118\":3,\"119\":1,\"122\":25,\"135\":9,\"150\":5,\"254\":4,\"269\":7,\"273\":9,\"279\":2}}],[\"consectetuer\",{\"2\":{\"57\":4,\"68\":7}}],[\"conversion\",{\"2\":{\"273\":2}}],[\"convert\",{\"2\":{\"40\":1,\"269\":1,\"273\":1}}],[\"conv4\",{\"2\":{\"86\":2}}],[\"conv3\",{\"2\":{\"86\":2}}],[\"conv2\",{\"2\":{\"86\":2}}],[\"conv2d可以通过转换成矩阵乘法来计算\",{\"2\":{\"23\":1}}],[\"conv2d\",{\"2\":{\"23\":1,\"63\":1,\"75\":3,\"86\":9,\"130\":8,\"144\":12,\"247\":4}}],[\"conv1\",{\"2\":{\"86\":2}}],[\"convs\",{\"2\":{\"63\":4}}],[\"conv\",{\"2\":{\"55\":1,\"63\":9}}],[\"color\",{\"2\":{\"271\":2}}],[\"cols\",{\"2\":{\"269\":2,\"273\":2}}],[\"collectively\",{\"2\":{\"254\":1}}],[\"collections\",{\"2\":{\"117\":2}}],[\"col\",{\"2\":{\"50\":4,\"222\":1,\"269\":9,\"273\":6}}],[\"code>`foo`\",{\"2\":{\"141\":1}}],[\"code>`\",{\"2\":{\"141\":1}}],[\"code>printf\",{\"2\":{\"141\":1}}],[\"code>there\",{\"2\":{\"141\":1}}],[\"code>this\",{\"2\":{\"79\":1}}],[\"code>tell\",{\"2\":{\"79\":1}}],[\"code>\",{\"2\":{\"79\":4,\"141\":10}}],[\"code\",{\"2\":{\"24\":3,\"36\":3,\"37\":3,\"42\":3,\"57\":1,\"79\":3,\"100\":24,\"114\":4,\"141\":4,\"197\":1,\"228\":1}}],[\"committed\",{\"2\":{\"282\":1}}],[\"commits\",{\"2\":{\"279\":1}}],[\"commit\",{\"2\":{\"265\":2,\"269\":1,\"273\":1,\"279\":3}}],[\"communication\",{\"0\":{\"213\":1},\"2\":{\"263\":2}}],[\"commands\",{\"2\":{\"169\":3}}],[\"com>\",{\"2\":{\"199\":1}}],[\"combination\",{\"2\":{\"153\":1,\"193\":1}}],[\"combines\",{\"2\":{\"97\":1,\"193\":1}}],[\"combine\",{\"2\":{\"61\":1,\"97\":3,\"193\":3}}],[\"compute\",{\"2\":{\"282\":1}}],[\"computation\",{\"2\":{\"263\":1}}],[\"compared\",{\"2\":{\"263\":1}}],[\"compiler\",{\"2\":{\"169\":1}}],[\"compileflags\",{\"2\":{\"169\":1}}],[\"compile\",{\"2\":{\"169\":1}}],[\"comp\",{\"2\":{\"144\":2}}],[\"completing\",{\"2\":{\"282\":1}}],[\"completion\",{\"2\":{\"169\":1,\"260\":1,\"265\":1}}],[\"complete\",{\"2\":{\"138\":1,\"153\":1,\"193\":2,\"265\":3,\"269\":2,\"273\":1,\"282\":1}}],[\"complex\",{\"2\":{\"138\":1,\"193\":1}}],[\"components\",{\"2\":{\"138\":1,\"193\":1}}],[\"com\",{\"2\":{\"15\":2,\"24\":2,\"36\":2,\"37\":2,\"42\":2,\"100\":2,\"106\":4,\"113\":22,\"175\":1,\"199\":4,\"273\":2}}]],\"serializationVersion\":2}"