{"content":"<p><a href=\"https://gordicaleksa.medium.com/eli5-flash-attention-5c44017022ad\" target=\"_blank\" rel=\"noopener noreferrer\">优质博客</a></p>\n","env":{"base":"/","filePath":"/Users/zhangfan/zfan2356/github/AI-Router/ai-router-v2/docs/notes/system/inference/flash_attention.md","filePathRelative":"notes/system/inference/flash_attention.md","frontmatter":{"title":"Flash Attention 优化","author":"zfan","createTime":"2025/04/11 22:07:39","permalink":"/system/inference/flash_attention/","tags":["system","inference"]},"sfcBlocks":{"template":{"type":"template","content":"<template><p><a href=\"https://gordicaleksa.medium.com/eli5-flash-attention-5c44017022ad\" target=\"_blank\" rel=\"noopener noreferrer\">优质博客</a></p>\n</template>","contentStripped":"<p><a href=\"https://gordicaleksa.medium.com/eli5-flash-attention-5c44017022ad\" target=\"_blank\" rel=\"noopener noreferrer\">优质博客</a></p>\n","tagOpen":"<template>","tagClose":"</template>"},"script":null,"scriptSetup":null,"scripts":[],"styles":[],"customBlocks":[]},"content":"[优质博客](https://gordicaleksa.medium.com/eli5-flash-attention-5c44017022ad)","excerpt":"","includedFiles":[],"tasklistId":0,"title":"","headers":[]}}
