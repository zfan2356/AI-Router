const e='{"documentCount":313,"nextId":313,"documentIds":{"0":"/","1":"/#sections","2":"/#一些想法","3":"/friends/","4":"/faq/","5":"/article/mcz1csb4/","6":"/article/mcgayb5w/","7":"/article/mcz1csb4/#概述","8":"/article/97s6ha1e/","9":"/article/2z59hh8g/","10":"/article/i4cuuonn/","11":"/article/mcgayb5w/#标题锚点","12":"/article/mcz1csb4/#用途","13":"/article/97s6ha1e/#概述","14":"/article/p6ciasa4/","15":"/article/2z59hh8g/#概述","16":"/algorithm/qa/","17":"/article/i4cuuonn/#概述","18":"/article/mcgayb5w/#自定义锚点","19":"/article/mcz1csb4/#行内-html","20":"/article/97s6ha1e/#用途","21":"/algorithm/","22":"/article/2z59hh8g/#用途","23":"/algorithm/qa/#说出resnet的模型结构","24":"/article/i4cuuonn/#用途","25":"/article/mcgayb5w/#链接","26":"/article/mcz1csb4/#特殊字元自动转换","27":"/article/97s6ha1e/#行内-html","28":"/python/","29":"/article/2z59hh8g/#行内-html","30":"/algorithm/qa/#transformer-encoder-block的模型结构","31":"/article/i4cuuonn/#行内-html","32":"/article/mcgayb5w/#内部链接","33":"/article/mcz1csb4/#块元素","34":"/article/97s6ha1e/#特殊字元自动转换","35":"/papers/","36":"/article/2z59hh8g/#特殊字元自动转换","37":"/algorithm/qa/#写出batchnorm和softmax的公式-bathnorm由哪些小算子构成-batchnorm和softmax在什么情况下计算结果可能会出现精度问题-为什么-如何解决","38":"/paper/read/","39":"/article/i4cuuonn/#特殊字元自动转换","40":"/article/mcgayb5w/#外部链接","41":"/article/mcz1csb4/#段落和换行","42":"/paper/transformer/","43":"/algorithm/qa/#加速ai模型的推理速度-该从哪些角度去考虑","44":"/cpp/","45":"/article/mcgayb5w/#github风格的表格","46":"/article/mcz1csb4/#标题","47":"/paper/transformer/#_2-常见问题","48":"/cuda/","49":"/algorithm/qa/#模型大小的四大评估指标是什么-举例说明对他们的理解","50":"/cuda/env/","51":"/article/mcgayb5w/#emoji","52":"/article/mcz1csb4/#blockquotes","53":"/cuda/gemm/","54":"/algorithm/qa/#说出加速resnet50推理速度的一些手段","55":"/cuda/hardware/","56":"/cuda/memory/","57":"/system/","58":"/article/mcgayb5w/#目录表","59":"/article/mcz1csb4/#列表","60":"/algorithm/limu/attention/","61":"/cuda/gemm/#cutlass-fast-gemm-with-wgmma","62":"/algorithm/limu/cnn/","63":"/algorithm/limu/linear/","64":"/cuda/memory/#一-memory-consistency-model","65":"/system/#一-技术杂谈","66":"/article/mcgayb5w/#自定义容器","67":"/article/mcz1csb4/#代码块","68":"/algorithm/limu/attention/#一-注意力机制简介","69":"/algorithm/limu/modern_cnn/","70":"/cuda/gemm/#gemm","71":"/algorithm/limu/cnn/#一-从全连接层过渡到卷积层","72":"/algorithm/limu/rnn/","73":"/algorithm/limu/linear/#一-什么是线性回归","74":"/algorithm/limu/softmax/","75":"/algorithm/limu/transformer/","76":"/system/#二-源码剖析","77":"/article/mcgayb5w/#默认标题","78":"/article/mcz1csb4/#分隔线","79":"/algorithm/limu/attention/#_1-引入","80":"/algorithm/limu/modern_cnn/#一-alexnet","81":"/algorithm/llm/mla/","82":"/algorithm/limu/cnn/#_1-介绍","83":"/algorithm/limu/rnn/#一-rnn引入","84":"/algorithm/llm/moe/","85":"/algorithm/limu/linear/#二-梯度下降","86":"/algorithm/limu/softmax/#一-什么是softmax","87":"/algorithm/limu/transformer/#一-模型架构","88":"/system/#rl","89":"/article/mcgayb5w/#自定义标题","90":"/algorithm/llm/mtp/","91":"/article/mcz1csb4/#行内元素","92":"/algorithm/llm/optimizer/","93":"/algorithm/limu/attention/#_2-非参数注意力汇聚","94":"/algorithm/limu/modern_cnn/#二-vgg","95":"/algorithm/limu/cnn/#_2-特性","96":"/algorithm/limu/rnn/#_1-简介","97":"/algorithm/llm/moe/#basic-moe","98":"/algorithm/llm/ppo/","99":"/algorithm/limu/linear/#_1-简介","100":"/algorithm/limu/softmax/#_1-引入","101":"/algorithm/limu/transformer/#_1-multi-head-attention","102":"/system/#inference","103":"/article/mcgayb5w/#导入代码块","104":"/article/mcz1csb4/#链接","105":"/algorithm/llm/optimizer/#一-optimizer","106":"/algorithm/limu/attention/#_3-带参数注意力汇聚","107":"/algorithm/limu/modern_cnn/#三-nin","108":"/python/language/async/","109":"/algorithm/limu/cnn/#_3-推导","110":"/algorithm/limu/rnn/#_2-马尔科夫模型","111":"/algorithm/llm/moe/#shared-experts-and-router","112":"/algorithm/llm/ppo/#一-ppo原理","113":"/pytorch/","114":"/algorithm/limu/linear/#_2-如何理解-沿梯度","115":"/algorithm/limu/softmax/#_2-介绍","116":"/algorithm/limu/transformer/#_2-position-wise-feed-forward-networks","117":"/python/pytorch/autograd/","118":"/system/#quant","119":"/article/mcgayb5w/#数学方程","120":"/article/mcz1csb4/#强调","121":"/algorithm/llm/optimizer/#二-zero","122":"/algorithm/limu/attention/#_4-注意力评分","123":"/algorithm/limu/modern_cnn/#四-googlenet","124":"/python/language/async/#一-多线程","125":"/algorithm/limu/cnn/#_4-通道","126":"/algorithm/limu/rnn/#_3-文本预处理","127":"/algorithm/llm/ppo/#二-deepspeed-chat","128":"/python/pytorch/basic/","129":"/algorithm/limu/linear/#_3-具体解法","130":"/python/pytorch/gradient/","131":"/algorithm/limu/softmax/#_3-梯度计算","132":"/algorithm/limu/transformer/#_3-positional-encoding","133":"/python/pytorch/autograd/#torch-autograd-function","134":"/article/mcgayb5w/#标记","135":"/article/mcz1csb4/#代码","136":"/algorithm/limu/attention/#加性注意力","137":"/algorithm/limu/modern_cnn/#五-batch-normalization","138":"/python/language/async/#为什么python中多线程的效率这么差","139":"/algorithm/limu/cnn/#_5-特征映射和感受野","140":"/algorithm/limu/rnn/#_4-语言模型","141":"/algorithm/llm/ppo/#_1-step1-sft","142":"/python/pytorch/basic/#一-torch-tensor","143":"/cpp/language/const/","144":"/cpp/language/modern/","145":"/python/pytorch/gradient/#一个简单的梯度计算例子","146":"/algorithm/limu/softmax/#_4-损失函数","147":"/algorithm/limu/transformer/#_4-encoder-layer","148":"/article/mcgayb5w/#上下角标","149":"/article/mcz1csb4/#图片","150":"/algorithm/limu/attention/#缩放点积注意力","151":"/algorithm/limu/modern_cnn/#六-resnet","152":"/python/language/async/#_1-对比其他语言","153":"/algorithm/limu/cnn/#_6-总结","154":"/algorithm/limu/rnn/#齐普夫定律","155":"/python/pytorch/basic/#_1-基础操作","156":"/cpp/language/const/#一-const修饰变量","157":"/cpp/language/move/","158":"/cpp/language/modern/#一-初始化","159":"/python/pytorch/gradient/#自动微分对向量的兼容","160":"/algorithm/limu/softmax/#二-从零实现softmax回归","161":"/algorithm/limu/transformer/#_5-decoder-layer","162":"/cpp/language/type/","163":"/cpp/projects/tiny_cpp_projects/","164":"/article/mcgayb5w/#自定义对齐","165":"/article/mcz1csb4/#其他文本样式","166":"/algorithm/limu/attention/#二-注意力模型","167":"/python/language/async/#_2-对比串行","168":"/algorithm/limu/cnn/#二-cnn-实现","169":"/algorithm/limu/rnn/#_5-数据集随机采样","170":"/python/pytorch/basic/#创建操作","171":"/cpp/language/const/#const修饰函数","172":"/cpp/language/move/#一-value-category","173":"/cpp/underlying/compiler/","174":"/cuda/exercise/chapter01/","175":"/cpp/language/modern/#二-nullptr","176":"/cuda/lszlsdfw/","177":"/python/pytorch/gradient/#反向传播起点","178":"/algorithm/limu/transformer/#transformer","179":"/cpp/language/type/#一-模板类型推导","180":"/cuda/kittens/ptx_inline/","181":"/article/mcgayb5w/#属性支持","182":"/article/mcz1csb4/#其它","183":"/algorithm/limu/attention/#_1-bahdanau注意力模型","184":"/python/language/async/#如何实现真正意义上的并行","185":"/system/29e039p4/","186":"/algorithm/limu/cnn/#_1-互相关运算","187":"/algorithm/limu/rnn/#随机采样","188":"/python/pytorch/basic/#计算操作","189":"/cpp/language/move/#二-为什么需要move","190":"/cpp/underlying/compiler/#一-简介","191":"/system/inference/flash_attention/","192":"/cpp/language/modern/#三-using","193":"/algorithm/limu/transformer/#二-模型训练","194":"/cpp/language/type/#二-auto类型推导","195":"/system/inference/kvcache/","196":"/cuda/kittens/ptx_inline/#一-浅谈一些封装的ptx","197":"/article/mcgayb5w/#任务列表","198":"/article/mcz1csb4/#自动链接","199":"/algorithm/limu/attention/#encoder步骤","200":"/python/language/async/#二-async-await异步编程","201":"/algorithm/limu/cnn/#_2-填充和步幅","202":"/algorithm/limu/rnn/#顺序分区","203":"/python/pytorch/basic/#_2-梯度操作","204":"/cpp/language/move/#三-其他","205":"/cpp/underlying/compiler/#二-编译流程","206":"/system/inference/gqa/","207":"/cpp/language/modern/#四-scoped-enum","208":"/system/inference/page-attn/","209":"/cpp/language/type/#三-decltype","210":"/system/inference/kvcache/#一-decoder-only模型量级分析","211":"/cuda/kittens/ptx_inline/#move-t-load-store","212":"/article/mcgayb5w/#脚注","213":"/article/mcz1csb4/#转义字符","214":"/algorithm/limu/attention/#decoder与attention机制步骤","215":"/python/language/async/#_1-介绍","216":"/system/inference/paper/","217":"/algorithm/limu/cnn/#_3-多输入和多输出通道","218":"/algorithm/limu/rnn/#二-rnn介绍","219":"/system/03fa33xq/","220":"/python/pytorch/basic/#_3-转换操作","221":"/cpp/underlying/compiler/#三-性能分析","222":"/system/pre-train/model-parallel/","223":"/cpp/language/modern/#五-deleted","224":"/system/inference/kvcache/#_1-模型参数量","225":"/system/pre-train/pp/","226":"/system/pre-train/zero/","227":"/cuda/kittens/ptx_inline/#semaphore-mbarrier-barrier-bar","228":"/article/mcz1csb4/#快捷键","229":"/system/m1n84ym5/","230":"/algorithm/limu/attention/#_2-多头注意力","231":"/system/quant/intro/","232":"/python/language/async/#_2-对比多线程","233":"/algorithm/limu/cnn/#多输入通道","234":"/algorithm/limu/rnn/#_1-原理","235":"/python/pytorch/basic/#_4-切片操作","236":"/cpp/underlying/compiler/#四-补充","237":"/system/pre-train/model-parallel/#megatron-lm-training-multi-billion-parameter-language-models","238":"/system/quant/pytorch-quant/","239":"/cpp/language/modern/#六-override-noexcept","240":"/system/sy4ndlm7/","241":"/system/inference/kvcache/#总结","242":"/system/rl/intro/","243":"/system/pre-train/zero/#一-zero","244":"/cuda/kittens/ptx_inline/#cp-async","245":"/article/mcz1csb4/#表格","246":"/algorithm/limu/attention/#实现","247":"/system/quant/intro/#一-什么是模型量化","248":"/python/language/async/#_3-对比其他语言的协程","249":"/system/pre-train/deepspeed/deepspeed01/","250":"/algorithm/limu/cnn/#多输出通道","251":"/algorithm/limu/rnn/#有隐状态的循环神经网络","252":"/python/pytorch/basic/#_5-线性代数","253":"/cpp/underlying/compiler/#_1-指令集","254":"/system/pre-train/model-parallel/#megatron-lm2-efficient-large-scale-language-model-training-on-gpu-clusters-using-megatron-lm","255":"/cpp/language/modern/#七-constexpr","256":"/system/inference/kvcache/#_1-1-训练过程显存占用分析","257":"/cuda/kittens/ptx_inline/#load-async","258":"/algorithm/limu/attention/#_3-自注意力和位置编码","259":"/system/quant/intro/#二-模型量化分类和粒度","260":"/python/language/async/#三-在python中书写并行","261":"/system/pre-train/deepspeed/deepspeed01/#一-launcher","262":"/algorithm/limu/cnn/#_4-1-1卷积层","263":"/algorithm/limu/rnn/#设计字符级rnn模型","264":"/cpp/underlying/compiler/#_2-汇编语法初探","265":"/system/pre-train/model-parallel/#_1-mix-parallel","266":"/cpp/language/modern/#八-const成员函数的线程安全","267":"/system/inference/kvcache/#_1-2-推理过程显存占用分析","268":"/cuda/kittens/ptx_inline/#store-async","269":"/algorithm/limu/attention/#对比","270":"/system/quant/intro/#_1-量化分类","271":"/python/language/async/#_1-进程并行","272":"/system/pre-train/deepspeed/deepspeed01/#_1-communication","273":"/algorithm/limu/cnn/#三-汇聚层pooling","274":"/algorithm/limu/rnn/#模型困惑度","275":"/system/pre-train/model-parallel/#_2-interleaved-schedule","276":"/cpp/language/modern/#九-特殊成员函数","277":"/system/inference/kvcache/#_2-计算量flops估计","278":"/cuda/kittens/ptx_inline/#同步机制","279":"/system/quant/intro/#三-如何做量化","280":"/system/pre-train/deepspeed/deepspeed01/#_2-network","281":"/algorithm/limu/cnn/#_1-最大汇聚层与平均汇聚层","282":"/algorithm/limu/rnn/#_2-实现","283":"/system/pre-train/model-parallel/#_3-sequence-parallel","284":"/system/inference/kvcache/#_2-1-计算量与参数量关联","285":"/cuda/kittens/ptx_inline/#with-tma","286":"/system/quant/intro/#公式","287":"/system/pre-train/deepspeed/deepspeed01/#_3-subprocess","288":"/algorithm/limu/cnn/#_2-总结","289":"/algorithm/limu/rnn/#预测","290":"/system/pre-train/model-parallel/#dualpipe","291":"/system/inference/kvcache/#_2-2-训练时间估计","292":"/cuda/kittens/ptx_inline/#non-tma","293":"/system/quant/intro/#四-实际应用","294":"/system/pre-train/deepspeed/deepspeed01/#二-initialize","295":"/algorithm/limu/cnn/#四-lenet","296":"/algorithm/limu/rnn/#_3-梯度裁剪","297":"/system/inference/kvcache/#_3-中间激活值分析","298":"/system/quant/intro/#五-如何选择","299":"/system/pre-train/deepspeed/deepspeed01/#_1-distribute","300":"/algorithm/limu/rnn/#_4-训练","301":"/system/inference/kvcache/#_3-1-对比中间激活与模型参数大小","302":"/system/pre-train/deepspeed/deepspeed01/#_2-deepspeed-initialize","303":"/algorithm/limu/rnn/#三-现代rnn","304":"/system/inference/kvcache/#二-推理与kv-cache","305":"/system/pre-train/deepspeed/deepspeed01/#_3-config","306":"/algorithm/limu/rnn/#_1-基本结构","307":"/system/inference/kvcache/#三-kv-cache延伸技术","308":"/algorithm/limu/rnn/#_2-encoder-decoder","309":"/system/inference/kvcache/#_1-batch-prompting","310":"/algorithm/limu/rnn/#_3-seq2seq","311":"/system/inference/kvcache/#_2-ralyattention","312":"/algorithm/limu/rnn/#训练"},"fieldIds":{"title":0,"titles":1,"text":2},"fieldLength":{"0":[2,1,4],"1":[1,2,31],"2":[1,2,12],"3":[1,1,1],"4":[1,1,2],"5":[2,1,7],"6":[2,1,1],"7":[1,2,59],"8":[1,1,1],"9":[1,1,1],"10":[1,1,1],"11":[1,2,2],"12":[1,2,32],"13":[1,1,59],"14":[3,1,30],"15":[1,1,59],"16":[2,1,1],"17":[1,1,59],"18":[1,3,8],"19":[2,3,54],"20":[1,1,32],"21":[2,1,3],"22":[1,1,32],"23":[2,2,23],"24":[1,1,32],"25":[1,2,20],"26":[1,3,80],"27":[2,2,54],"28":[1,1,1],"29":[2,2,54],"30":[4,2,3],"31":[2,2,54],"32":[1,3,19],"33":[1,2,1],"34":[1,2,80],"35":[1,1,1],"36":[1,2,80],"37":[6,2,28],"38":[1,1,30],"39":[1,2,80],"40":[1,4,8],"41":[1,3,52],"42":[1,1,2],"43":[2,2,10],"44":[1,1,1],"45":[1,2,21],"46":[1,3,39],"47":[2,1,18],"48":[1,1,1],"49":[2,2,72],"50":[3,1,147],"51":[2,2,11],"52":[1,3,92],"53":[1,1,10],"54":[1,2,18],"55":[2,1,6],"56":[2,1,1],"57":[1,1,5],"58":[1,2,6],"59":[1,3,144],"60":[1,1,1],"61":[5,1,5],"62":[1,1,5],"63":[2,1,1],"64":[4,2,71],"65":[2,1,13],"66":[1,2,3],"67":[1,3,91],"68":[2,1,1],"69":[1,1,3],"70":[1,1,113],"71":[2,1,1],"72":[1,1,1],"73":[3,2,44],"74":[1,1,1],"75":[1,1,3],"76":[2,1,14],"77":[1,3,16],"78":[1,3,8],"79":[2,3,11],"80":[2,1,1],"81":[4,1,2],"82":[2,3,13],"83":[2,1,1],"84":[1,1,1],"85":[2,2,1],"86":[2,1,1],"87":[2,1,76],"88":[1,1,2],"89":[1,3,195],"90":[3,1,2],"91":[1,2,1],"92":[1,1,1],"93":[2,3,110],"94":[2,1,80],"95":[2,3,13],"96":[2,3,21],"97":[2,1,97],"98":[1,1,1],"99":[2,4,28],"100":[2,3,60],"101":[4,3,127],"102":[1,1,2],"103":[1,2,27],"104":[1,3,168],"105":[2,1,70],"106":[2,3,156],"107":[2,1,42],"108":[2,1,1],"109":[2,3,90],"110":[2,3,218],"111":[4,1,19],"112":[2,1,34],"113":[1,1,1],"114":[4,4,55],"115":[2,3,69],"116":[6,3,53],"117":[2,1,41],"118":[1,1,2],"119":[1,2,75],"120":[1,3,48],"121":[2,1,18],"122":[2,3,104],"123":[2,1,96],"124":[2,2,14],"125":[2,3,68],"126":[2,3,154],"127":[3,1,100],"128":[1,1,1],"129":[2,4,208],"130":[1,1,5],"131":[2,3,102],"132":[3,3,57],"133":[3,2,133],"134":[1,2,15],"135":[1,3,71],"136":[1,5,132],"137":[3,1,86],"138":[2,4,1],"139":[2,3,14],"140":[2,3,48],"141":[3,4,155],"142":[3,1,1],"143":[2,1,1],"144":[1,1,1],"145":[1,1,150],"146":[2,3,89],"147":[3,3,93],"148":[1,2,12],"149":[1,3,42],"150":[1,5,106],"151":[2,1,1],"152":[2,6,46],"153":[2,3,14],"154":[1,5,33],"155":[2,4,4],"156":[2,2,32],"157":[2,1,1],"158":[2,1,78],"159":[1,1,100],"160":[2,1,144],"161":[3,3,95],"162":[1,1,1],"163":[3,1,10],"164":[1,2,6],"165":[1,3,7],"166":[2,1,1],"167":[2,6,14],"168":[3,1,1],"169":[2,3,6],"170":[1,6,22],"171":[1,2,48],"172":[3,2,69],"173":[1,1,1],"174":[1,1,2],"175":[2,1,11],"176":[1,1,1],"177":[1,1,34],"178":[1,3,63],"179":[2,1,66],"180":[2,1,2],"181":[1,2,38],"182":[1,2,1],"183":[2,3,137],"184":[1,4,14],"185":[1,1,1],"186":[2,4,127],"187":[1,5,57],"188":[1,6,40],"189":[2,2,4],"190":[2,1,88],"191":[3,1,2],"192":[2,1,30],"193":[2,1,65],"194":[2,1,56],"195":[2,1,1],"196":[2,2,32],"197":[1,2,8],"198":[1,3,57],"199":[1,5,18],"200":[3,2,1],"201":[2,4,106],"202":[1,5,60],"203":[2,4,8],"204":[2,2,4],"205":[2,1,83],"206":[3,1,1],"207":[3,1,98],"208":[3,1,1],"209":[2,1,84],"210":[3,2,26],"211":[6,4,124],"212":[1,2,12],"213":[1,3,28],"214":[1,5,45],"215":[2,5,20],"216":[2,1,6],"217":[2,4,3],"218":[2,1,1],"219":[1,1,1],"220":[2,4,41],"221":[2,1,153],"222":[3,1,1],"223":[2,1,14],"224":[2,5,76],"225":[2,1,143],"226":[1,1,1],"227":[4,4,141],"228":[1,2,17],"229":[1,1,1],"230":[2,3,108],"231":[1,1,1],"232":[2,5,41],"233":[1,6,66],"234":[2,3,50],"235":[2,4,18],"236":[2,1,3],"237":[8,3,76],"238":[1,1,16],"239":[3,1,11],"240":[1,1,1],"241":[1,7,23],"242":[1,1,1],"243":[2,1,1],"244":[2,4,93],"245":[1,2,12],"246":[1,5,103],"247":[2,1,1],"248":[2,5,6],"249":[2,1,5],"250":[1,6,57],"251":[1,5,83],"252":[2,4,16],"253":[2,3,111],"254":[13,3,19],"255":[2,1,4],"256":[2,7,48],"257":[2,6,179],"258":[2,3,56],"259":[2,1,1],"260":[2,2,5],"261":[2,2,14],"262":[3,4,52],"263":[1,5,10],"264":[2,3,5],"265":[3,16,27],"266":[2,1,10],"267":[3,7,27],"268":[2,6,217],"269":[1,5,140],"270":[2,3,39],"271":[2,4,52],"272":[2,4,101],"273":[2,1,15],"274":[1,5,65],"275":[3,16,111],"276":[2,1,7],"277":[2,5,118],"278":[1,6,3],"279":[2,1,19],"280":[2,4,29],"281":[2,3,112],"282":[2,3,164],"283":[3,16,6],"284":[3,7,39],"285":[3,7,89],"286":[1,3,56],"287":[2,4,47],"288":[2,3,10],"289":[1,5,65],"290":[1,3,130],"291":[2,7,49],"292":[2,7,99],"293":[2,1,51],"294":[2,2,48],"295":[2,1,164],"296":[2,3,80],"297":[2,5,139],"298":[2,3,68],"299":[2,4,90],"300":[2,3,133],"301":[3,7,39],"302":[3,4,95],"303":[2,1,1],"304":[3,2,165],"305":[2,4,296],"306":[2,3,66],"307":[3,2,1],"308":[3,3,31],"309":[3,4,8],"310":[2,3,139],"311":[2,4,3],"312":[1,5,147]},"averageFieldLength":[1.8753993610223643,2.543130990415338,45.297124600638966],"storedFields":{"0":{"title":"AI-Router","titles":[]},"1":{"title":"Sections","titles":["AI-Router"]},"2":{"title":"一些想法","titles":["AI-Router"]},"3":{"title":"友情链接","titles":[]},"4":{"title":"常见问题","titles":[]},"5":{"title":"Markdown 基础","titles":[]},"6":{"title":"markdown 扩展","titles":[]},"7":{"title":"概述","titles":["Markdown 基础"]},"8":{"title":"全屏水印","titles":[]},"9":{"title":"内容水印","titles":[]},"10":{"title":"图片水印","titles":[]},"11":{"title":"标题锚点","titles":["markdown 扩展"]},"12":{"title":"用途","titles":["Markdown 基础"]},"13":{"title":"概述","titles":["全屏水印"]},"14":{"title":"Some TODO Notes","titles":[]},"15":{"title":"概述","titles":["内容水印"]},"16":{"title":"Q&A","titles":[]},"17":{"title":"概述","titles":["图片水印"]},"18":{"title":"自定义锚点","titles":["markdown 扩展","标题锚点"]},"19":{"title":"行内 HTML","titles":["Markdown 基础","用途"]},"20":{"title":"用途","titles":["全屏水印"]},"21":{"title":"Linear Regression","titles":[]},"22":{"title":"用途","titles":["内容水印"]},"23":{"title":"说出ResNet的模型结构?","titles":["Q&A"]},"24":{"title":"用途","titles":["图片水印"]},"25":{"title":"链接","titles":["markdown 扩展"]},"26":{"title":"特殊字元自动转换","titles":["Markdown 基础","用途"]},"27":{"title":"行内 HTML","titles":["全屏水印","用途"]},"28":{"title":"python","titles":[]},"29":{"title":"行内 HTML","titles":["内容水印","用途"]},"30":{"title":"Transformer encoder block的模型结构？","titles":["Q&A"]},"31":{"title":"行内 HTML","titles":["图片水印","用途"]},"32":{"title":"内部链接","titles":["markdown 扩展","链接"]},"33":{"title":"块元素","titles":["Markdown 基础"]},"34":{"title":"特殊字元自动转换","titles":["全屏水印","用途"]},"35":{"title":"papers","titles":[]},"36":{"title":"特殊字元自动转换","titles":["内容水印","用途"]},"37":{"title":"写出batchnorm和softmax的公式，bathnorm由哪些小算子构成，batchnorm和softmax在什么情况下计算结果可能会出现精度问题？为什么？如何解决？","titles":["Q&A"]},"38":{"title":"paper阅读记录","titles":[]},"39":{"title":"特殊字元自动转换","titles":["图片水印","用途"]},"40":{"title":"外部链接","titles":["markdown 扩展","链接","内部链接"]},"41":{"title":"段落和换行","titles":["Markdown 基础","块元素"]},"42":{"title":"Transformer论文","titles":[]},"43":{"title":"加速AI模型的推理速度，该从哪些角度去考虑","titles":["Q&A"]},"44":{"title":"cpp","titles":[]},"45":{"title":"Github风格的表格","titles":["markdown 扩展"]},"46":{"title":"标题","titles":["Markdown 基础","块元素"]},"47":{"title":"2. 常见问题","titles":["Transformer论文"]},"48":{"title":"cuda","titles":[]},"49":{"title":"模型大小的四大评估指标是什么，举例说明对他们的理解","titles":["Q&A"]},"50":{"title":"CUDA Dev Env","titles":[]},"51":{"title":"Emoji 🎉","titles":["markdown 扩展"]},"52":{"title":"Blockquotes","titles":["Markdown 基础","块元素"]},"53":{"title":"Gemm","titles":[]},"54":{"title":"说出加速ResNet50推理速度的一些手段","titles":["Q&A"]},"55":{"title":"hardware paper","titles":[]},"56":{"title":"Memory Model","titles":[]},"57":{"title":"system","titles":[]},"58":{"title":"目录表","titles":["markdown 扩展"]},"59":{"title":"列表","titles":["Markdown 基础","块元素"]},"60":{"title":"注意力机制","titles":[]},"61":{"title":"Cutlass: Fast GEMM with WGMMA","titles":["Gemm"]},"62":{"title":"卷积神经网络CNN","titles":[]},"63":{"title":"Linear Regression","titles":[]},"64":{"title":"一. Memory Consistency Model","titles":["Memory Model"]},"65":{"title":"一. 技术杂谈","titles":["system"]},"66":{"title":"自定义容器","titles":["markdown 扩展"]},"67":{"title":"代码块","titles":["Markdown 基础","块元素"]},"68":{"title":"一. 注意力机制简介","titles":["注意力机制"]},"69":{"title":"现代卷积神经网络","titles":[]},"70":{"title":"GEMM","titles":["Gemm"]},"71":{"title":"一. 从全连接层过渡到卷积层","titles":["卷积神经网络CNN"]},"72":{"title":"循环神经网络RNN","titles":[]},"73":{"title":"一. 什么是线性回归？","titles":["Linear Regression"]},"74":{"title":"Softmax","titles":[]},"75":{"title":"Transformer架构","titles":[]},"76":{"title":"二. 源码剖析","titles":["system"]},"77":{"title":"默认标题","titles":["markdown 扩展","自定义容器"]},"78":{"title":"分隔线","titles":["Markdown 基础","块元素"]},"79":{"title":"1. 引入","titles":["注意力机制","一. 注意力机制简介"]},"80":{"title":"一. AlexNet","titles":["现代卷积神经网络"]},"81":{"title":"Multi-Head Latent Attention","titles":[]},"82":{"title":"1. 介绍","titles":["卷积神经网络CNN","一. 从全连接层过渡到卷积层"]},"83":{"title":"一. RNN引入","titles":["循环神经网络RNN"]},"84":{"title":"MoE架构","titles":[]},"85":{"title":"二. 梯度下降","titles":["Linear Regression"]},"86":{"title":"一. 什么是Softmax","titles":["Softmax"]},"87":{"title":"一. 模型架构","titles":["Transformer架构"]},"88":{"title":"RL","titles":[]},"89":{"title":"自定义标题","titles":["markdown 扩展","自定义容器"]},"90":{"title":"Multi-Token Prediction","titles":[]},"91":{"title":"行内元素","titles":["Markdown 基础"]},"92":{"title":"Optimizer","titles":[]},"93":{"title":"2. 非参数注意力汇聚","titles":["注意力机制","一. 注意力机制简介"]},"94":{"title":"二. VGG","titles":["现代卷积神经网络"]},"95":{"title":"2. 特性","titles":["卷积神经网络CNN","一. 从全连接层过渡到卷积层"]},"96":{"title":"1. 简介","titles":["循环神经网络RNN","一. RNN引入"]},"97":{"title":"Basic MoE","titles":["MoE架构"]},"98":{"title":"PPO","titles":[]},"99":{"title":"1. 简介","titles":["Linear Regression","二. 梯度下降"]},"100":{"title":"1. 引入","titles":["Softmax","一. 什么是Softmax"]},"101":{"title":"1. Multi-Head Attention","titles":["Transformer架构","一. 模型架构"]},"102":{"title":"Inference","titles":[]},"103":{"title":"导入代码块","titles":["markdown 扩展"]},"104":{"title":"链接","titles":["Markdown 基础","行内元素"]},"105":{"title":"一. Optimizer","titles":["Optimizer"]},"106":{"title":"3. 带参数注意力汇聚","titles":["注意力机制","一. 注意力机制简介"]},"107":{"title":"三. NiN","titles":["现代卷积神经网络"]},"108":{"title":"Python中多线程和async/await异步","titles":[]},"109":{"title":"3. 推导","titles":["卷积神经网络CNN","一. 从全连接层过渡到卷积层"]},"110":{"title":"2. 马尔科夫模型","titles":["循环神经网络RNN","一. RNN引入"]},"111":{"title":"Shared Experts and Router","titles":["MoE架构"]},"112":{"title":"一. PPO原理","titles":["PPO"]},"113":{"title":"pytorch","titles":[]},"114":{"title":"2. 如何理解“沿梯度”","titles":["Linear Regression","二. 梯度下降"]},"115":{"title":"2. 介绍","titles":["Softmax","一. 什么是Softmax"]},"116":{"title":"2. Position-wise Feed-Forward Networks","titles":["Transformer架构","一. 模型架构"]},"117":{"title":"PyTorch AutoGrad","titles":[]},"118":{"title":"Quant","titles":[]},"119":{"title":"数学方程","titles":["markdown 扩展"]},"120":{"title":"强调","titles":["Markdown 基础","行内元素"]},"121":{"title":"二. ZeRO","titles":["Optimizer"]},"122":{"title":"4. 注意力评分","titles":["注意力机制","一. 注意力机制简介"]},"123":{"title":"四. GoogLeNet","titles":["现代卷积神经网络"]},"124":{"title":"一. 多线程","titles":["Python中多线程和async/await异步"]},"125":{"title":"4. 通道","titles":["卷积神经网络CNN","一. 从全连接层过渡到卷积层"]},"126":{"title":"3. 文本预处理","titles":["循环神经网络RNN","一. RNN引入"]},"127":{"title":"二. DeepSpeed-Chat","titles":["PPO"]},"128":{"title":"PyTorch常用函数以及方法","titles":[]},"129":{"title":"3. 具体解法","titles":["Linear Regression","二. 梯度下降"]},"130":{"title":"PyTorch中的梯度计算","titles":[]},"131":{"title":"3. 梯度计算","titles":["Softmax","一. 什么是Softmax"]},"132":{"title":"3. Positional Encoding","titles":["Transformer架构","一. 模型架构"]},"133":{"title":"torch.autograd.Function","titles":["PyTorch AutoGrad"]},"134":{"title":"标记","titles":["markdown 扩展"]},"135":{"title":"代码","titles":["Markdown 基础","行内元素"]},"136":{"title":"加性注意力","titles":["注意力机制","一. 注意力机制简介","4. 注意力评分"]},"137":{"title":"五. Batch Normalization","titles":["现代卷积神经网络"]},"138":{"title":"为什么Python中多线程的效率这么差？","titles":["Python中多线程和async/await异步","一. 多线程"]},"139":{"title":"5. 特征映射和感受野","titles":["卷积神经网络CNN","一. 从全连接层过渡到卷积层"]},"140":{"title":"4. 语言模型","titles":["循环神经网络RNN","一. RNN引入"]},"141":{"title":"1. Step1: SFT","titles":["PPO","二. DeepSpeed-Chat"]},"142":{"title":"一. torch.tensor","titles":["PyTorch常用函数以及方法"]},"143":{"title":"Const 语义","titles":[]},"144":{"title":"现代cpp的一些特性","titles":[]},"145":{"title":"一个简单的梯度计算例子","titles":["PyTorch中的梯度计算"]},"146":{"title":"4. 损失函数","titles":["Softmax","一. 什么是Softmax"]},"147":{"title":"4. Encoder Layer","titles":["Transformer架构","一. 模型架构"]},"148":{"title":"上下角标","titles":["markdown 扩展"]},"149":{"title":"图片","titles":["Markdown 基础","行内元素"]},"150":{"title":"缩放点积注意力","titles":["注意力机制","一. 注意力机制简介","4. 注意力评分"]},"151":{"title":"六. ResNet","titles":["现代卷积神经网络"]},"152":{"title":"1. 对比其他语言","titles":["Python中多线程和async/await异步","一. 多线程","为什么Python中多线程的效率这么差？"]},"153":{"title":"6. 总结","titles":["卷积神经网络CNN","一. 从全连接层过渡到卷积层"]},"154":{"title":"齐普夫定律","titles":["循环神经网络RNN","一. RNN引入","4. 语言模型"]},"155":{"title":"1. 基础操作","titles":["PyTorch常用函数以及方法","一. torch.tensor"]},"156":{"title":"一. const修饰变量","titles":["Const 语义"]},"157":{"title":"move 语义","titles":[]},"158":{"title":"一. {} 初始化","titles":["现代cpp的一些特性"]},"159":{"title":"自动微分对向量的兼容","titles":["PyTorch中的梯度计算"]},"160":{"title":"二. 从零实现Softmax回归","titles":["Softmax"]},"161":{"title":"5. Decoder Layer","titles":["Transformer架构","一. 模型架构"]},"162":{"title":"类型推导","titles":[]},"163":{"title":"tiny cpp projects","titles":[]},"164":{"title":"自定义对齐","titles":["markdown 扩展"]},"165":{"title":"其他文本样式","titles":["Markdown 基础","行内元素"]},"166":{"title":"二. 注意力模型","titles":["注意力机制"]},"167":{"title":"2. 对比串行","titles":["Python中多线程和async/await异步","一. 多线程","为什么Python中多线程的效率这么差？"]},"168":{"title":"二. CNN 实现","titles":["卷积神经网络CNN"]},"169":{"title":"5. 数据集随机采样","titles":["循环神经网络RNN","一. RNN引入"]},"170":{"title":"创建操作","titles":["PyTorch常用函数以及方法","一. torch.tensor","1. 基础操作"]},"171":{"title":"const修饰函数","titles":["Const 语义"]},"172":{"title":"一. Value Category","titles":["move 语义"]},"173":{"title":"编译链接","titles":[]},"174":{"title":"CUDA实战01","titles":[]},"175":{"title":"二. nullptr","titles":["现代cpp的一些特性"]},"176":{"title":"README","titles":[]},"177":{"title":"反向传播起点","titles":["PyTorch中的梯度计算"]},"178":{"title":"transformer","titles":["Transformer架构","一. 模型架构"]},"179":{"title":"一. 模板类型推导","titles":["类型推导"]},"180":{"title":"Kittens PTX","titles":[]},"181":{"title":"属性支持","titles":["markdown 扩展"]},"182":{"title":"其它","titles":["Markdown 基础"]},"183":{"title":"1. Bahdanau注意力模型","titles":["注意力机制","二. 注意力模型"]},"184":{"title":"如何实现真正意义上的并行","titles":["Python中多线程和async/await异步","一. 多线程"]},"185":{"title":"README","titles":[]},"186":{"title":"1. 互相关运算","titles":["卷积神经网络CNN","二. CNN 实现"]},"187":{"title":"随机采样","titles":["循环神经网络RNN","一. RNN引入","5. 数据集随机采样"]},"188":{"title":"计算操作","titles":["PyTorch常用函数以及方法","一. torch.tensor","1. 基础操作"]},"189":{"title":"二. 为什么需要move","titles":["move 语义"]},"190":{"title":"一. 简介","titles":["编译链接"]},"191":{"title":"Flash Attention 优化","titles":[]},"192":{"title":"三. using","titles":["现代cpp的一些特性"]},"193":{"title":"二. 模型训练","titles":["Transformer架构"]},"194":{"title":"二. auto类型推导","titles":["类型推导"]},"195":{"title":"KV Cache","titles":[]},"196":{"title":"一. 浅谈一些封装的PTX","titles":["Kittens PTX"]},"197":{"title":"任务列表","titles":["markdown 扩展"]},"198":{"title":"自动链接","titles":["Markdown 基础","其它"]},"199":{"title":"Encoder步骤","titles":["注意力机制","二. 注意力模型","1. Bahdanau注意力模型"]},"200":{"title":"二. async/await异步编程","titles":["Python中多线程和async/await异步"]},"201":{"title":"2. 填充和步幅","titles":["卷积神经网络CNN","二. CNN 实现"]},"202":{"title":"顺序分区","titles":["循环神经网络RNN","一. RNN引入","5. 数据集随机采样"]},"203":{"title":"2. 梯度操作","titles":["PyTorch常用函数以及方法","一. torch.tensor"]},"204":{"title":"三. 其他","titles":["move 语义"]},"205":{"title":"二. 编译流程","titles":["编译链接"]},"206":{"title":"MHA/GQA/MQA优化技术","titles":[]},"207":{"title":"四. scoped enum","titles":["现代cpp的一些特性"]},"208":{"title":"Page Attention 显存优化","titles":[]},"209":{"title":"三. decltype","titles":["类型推导"]},"210":{"title":"一. decoder-only模型量级分析","titles":["KV Cache"]},"211":{"title":"move&lt;T&gt;: load/store","titles":["Kittens PTX","一. 浅谈一些封装的PTX"]},"212":{"title":"脚注","titles":["markdown 扩展"]},"213":{"title":"转义字符","titles":["Markdown 基础","其它"]},"214":{"title":"Decoder与Attention机制步骤","titles":["注意力机制","二. 注意力模型","1. Bahdanau注意力模型"]},"215":{"title":"1. 介绍","titles":["Python中多线程和async/await异步","二. async/await异步编程"]},"216":{"title":"some papers","titles":[]},"217":{"title":"3. 多输入和多输出通道","titles":["卷积神经网络CNN","二. CNN 实现"]},"218":{"title":"二. RNN介绍","titles":["循环神经网络RNN"]},"219":{"title":"README","titles":[]},"220":{"title":"3. 转换操作","titles":["PyTorch常用函数以及方法","一. torch.tensor"]},"221":{"title":"三. 性能分析","titles":["编译链接"]},"222":{"title":"LLM Parallel Strategy","titles":[]},"223":{"title":"五. deleted","titles":["现代cpp的一些特性"]},"224":{"title":"1. 模型参数量","titles":["KV Cache","一. decoder-only模型量级分析"]},"225":{"title":"Pipline Communication","titles":[]},"226":{"title":"ZeRO","titles":[]},"227":{"title":"semaphore: mbarrier/barrier/bar","titles":["Kittens PTX","一. 浅谈一些封装的PTX"]},"228":{"title":"快捷键","titles":["Markdown 基础"]},"229":{"title":"README","titles":[]},"230":{"title":"2. 多头注意力","titles":["注意力机制","二. 注意力模型"]},"231":{"title":"大模型量化简介","titles":[]},"232":{"title":"2. 对比多线程","titles":["Python中多线程和async/await异步","二. async/await异步编程"]},"233":{"title":"多输入通道","titles":["卷积神经网络CNN","二. CNN 实现","3. 多输入和多输出通道"]},"234":{"title":"1. 原理","titles":["循环神经网络RNN","二. RNN介绍"]},"235":{"title":"4. 切片操作","titles":["PyTorch常用函数以及方法","一. torch.tensor"]},"236":{"title":"四. 补充","titles":["编译链接"]},"237":{"title":"Megatron-LM: Training Multi-Billion Parameter Language Models","titles":["LLM Parallel Strategy"]},"238":{"title":"PyTorch模型量化","titles":[]},"239":{"title":"六. override/noexcept","titles":["现代cpp的一些特性"]},"240":{"title":"README","titles":[]},"241":{"title":"总结","titles":["KV Cache","一. decoder-only模型量级分析","1. 模型参数量"]},"242":{"title":"RL介绍","titles":[]},"243":{"title":"一. ZeRO","titles":["ZeRO"]},"244":{"title":"cp.async","titles":["Kittens PTX","一. 浅谈一些封装的PTX"]},"245":{"title":"表格","titles":["Markdown 基础"]},"246":{"title":"实现","titles":["注意力机制","二. 注意力模型","2. 多头注意力"]},"247":{"title":"一. 什么是模型量化","titles":["大模型量化简介"]},"248":{"title":"3. 对比其他语言的协程","titles":["Python中多线程和async/await异步","二. async/await异步编程"]},"249":{"title":"DeepSpeed 源码解读01","titles":[]},"250":{"title":"多输出通道","titles":["卷积神经网络CNN","二. CNN 实现","3. 多输入和多输出通道"]},"251":{"title":"有隐状态的循环神经网络","titles":["循环神经网络RNN","二. RNN介绍","1. 原理"]},"252":{"title":"5. 线性代数","titles":["PyTorch常用函数以及方法","一. torch.tensor"]},"253":{"title":"1. 指令集","titles":["编译链接","四. 补充"]},"254":{"title":"Megatron-LM2: Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM","titles":["LLM Parallel Strategy"]},"255":{"title":"七. constexpr","titles":["现代cpp的一些特性"]},"256":{"title":"1.1 训练过程显存占用分析","titles":["KV Cache","一. decoder-only模型量级分析","1. 模型参数量"]},"257":{"title":"load_async","titles":["Kittens PTX","一. 浅谈一些封装的PTX","cp.async"]},"258":{"title":"3. 自注意力和位置编码","titles":["注意力机制","二. 注意力模型"]},"259":{"title":"二. 模型量化分类和粒度","titles":["大模型量化简介"]},"260":{"title":"三. 在Python中书写并行","titles":["Python中多线程和async/await异步"]},"261":{"title":"一. Launcher","titles":["DeepSpeed 源码解读01"]},"262":{"title":"4. 1 * 1卷积层","titles":["卷积神经网络CNN","二. CNN 实现"]},"263":{"title":"设计字符级RNN模型","titles":["循环神经网络RNN","二. RNN介绍","1. 原理"]},"264":{"title":"2. 汇编语法初探","titles":["编译链接","四. 补充"]},"265":{"title":"1. Mix Parallel","titles":["LLM Parallel Strategy","Megatron-LM2: Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM"]},"266":{"title":"八. const成员函数的线程安全","titles":["现代cpp的一些特性"]},"267":{"title":"1.2 推理过程显存占用分析","titles":["KV Cache","一. decoder-only模型量级分析","1. 模型参数量"]},"268":{"title":"store_async","titles":["Kittens PTX","一. 浅谈一些封装的PTX","cp.async"]},"269":{"title":"对比","titles":["注意力机制","二. 注意力模型","3. 自注意力和位置编码"]},"270":{"title":"1. 量化分类","titles":["大模型量化简介","二. 模型量化分类和粒度"]},"271":{"title":"1. 进程并行","titles":["Python中多线程和async/await异步","三. 在Python中书写并行"]},"272":{"title":"1. communication","titles":["DeepSpeed 源码解读01","一. Launcher"]},"273":{"title":"三. 汇聚层pooling","titles":["卷积神经网络CNN"]},"274":{"title":"模型困惑度","titles":["循环神经网络RNN","二. RNN介绍","1. 原理"]},"275":{"title":"2. Interleaved Schedule","titles":["LLM Parallel Strategy","Megatron-LM2: Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM"]},"276":{"title":"九. 特殊成员函数","titles":["现代cpp的一些特性"]},"277":{"title":"2. 计算量FlOPs估计","titles":["KV Cache","一. decoder-only模型量级分析"]},"278":{"title":"同步机制","titles":["Kittens PTX","一. 浅谈一些封装的PTX","cp.async"]},"279":{"title":"三. 如何做量化","titles":["大模型量化简介"]},"280":{"title":"2. network","titles":["DeepSpeed 源码解读01","一. Launcher"]},"281":{"title":"1. 最大汇聚层与平均汇聚层","titles":["卷积神经网络CNN","三. 汇聚层pooling"]},"282":{"title":"2. 实现","titles":["循环神经网络RNN","二. RNN介绍"]},"283":{"title":"3. Sequence Parallel","titles":["LLM Parallel Strategy","Megatron-LM2: Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM"]},"284":{"title":"2.1 计算量与参数量关联","titles":["KV Cache","一. decoder-only模型量级分析","2. 计算量FlOPs估计"]},"285":{"title":"With-TMA：","titles":["Kittens PTX","一. 浅谈一些封装的PTX","cp.async","同步机制"]},"286":{"title":"公式","titles":["大模型量化简介","三. 如何做量化"]},"287":{"title":"3. subprocess","titles":["DeepSpeed 源码解读01","一. Launcher"]},"288":{"title":"2. 总结","titles":["卷积神经网络CNN","三. 汇聚层pooling"]},"289":{"title":"预测","titles":["循环神经网络RNN","二. RNN介绍","2. 实现"]},"290":{"title":"Dualpipe","titles":["LLM Parallel Strategy"]},"291":{"title":"2.2 训练时间估计","titles":["KV Cache","一. decoder-only模型量级分析","2. 计算量FlOPs估计"]},"292":{"title":"Non-TMA","titles":["Kittens PTX","一. 浅谈一些封装的PTX","cp.async","同步机制"]},"293":{"title":"四. 实际应用","titles":["大模型量化简介"]},"294":{"title":"二. Initialize","titles":["DeepSpeed 源码解读01"]},"295":{"title":"四. LeNet","titles":["卷积神经网络CNN"]},"296":{"title":"3. 梯度裁剪","titles":["循环神经网络RNN","二. RNN介绍"]},"297":{"title":"3. 中间激活值分析","titles":["KV Cache","一. decoder-only模型量级分析"]},"298":{"title":"五. 如何选择","titles":["大模型量化简介","四. 实际应用"]},"299":{"title":"1. distribute","titles":["DeepSpeed 源码解读01","二. Initialize"]},"300":{"title":"4. 训练","titles":["循环神经网络RNN","二. RNN介绍"]},"301":{"title":"3.1 对比中间激活与模型参数大小","titles":["KV Cache","一. decoder-only模型量级分析","3. 中间激活值分析"]},"302":{"title":"2. deepspeed.initialize","titles":["DeepSpeed 源码解读01","二. Initialize"]},"303":{"title":"三. 现代RNN","titles":["循环神经网络RNN"]},"304":{"title":"二. 推理与KV Cache","titles":["KV Cache"]},"305":{"title":"3. Config","titles":["DeepSpeed 源码解读01","二. Initialize"]},"306":{"title":"1. 基本结构","titles":["循环神经网络RNN","三. 现代RNN"]},"307":{"title":"三. KV Cache延伸技术","titles":["KV Cache"]},"308":{"title":"2. encoder-decoder","titles":["循环神经网络RNN","三. 现代RNN"]},"309":{"title":"1. Batch Prompting","titles":["KV Cache","三. KV Cache延伸技术"]},"310":{"title":"3. seq2seq","titles":["循环神经网络RNN","三. 现代RNN"]},"311":{"title":"2. RalyAttention","titles":["KV Cache","三. KV Cache延伸技术"]},"312":{"title":"训练","titles":["循环神经网络RNN","三. 现代RNN","3. seq2seq"]}},"dirtCount":0,"index":[["知乎",{"2":{"311":3}}],["广播context",{"2":{"310":1}}],["嵌入层",{"2":{"310":1}}],["新的state记为state",{"2":{"310":1}}],["借助初始的隐状态",{"2":{"310":1}}],["借此我们可以看一下deepspeed的通信包是如何设计的",{"2":{"299":1}}],["思路其实就是对于encoder",{"2":{"310":1}}],["思路其实就是在函数上放一个",{"2":{"99":1}}],["否则应该是1",{"2":{"306":1}}],["否则为零",{"2":{"100":1}}],["旧字段",{"2":{"305":1}}],["禁止额外的字段",{"2":{"305":1}}],["赋值时进行验证",{"2":{"305":1}}],["←concat",{"2":{"304":2}}],["∣",{"2":{"304":2}}],["流程有很多可以复用的中间状态",{"2":{"304":1}}],["流水线并行",{"2":{"65":1}}],["弹性训练打算在单独开一个章节记录",{"2":{"302":1}}],["弹性扩缩容等操作",{"2":{"272":1}}],["走的是zero这一套",{"2":{"302":1}}],["问题时",{"2":{"301":1}}],["阅读这部分代码感觉也可以为未来阅读pytorch源码打下基础",{"2":{"299":1}}],["含有relu激活层的模型",{"2":{"298":1}}],["理论上可以从",{"2":{"301":1}}],["理论上",{"2":{"298":1}}],["综上",{"2":{"297":1}}],["综上所述",{"2":{"97":1}}],["唯一例外的是",{"2":{"297":1}}],["唯一的限制是",{"2":{"120":1}}],["σ2",{"2":{"297":1}}],["μ",{"2":{"297":1}}],["忽略掉一些小的buffers",{"2":{"297":1}}],["裁剪梯度",{"2":{"296":1}}],["∥g∥θ​",{"2":{"296":1}}],["感性理解一下lenet",{"2":{"295":1}}],["感受野可能大于输入的实际大小",{"2":{"139":1}}],["样本数",{"2":{"295":1}}],["样式的引言",{"2":{"52":1}}],["策略就是当计算完成之后",{"2":{"293":1}}],["肯定不会一直保持在int8的值域",{"2":{"293":1}}],["故忽略",{"2":{"292":1}}],["激活函数保存其输入",{"2":{"297":1}}],["激活重计算的系数",{"2":{"291":1}}],["激进策略",{"2":{"221":1}}],["获得一个输出output",{"2":{"310":1}}],["获得数据",{"2":{"290":1}}],["获取",{"2":{"64":1}}],["稳定阶段的dualpipev",{"2":{"290":1}}],["灵活地进行调度",{"2":{"290":1}}],["抹去了这一次通信",{"2":{"290":1}}],["开启stage2的forward需要再度传给first",{"2":{"290":1}}],["开始执行分布式训练进程",{"2":{"280":1}}],["开始向前",{"2":{"110":1}}],["观察1f1b",{"2":{"290":1}}],["观察损失函数其实就是一个二元函数",{"2":{"73":1}}],["果然tp已经是时代的眼泪了",{"2":{"290":1}}],["题外话",{"2":{"290":1}}],["似乎因为deepspeed版本过老的原因",{"2":{"287":1}}],["关系如下图所示",{"2":{"287":1}}],["关于",{"2":{"145":2}}],["仔细阅读上文中with",{"2":{"285":1}}],["仔细思考一下",{"2":{"186":1}}],["足够大",{"2":{"284":1}}],["附加梯度",{"2":{"282":1}}],["池运算是确定性的",{"2":{"281":1}}],["池化层",{"2":{"273":1}}],["遍历的每个位置计算一个输出",{"2":{"281":1}}],["机器之间必然会产生通信",{"2":{"280":1}}],["机器码的执行逻辑是一样的",{"2":{"221":1}}],["机器码就是直接在cpu上运行的代码",{"2":{"190":1}}],["既然是多机分布式训练",{"2":{"280":1}}],["既是键",{"2":{"183":1}}],["粒度更细致",{"2":{"279":1}}],["粒度更大一些",{"2":{"279":1}}],["×",{"2":{"277":8}}],["×n×c×h×w×sizeof",{"2":{"49":2}}],["次乘法运算和加法运算",{"2":{"277":1}}],["衡量了计算量的大小",{"2":{"277":1}}],["九",{"0":{"276":1}}],["量",{"2":{"275":1}}],["量化可以分为均匀量化和非均匀量化",{"2":{"270":1}}],["量化分类",{"0":{"270":1}}],["浅色为chunk2",{"2":{"275":1}}],["浅谈一些封装的ptx",{"0":{"196":1},"1":{"211":1,"227":1,"244":1,"257":1,"268":1,"278":1,"285":1,"292":1}}],["深色为chunk1",{"2":{"275":1}}],["深度学习框架",{"2":{"1":1}}],["成为多个chunk",{"2":{"275":1}}],["成员函数",{"2":{"171":1}}],["立马执行bwd",{"2":{"275":1}}],["立即数",{"2":{"196":1}}],["困惑度",{"2":{"300":1}}],["困惑度等于词表中唯一词元的数量",{"2":{"274":1}}],["困惑度是正无穷大",{"2":{"274":1}}],["符合认知的语言",{"2":{"274":1}}],["符号作为",{"2":{"26":1,"34":1,"36":1,"39":1}}],["符号上",{"2":{"26":1,"34":1,"36":1,"39":1}}],["符号的话",{"2":{"26":1,"34":1,"36":1,"39":1}}],["符号",{"2":{"26":1,"34":1,"36":1,"39":1}}],["符号其实很容易让写作网络文件的人感到困扰",{"2":{"26":1,"34":1,"36":1,"39":1}}],["符号则用于标记",{"2":{"26":1,"34":1,"36":1,"39":1}}],["符号用于起始标签",{"2":{"26":1,"34":1,"36":1,"39":1}}],["惊异度",{"2":{"274":1}}],["惊叹号",{"2":{"213":1}}],["降低对空间降采样表示的敏感性",{"2":{"273":1}}],["降低卷积层对位置的敏感性",{"2":{"273":1}}],["降低显存占用",{"2":{"121":1}}],["聚集信息",{"2":{"273":1}}],["专为多个gpu之间提供优化的传输效率和简化应用而设计",{"2":{"272":1}}],["封装物理层能力",{"2":{"272":1}}],["软件层面的通信优化",{"2":{"272":1}}],["软性",{"2":{"100":1}}],["速度最快200gbps+",{"2":{"272":1}}],["节点内通信直接使用nvlink即可",{"2":{"272":1}}],["节点信息",{"2":{"133":1}}],["底层通信是指底层硬件的物理层传输",{"2":{"272":1}}],["底线",{"2":{"213":1}}],["底线来建立一个分隔线",{"2":{"78":1}}],["物理层传输",{"2":{"272":1}}],["伴随着过多的outlier值的突出",{"2":{"270":1}}],["适用的场景就是数据分布非常不均匀",{"2":{"270":1}}],["适合io密集型任务",{"2":{"215":1}}],["位置编码",{"2":{"269":1}}],["位置编码使用相同形状的位置嵌入矩阵",{"2":{"269":1}}],["位置编码是为了让self",{"2":{"269":1}}],["拥有更少的bubbles",{"2":{"290":1}}],["拥有",{"2":{"269":1}}],["拥有权重矩阵",{"2":{"224":1}}],["考虑一个具有",{"2":{"296":1}}],["考虑一个卷积核大小为",{"2":{"269":1}}],["考察的是transformer的模型结构",{"2":{"30":1}}],["路径越短则更可以学习序列中的远距离依赖关系",{"2":{"269":1}}],["路径都比较固定",{"2":{"50":1}}],["顺序操作会妨碍并行计算",{"2":{"269":1}}],["顺序操作和最大路径长度",{"2":{"269":1}}],["顺序分区",{"0":{"202":1}}],["少了梯度",{"2":{"267":1}}],["八",{"0":{"266":1}}],["划分完virtual",{"2":{"275":1}}],["划分weight到不同gpu上",{"2":{"265":1}}],["划分batch为若干mini",{"2":{"265":1}}],["暂且不考虑单worker的情况",{"2":{"261":1}}],["经常用在llm量化中",{"2":{"279":1}}],["经常使用cnn或者rnn对序列进行编码",{"2":{"258":1}}],["经过上述的launcher",{"2":{"294":1}}],["经过上述的网络通信基础设置",{"2":{"280":1}}],["经过变换后",{"2":{"246":1}}],["经过堆叠之后",{"2":{"224":1}}],["占用的显存大小只与模型参数量和参数数据类型有关",{"2":{"301":1}}],["占用为",{"2":{"297":2}}],["占用大小",{"2":{"297":1}}],["占用显存大小合计为",{"2":{"297":1}}],["占用显存大小为",{"2":{"297":1}}],["占用显存的大头就是前向传递过程中计算得到的中间激活值了",{"2":{"297":1}}],["占用显存的大头主要是模型参数",{"2":{"267":1}}],["占用显存的大头主要分为四部分",{"2":{"256":1}}],["占用了",{"2":{"256":1}}],["ϕ",{"2":{"256":2}}],["后展平",{"2":{"300":1}}],["后向传递",{"2":{"291":1}}],["后向传递的系数",{"2":{"284":1}}],["后向传递的计算量是前向传递的2倍",{"2":{"284":1}}],["后向传递计算得到的梯度",{"2":{"256":1}}],["后者可以特定优化",{"2":{"253":1}}],["后者可以针对硬件做更大程度的系统级别的优化",{"2":{"54":1}}],["后者是第二种",{"2":{"159":1}}],["七",{"0":{"255":1}}],["整篇论文中有如下三个要点",{"2":{"254":1}}],["整个运算就定义了卷积层",{"2":{"109":1}}],["向量扩展",{"2":{"253":2}}],["向量化计算",{"2":{"221":1}}],["向量化计算密度更高",{"2":{"221":1}}],["条件编译与运行时检测",{"2":{"253":1}}],["条件操作",{"2":{"133":1}}],["硬件环境配置的情况下",{"2":{"291":1}}],["硬件",{"2":{"253":1}}],["硬件架构意思是cpu的指令集架构",{"2":{"190":1}}],["硬件架构",{"2":{"190":1}}],["检测方法",{"2":{"253":1}}],["矩阵扩展",{"2":{"253":1}}],["矩阵运算",{"2":{"253":1}}],["矩阵乘法",{"2":{"252":1,"297":1}}],["矩阵的形式",{"2":{"131":1}}],["堆叠操作",{"2":{"250":1}}],["记录一些阅读deepspeed源码过程中的心得与感悟",{"2":{"249":1}}],["源码解读01",{"0":{"249":1},"1":{"261":1,"272":1,"280":1,"287":1,"294":1,"299":1,"302":1,"305":1}}],["源码剖析",{"0":{"76":1}}],["基本结构",{"0":{"306":1}}],["基于mpi标准",{"2":{"272":1}}],["基于这个前提分析显存占用",{"2":{"256":1}}],["基于适当的张量操作",{"2":{"246":1}}],["基础isa",{"2":{"253":1}}],["基础传播",{"2":{"221":1}}],["基础操作",{"0":{"155":1},"1":{"170":1,"188":1}}],["基础",{"0":{"5":1},"1":{"7":1,"12":1,"19":1,"26":1,"33":1,"41":1,"46":1,"52":1,"59":1,"67":1,"78":1,"91":1,"104":1,"120":1,"135":1,"149":1,"165":1,"182":1,"198":1,"213":1,"228":1,"245":1}}],["逆转transpose",{"2":{"246":1}}],["右对齐使用",{"2":{"245":1}}],["右对齐",{"2":{"245":1}}],["居中使用",{"2":{"245":1}}],["居中",{"2":{"245":1}}],["→",{"2":{"244":2}}],["貌似只能从global",{"2":{"244":1}}],["较大的时候",{"2":{"241":1}}],["较慢",{"2":{"221":1}}],["尤其是作用于拷贝移动赋值",{"2":{"239":1}}],["尤其大型项目",{"2":{"221":1}}],["便于编译器检查",{"2":{"239":1}}],["便会被视为空行",{"2":{"41":1}}],["仍然会出现梯度消失",{"2":{"296":1}}],["仍然保持分割状态",{"2":{"237":1}}],["仍然使用小批次训练的方式",{"2":{"160":1}}],["补充",{"0":{"236":1},"1":{"253":1,"264":1}}],["切片操作",{"0":{"235":1}}],["步的所有序列信息",{"2":{"234":1}}],["步幅",{"2":{"201":1}}],["≈p",{"2":{"234":2}}],["时间步数",{"2":{"282":3,"306":2}}],["时",{"2":{"233":1,"284":1,"304":1}}],["时可以把卷积核看为二维张量",{"2":{"233":1}}],["时的解码器隐状态为",{"2":{"183":1}}],["亦或是async协程",{"2":{"232":1}}],["亦可以视作对向量",{"2":{"114":1}}],["长度的字节码之后也会释放gil锁",{"2":{"232":1}}],["长度为num",{"2":{"187":1}}],["长度为784",{"2":{"160":1}}],["能更加高效的处理io任务",{"2":{"232":1}}],["能很好的支持",{"2":{"12":1,"20":1,"22":1,"24":1}}],["组变换后的查询",{"2":{"230":1}}],["组不同的",{"2":{"230":1}}],["线性变换复杂度为",{"2":{"277":1}}],["线性代数",{"0":{"252":1}}],["线性投影",{"2":{"230":1}}],["线性回归模型",{"2":{"129":1}}],["线性回归主要描述一个或者多个自变量与一个因变量之间的线性关系的模型",{"2":{"73":1}}],["子空间表示",{"2":{"230":1}}],["子层表示为",{"2":{"87":1}}],["短距离依赖和长距离依赖关系",{"2":{"230":1}}],["捕获序列内各种范围的依赖关系",{"2":{"230":1}}],["⌘",{"2":{"228":2}}],["快捷键",{"0":{"228":1},"2":{"228":1}}],["快30",{"2":{"221":1}}],["存储了从起始状态到",{"2":{"234":1}}],["存储在input",{"2":{"225":1}}],["存在舍入误差",{"2":{"37":1}}],["伪释放",{"2":{"225":1}}],["此后的调度策略通过实现这个基类来进行",{"2":{"225":1}}],["此外logits计算会将隐藏向量映射为词表大小",{"2":{"277":1}}],["此外",{"2":{"89":1,"267":1}}],["映射回词表",{"2":{"224":1}}],["映射回",{"2":{"224":1}}],["映射为",{"2":{"115":1,"224":1}}],["执行阶段",{"2":{"221":1}}],["执行对应矩阵相乘",{"2":{"106":1}}],["启用lto",{"2":{"221":2}}],["启动一个异步数据拷贝",{"2":{"244":1}}],["启动和管理进程会带来更大的开销以及更高昂的内存消耗",{"2":{"184":1}}],["启动脚本",{"2":{"127":1}}],["体积也会减少20",{"2":{"221":1}}],["他可以解决一个比较痛苦的地方",{"2":{"305":1}}],["他会保存编译时的中间表示",{"2":{"221":1}}],["他们会在需要的时候才会自动生成",{"2":{"276":1}}],["他们会包含fwd和bwd所需的信息",{"2":{"133":1}}],["他们也享有独立的shared",{"2":{"70":1}}],["超快链接器",{"2":{"221":1}}],["超参数为",{"2":{"136":1}}],["默认是pdsh",{"2":{"272":1}}],["默认使用",{"2":{"221":1}}],["默认标题",{"0":{"77":1}}],["稍小",{"2":{"221":1}}],["稍大",{"2":{"221":1}}],["差异原因",{"2":{"221":1}}],["差异幅度",{"2":{"221":1}}],["调试支持",{"2":{"221":1}}],["调试信息",{"2":{"221":1}}],["调试信息一般是dwarf格式",{"2":{"221":1}}],["调用backward",{"2":{"159":1}}],["调用training里面的scripts",{"2":{"127":1}}],["调用inference",{"2":{"127":1}}],["复杂度为",{"2":{"277":3}}],["复杂控制流中优势明显",{"2":{"221":1}}],["复制num",{"2":{"246":1}}],["复制到x所在显存上",{"2":{"137":1}}],["平台上的hello",{"2":{"264":1}}],["平台",{"2":{"253":1}}],["平移参数",{"2":{"224":1}}],["平均汇聚层会输出该窗口内的平均值",{"2":{"288":1}}],["平均优3",{"2":{"221":1}}],["平均生成少10",{"2":{"221":1}}],["平方损失",{"2":{"106":1}}],["寄存器溢出5",{"2":{"221":1}}],["寄存器的高16位",{"2":{"196":1}}],["依赖链优化较好",{"2":{"221":1}}],["依赖于triton",{"2":{"70":1}}],["性能指标是文件大小",{"2":{"221":1}}],["性能因素取决于汇编指令数",{"2":{"221":1}}],["性能分析",{"0":{"221":1}}],["跨函数传播",{"2":{"221":1}}],["静态函数优化",{"2":{"221":1}}],["静态显存管理",{"2":{"54":1}}],["诊断信息质量",{"2":{"221":1}}],["⚪",{"2":{"221":1}}],["低20",{"2":{"221":1}}],["🔴",{"2":{"221":2}}],["💯",{"2":{"51":1}}],["沿新维度堆叠",{"2":{"220":1}}],["沿梯度",{"0":{"114":1}}],["变得杂乱是不可避免的",{"2":{"305":1}}],["变为新的x",{"2":{"310":1}}],["变为",{"2":{"282":1,"310":2}}],["变为四维张量",{"2":{"250":1}}],["变换",{"2":{"220":1}}],["变化时的规律",{"2":{"145":1}}],["让我们首先定义预测函数来生成prefix之后的新字符",{"2":{"289":1}}],["让我们用数学语言描述一下多头注意力模型",{"2":{"230":1}}],["让渡给其他协程",{"2":{"215":1}}],["让你可以把一些标记相关的资讯移到段落文字之外",{"2":{"104":1}}],["协程可以自主切换",{"2":{"215":1}}],["异常方便",{"2":{"215":1}}],["挨个处理会很耗时",{"2":{"215":1}}],["回想一下",{"2":{"282":1}}],["回想一下网络的本质",{"2":{"215":1}}],["回顾一下我们引入过程中的马尔科夫模型",{"2":{"234":1}}],["回到main函数",{"2":{"305":1}}],["回到本节开头提到的对象边缘检测示例",{"2":{"281":1}}],["回到我们一开始的模型公式",{"2":{"160":1}}],["回到我们一开始提到的生成序列的方法",{"2":{"140":1}}],["回到autograd",{"2":{"133":1}}],["回到原来的问题",{"2":{"129":1}}],["迭代过程是一个熵增的过程",{"2":{"305":1}}],["迭代时间步数",{"2":{"282":1}}],["迭代输出",{"2":{"214":1}}],["迭代次数和批次",{"2":{"94":1}}],["概率分布",{"2":{"214":1}}],["概述",{"0":{"7":1,"13":1,"15":1,"17":1}}],["根据具体情况",{"2":{"238":1}}],["根据注意力权重用加权求和生成上下文向量",{"2":{"214":1}}],["根据pytorch的自动微分机制",{"2":{"117":1}}],["英文句点",{"2":{"213":1}}],["井字号",{"2":{"213":1}}],["括号",{"2":{"213":1}}],["星号",{"2":{"213":1}}],["↩︎",{"2":{"212":1}}],["过零丁洋",{"2":{"212":2}}],["宋",{"2":{"212":2}}],["留取丹心照汗青",{"2":{"212":2}}],["人生自古谁无死",{"2":{"212":2}}],["序列长度",{"2":{"210":1}}],["隐状态的值会更加适合预测",{"2":{"289":1}}],["隐藏单元数",{"2":{"282":1,"306":1}}],["隐藏变量捕获并保留了序列直到当前时间步的历史信息",{"2":{"251":1}}],["隐藏层参数",{"2":{"282":1}}],["隐藏层的输出为",{"2":{"251":1}}],["隐藏层维度",{"2":{"210":1}}],["隐变量一般使用递推式更新",{"2":{"234":1}}],["隐变量自回归模型",{"2":{"110":1}}],["避免无意义的拷贝内存开销",{"2":{"209":1}}],["避免了拷贝构造带来的性能开销",{"2":{"189":1}}],["重点来了",{"2":{"302":1}}],["重点在于",{"2":{"59":1}}],["重新映射回int8",{"2":{"293":1}}],["重新排列",{"2":{"220":1}}],["重定位信息以及调试信息",{"2":{"221":1}}],["重复步骤3",{"2":{"214":1}}],["重载是一个不错的选择",{"2":{"209":1}}],["强制教学",{"2":{"312":1}}],["强化",{"2":{"209":1}}],["强调也可以直接插在文字中间",{"2":{"120":1}}],["强调用户在快速浏览文档时也不应忽略的重要信息",{"2":{"89":2}}],["强调",{"0":{"120":1},"2":{"7":1,"13":1,"15":1,"17":1,"19":1,"27":1,"29":1,"31":1}}],["针对我们这个函数而言",{"2":{"209":1}}],["针对此类数据而设计特定模型",{"2":{"96":1}}],["限域写法",{"2":{"207":1}}],["限域enum避免了命名空间污染",{"2":{"207":1}}],["枚举名是强类型",{"2":{"207":1}}],["虽然计划将engine放到下一章来讲",{"2":{"305":1}}],["虽然tp分割的是hidden",{"2":{"283":1}}],["虽然这里我感觉",{"2":{"275":1}}],["虽然这并不代表两者产生的机器码是相同的",{"2":{"205":1}}],["虽然python创建的也是原生线程",{"2":{"152":1}}],["万能引用",{"2":{"204":1}}],["与模型参数量有关",{"2":{"301":1}}],["与优化器类型有关",{"2":{"301":1}}],["与输入数据的大小是没有关系的",{"2":{"301":1}}],["与全连接层一样",{"2":{"295":1}}],["与上一层相比",{"2":{"295":1}}],["与卷积层类似",{"2":{"281":1}}],["与卷积核进行互相关计算得到的",{"2":{"201":1}}],["与其只使用单独一个注意力汇聚",{"2":{"230":1}}],["与t",{"2":{"156":1}}],["均匀量化适用于数据比较均匀",{"2":{"270":1}}],["均匀分配即可",{"2":{"201":1}}],["均方误差",{"2":{"129":1}}],["均方损失",{"2":{"129":1}}],["左对齐使用",{"2":{"245":1}}],["左对齐",{"2":{"245":1}}],["左右",{"2":{"201":1}}],["左值实参会被特殊对待",{"2":{"179":1}}],["左值引用",{"2":{"172":1}}],["左值",{"2":{"172":1}}],["正确预测的数量",{"2":{"295":1}}],["正确地运行错误提示以及代码补全",{"2":{"50":1}}],["正交性",{"2":{"265":1}}],["正如我们推导的一样",{"2":{"201":1}}],["填充和步幅",{"0":{"201":1}}],["公式",{"0":{"286":1}}],["公式为",{"2":{"277":1}}],["公式就变为",{"2":{"125":1}}],["公共子表达式消除",{"2":{"221":1}}],["公开你的信箱终究会引来广告信件的",{"2":{"198":1}}],["把文字字元转成",{"2":{"198":1}}],["任务",{"2":{"197":6}}],["任务列表",{"0":{"197":1}}],["任何函数都可以标记为deleted",{"2":{"223":1}}],["任何可以被解析为declaration的东西就必须解析为declaration",{"2":{"158":1}}],["任何标准的文字编辑器都能简单地建立",{"2":{"52":1}}],["任何数量的",{"2":{"46":1}}],["且步长为3",{"2":{"281":1}}],["且有固定的类型和位置",{"2":{"227":1}}],["且只写",{"2":{"196":1}}],["且相互独立",{"2":{"96":1}}],["别名声明可以模板化",{"2":{"192":1}}],["处元素置为1",{"2":{"282":1}}],["处理gemm",{"2":{"237":1}}],["处理指令示例",{"2":{"190":1}}],["处相对于",{"2":{"145":1}}],["架构类型",{"2":{"190":1}}],["优10",{"2":{"221":1}}],["优5",{"2":{"221":1}}],["优势",{"2":{"221":2}}],["优质博客",{"2":{"191":1}}],["优化为",{"2":{"301":1}}],["优化器更新",{"2":{"291":1}}],["优化器状态占用的显存大小也是一样",{"2":{"301":1}}],["优化器状态外",{"2":{"297":1}}],["优化器状态",{"2":{"256":1,"267":1}}],["优化类型",{"2":{"221":1}}],["优化的",{"2":{"205":1}}],["优化",{"0":{"191":1},"2":{"190":1}}],["优先度no",{"2":{"53":1}}],["系统调用约定",{"2":{"190":1}}],["工具链",{"2":{"190":1}}],["汇编语法初探",{"0":{"264":1}}],["汇编语法规范",{"2":{"190":1}}],["汇编代码生成hello",{"2":{"221":1}}],["汇编阶段",{"2":{"205":1}}],["汇编器代表",{"2":{"190":1}}],["汇编器的作用就是将汇编语言转化为机器码",{"2":{"190":1}}],["汇聚窗口形状为",{"2":{"281":1}}],["汇聚层的主要优点之一是减轻卷积层对位置的过度敏感",{"2":{"288":1}}],["汇聚层的输出通道数与输入通道数相同",{"2":{"281":1,"288":1}}],["汇聚层在每个输入通道上单独计算",{"2":{"281":1}}],["汇聚层也会有填充和步幅",{"2":{"281":1}}],["汇聚层始终输出",{"2":{"281":1}}],["汇聚层输出为",{"2":{"281":1}}],["汇聚层不包含参数",{"2":{"281":1}}],["汇聚层运算符由一个固定形状的窗口组成",{"2":{"281":1}}],["汇聚层pooling",{"0":{"273":1},"1":{"281":1,"288":1},"2":{"281":1}}],["汇聚",{"2":{"87":1,"281":1}}],["影响",{"2":{"190":1}}],["典型代表",{"2":{"190":1}}],["逐元素相乘",{"2":{"188":1}}],["小批量中的子序列不一定在原始序列上相邻",{"2":{"187":1}}],["小批量随机梯度下降",{"2":{"129":1}}],["尽量使用using",{"2":{"192":1}}],["尽量使用nullptr",{"2":{"175":1}}],["尽管这样并不严谨",{"2":{"186":1}}],["下文会详细介绍",{"2":{"291":1}}],["下文中我们会将互相关运算称为卷积运算",{"2":{"186":1}}],["下位方案是以太网tcp",{"2":{"272":1}}],["下位方案是pcie通用总线",{"2":{"272":1}}],["下图展示了使用全连接层来实现可学习的线性变换的多头注意力",{"2":{"230":1}}],["下面为代码实现",{"2":{"150":1}}],["下面文章走读的master版本是这个deepspeed",{"2":{"127":1}}],["下面是编译工具链的全过程",{"2":{"205":1}}],["下面是用行内形式写的同样一段内容的",{"2":{"104":1}}],["下面是一个参考式链接的范例",{"2":{"104":1}}],["下面这三种链接的定义相同",{"2":{"104":1}}],["下面每种写法都可以建立分隔线",{"2":{"78":1}}],["下面的输入",{"2":{"67":1}}],["宽度",{"2":{"186":1}}],["更具体地说",{"2":{"304":1}}],["更加便捷",{"2":{"302":1}}],["更加精细的异步与tensor内存释放",{"2":{"290":1}}],["更多内联",{"2":{"221":1}}],["更新结果",{"2":{"300":1}}],["更新decoder的隐状态",{"2":{"214":1}}],["更新移动平均的均值和方差",{"2":{"137":1}}],["更复杂的卷积核例子",{"2":{"186":1}}],["先照抄下来",{"2":{"296":1}}],["先求一下scale",{"2":{"286":1}}],["先load",{"2":{"257":1}}],["先计算出来预期结果",{"2":{"186":1}}],["先将输入的参数reshape一下",{"2":{"160":1}}],["⋅xv",{"2":{"304":3}}],["⋅w2​+tout",{"2":{"304":1}}],["⋅w2​+xout",{"2":{"304":1}}],["⋅w2+tout",{"2":{"304":1}}],["⋅w2+xout",{"2":{"304":1}}],["⋅w1",{"2":{"304":2}}],["⋅wo",{"2":{"304":2}}],["⋅wq",{"2":{"304":4}}],["⋅wv",{"2":{"304":4}}],["⋅wk",{"2":{"304":4}}],["⋅v⋅wo​+x",{"2":{"277":1}}],["⋅v⋅wo+xx",{"2":{"277":1}}],["⋅",{"2":{"186":2,"201":2}}],["⋅gt2​wt​=wt−1​−lr⋅vt​+ε​mt​​​​",{"2":{"105":1}}],["⋅gt2wt=wt−1−lr⋅mtvt+ε",{"2":{"105":1}}],["⋅gt​vt​=β2​⋅vt−1​+",{"2":{"105":1}}],["⋅gtvt=β2⋅vt−1+",{"2":{"105":1}}],["探究二维张量的互相关运算",{"2":{"186":1}}],["互相关运算是怎么做的",{"2":{"217":1}}],["互相关运算就可以转化为卷积运算",{"2":{"186":1}}],["互相关运算",{"0":{"186":1}}],["兼容问题",{"2":{"184":1}}],["高性能消息传输接口",{"2":{"272":1}}],["高",{"2":{"221":1}}],["高度",{"2":{"186":1}}],["高开销",{"2":{"184":1}}],["高亮",{"2":{"89":1}}],["带遮蔽的softmax交叉熵损失函数",{"2":{"312":1}}],["带有下划线的意思是就地操作",{"2":{"293":1}}],["带有注意力机制解码器的基本接口",{"2":{"183":1}}],["带宽约32gb",{"2":{"272":1}}],["带宽达到900gb",{"2":{"272":1}}],["带参数注意力汇聚",{"0":{"106":1}}],["替换",{"2":{"183":1}}],["名为",{"2":{"181":1}}],["名为高斯核",{"2":{"93":1}}],["顶层const会去除",{"2":{"179":1}}],["无法并行化",{"2":{"269":1}}],["无法很好的处理计算密集型任务",{"2":{"232":1}}],["无法编译通过",{"2":{"194":1}}],["无用代码全局消除",{"2":{"221":1}}],["无差异",{"2":{"221":1}}],["无论",{"2":{"281":1}}],["无论如何",{"2":{"198":1}}],["无论传递什么",{"2":{"179":1}}],["无序列表使用减号作为列表标记",{"2":{"59":1}}],["传入权重和偏置参数",{"2":{"282":1}}],["传入上一个隐状态",{"2":{"282":1}}],["传入当前时间步的输入",{"2":{"282":1}}],["传入一个二维的卷积核",{"2":{"186":1}}],["传入的实参会忽略const和ref",{"2":{"179":1}}],["传入的是维度",{"2":{"170":1}}],["传入ref会先忽略ref",{"2":{"179":1}}],["规则的一些特性",{"2":{"179":1}}],["规则",{"2":{"179":4}}],["总预测的数量",{"2":{"295":1}}],["总是不方便的",{"2":{"207":1}}],["总共添加了2行2列",{"2":{"201":1}}],["总效应",{"2":{"177":1}}],["总结下来",{"2":{"241":1}}],["总结下来就是",{"2":{"153":1}}],["总结",{"0":{"153":1,"241":1,"288":1},"2":{"159":1,"179":1,"194":1,"221":1,"225":2,"237":1,"268":1,"269":1,"277":1,"292":1}}],["总结来说",{"2":{"131":1,"227":1}}],["总结pp的通信和调度算法",{"2":{"65":1}}],["链式法则用于计算复合函数的导数",{"2":{"177":1}}],["链式法则",{"2":{"177":1}}],["链接阶段关心的性能是链接速度",{"2":{"221":1}}],["链接阶段",{"2":{"205":1,"221":1}}],["链接器是可以兼容的",{"2":{"205":1}}],["链接过程中",{"2":{"205":1}}],["链接到",{"2":{"104":1}}],["链接标签和链接文字会视为相同",{"2":{"104":1}}],["链接辨识标签可以有字母",{"2":{"104":1}}],["链接网址也可以用方括号包起来",{"2":{"104":1}}],["链接的是该平台的机器码",{"2":{"205":1}}],["链接的文字就和链接位置一样",{"2":{"198":1}}],["链接的文字都是用",{"2":{"104":1}}],["链接的定义可以放在文件中的任何一个地方",{"2":{"104":1}}],["链接的网址",{"2":{"104":1}}],["链接定义的形式为",{"2":{"104":1}}],["链接",{"0":{"25":1,"104":1},"1":{"32":1,"40":1},"2":{"25":1,"198":1}}],["字面量",{"2":{"172":1}}],["字符串",{"2":{"126":1}}],["临时对象",{"2":{"172":1}}],["给右值一个续命的",{"2":{"172":1}}],["给定当前生成词在第",{"2":{"304":1}}],["给定计算量",{"2":{"291":1}}],["给定硬件gpu类型的情况下",{"2":{"291":1}}],["给定一个由词元组成的输入序列",{"2":{"258":1}}],["给定一个默认类型int",{"2":{"207":1}}],["给定查询",{"2":{"136":1,"230":1}}],["给定任何查询",{"2":{"79":1}}],["返回的是inferenceengine",{"2":{"302":1}}],["返回的c",{"2":{"209":1}}],["返回rnn的初始隐状态",{"2":{"282":1}}],["返回类型推导",{"2":{"207":1}}],["返回元素个数",{"2":{"188":1}}],["返回从pos位置开始的长度为num",{"2":{"187":1}}],["返回值的表达式",{"2":{"172":1}}],["返回左值引用的函数",{"2":{"172":1}}],["返回",{"2":{"172":1}}],["纯右值",{"2":{"172":2}}],["纯python操作",{"2":{"133":1}}],["普通乘法",{"2":{"188":1}}],["普通对象则会优先调用普通方法",{"2":{"171":1}}],["普通对象则都可以调用",{"2":{"171":1}}],["普通moe并行策略",{"2":{"14":1}}],["常数传播",{"2":{"221":1}}],["常用约束符",{"2":{"196":1}}],["常量对象会优先调用常量方法",{"2":{"171":1}}],["常量对象只能调用常量函数",{"2":{"171":1}}],["常成员函数",{"2":{"171":1}}],["常见的数学方法就是分别对θ0",{"2":{"73":1}}],["常见问题",{"0":{"4":1,"47":1}}],["偏差+",{"2":{"170":1}}],["去掉批量和通道",{"2":{"201":1}}],["去等待io阻塞",{"2":{"167":1}}],["去从最基础的东西讲起",{"2":{"2":1}}],["换言之对称量化的值域的零点就是中点",{"2":{"270":1}}],["换行符",{"2":{"165":1}}],["换句话说",{"2":{"59":1}}],["段落之间空一行",{"2":{"165":1}}],["段落",{"2":{"165":1}}],["段落和换行",{"0":{"41":1}}],["删除",{"2":{"165":1}}],["模板处理效率",{"2":{"221":1}}],["模板类型推导时",{"2":{"179":1}}],["模板类型推导主要使用以下模板和调用来解释",{"2":{"179":1}}],["模板类型推导",{"0":{"179":1}}],["模板学习",{"2":{"163":1}}],["模型总是预测标签词元的概率为0",{"2":{"274":1}}],["模型总是完美地估计标签词元的概率为1",{"2":{"274":1}}],["模型困惑度",{"0":{"274":1}}],["模型推理阶段",{"2":{"267":1}}],["模型推理阶段占用的显存要远小于训练阶段",{"2":{"267":1}}],["模型量化分类和粒度",{"0":{"259":1},"1":{"270":1}}],["模型参数",{"2":{"256":1,"301":1}}],["模型参数量和训练总tokens数决定了训练transformer模型需要的计算量",{"2":{"291":1}}],["模型参数量",{"0":{"224":1},"1":{"241":1,"256":1,"267":1},"2":{"291":1}}],["模型通过这种方式逐步生成目标语句",{"2":{"214":1}}],["模型层数",{"2":{"210":1}}],["模型的困惑度为1",{"2":{"274":1}}],["模型的架构主要有两大类",{"2":{"210":1}}],["模型的整体计算量等于模型中每个算子的计算量之和",{"2":{"49":1}}],["模型训练",{"0":{"193":1}}],["模型网络",{"2":{"160":1}}],["模型代码",{"2":{"160":1}}],["模型其实就是开头的公式",{"2":{"160":1}}],["模型架构",{"0":{"87":1},"1":{"101":1,"116":1,"132":1,"147":1,"161":1,"178":1}}],["模型中的参数的综合",{"2":{"49":1}}],["模型大小的四大评估指标是什么",{"0":{"49":1}}],["各种lock",{"2":{"163":1}}],["交叉熵",{"2":{"160":1}}],["交叉熵函数",{"2":{"146":1}}],["测试数据",{"2":{"160":1}}],["前面提到当模型参数为",{"2":{"284":1}}],["前向传播的时候第",{"2":{"296":1}}],["前向传播就是对输入扫描了一遍互相关运算得出结果",{"2":{"186":1}}],["前向传递过程中计算得到的",{"2":{"297":1}}],["前向传递",{"2":{"284":1}}],["前向计算过程中产生的中间激活",{"2":{"256":1}}],["前者比较通用",{"2":{"253":1}}],["前者是第一种",{"2":{"159":1}}],["前端",{"2":{"221":1}}],["前言",{"2":{"62":1}}],["甚至普通构造函数和移动构造函数也会被劫持",{"2":{"158":1}}],["产生的效果是相同的",{"2":{"158":1}}],["产品文档",{"2":{"12":1,"20":1,"22":1,"24":1}}],["意思是如果没有设置这种rank",{"2":{"299":1}}],["意思是启动一个批量异步拷贝",{"2":{"244":1}}],["意为第一维取所有",{"2":{"235":1}}],["意为一个张量",{"2":{"155":1}}],["意味着指针不可变",{"2":{"156":1}}],["意味着对象不可变",{"2":{"156":1}}],["意味着过了2个step才会去更新参数",{"2":{"141":1}}],["意味着我们一个token会对所有的experts都计算",{"2":{"111":1}}],["剩余所有的单词大致遵循双对数坐标图上的一条直线",{"2":{"154":1}}],["剩下的",{"2":{"67":1}}],["齐普夫定律",{"0":{"154":1},"2":{"154":1}}],["至此我们就完成了从全连接到卷积层cnn的过渡",{"2":{"153":1}}],["秒",{"2":{"152":1,"300":1}}],["运行",{"2":{"271":1}}],["运行之后显示如下",{"2":{"253":1}}],["运行时cpuid检测",{"2":{"253":1}}],["运行时性能",{"2":{"221":1}}],["运行时优化",{"2":{"54":1}}],["运行一下可以看出偏差在不断变小",{"2":{"186":1}}],["运行了",{"2":{"152":1}}],["另外还需要一些序列化方法",{"2":{"305":1}}],["另外deepspeed还提供了一个init",{"2":{"302":1}}],["另外我们考虑两个layer",{"2":{"297":1}}],["另外一种模式是no",{"2":{"280":1}}],["另外一个好处就是提供了书写上的便利",{"2":{"201":1}}],["另外一个与lll呈幂律关系",{"2":{"38":1}}],["另外数组和函数会退化为指针",{"2":{"179":1}}],["另外图片是一个二维像素点矩阵",{"2":{"160":1}}],["另一种是不间断运行了一定量的字节码",{"2":{"152":1}}],["释放锁的时机有两种",{"2":{"152":1}}],["官方解释器",{"2":{"152":1}}],["官方教程中是对m维度划分了group",{"2":{"70":1}}],["六",{"0":{"151":1,"239":1}}],["评分函数为",{"2":{"150":1}}],["点积",{"2":{"186":1}}],["点积的方差在不考虑向量长度的情况下仍然是1",{"2":{"150":1}}],["点我查看代码",{"2":{"89":2}}],["缩放点积注意力",{"0":{"150":1},"2":{"150":1}}],["缩小一下通道数",{"2":{"94":1}}],["里面会有load",{"2":{"305":1}}],["里面的bert",{"2":{"294":1}}],["里面大多封装了关于ld",{"2":{"211":1}}],["里面放上图片的网址",{"2":{"149":1}}],["里面放上图片的替代文字",{"2":{"149":1}}],["里面是这样说的",{"2":{"272":1}}],["里面是sft的逻辑",{"2":{"127":1}}],["里面是rlhf的step",{"2":{"127":1}}],["详细叙述如下",{"2":{"149":1}}],["详情请阅读上面的gemm",{"2":{"70":1}}],["减少prefill的计算",{"2":{"309":1}}],["减少了bubble",{"2":{"290":1}}],["减少网络拥塞",{"2":{"272":1}}],["减少代码膨胀",{"2":{"221":1}}],["减去1",{"2":{"187":1}}],["减一",{"2":{"146":1}}],["减号",{"2":{"78":1,"213":1}}],["函数",{"2":{"294":1}}],["函数变为",{"2":{"146":1}}],["函数的基本定义如下",{"2":{"115":1}}],["置为1",{"2":{"146":1}}],["~mask",{"2":{"312":1}}],["~~delete~~",{"2":{"165":1}}],["~t",{"2":{"156":1,"171":1}}],["~",{"2":{"145":1,"148":2}}],["该窗口根据其步幅大小在输入的所有区域上滑动",{"2":{"281":1}}],["该模型的预测是词表的所有可用词元上的均匀分布",{"2":{"274":1}}],["该序列的自注意力输出为一个长度相同的序列",{"2":{"258":1}}],["该注意力模型优化了seq2seq模型",{"2":{"183":1}}],["该如何计算概率呢",{"2":{"140":1}}],["该从哪些角度去考虑",{"0":{"43":1}}],["出自",{"2":{"212":2}}],["出现某个单词的条件概率",{"2":{"140":1}}],["出来的维度为1",{"2":{"129":1}}],["举一个bf16的特化模板例子",{"2":{"211":1}}],["举一个例子",{"2":{"140":1,"183":1}}],["举例说明对他们的理解",{"0":{"49":1}}],["举例来说",{"2":{"19":1,"27":1,"29":1,"31":1,"59":1}}],["语言底层实现了gmp机制",{"2":{"248":1}}],["语言模型",{"0":{"140":1},"1":{"154":1}}],["语义",{"0":{"143":1,"157":1},"1":{"156":1,"171":1,"172":1,"189":1,"204":1}}],["语法风格的话其实就是汇编语言的风格",{"2":{"190":1}}],["语法风格",{"2":{"190":1}}],["语法相关的文件",{"2":{"67":1}}],["语法撰写",{"2":{"67":1}}],["语法不会被转换",{"2":{"67":1}}],["语法",{"2":{"52":1}}],["语法中",{"2":{"26":1,"34":1,"36":1,"39":1}}],["语法在",{"2":{"19":1,"27":1,"29":1,"31":1}}],["语法受到一些既有",{"2":{"7":1,"13":1,"15":1,"17":1}}],["保存mask矩阵",{"2":{"297":1}}],["保存一个mask矩阵",{"2":{"297":1}}],["保存的tensor一般是一份引用",{"2":{"225":1}}],["保存更新过的moving",{"2":{"137":1}}],["保留grad",{"2":{"225":1}}],["保守策略",{"2":{"221":1}}],["保证了",{"2":{"171":1}}],["保证了任何时刻",{"2":{"152":1}}],["保证后续的操作能够正确的读取",{"2":{"64":1}}],["保证能看到",{"2":{"64":1}}],["保证之前的操作对",{"2":{"64":1}}],["保证该读操作后的所有操作能看到该读操作前的所有写操作",{"2":{"64":1}}],["保证该写操作前的所有操作对其他线程可见",{"2":{"64":1}}],["完全销毁掉",{"2":{"225":1}}],["完全保留",{"2":{"225":1}}],["完全连接层的输出数量或卷积层的输出通道数",{"2":{"137":1}}],["完善",{"2":{"221":1}}],["完美转发",{"2":{"204":1}}],["完整代码如下",{"2":{"70":1}}],["卷积的本质是有效提取相邻像素之间的特征",{"2":{"262":1}}],["卷积的形状取决于输入形状和卷积核的形状",{"2":{"201":1}}],["卷积核为",{"2":{"233":1}}],["卷积核的高度和宽度均为2",{"2":{"201":1}}],["卷积核shape",{"2":{"186":1}}],["卷积核窗口其实就是从左上角到右下角的一个滑动窗口",{"2":{"186":1}}],["卷积神经网络",{"2":{"153":1}}],["卷积神经网络cnn",{"0":{"62":1},"1":{"71":1,"82":1,"95":1,"109":1,"125":1,"139":1,"153":1,"168":1,"186":1,"201":1,"217":1,"233":1,"250":1,"262":1,"273":1,"281":1,"288":1,"295":1}}],["卷积层仍然可以识别到模式",{"2":{"281":1}}],["卷积层的输出都不会受到影响",{"2":{"186":1}}],["卷积层其实是一个错误的叫法",{"2":{"186":1}}],["卷积层通常比全连接层需要更少的参数",{"2":{"153":1}}],["卷积层有时被称为特征映射",{"2":{"139":1}}],["卷积层",{"2":{"137":1,"262":1}}],["直接torchrun即可",{"2":{"287":1}}],["直接变为virtual",{"2":{"275":1}}],["直接使用传入的移动平均所得的均值和方差",{"2":{"137":1}}],["直观地说",{"2":{"250":1}}],["直到生成",{"2":{"214":1}}],["直到这里",{"2":{"109":1}}],["直到找到j",{"2":{"99":1}}],["预填充",{"2":{"304":1}}],["预填充阶段",{"2":{"304":1}}],["预热期",{"2":{"289":1}}],["预热期结束之后",{"2":{"289":1}}],["预测num",{"2":{"289":1}}],["预测",{"0":{"289":1}}],["预测模式",{"2":{"137":1}}],["预处理阶段",{"2":{"205":1,"221":1}}],["预设的链接标签功能让你可以省略指定链接标签",{"2":{"104":1}}],["五",{"0":{"137":1,"223":1,"298":1}}],["结合我们的概率输出和softmax",{"2":{"282":1}}],["结合了gpipe与data",{"2":{"254":1}}],["结合线程池能得到较大的改善",{"2":{"232":1}}],["结合当前decoder隐状态和encoder的隐状态序列",{"2":{"214":1}}],["结束端前面一个",{"2":{"135":1}}],["结果为",{"2":{"159":1,"252":1}}],["结果",{"2":{"59":1}}],["起始端后面一个",{"2":{"135":1}}],["简而言之",{"2":{"282":1}}],["简单了很多",{"2":{"225":1}}],["简单循环展开",{"2":{"221":1}}],["简洁美观",{"2":{"134":1}}],["简介",{"0":{"96":1,"99":1,"190":1}}],["事实上",{"2":{"274":1}}],["事实上如果当前有nn",{"2":{"133":1}}],["事实上虽然在cuda编程的范式上",{"2":{"70":1}}],["显然1",{"2":{"262":1}}],["显然f2会导致悬垂引用",{"2":{"209":1}}],["显式使用指令",{"2":{"253":1}}],["显著差异",{"2":{"221":2}}],["显示前驱节点",{"2":{"133":1}}],["显示创建y的操作",{"2":{"133":1}}],["显存优化",{"0":{"208":1}}],["显存占用的峰值",{"2":{"49":1}}],["显存大小",{"2":{"49":1}}],["显存带宽的需求",{"2":{"49":1}}],["显存的字节大小",{"2":{"49":1}}],["原来的fp32",{"2":{"298":1}}],["原理是在每个node都启动一个训练进程",{"2":{"280":1}}],["原理",{"0":{"234":1},"1":{"251":1,"263":1,"274":1}}],["原理就是其中的枚举名被隐式转换为了std",{"2":{"207":1}}],["原因在于它的核心算法",{"2":{"177":1}}],["原生线程",{"2":{"152":1}}],["原地操作",{"2":{"133":1}}],["原始码",{"2":{"67":1,"135":1}}],["索引操作",{"2":{"133":1}}],["张量最后一个维度为词表大小",{"2":{"282":1}}],["张量操作",{"2":{"133":1}}],["张量并行",{"2":{"65":1}}],["神经网络操作",{"2":{"133":1}}],["神经网络的每一层应该只探索图像中的局部区域",{"2":{"95":1}}],["创建一个足够长的p",{"2":{"269":1}}],["创建和销毁都是一笔开销",{"2":{"232":1}}],["创建操作",{"0":{"170":1}}],["创建计算图节点",{"2":{"133":1}}],["创建求和节点",{"2":{"133":1}}],["创建视图节点",{"2":{"133":1}}],["创建线性层节点",{"2":{"133":1}}],["创建relu节点",{"2":{"133":1}}],["创建乘法节点",{"2":{"133":1}}],["创建加法节点",{"2":{"133":1}}],["视应用类型而定",{"2":{"221":1}}],["视为创建一个计算图节点",{"2":{"133":1}}],["视频中的图像帧",{"2":{"96":1}}],["范数有一个简单的形式",{"2":{"131":1}}],["范围内",{"2":{"26":1,"34":1,"36":1,"39":1}}],["维embedding向量",{"2":{"269":1}}],["维隐状态",{"2":{"269":1}}],["维向量",{"2":{"269":1}}],["维度",{"2":{"225":1}}],["维度为2",{"2":{"170":1}}],["维张量",{"2":{"131":2}}],["维的张量",{"2":{"100":1,"115":1}}],["了解一个函数的性质最重要的方式之一就是了解它的梯度",{"2":{"131":1}}],["提高了效率",{"2":{"290":1}}],["提高效率",{"2":{"129":1}}],["提出了dp",{"2":{"254":1}}],["提供多机间通信能力",{"2":{"272":1}}],["提供了最基础的load",{"2":{"268":1}}],["提供了更加灵活的方式",{"2":{"159":1}}],["提供了一个main",{"2":{"127":1}}],["提供一个推理服务",{"2":{"127":1}}],["提供作为比较之用",{"2":{"104":1}}],["损失函数的标量进行",{"2":{"312":1}}],["损失函数会如何变化",{"2":{"177":1}}],["损失函数是一个标量",{"2":{"177":1}}],["损失函数这里采取上文所述的交叉熵",{"2":{"160":1}}],["损失函数",{"0":{"146":1},"2":{"129":1}}],["损失函数可以定义为",{"2":{"73":1}}],["批次大小",{"2":{"301":1}}],["批次返回",{"2":{"129":1}}],["批量规范化是一种流行且有效的技术",{"2":{"137":1}}],["批量大小",{"2":{"136":2,"186":1,"282":4,"306":2}}],["批量导入数据",{"2":{"110":1}}],["批量矩阵乘法",{"2":{"106":1}}],["真实的参数",{"2":{"129":1}}],["查看标志位",{"2":{"253":1}}],["查看推理结果",{"2":{"127":1}}],["查询或者",{"2":{"246":6}}],["查询的步数",{"2":{"136":1}}],["查询的个数",{"2":{"136":4,"150":2,"246":3}}],["查询个数",{"2":{"106":3}}],["查询来自前一个解码器层的输出",{"2":{"87":1}}],["查询",{"2":{"87":2,"136":1}}],["└──",{"2":{"127":19,"287":2}}],["│",{"2":{"127":51}}],["├──",{"2":{"127":34,"287":3}}],["展平",{"2":{"126":1}}],["统计词元的频率",{"2":{"126":1}}],["未知词元的索引为0",{"2":{"126":2}}],["未知词元类型",{"2":{"126":1}}],["按照第二维拼接",{"2":{"310":1}}],["按照第一维拼接",{"2":{"220":1}}],["按照块来分治",{"2":{"70":1}}],["按行求和",{"2":{"160":1}}],["按出现频率排序",{"2":{"126":1}}],["词元",{"2":{"300":1}}],["词元数量",{"2":{"300":1,"312":1}}],["词元的本质就是一个个字符",{"2":{"126":1}}],["词表大小",{"2":{"210":1,"282":2,"306":1}}],["词高亮",{"2":{"89":1}}],["读一下",{"2":{"270":1}}],["读取语料库",{"2":{"126":1}}],["读操作",{"2":{"64":2}}],["建立一个词表",{"2":{"126":1}}],["建议将其声明为",{"2":{"239":1}}],["建议来细读这一篇megatron",{"2":{"237":1}}],["建议",{"2":{"78":1,"120":2}}],["颜色等",{"2":{"125":1}}],["外表",{"2":{"125":1}}],["外部链接带有",{"2":{"40":1}}],["外部链接",{"0":{"40":1}}],["没有使用nccl",{"2":{"272":1}}],["没有过多的异常值的类型",{"2":{"270":1}}],["没有优化器状态和梯度",{"2":{"267":1}}],["没有除以样本",{"2":{"129":1}}],["没有局部性",{"2":{"125":1}}],["没有限定上下界",{"2":{"115":1}}],["程序需要在cpu上执行",{"2":{"124":1}}],["网络io",{"2":{"124":1}}],["网址定义只有在产生链接的时候用到",{"2":{"104":1}}],["网址太长的话",{"2":{"104":1}}],["四",{"0":{"123":1,"207":1,"236":1,"293":1,"295":1},"1":{"253":1,"264":1,"298":1}}],["两边都有空白的话",{"2":{"120":1}}],["两个张量形状大致均为",{"2":{"297":1}}],["两个值矩阵是相同的",{"2":{"136":1}}],["两个thread均执行以下操作",{"2":{"64":1}}],["两个shape为",{"2":{"49":2}}],["两个符号都一定会被转换成",{"2":{"26":1,"34":1,"36":1,"39":1}}],["则默认为0",{"2":{"310":1}}],["则缩放点积注意力",{"2":{"150":1}}],["则会被转成",{"2":{"120":1}}],["则该行也会被视为空行",{"2":{"41":1}}],["包含一个序列中",{"2":{"269":1}}],["包含一个线性层",{"2":{"224":1}}],["包含两个可训练模型参数",{"2":{"224":1}}],["包含字面值",{"2":{"172":1}}],["包起来的话",{"2":{"120":1}}],["包围的字词会被转成用",{"2":{"120":1}}],["包括rlhf代码实现",{"2":{"127":1}}],["包括标题",{"2":{"52":1}}],["包括代码补全",{"2":{"50":1}}],["包括",{"2":{"7":1,"13":1,"15":1,"17":1,"41":1}}],["∂xi​∂​j=1∑n​yj​",{"2":{"159":1}}],["∂x∂loss",{"2":{"146":1}}],["∂x=p−onehot",{"2":{"146":1}}],["∂xj​∂pi​​=pi​δi",{"2":{"131":1}}],["∂loss",{"2":{"146":1}}],["∂∂xi∑j=1nyj",{"2":{"159":1}}],["∂∂xiexi∑k=1nexk=",{"2":{"131":1}}],["∂∂xjexi∑k=1nexk=",{"2":{"131":1}}],["∂pi∂xj=piδi",{"2":{"131":1}}],["∂pi∂xj=",{"2":{"131":2}}],["∂e⃗∂t=4πcj⃗∇⋅e⃗=4πρ",{"2":{"119":1}}],["∂b⃗∂t=0⃗",{"2":{"119":1}}],["∇×b⃗−",{"2":{"119":1}}],["∇×e+c1​∂t∂b​=0",{"2":{"119":1}}],["∇×e⃗",{"2":{"119":1}}],["∇⋅b⃗=0",{"2":{"119":1}}],["∇f",{"2":{"114":3}}],["满足概率的性质",{"2":{"115":1}}],["∈rpo",{"2":{"230":1}}],["∈rpk∗dk",{"2":{"230":1}}],["∈rpq∗dq",{"2":{"230":1}}],["∈rpv∗dv",{"2":{"230":1}}],["∈rpv​",{"2":{"230":1}}],["∈rpv",{"2":{"230":1}}],["∈r",{"2":{"122":1,"136":2}}],["∈rn",{"2":{"115":2}}],["∈rd",{"2":{"87":1,"258":2}}],["∈rdsublayer",{"2":{"87":1}}],["增加到第一个卷积层之后的6个",{"2":{"295":1}}],["增加一个",{"2":{"145":1}}],["增长最快的地方",{"2":{"114":1}}],["增强版中比较有名的有",{"2":{"7":1,"13":1,"15":1,"17":1}}],["得出的梯度是一个二维向量",{"2":{"114":1}}],["得到encoder的隐状态序列",{"2":{"199":1}}],["得到一个标量",{"2":{"159":1}}],["得到",{"2":{"109":1}}],["求映射就可以了",{"2":{"286":1}}],["求平均值",{"2":{"188":1}}],["求和",{"2":{"159":1,"233":1}}],["求导",{"2":{"114":1}}],["求方差",{"2":{"37":1}}],["求方差时",{"2":{"37":1}}],["由语言模型给出",{"2":{"274":1}}],["由两个线性层组成",{"2":{"224":1}}],["由os调度",{"2":{"152":1}}],["由此得知卷积层的权重也应该调整为",{"2":{"125":1}}],["由此我们就得到了每次参数的变化公式",{"2":{"114":1}}],["由于我们每次采样的小批量数据形状为二维张量",{"2":{"282":1}}],["由于bwd耗时往往为fwd的两倍",{"2":{"275":1,"290":1}}],["由于历史原因",{"2":{"274":1}}],["由于序列长度为",{"2":{"269":2}}],["由于序列数据本质上是连续的",{"2":{"169":1}}],["由于查询",{"2":{"258":1}}],["由于cpp中的继承重写有诸多限制",{"2":{"239":1}}],["由于求导的线性特性",{"2":{"159":1}}],["由于",{"2":{"110":1,"297":1}}],["由于链接文字可能包含空白",{"2":{"104":1}}],["梯度和优化器的显存",{"2":{"301":1}}],["梯度和优化器状态的显存占用",{"2":{"256":1}}],["梯度",{"2":{"297":1}}],["梯度爆炸的现象",{"2":{"296":1}}],["梯度裁剪",{"0":{"296":1}}],["梯度清零",{"2":{"203":1}}],["梯度操作",{"0":{"203":1}}],["梯度在机器学习很重要",{"2":{"145":1}}],["梯度消失现象会很严重",{"2":{"131":1}}],["梯度计算",{"0":{"131":1}}],["梯度的计算一般是依赖pytorch的自动微分",{"2":{"130":1}}],["梯度以及参数分片到多卡上",{"2":{"121":1}}],["梯度肯定是一个和自变量维数等同的向量",{"2":{"114":1}}],["梯度向量对应着增长最快的方向",{"2":{"114":1}}],["梯度下降计算函数sgd",{"2":{"129":1}}],["梯度下降法其实就是用来计算函数最小值的",{"2":{"99":1}}],["梯度下降",{"0":{"85":1},"1":{"99":1,"114":1,"129":1}}],["讲解一下如何弹性训练",{"2":{"302":1}}],["讲解一下如何进行一次ppo",{"2":{"112":1}}],["讲解一下该优化器的细节",{"2":{"105":1}}],["采用rdma技术加速",{"2":{"272":1}}],["采用的是正弦波+一个随机噪声",{"2":{"110":1}}],["采取各种action",{"2":{"112":1}}],["匹配度",{"2":{"111":1}}],["单位是bytes",{"2":{"297":1}}],["单位是ops",{"2":{"49":1}}],["单一的值",{"2":{"177":1}}],["单调性",{"2":{"115":1}}],["单步预测效果不错",{"2":{"110":1}}],["初始状态选择的是encoder输出的state",{"2":{"310":1}}],["初始化device",{"2":{"302":1}}],["初始化分布式环境",{"2":{"302":1}}],["初始化对于",{"2":{"158":1}}],["初始化的好处",{"2":{"158":1}}],["初始化不允许内置类型间隐式的变窄转换",{"2":{"158":1}}],["初始化具有如下的好处",{"2":{"158":1}}],["初始化",{"0":{"158":1},"2":{"214":1,"300":1}}],["初始化模型的权重",{"2":{"110":1}}],["初始参数",{"2":{"129":1}}],["初始值均为0",{"2":{"64":1}}],["∑k=1n​exk​exi​​",{"2":{"131":1}}],["∑k=1n​exk​",{"2":{"131":2}}],["∑k=1nexk",{"2":{"131":2}}],["∑j=1mexp⁡",{"2":{"122":1}}],["∑j=1ngradientj∗∂yj∂xi=∑j=1n∂yj∂xi=4xi",{"2":{"159":1}}],["∑j=1n∂yj∂xi",{"2":{"159":1}}],["∑j=1nexp⁡",{"2":{"93":1,"106":1}}],["∑j=1nk",{"2":{"93":1}}],["∑xt​​p",{"2":{"110":2}}],["称之为线性回归模型linreg",{"2":{"129":1}}],["称之为",{"2":{"110":1}}],["称为编码器",{"2":{"87":1}}],["设置到",{"2":{"305":1}}],["设置为评估模式",{"2":{"295":1}}],["设置卷积层输入为",{"2":{"281":1}}],["设置transpose",{"2":{"150":1}}],["设计字符级rnn模型",{"0":{"263":1}}],["设计模型",{"2":{"110":1}}],["设模型参数为",{"2":{"256":1}}],["设",{"2":{"110":1,"159":1}}],["之间",{"2":{"291":1}}],["之间的传输",{"2":{"268":1}}],["之前gpu0的layer",{"2":{"275":1}}],["之外的时间点我们认为其实是没有很大必要的",{"2":{"110":1}}],["之后有空再load进来继续训练的技术",{"2":{"305":1}}],["之后的config类可以继承自这个类",{"2":{"305":1}}],["之后就是一个if",{"2":{"302":1}}],["之后就是deepspeed的training的config配置",{"2":{"141":1}}],["之后将介绍",{"2":{"295":1,"306":1}}],["之后对于多node而言",{"2":{"287":1}}],["之后wait",{"2":{"275":1}}],["之后计算一个backward",{"2":{"275":1}}],["之后input",{"2":{"225":1}}],["之后这段代码使得x0x",{"2":{"145":1}}],["之后load",{"2":{"141":1}}],["之后是distributed相关配置",{"2":{"141":1}}],["之后我们的目标其实就是随机钦定w0w",{"2":{"129":1}}],["之后逐一分配下标",{"2":{"126":1}}],["之后还有一篇ppo的理论解析",{"2":{"112":1}}],["之后引出zero",{"2":{"105":1}}],["之后附加文本来设置自定义标题",{"2":{"89":1}}],["之后settings",{"2":{"50":1}}],["之后再完善",{"2":{"47":1}}],["τ",{"2":{"110":3}}],["想要预测股票所能依靠的信息只有",{"2":{"110":1}}],["想象一下",{"2":{"110":1}}],["天的价格",{"2":{"110":1}}],["马尔科夫模型",{"0":{"110":1}}],["δt",{"2":{"146":2}}],["δ",{"2":{"109":1,"145":1}}],["定值",{"2":{"109":1}}],["定义rnn计算层",{"2":{"282":1}}],["定义一个通用的schedule基类",{"2":{"225":1}}],["定义一个层",{"2":{"129":1}}],["定义模型以及损失函数",{"2":{"160":1}}],["定义模型参数",{"2":{"160":1}}],["定义w2对象",{"2":{"158":1}}],["定义初始值w",{"2":{"129":1}}],["定义学习率",{"2":{"94":1}}],["定义块的数量和通道",{"2":{"94":1}}],["定义要聚焦的行数",{"2":{"89":1}}],["∀c∈r",{"2":{"115":1}}],["∀c∈rsoftmax",{"2":{"115":1}}],["∀",{"2":{"109":2}}],["权重参数变为了",{"2":{"109":1}}],["代价就是",{"2":{"109":1}}],["代表",{"2":{"310":1}}],["代表具体的训练进程",{"2":{"287":1}}],["代表的是一个卷积核啥时候可以覆盖到两个词元",{"2":{"269":1}}],["代表的t是一个指向t对象的指针",{"2":{"156":1}}],["代表丢弃了某些采样点",{"2":{"201":1}}],["代表一次训练十张图片",{"2":{"160":1}}],["代表一个方向",{"2":{"114":1}}],["代表我们需要训练的权重参数",{"2":{"109":1}}],["代表偏置参数",{"2":{"109":1}}],["代码生成方式",{"2":{"190":1}}],["代码目前如下",{"2":{"160":1}}],["代码码区段的起始和结束端都可以放入一个空白",{"2":{"135":1}}],["代码",{"0":{"135":1}}],["代码执行的操作不会被记录在计算图中",{"2":{"129":1}}],["代码中出现很多io操作",{"2":{"124":1}}],["代码语言会根据文件扩展名进行推断",{"2":{"103":1}}],["代码组",{"2":{"89":1}}],["代码块中的颜色差异",{"2":{"89":1}}],["代码块中的语法高亮",{"2":{"89":1}}],["代码块中聚焦",{"2":{"89":1}}],["代码块中使用彩色文本实现语法高亮",{"2":{"89":1}}],["代码块中",{"2":{"67":1,"89":1}}],["代码块",{"0":{"67":1}}],["代码块等",{"2":{"52":1}}],["应用接口层",{"2":{"272":1}}],["应用程序",{"2":{"253":1}}],["应用笔记",{"2":{"1":1}}],["应该具有相同的结构",{"2":{"109":1}}],["三种原色",{"2":{"125":1}}],["三",{"0":{"107":1,"192":1,"204":1,"209":1,"221":1,"260":1,"273":1,"279":1,"303":1,"307":1},"1":{"271":1,"281":1,"286":1,"288":1,"306":1,"308":1,"309":1,"310":1,"311":1,"312":1}}],["三者中的其中两者不是瓶颈的时候",{"2":{"38":1}}],["列填充",{"2":{"201":1}}],["列不拓展",{"2":{"106":1}}],["列表项目可以包含多个段落",{"2":{"59":1}}],["列表项目标记通常是放在最左边",{"2":{"59":1}}],["列表",{"0":{"59":1},"2":{"41":1,"51":1,"52":1}}],["每行两个",{"2":{"211":1}}],["每次启动一个异步拷贝之后记得",{"2":{"244":1}}],["每次滑动多个元素",{"2":{"201":1}}],["每次默认移动1",{"2":{"201":1}}],["每次随机分别取出小批次数据",{"2":{"129":1}}],["每一层特征的高度和宽度都减小了",{"2":{"295":1}}],["每一层有多个输出通道是至关重要的",{"2":{"250":1}}],["每一维都是一个带有隐藏层的神经网络",{"2":{"251":1}}],["每一个注意力汇聚都被称作一个头",{"2":{"230":1}}],["每一个节点的任务",{"2":{"133":1}}],["每一行是一个样本",{"2":{"129":1}}],["每一行都包含着相同的训练输出",{"2":{"106":1}}],["每一行都包含着相同的训练输入",{"2":{"106":1}}],["每个元素只占1个bytes",{"2":{"297":1}}],["每个元素占了2个bytes",{"2":{"297":1}}],["每个元素的梯度权重",{"2":{"159":1}}],["每个元素的梯度",{"2":{"145":1}}],["每个全连接层减少维数",{"2":{"295":1}}],["每个汇聚层的高度和宽度都减半",{"2":{"295":1}}],["每个卷积块中的基本单元是一个卷积层",{"2":{"295":1}}],["每个卷积核可以视为一个通道",{"2":{"125":1}}],["每个模型参数",{"2":{"284":2,"291":2}}],["每个词元其实都表示为一个数字索引",{"2":{"282":1}}],["每个词元都通过自注意力直接连接到其他的词元",{"2":{"269":1}}],["每个token的hidden",{"2":{"279":1}}],["每个transformer层的参数量为",{"2":{"241":1}}],["每个通道的量化参数不同",{"2":{"279":1}}],["每个神经元对其敏感的感受野",{"2":{"273":1}}],["每个应用进程会分到",{"2":{"271":1}}],["每个查询都会关注所有的键",{"2":{"258":1}}],["每个查询对应",{"2":{"106":1}}],["每个可训练模型参数都会对应1个梯度",{"2":{"256":1}}],["每个输出通道先获取所有输入通道",{"2":{"250":1}}],["每个注意力头",{"2":{"230":1}}],["每个层有两个子层",{"2":{"224":1}}],["每个层都有两个子层",{"2":{"87":1}}],["每个进程都会持有一把锁",{"2":{"184":1}}],["每个计算图的节点都有如下的一些属性",{"2":{"133":1}}],["每个step对应一个main",{"2":{"127":1}}],["每个expert都是一个mlp",{"2":{"97":1}}],["每个子层都采用了残差连接",{"2":{"87":1}}],["每个项目下的段落都必须缩进",{"2":{"59":1}}],["每个换行都转换为",{"2":{"41":1}}],["值对并生成一个注意力输出",{"2":{"258":1}}],["值得一提的是",{"2":{"186":1}}],["值为",{"2":{"181":1}}],["值随机的矩阵",{"2":{"170":1}}],["值v∈rm∗v",{"2":{"150":1}}],["值的长度为",{"2":{"150":1}}],["值的维度v",{"2":{"150":1}}],["值的维度",{"2":{"136":3}}],["值",{"2":{"106":2,"136":4,"150":2,"246":6}}],["键和值来自同一组输入",{"2":{"258":1}}],["键和值将并行地送到注意力汇聚中",{"2":{"230":1}}],["键和值",{"2":{"230":1,"258":1}}],["键和值的不同的子空间表示",{"2":{"246":1}}],["键和值的不同",{"2":{"230":1}}],["键和值的集合时",{"2":{"230":1}}],["键和值的形状为",{"2":{"136":1}}],["键和值都来自上一个解码器层的输出",{"2":{"87":1}}],["键和值都来自前一个编码器层的输出",{"2":{"87":1}}],["键",{"2":{"106":2,"136":4,"150":2,"246":6}}],["集中看一下模型的定义以及训练",{"2":{"106":1}}],["集合1f1b调度以及dualpipe",{"2":{"65":1}}],["ε",{"2":{"105":1}}],["β2",{"2":{"105":1}}],["β1",{"2":{"105":1}}],["​+t",{"2":{"304":1}}],["​+x",{"2":{"304":1}}],["​←concat",{"2":{"304":2}}],["​⋅w1​",{"2":{"304":2}}],["​⋅wo",{"2":{"304":2}}],["​t​​⋅xv",{"2":{"304":1}}],["​xk",{"2":{"304":2}}],["​v",{"2":{"230":1}}],["​k",{"2":{"230":1}}],["​q",{"2":{"230":1}}],["​",{"2":{"183":1,"286":3,"304":19}}],["​​const左值引用",{"2":{"172":1}}],["​​右值引用",{"2":{"172":1}}],["​i=ji=j​",{"2":{"131":1}}],["​∂xj​∂pi​​∂xj​∂​∑k=1n​exk​exi​​",{"2":{"131":1}}],["​∂xj​∂pi​​∂xi​∂​∑k=1n​exk​exi​​",{"2":{"131":1}}],["​∈rpv​∗dv​",{"2":{"230":1}}],["​∈rpk​∗dk​",{"2":{"230":1}}],["​∈rpq​∗dq​",{"2":{"230":1}}],["​∈r",{"2":{"122":1}}],["​=softmax",{"2":{"304":1}}],["​=softmax​h​xq",{"2":{"304":1}}],["​=t",{"2":{"304":1}}],["​=t=1∑t​α",{"2":{"183":1}}],["​=x",{"2":{"304":3}}],["​=xt​∑​p",{"2":{"110":1}}],["​=θi​−αdθi​d​j",{"2":{"129":1}}],["​=p−onehot",{"2":{"146":1}}],["​=p",{"2":{"110":1}}],["​mt​=β1​⋅mt−1​+",{"2":{"105":1}}],["​yi​",{"2":{"93":2,"106":1}}],["数值计算",{"2":{"221":1}}],["数值计算lib",{"2":{"163":1}}],["数值操作",{"2":{"188":1}}],["数组或者函数名实参会退化为指针",{"2":{"179":1}}],["数据集随机采样",{"0":{"169":1},"1":{"187":1,"202":1}}],["数据库操作",{"2":{"124":1}}],["数学运算",{"2":{"133":1}}],["数学方程",{"0":{"119":1}}],["数字",{"2":{"104":1}}],["数量最多的",{"2":{"26":1,"34":1,"36":1,"39":1}}],["双引号或是括号包括",{"2":{"104":1}}],["选per",{"2":{"298":1}}],["选int8还是uint8",{"2":{"298":1}}],["选asym还是sym",{"2":{"298":1}}],["选取合适的通信后端",{"2":{"272":1}}],["选中后",{"2":{"228":1}}],["选择性地添加",{"2":{"104":1}}],["选项",{"2":{"41":1}}],["选项来禁用这个功能",{"2":{"25":1}}],["冒号",{"2":{"104":1}}],["方便用户迁移",{"2":{"299":1}}],["方便模型操作",{"2":{"126":1}}],["方差为",{"2":{"150":1}}],["方向的变化比较敏感",{"2":{"145":1}}],["方向的变化不敏感",{"2":{"145":1}}],["方括号",{"2":{"104":2,"213":1}}],["方法是设置",{"2":{"50":1}}],["指向嵌套配置中的字段",{"2":{"305":1}}],["指向的是",{"2":{"114":1}}],["指的是",{"2":{"297":1}}],["指的是cpp会自己生成的函数",{"2":{"276":1}}],["指标",{"2":{"221":1}}],["指令集",{"0":{"253":1},"2":{"253":1}}],["指令选择质量",{"2":{"221":1}}],["指令",{"2":{"196":1}}],["指定一个长度可变的输入",{"2":{"308":1}}],["指定输入输出通道",{"2":{"186":1}}],["指定kernel",{"2":{"186":1}}],["指定代码语言",{"2":{"103":1}}],["指针本身不可变",{"2":{"156":1}}],["指针指向的对象是常量",{"2":{"156":1}}],["指模型计算时所需访问内存",{"2":{"49":1}}],["仅导入第",{"2":{"103":1}}],["导入代码块",{"0":{"103":1}}],["导致出现a",{"2":{"64":1}}],["导致一些矛盾",{"2":{"64":1}}],["实际应用",{"0":{"293":1},"1":{"298":1}}],["实际上也离不开量化最基础的步骤",{"2":{"238":1}}],["实际上不依赖于",{"2":{"109":1}}],["实际进行的计算为",{"2":{"159":1}}],["实现通用引用",{"2":{"209":1}}],["实现真正意义上的并行只能通过多进程的方式",{"2":{"184":1}}],["实现一个",{"2":{"174":1}}],["实现一些高效的gpu算子",{"2":{"133":1}}],["实现",{"0":{"168":1,"246":1,"282":1},"1":{"186":1,"201":1,"217":1,"233":1,"250":1,"262":1,"289":1}}],["实现softmax操作",{"2":{"160":1}}],["实现各个核的负载均衡",{"2":{"152":1}}],["实现计算操作",{"2":{"133":1}}],["实现多头但是只有一次矩阵乘法",{"2":{"101":1}}],["实体中使用",{"2":{"26":1,"34":1,"36":1,"39":1}}],["实体",{"2":{"26":3,"34":3,"36":3,"39":3,"67":1,"135":1,"198":1}}],["元语法模型",{"2":{"234":1}}],["元的离散型概率分布",{"2":{"100":1}}],["元素个数为",{"2":{"297":1}}],["元素添加属性",{"2":{"181":1}}],["元素",{"2":{"19":1,"27":1,"29":1,"31":1}}],["属于该类别的分量为1",{"2":{"100":1}}],["属性支持",{"0":{"181":1}}],["属性为true",{"2":{"145":1}}],["属性放到下一行",{"2":{"104":1}}],["属性",{"2":{"87":1,"181":2}}],["属性里",{"2":{"26":1,"34":1,"36":1,"39":1}}],["类也会继承",{"2":{"305":1}}],["类型",{"2":{"209":1}}],["类型推导",{"0":{"162":1},"1":{"179":1,"194":1,"209":1}}],["类似于rnn中将一些特殊词元忽略掉",{"2":{"122":1}}],["类似于隐藏层",{"2":{"110":1}}],["类似滑动窗口",{"2":{"110":1}}],["类似的状况也会发生在",{"2":{"26":1,"34":1,"36":1,"39":1}}],["类别",{"2":{"100":1}}],["鸡鸭鹅",{"2":{"100":1}}],["递减",{"2":{"99":1}}],["钦定θ0",{"2":{"99":1}}],["滚去",{"2":{"99":1}}],["谷底",{"2":{"99":1}}],["球",{"2":{"99":1}}],["核心思想就是将所有的experts划分为若干local",{"2":{"97":1}}],["核回归其实定义了一种汇聚方式",{"2":{"93":1}}],["大致思路其实是想设计一个更加普适通用的通信后端框架",{"2":{"299":1}}],["大致分为三步",{"2":{"127":1}}],["大模型在训练过程中通常采用混合精度训练",{"2":{"297":1}}],["大模型量化简介",{"0":{"231":1},"1":{"247":1,"259":1,"270":1,"279":1,"286":1,"293":1,"298":1}}],["大头在计算",{"2":{"275":1}}],["大概描述了调用层级",{"2":{"249":1}}],["大概多一倍",{"2":{"221":1}}],["大概浏览了一下summary",{"2":{"38":1}}],["大括号",{"2":{"213":1}}],["大约增加",{"2":{"145":1}}],["大小为",{"2":{"297":3}}],["大小",{"2":{"125":1}}],["大多数的数据并非如此",{"2":{"96":1}}],["局部性意味着计算相应的隐藏表示只需一小部分局部图像像素",{"2":{"153":1}}],["局部性",{"2":{"95":1,"109":1}}],["反引号",{"2":{"213":1}}],["反斜线",{"2":{"213":1}}],["反向传播",{"2":{"300":1,"312":1}}],["反向传播的时候根据链式法则",{"2":{"296":1}}],["反向传播计算梯度",{"2":{"203":1}}],["反向传播起点",{"0":{"177":1}}],["反之",{"2":{"167":1}}],["反应",{"2":{"95":1}}],["反映了模型对内存",{"2":{"49":1}}],["反映了模型对硬件计算单元的需求",{"2":{"49":1}}],["反映了模型站的磁盘空间",{"2":{"49":1}}],["某个固定的物体不管出现在图像的哪个位置",{"2":{"95":1}}],["某个物体会具有以下两种特性",{"2":{"95":1}}],["特别是x",{"2":{"304":1}}],["特别是在模板解析过程中",{"2":{"221":1}}],["特征映射和感受野",{"0":{"139":1}}],["特征大小",{"2":{"136":1}}],["特征",{"2":{"125":1,"221":1}}],["特殊成员函数有六个",{"2":{"276":1}}],["特殊成员函数",{"0":{"276":1}}],["特殊功能扩展",{"2":{"253":1}}],["特殊的",{"2":{"110":1}}],["特殊字元自动转换",{"0":{"26":1,"34":1,"36":1,"39":1}}],["特性",{"0":{"95":1}}],["生成下一个token需要重新走一下所有流程",{"2":{"304":1}}],["生成一个0",{"2":{"220":1}}],["生成输出",{"2":{"214":1}}],["生成hello",{"2":{"205":1}}],["生成数据",{"2":{"129":1}}],["生成器函数",{"2":{"129":1}}],["生成",{"2":{"129":1}}],["生成时间序列数据",{"2":{"110":1}}],["生成vgg网络",{"2":{"94":2}}],["生成vgg块",{"2":{"94":1}}],["生成的hello",{"2":{"205":1}}],["生成的输出表征的维数为",{"2":{"201":1}}],["生成的",{"2":{"32":1}}],["越是接近给定的",{"2":{"93":1}}],["−min",{"2":{"286":2}}],["−n1​t=1∑n​logp",{"2":{"274":1}}],["−1n∑t=1nlog⁡p",{"2":{"274":1}}],["−1s",{"2":{"183":1}}],["−1t",{"2":{"183":1}}],["−1​",{"2":{"183":2}}],["−1",{"2":{"183":2}}],["−128",{"2":{"286":2}}],["−12",{"2":{"93":3,"106":3}}],["−∂xj​∂lnpt​​=pj​−δt",{"2":{"146":1}}],["−∂lnpt∂xj=pj−δt",{"2":{"146":1}}],["−pi​pj​",{"2":{"131":1}}],["−pipj",{"2":{"131":1}}],["−exi∑k=1nexk⋅exj∑k=1nexk=",{"2":{"131":1}}],["−21​",{"2":{"93":3,"106":3}}],["−2u2​",{"2":{"93":1}}],["−u22",{"2":{"93":1}}],["−yi",{"2":{"73":2}}],["被",{"2":{"120":1}}],["被称之为注意力权重",{"2":{"93":1}}],["被重组了",{"2":{"50":1}}],["α",{"2":{"93":1,"114":1,"122":3,"183":1,"214":1}}],["形状与",{"2":{"297":1}}],["形状的张量",{"2":{"252":1}}],["形状为",{"2":{"199":2,"297":1}}],["形参既不是指针也不是引用",{"2":{"179":1}}],["形成一种更为通用的注意力汇聚方式",{"2":{"93":1}}],["形式如下",{"2":{"146":1}}],["形式则是在行首插入",{"2":{"46":1}}],["形式是用底线的形式",{"2":{"46":1}}],["形式",{"2":{"46":1}}],["形式的块引言",{"2":{"52":1}}],["形式的",{"2":{"19":1,"27":1,"29":1,"31":1}}],["非均匀量化",{"2":{"270":1}}],["非对称量化",{"2":{"270":1}}],["非模型参数的变量初始化为0和1",{"2":{"137":1}}],["非参数的模型收敛其实取决于key的数目",{"2":{"106":1}}],["非参数注意力汇聚",{"0":{"93":1}}],["非凸的局部最小值",{"2":{"99":1}}],["非常厉害",{"2":{"53":1}}],["文天祥",{"2":{"212":2}}],["文本词表",{"2":{"126":1}}],["文本预处理",{"0":{"126":1}}],["文字包起来即可",{"2":{"104":1}}],["文字",{"2":{"104":1,"149":1}}],["文章内分为两个部分",{"2":{"112":1}}],["文章中的单词是按顺序写的",{"2":{"96":1}}],["文章",{"2":{"90":1}}],["文件大小",{"2":{"221":1}}],["文件",{"2":{"104":1}}],["文件里面写出",{"2":{"26":1,"34":1,"36":1,"39":1}}],["文件里加上一段",{"2":{"19":1,"27":1,"29":1,"31":1}}],["文件中建立一个块引言",{"2":{"52":1}}],["文件中",{"2":{"26":1,"34":1,"36":1,"39":1}}],["文件的列表数字和输出的结果相同",{"2":{"59":1}}],["文件的绝对路径作为内部链接的目标",{"2":{"32":1}}],["文件的相对路径作为内部链接的目标",{"2":{"32":1}}],["文件的",{"2":{"25":1}}],["文件自动生成一个新的",{"2":{"25":1}}],["警告",{"2":{"89":1}}],["错误",{"2":{"89":1,"126":1}}],["错误检查",{"2":{"50":1}}],["注释将会为该行相应的着色",{"2":{"89":1}}],["注释将会为该行创建",{"2":{"89":1}}],["注释将聚焦它并模糊代码的其他部分",{"2":{"89":1}}],["注释实现行高亮",{"2":{"89":1}}],["注意这里不需要",{"2":{"285":1}}],["注意这些函数签名是写死的",{"2":{"276":1}}],["注意力头数",{"2":{"210":1}}],["注意力权重函数",{"2":{"183":1}}],["注意力模型",{"0":{"166":1},"1":{"183":1,"199":1,"214":1,"230":1,"246":1,"258":1,"269":1}}],["注意力汇聚输出的形状为",{"2":{"136":1}}],["注意力汇聚是",{"2":{"93":1}}],["注意力评分",{"0":{"122":1},"1":{"136":1,"150":1}}],["注意力保留了自回归",{"2":{"87":1}}],["注意力分为自主性和非自主性的提示",{"2":{"79":1}}],["注意力机制通过注意力汇聚",{"2":{"79":1}}],["注意力机制简介",{"0":{"68":1},"1":{"79":1,"93":1,"106":1,"122":1,"136":1,"150":1}}],["注意力机制",{"0":{"60":1},"1":{"68":1,"79":1,"93":1,"106":1,"122":1,"136":1,"150":1,"166":1,"183":1,"199":1,"214":1,"230":1,"246":1,"258":1,"269":1}}],["注意内存占用",{"2":{"49":1}}],["90+会有",{"2":{"227":1}}],["99",{"2":{"198":2}}],["98",{"2":{"193":1}}],["96",{"2":{"107":2,"123":3}}],["9",{"2":{"89":1,"137":1,"193":2,"220":1,"233":1,"275":1,"295":1}}],["多卡通信和记录日志的时间",{"2":{"291":1}}],["多输出通道并不仅是学习多个单通道的检测器",{"2":{"250":1}}],["多输出通道",{"0":{"250":1},"2":{"250":1}}],["多输入通道",{"0":{"233":1}}],["多输入和多输出通道",{"0":{"217":1},"1":{"233":1,"250":1}}],["多头注意力融合了来自于多个注意力汇聚的不同知识",{"2":{"246":1}}],["多头注意力的输出需要经过另一个线性变换",{"2":{"230":1}}],["多头注意力",{"0":{"230":1},"1":{"246":1},"2":{"246":1}}],["多元语法也同样满足齐普夫定律",{"2":{"154":1}}],["多个输入和输出通道使模型在每个空间位置可以获取图像的多方面特征",{"2":{"153":1}}],["多个单行",{"2":{"89":1}}],["多线程是受限于cil机制",{"2":{"232":1}}],["多线程之间的线程切换也是一笔开销",{"2":{"232":1}}],["多线程和协程",{"2":{"232":1}}],["多线程",{"0":{"124":1},"1":{"138":1,"152":1,"167":1,"184":1}}],["多行与单行",{"2":{"89":1}}],["多行",{"2":{"89":2}}],["`code`",{"2":{"228":1}}],["`foo`",{"2":{"135":1}}],["``cls=scientificnotationencoder``",{"2":{"305":1}}],["``json",{"2":{"305":2}}],["``",{"2":{"135":5}}],["``there",{"2":{"135":1}}],["```ts",{"2":{"89":3}}],["```html",{"2":{"89":1}}],["```md",{"2":{"89":1}}],["````",{"2":{"67":1}}],["````md",{"2":{"67":1,"89":1}}],["```js",{"2":{"67":2,"89":10}}],["```",{"2":{"67":4,"89":15}}],["`printf",{"2":{"135":1}}],["`options`",{"2":{"89":1}}],["`highlighted",{"2":{"89":2}}],["`",{"2":{"89":28,"135":10,"213":1,"228":1}}],["合法的编程语言列表",{"2":{"89":1}}],["需要保存其输入",{"2":{"297":1}}],["需要保存softmax的结果",{"2":{"297":1}}],["需要保存输入",{"2":{"297":1}}],["需要保存中间激活",{"2":{"297":1}}],["需要保存中间激活以便在后向传递计算梯度时使用",{"2":{"297":1}}],["需要保存他们的共同的输入",{"2":{"297":1}}],["需要进行8次浮点数运算",{"2":{"291":1}}],["需要进行一次额外的前向传递",{"2":{"291":1}}],["需要进行6次浮点数运算",{"2":{"284":1}}],["需要进行2次浮点数运算",{"2":{"284":1}}],["需要有一套sync机制保证",{"2":{"278":1}}],["需要使用tma",{"2":{"257":1}}],["需要传入mbarrier",{"2":{"244":1}}],["需要创建tensor",{"2":{"244":1}}],["需要构造一个与输入具有相同通道数的卷积核",{"2":{"233":1}}],["需要显式arrive一下",{"2":{"227":1}}],["需要input",{"2":{"225":1}}],["需要考虑更多的细节",{"2":{"225":1}}],["需要自己实现fwd和bwd方法",{"2":{"133":1}}],["需要做的就是将有效的语言别名附加到代码块的开头",{"2":{"89":1}}],["需要具备以下一些特点",{"2":{"70":1}}],["行填充和",{"2":{"201":1}}],["行高亮",{"2":{"103":1}}],["行",{"2":{"103":1}}],["行至第",{"2":{"103":1}}],["行为可能带来的负面影响",{"2":{"89":2}}],["行内图片的语法看起来像是",{"2":{"149":1}}],["行内和参考两种形式",{"2":{"104":1}}],["行内元素",{"0":{"91":1},"1":{"104":1,"120":1,"135":1,"149":1,"165":1}}],["行内不能有其他东西",{"2":{"78":1}}],["行内",{"0":{"19":1,"27":1,"29":1,"31":1},"2":{"26":1,"34":1,"36":1,"39":1,"149":1}}],["同步机制",{"0":{"278":1},"1":{"285":1,"292":1}}],["同上",{"2":{"188":1}}],["同形状的全1张量作为梯度权重",{"2":{"159":1}}],["同形状的gradient参数来计算",{"2":{"159":1}}],["同理",{"2":{"115":1,"145":1}}],["同样也允许两种样式",{"2":{"149":1}}],["同样",{"2":{"96":1}}],["同样支持以标注的方式渲染",{"2":{"89":1}}],["同时",{"2":{"295":1}}],["同时也会提供故障重启",{"2":{"272":1}}],["同时也会有上面",{"2":{"179":1}}],["同时也提供了aync方法",{"2":{"268":1}}],["同时也支持其他属性",{"2":{"181":1}}],["同时也为学好cuda打下基础",{"2":{"1":1}}],["同时收敛稳定",{"2":{"129":1}}],["同时保留代码块的颜色",{"2":{"89":1}}],["风格的警报",{"2":{"89":2}}],["已经在上一章attention机制中讲过了",{"2":{"87":1}}],["已经广泛使用",{"2":{"12":1,"20":1,"22":1,"24":1}}],["确保预测仅依赖于已生成的输出词元",{"2":{"87":1}}],["层数不变",{"2":{"275":1}}],["层级",{"2":{"253":1}}],["层之后",{"2":{"241":1}}],["层",{"2":{"87":1}}],["层的输入为",{"2":{"304":1}}],["层的",{"2":{"49":1}}],["除非是const左值",{"2":{"209":1}}],["除非他们被用于初始化引用",{"2":{"179":1}}],["除了模型参数",{"2":{"297":1}}],["除了单行之外",{"2":{"89":1}}],["除了编码器中描述的两个子层之外",{"2":{"87":1}}],["除此之外",{"2":{"12":1,"20":1,"22":1,"24":1}}],["紧接着应用层规范化",{"2":{"87":1}}],["7h",{"2":{"224":1}}],["7的一维张量",{"2":{"220":1}}],["784",{"2":{"160":3}}],["7",{"2":{"87":1,"89":2,"94":2,"186":1,"188":1,"220":2,"233":2,"257":2,"268":1,"310":1}}],["受限于cpython",{"2":{"232":1}}],["受",{"2":{"87":1}}],["第三项和第四项可以预先计算得出",{"2":{"298":1}}],["第三维就是时间",{"2":{"251":1}}],["第三维就是颜色",{"2":{"125":1}}],["第一行是dp的gpu",{"2":{"302":1}}],["第一部分的分布式环境初始化也应该是这个初始化的一部分",{"2":{"302":1}}],["第一项其实就是sym量化",{"2":{"298":1}}],["第一步总是先求scale",{"2":{"286":1}}],["第一个轴对应于时间步",{"2":{"310":1}}],["第一个卷积层使用2个像素的填充",{"2":{"295":1}}],["第一个线性层保存其输入",{"2":{"297":1}}],["第一个线性层",{"2":{"277":1}}],["第一个线性层拥有权重矩阵",{"2":{"224":1}}],["第一个线性层维度将",{"2":{"224":1}}],["第一个step是sft",{"2":{"127":1}}],["第一个子层是多头自注意力",{"2":{"87":1}}],["第1维变成第0维",{"2":{"220":1}}],["第",{"2":{"154":1}}],["第二行是sp的gpu",{"2":{"302":1}}],["第二项就为0",{"2":{"298":1}}],["第二维只取第一列",{"2":{"235":1}}],["第二个阶段是work阶段",{"2":{"299":1}}],["第二个卷积层没有填充",{"2":{"295":1}}],["第二个线性层保存其输入",{"2":{"297":1}}],["第二个线性层",{"2":{"277":1}}],["第二个线性层再将维度从",{"2":{"224":1}}],["第二个拥有权重矩阵",{"2":{"224":1}}],["第二个子层是基于位置的前馈网络",{"2":{"87":1}}],["第二阶标题",{"2":{"46":1}}],["进入decoder",{"2":{"310":1}}],["进入encoder",{"2":{"310":1}}],["进入rnn网络计算",{"2":{"300":1}}],["进入的维度为2",{"2":{"129":1}}],["进程并行",{"0":{"271":1}}],["进程间通信需要通过管道等方式",{"2":{"184":1}}],["进而更新各个权重参数",{"2":{"263":1}}],["进而改进这一结构",{"2":{"82":1}}],["进一步印证了",{"2":{"244":1}}],["进位码的",{"2":{"198":1}}],["进行封装",{"2":{"299":1}}],["进行2次浮点数计算",{"2":{"291":1}}],["进行互相关运算",{"2":{"233":1}}],["进行下角标标注",{"2":{"148":1}}],["进行上角标标注",{"2":{"148":1}}],["进行标记",{"2":{"134":1}}],["进行三轮迭代",{"2":{"129":1}}],["进行完softmax操作之后attention",{"2":{"106":1}}],["进阶指南",{"2":{"1":1}}],["图片参考的定义方式则和链接参考一样",{"2":{"149":1}}],["图片",{"0":{"149":1}}],["图片水印",{"0":{"10":1},"1":{"17":1,"24":1,"31":1,"39":1}}],["图像的平移不变性使我们以相同的方式处理局部图像",{"2":{"153":1}}],["图像的一个像素点一般包含三个通道",{"2":{"125":1}}],["图像天然本就拥有丰富的空间结构",{"2":{"82":1}}],["操作系统一般是基于硬件架构来编写的",{"2":{"190":1}}],["操作系统",{"2":{"190":1,"253":1}}],["操作系统会提供线程管理器",{"2":{"152":1}}],["操作",{"2":{"82":1,"186":1}}],["拟合",{"2":{"82":1}}],["全程序指针分析等等",{"2":{"221":1}}],["全局常量传播",{"2":{"221":1}}],["全连接层输出形状是",{"2":{"306":1}}],["全连接层变换后",{"2":{"183":1}}],["全连接层",{"2":{"137":1,"262":1}}],["全连接层可以理解为一种",{"2":{"82":1}}],["全屏水印",{"0":{"8":1},"1":{"13":1,"20":1,"27":1,"34":1}}],["介绍一下西安",{"2":{"183":1,"199":1}}],["介绍",{"0":{"82":1,"115":1,"215":1}}],["很明显地",{"2":{"149":1}}],["很好的一篇文章",{"2":{"81":1}}],["很重要的一点是",{"2":{"59":1}}],["自注意力",{"2":{"258":1}}],["自注意力和位置编码",{"0":{"258":1},"1":{"269":1}}],["自左而右滑动计算",{"2":{"201":1}}],["自动优化通信路径",{"2":{"272":1}}],["自动的邮件链接也很类似",{"2":{"198":1}}],["自动链接",{"0":{"198":1}}],["自动微分对向量的兼容",{"0":{"159":1}}],["自然",{"2":{"149":1}}],["自始至终没有出现过",{"2":{"110":1}}],["自回归模型",{"2":{"110":1}}],["自适应调整学习率",{"2":{"105":1}}],["自主性被称为查询",{"2":{"79":1}}],["自定义对齐",{"0":{"164":1}}],["自定义标题",{"0":{"89":1}}],["自定义容器可以通过它们的类型",{"2":{"66":1}}],["自定义容器",{"0":{"66":1},"1":{"77":1,"89":1},"2":{"89":2}}],["自定义锚点",{"0":{"18":1}}],["引来ub",{"2":{"209":1}}],["引用折叠",{"2":{"204":1}}],["引用",{"2":{"172":1}}],["引入一个",{"2":{"115":1}}],["引入",{"0":{"79":1,"100":1}}],["引言的块内也可以使用其他的",{"2":{"52":1}}],["引言内的引言",{"2":{"52":1}}],["引言写法看起来就真的像是引用一段文字",{"2":{"7":1,"13":1,"15":1,"17":1}}],["何为zero",{"2":{"76":1}}],["首先会进入embedding",{"2":{"310":1}}],["首先将y的形状改为",{"2":{"306":1}}],["首先将默认的torch",{"2":{"299":1}}],["首先这里就不对checkpoint技术做过多赘述",{"2":{"305":1}}],["首先这里有一个表格",{"2":{"190":1}}],["首先设第",{"2":{"304":1}}],["首先要明确",{"2":{"304":1}}],["首先要生成数据",{"2":{"129":1}}],["首先gpu是由device",{"2":{"302":1}}],["首先输入的x和目标y",{"2":{"300":1}}],["首先如果",{"2":{"284":1}}],["首先准备数据",{"2":{"282":1}}],["首先介绍均匀量化",{"2":{"279":1}}],["首先对于",{"2":{"277":1}}],["首先需要理解gpipe中的native",{"2":{"275":1}}],["首先需要知道何为3d并行",{"2":{"76":1}}],["首先就是infiniband",{"2":{"272":1}}],["首先是均匀量化",{"2":{"270":1}}],["首先是runner",{"2":{"261":1}}],["首先是with",{"2":{"257":1}}],["首先是指令集问题",{"2":{"253":1}}],["首先是基于deepspeedexample来通俗地讲解了ppo算法",{"2":{"112":1}}],["首先来看kittens中实现的最基础的async",{"2":{"244":1}}],["首先定义",{"2":{"210":1}}],["首先定义一个函数f",{"2":{"145":1}}],["首先两者会有自己的抽象ast",{"2":{"205":1}}],["首先造一个数据",{"2":{"186":1}}],["首先parse",{"2":{"141":1}}],["首先",{"2":{"140":1}}],["首先它的输入是一个",{"2":{"131":1}}],["首先从training代码讲解",{"2":{"127":1}}],["首先引入掩蔽softmax操作",{"2":{"122":1}}],["首先引入上述第一个原则不变性",{"2":{"109":1}}],["首先假设现在有三个类别",{"2":{"100":1}}],["首先我们实现评估函数",{"2":{"295":1}}],["首先我们会将输入矩阵quant成int8类型的矩阵",{"2":{"293":1}}],["首先我们设定输入和输出",{"2":{"263":1}}],["首先我们需要选择量化的粒度",{"2":{"279":1}}],["首先我们需要明确两个点",{"2":{"225":1}}],["首先我们需要设置",{"2":{"50":1}}],["首先我们将通道设为1",{"2":{"186":1}}],["首先我们的第一想法就是直接计算词元在语料库中出现的频率",{"2":{"140":1}}],["首先我们读取数据集",{"2":{"126":1}}],["首先我们输入一个二维图像",{"2":{"109":1}}],["首先我们来实现一下scheduler",{"2":{"70":1}}],["看样子deepspeed并不支持3d",{"2":{"302":1}}],["看了一下load",{"2":{"141":1}}],["看一下具体的code是怎么写的",{"2":{"76":1}}],["看起来会看好很多",{"2":{"59":1}}],["看起来就像",{"2":{"7":1,"13":1,"15":1,"17":1}}],["二者合计占用",{"2":{"297":1}}],["二者占用显存一共",{"2":{"297":1}}],["二维卷积层",{"2":{"186":1}}],["二维互相关运算",{"2":{"186":1}}],["二",{"0":{"76":1,"85":1,"94":1,"121":1,"127":1,"160":1,"166":1,"168":1,"175":1,"189":1,"193":1,"194":1,"200":1,"205":1,"218":1,"259":1,"294":1,"304":1},"1":{"99":1,"114":1,"129":1,"141":1,"183":1,"186":1,"199":1,"201":1,"214":1,"215":1,"217":1,"230":1,"232":1,"233":1,"234":1,"246":1,"248":1,"250":1,"251":1,"258":1,"262":1,"263":1,"269":1,"270":1,"274":1,"282":1,"289":1,"296":1,"299":1,"300":1,"302":1,"305":1}}],["解码",{"2":{"304":1}}],["解码阶段",{"2":{"304":1}}],["解码过程中逐词生成",{"2":{"214":1}}],["解码器架构的基类",{"2":{"308":1}}],["解码器架构的基本解码器接口",{"2":{"308":1}}],["解码器架构的基本编码器接口",{"2":{"308":1}}],["解码器中的每个位置只能考虑该位置之前的所有位置",{"2":{"87":1}}],["解码器注意力中",{"2":{"87":1}}],["解码器注意力",{"2":{"87":1}}],["解码器还在这两个子层之间插入了第三个子层",{"2":{"87":1}}],["解决这个问题的方式就是填充",{"2":{"201":1}}],["解决方案就是堆叠多个卷积核",{"2":{"125":1}}],["解决方案",{"2":{"37":2}}],["解析args",{"2":{"141":1}}],["解方程",{"2":{"73":1}}],["^l",{"2":{"304":1}}],["^=",{"2":{"292":1}}],["^d",{"2":{"258":1}}],["^脚注1",{"2":{"212":2}}],["^kk∈rk",{"2":{"136":1}}],["^qq∈rq",{"2":{"136":1}}],["^a",{"2":{"126":1}}],["^v",{"2":{"122":1}}],["^m",{"2":{"122":2}}],["^t",{"2":{"110":1,"304":1}}],["^nx=",{"2":{"115":1}}],["^n",{"2":{"93":7,"159":1,"274":2}}],["^",{"2":{"73":1,"87":2,"106":4,"109":2,"110":1,"114":1,"115":1,"125":4,"131":10,"136":3,"140":1,"146":1,"148":2,"150":6,"159":3,"160":2,"183":1,"230":9,"258":1,"269":2,"304":12}}],["^2",{"2":{"37":1,"73":1,"93":3,"106":3,"131":3}}],["θ∥g∥",{"2":{"296":1}}],["θi",{"2":{"129":2}}],["θ1​初值",{"2":{"99":1}}],["θ1​求偏导",{"2":{"73":1}}],["θ1​",{"2":{"73":2,"99":3,"129":1}}],["θ1",{"2":{"73":3,"99":4,"129":1}}],["θ0​",{"2":{"73":2,"99":2,"129":1}}],["θ0",{"2":{"73":2,"99":2,"129":1}}],["使其具有与x相同的num",{"2":{"310":1}}],["使其等于0",{"2":{"73":1}}],["使得其天然支持并行",{"2":{"248":1}}],["使得其近似正确",{"2":{"110":1}}],["使得输入和输出shape相同",{"2":{"201":1}}],["使得它不会立刻被析构",{"2":{"172":1}}],["使得我们可以按照自己的需求分配各个元素的贡献",{"2":{"159":1}}],["使得卷积层的参数大幅下降",{"2":{"109":1}}],["使得j",{"2":{"99":1}}],["使得损失函数最小",{"2":{"73":1}}],["使用示例",{"2":{"305":1}}],["使用方法如下",{"2":{"305":1}}],["使用枚举的值而不是枚举对象",{"2":{"305":1}}],["使用并更新kv",{"2":{"304":1}}],["使用mpi来通信一些基本信息和环境变量",{"2":{"299":1}}],["使用了deepspeed",{"2":{"299":1}}],["使用了加性注意力打分函数",{"2":{"183":1}}],["使用gpu计算模型在数据集上的精度",{"2":{"295":1}}],["使用kittens就有了一个范式",{"2":{"292":1}}],["使用kl散度约束actor模型",{"2":{"112":1}}],["使用激活重计算的一次训练迭代中",{"2":{"291":1}}],["使用激活重计算技术来减少中间激活显存",{"2":{"291":1}}],["使用一个thread去wait之前的cp",{"2":{"285":1}}],["使用一种和链接很相似的语法来标记图片",{"2":{"149":1}}],["使用最大汇聚层以及大于1的步幅",{"2":{"288":1}}],["使用最大汇聚层",{"2":{"281":1}}],["使用st",{"2":{"268":1}}],["使用cp",{"2":{"268":1}}],["使用tma",{"2":{"244":1}}],["使用deleted",{"2":{"223":1}}],["使用顺序分区生成一个小批量子序列",{"2":{"202":1}}],["使用随机抽样生成一个小批量子序列",{"2":{"187":1}}],["使用其他创建",{"2":{"170":1}}],["使用点积可以得到计算效率更高的评分函数",{"2":{"150":1}}],["使用广播方式进行求和",{"2":{"136":1}}],["使用梯度下降来尽可能靠近true",{"2":{"129":1}}],["使用梯度更新该参数",{"2":{"105":1}}],["使用星号",{"2":{"120":1}}],["使用参考式的文章本身只有",{"2":{"104":1}}],["使用某个可以更好地解决这个token问题的expert来处理该token",{"2":{"97":1}}],["使用交叉熵来反映",{"2":{"38":1}}],["使用",{"2":{"32":3,"52":1,"89":1,"104":1,"134":1,"148":2}}],["使用自定义锚点",{"2":{"18":2}}],["什么是模型量化",{"0":{"247":1}}],["什么是softmax",{"0":{"86":1},"1":{"100":1,"115":1,"131":1,"146":1}}],["什么是线性回归",{"0":{"73":1}}],["什么是数据并行",{"2":{"65":1}}],["循环神经网络模型",{"2":{"306":1}}],["循环神经网络rnn",{"0":{"72":1},"1":{"83":1,"96":1,"110":1,"126":1,"140":1,"154":1,"169":1,"187":1,"202":1,"218":1,"234":1,"251":1,"263":1,"274":1,"282":1,"289":1,"296":1,"300":1,"303":1,"306":1,"308":1,"310":1,"312":1}}],["循环向量化",{"2":{"221":1}}],["循环优化",{"2":{"221":1}}],["循环式地处理每块数据",{"2":{"70":1}}],["帮助我们调度需要计算的block",{"2":{"70":1}}],["just",{"2":{"305":1}}],["join",{"2":{"289":1,"305":3}}],["java中",{"2":{"152":1}}],["jacobianjacobianjacobian",{"2":{"131":1}}],["jpg",{"2":{"149":2}}],["jpi​",{"2":{"115":1}}],["j=t​",{"2":{"146":1}}],["j≠t",{"2":{"146":1}}],["j∑​​∂xj​∂pi​​​=21​i∑​",{"2":{"131":1}}],["j∣∂pi∂xj∣=12∑i",{"2":{"131":1}}],["j−pipj=",{"2":{"131":1}}],["j+2",{"2":{"281":2}}],["j+1",{"2":{"281":4}}],["j+b​",{"2":{"109":2}}],["j+b",{"2":{"109":4,"125":6}}],["j+∑a∑b",{"2":{"109":1}}],["j+∑k∑l",{"2":{"109":1}}],["ji=j",{"2":{"131":1}}],["ji=j",{"2":{"131":1}}],["ji",{"2":{"109":2}}],["jit",{"2":{"70":1}}],["j​",{"2":{"146":1}}],["j​−pi​pj​=",{"2":{"131":1}}],["j​+a∑​b∑​",{"2":{"109":1}}],["j​+k∑​l∑​",{"2":{"109":1}}],["j​=u+a=−δ∑δ​b=−δ∑δ​c∑​",{"2":{"125":1}}],["j​=u+a=−δ∑δ​b=−δ∑δ​",{"2":{"109":1}}],["j​=u+a∑​b∑​",{"2":{"109":1}}],["j​=",{"2":{"109":2,"146":1}}],["j=tpj​",{"2":{"146":1}}],["j=tpj",{"2":{"146":1}}],["j=u+∑a=−δδ∑b=−δδ∑c",{"2":{"125":1}}],["j=u+∑a=−δδ∑b=−δδ",{"2":{"109":1}}],["j=u+∑a∑b",{"2":{"109":1}}],["j=",{"2":{"109":2,"146":1}}],["j=1∑n​gradientj​∗∂xi​∂yj​​=j=1∑n​∂xi​∂yj​​=4xi​",{"2":{"159":1}}],["j=1∑n​∂xi​∂yj​​",{"2":{"159":1}}],["j=1",{"2":{"93":2,"106":1,"115":1,"122":1,"159":4}}],["jscvt",{"2":{"253":1}}],["js",{"2":{"89":2,"103":6}}],["jsonencoder",{"2":{"305":1}}],["json之中如果有额外的字段会报错",{"2":{"305":1}}],["json的路径就可以了",{"2":{"50":1}}],["json下面的clangd参数指定compile",{"2":{"50":1}}],["json下配置",{"2":{"50":1}}],["json",{"2":{"50":1,"305":6}}],["j",{"2":{"73":4,"93":2,"99":4,"106":1,"109":19,"114":3,"115":2,"119":2,"122":1,"125":10,"129":3,"131":16,"146":9,"156":2,"159":5,"171":2,"186":4,"187":4,"201":6,"281":16}}],["8bsh8bsh8bsh",{"2":{"297":2}}],["8bsh28bsh^28bsh2",{"2":{"277":2}}],["84",{"2":{"295":2}}],["8卡都需要参与",{"2":{"287":1}}],["8h2+7h",{"2":{"224":1}}],["8h2+7h8h^2",{"2":{"224":1}}],["8212",{"2":{"135":2}}],["832",{"2":{"123":2}}],["81",{"2":{"104":1}}],["8",{"2":{"70":2,"89":2,"93":1,"145":1,"159":3,"186":2,"188":1,"193":1,"201":2,"220":2,"233":2,"257":1,"275":1,"291":1}}],["又随着硬件而变化",{"2":{"70":1}}],["对其",{"2":{"310":1}}],["对默认值进行验证",{"2":{"305":1}}],["对各个torch版本都适用",{"2":{"299":1}}],["对全局的框架进行初始化",{"2":{"294":1}}],["对值做一个上下界的截断",{"2":{"286":1}}],["对称量化",{"2":{"270":1}}],["对每个通道输入的二维张量和每个通道的卷积核的二维张量",{"2":{"233":1}}],["对程序的性能有极大的影响",{"2":{"209":1}}],["对第二维求和",{"2":{"188":1}}],["对第一维求和",{"2":{"188":1}}],["对比中间激活与模型参数大小",{"0":{"301":1}}],["对比",{"0":{"269":1}}],["对比多线程",{"0":{"232":1}}],["对比串行",{"0":{"167":1}}],["对比其他语言的协程",{"0":{"248":1}}],["对比其他语言",{"0":{"152":1}}],["对比全量来说",{"2":{"129":1}}],["对",{"2":{"145":1}}],["对的个数",{"2":{"136":4,"150":2,"246":6}}],["对应",{"2":{"233":1}}],["对应都有一个权重矩阵",{"2":{"224":1}}],["对应每个的查询结果",{"2":{"106":1}}],["对应到标题",{"2":{"46":1}}],["对个数",{"2":{"106":2}}],["对话中的音频信号以及网站上的浏览行为都是有顺序的",{"2":{"96":1}}],["对用户达成目标至关重要的信息",{"2":{"89":2}}],["对于训练的损失函数",{"2":{"312":1}}],["对于训练来说",{"2":{"126":1}}],["对于encoder传入的state",{"2":{"310":1}}],["对于decoder来说",{"2":{"310":1}}],["对于data来说",{"2":{"225":1}}],["对于这种比较考验架构设计能力的地方",{"2":{"305":1}}],["对于这个函数来说",{"2":{"145":1}}],["对于y进行reshape操作",{"2":{"300":1}}],["对于封装的torchbackend主要是更加的普适",{"2":{"299":1}}],["对于softmax",{"2":{"297":1}}],["对于ssh模式",{"2":{"280":1}}],["对于layer",{"2":{"297":2}}],["对于l2",{"2":{"70":1}}],["对于最后的数据再次执行requantization",{"2":{"293":1}}],["对于量化的过程",{"2":{"293":1}}],["对于给定输入元素",{"2":{"288":1}}],["对于runner进程",{"2":{"287":1}}],["对于非对称量化",{"2":{"286":1}}],["对于uint8",{"2":{"286":1}}],["对于对称量化",{"2":{"286":1}}],["对于tma的async操作",{"2":{"278":1}}],["对于transformer类模型",{"2":{"304":1}}],["对于transformer",{"2":{"210":1}}],["对于interleaved",{"2":{"275":1}}],["对于io阻塞",{"2":{"215":1}}],["对于no",{"2":{"280":1}}],["对于native",{"2":{"275":1}}],["对于nullptr",{"2":{"175":1}}],["对于gil机制",{"2":{"271":1}}],["对于global",{"2":{"268":1}}],["对于go的goroutine来说",{"2":{"248":1}}],["对于mix",{"2":{"265":1}}],["对于megatronv1来说",{"2":{"237":1}}],["对于多node",{"2":{"287":1}}],["对于多核处理器",{"2":{"260":1}}],["对于多线程和协程",{"2":{"232":1}}],["对于时间步",{"2":{"251":1}}],["对于协程可以做到语言层面的调度",{"2":{"248":1}}],["对于协程来说",{"2":{"232":1}}],["对于再往前的单词如果我们还想统计它们的影响的话",{"2":{"234":1}}],["对于async",{"2":{"227":1,"244":1}}],["对于到达的thread",{"2":{"227":1}}],["对于cpu来说",{"2":{"221":1}}],["对于目标序列",{"2":{"214":1}}],["对于第二种",{"2":{"207":1}}],["对于第三维通道",{"2":{"125":1}}],["对于任何二维张量",{"2":{"201":1}}],["对于输入的y",{"2":{"300":1}}],["对于输入序列",{"2":{"183":1}}],["对于输出来说",{"2":{"125":1}}],["对于传值类型推导",{"2":{"179":1}}],["对于通用引用的推导",{"2":{"179":1}}],["对于模板类型推导",{"2":{"179":1}}],["对于模型的训练",{"2":{"146":1}}],["对于每种硬件架构",{"2":{"190":1}}],["对于每行数据都是采用onehot编码的结果",{"2":{"160":1}}],["对于每个token",{"2":{"284":2,"291":2}}],["对于每个进程",{"2":{"271":1}}],["对于每个可训练模型参数",{"2":{"256":1}}],["对于每个self",{"2":{"224":1}}],["对于每个窗口内实行",{"2":{"186":1}}],["对于每个数据",{"2":{"160":1}}],["对于每个阶段",{"2":{"127":1}}],["对于每个块",{"2":{"70":1}}],["对于解析问题",{"2":{"158":1}}],["对于此类线程",{"2":{"152":1}}],["对于某一层的任意元素",{"2":{"139":1}}],["对于某个函数",{"2":{"99":1}}],["对于bwd来说",{"2":{"133":1}}],["对于继承了torch",{"2":{"133":1}}],["对于",{"2":{"131":3,"145":2,"230":1,"297":2}}],["对于一个stage",{"2":{"275":1}}],["对于一个exp函数来说",{"2":{"133":1}}],["对于一个任务",{"2":{"124":1}}],["对于一些计算操作",{"2":{"124":1}}],["对于f",{"2":{"114":1}}],["对于hth",{"2":{"110":1}}],["对于其的改进其实就是将可学习的参数集成到注意力汇聚中",{"2":{"106":1}}],["对于图像数据",{"2":{"96":1}}],["对于表格数据我们可以使用全连接层来拟合",{"2":{"96":1}}],["对于query和key",{"2":{"93":1}}],["对于序列中任何位置的任何输入",{"2":{"87":1}}],["随着",{"2":{"301":2}}],["随着层叠的上升",{"2":{"295":1}}],["随着神经网络层数的加深",{"2":{"250":1}}],["随着我工作的时间变久",{"2":{"2":1}}],["随机的",{"2":{"187":1}}],["随机范围包括num",{"2":{"187":1}}],["随机采样",{"0":{"187":1}}],["随机梯度下降",{"2":{"129":1}}],["随后会再使用cuda写一遍",{"2":{"70":1}}],["现在我们将使用卷积层的输出作为",{"2":{"281":1}}],["现在如果我们规定virtual",{"2":{"275":1}}],["现在平台架构大概就是x86",{"2":{"253":1}}],["现在业界的大模型都是基于transformer架构",{"2":{"210":1}}],["现在假设有一个需求",{"2":{"207":1}}],["现在g++",{"2":{"205":1}}],["现在有一个常见的假设",{"2":{"110":1}}],["现在主要有两种方式",{"2":{"50":1}}],["现代rnn",{"0":{"303":1},"1":{"306":1,"308":1,"310":1,"312":1}}],["现代cpp的一些特性",{"0":{"144":1},"1":{"158":1,"175":1,"192":1,"207":1,"223":1,"239":1,"255":1,"266":1,"276":1}}],["现代的moe会设置shared",{"2":{"97":1}}],["现代卷积神经网络",{"0":{"69":1},"1":{"80":1,"94":1,"107":1,"123":1,"137":1,"151":1}}],["再获得一个隐变量state",{"2":{"310":1}}],["再到第二个卷积层之后的16个",{"2":{"295":1}}],["再次kittens",{"2":{"292":1}}],["再次地",{"2":{"59":1}}],["再下一轮的时候wait",{"2":{"275":1}}],["再以对应该输出通道的卷积核计算出结果",{"2":{"250":1}}],["再算上output和embedding",{"2":{"241":1}}],["再经过softmax运算得到的",{"2":{"122":1}}],["再加上缩进就可以了",{"2":{"67":1}}],["插入范例用的",{"2":{"67":1}}],["插件主要使用clangd",{"2":{"50":1}}],["从",{"2":{"312":1}}],["从图中可以看出",{"2":{"290":1}}],["从smem1中加载16bit的数据存入reg0",{"2":{"211":1}}],["从随机偏移量开始划分序列",{"2":{"202":1}}],["从随机偏移量开始对序列进行分区",{"2":{"187":1}}],["从而在单线程中处理大量的io任务",{"2":{"215":1}}],["从而可以应用链式法则来计算对每个输入的影响",{"2":{"177":1}}],["从而变为右值引用或者左值引用",{"2":{"172":1}}],["从而其softmax输出为0",{"2":{"122":1}}],["从零开始实现的循环神经网络模型",{"2":{"282":1}}],["从零实现softmax回归",{"0":{"160":1}}],["从零手搓一个pp调度库",{"2":{"65":1}}],["从上述例子可以看出",{"2":{"106":1}}],["从文件中导入代码块",{"2":{"103":1}}],["从宏观角度来看",{"2":{"87":1}}],["从全连接层过渡到卷积层",{"0":{"71":1},"1":{"82":1,"95":1,"109":1,"125":1,"139":1,"153":1}}],["从全连接层过渡到卷积",{"2":{"62":1}}],["技术杂谈",{"0":{"65":1}}],["具体如下",{"2":{"296":1}}],["具体使用isa的时候需要根据平台来进行取舍",{"2":{"253":1}}],["具体需要根据平台来决定",{"2":{"253":1}}],["具体的训练进程是运行在每个node的slots上的",{"2":{"287":1}}],["具体的内容将在后面讲解",{"2":{"209":1}}],["具体的底层原理可能在后面的章节会有讲解",{"2":{"179":1}}],["具体类型",{"2":{"190":1}}],["具体解法",{"0":{"129":1}}],["具体步骤如下",{"2":{"99":1}}],["具体来讲",{"2":{"271":1}}],["具体来讲是平移不变性",{"2":{"95":1}}],["具体来说",{"2":{"87":1,"100":1,"145":1,"258":1,"310":1}}],["具体原理的话",{"2":{"87":1}}],["具体讲解可以看ptx文档的第八节",{"2":{"64":1}}],["具有一系列衍生版本",{"2":{"7":1,"13":1,"15":1,"17":1}}],["发现预测出来了奇怪的东西",{"2":{"289":1}}],["发送完之后",{"2":{"225":1}}],["发布",{"2":{"64":1}}],["发生溢出",{"2":{"37":1}}],["必须按照某个全局顺序执行",{"2":{"64":1}}],["必须在前后加上空行",{"2":{"19":1,"27":1,"29":1,"31":1}}],["来选择自己的定制backend",{"2":{"299":1}}],["来选择最佳的动作",{"2":{"112":1}}],["来补偿卷积核导致的特征减少",{"2":{"295":1}}],["来完成overlap",{"2":{"290":1}}],["来做reduce",{"2":{"244":1}}],["来预取",{"2":{"244":1}}],["来预测每个类的概率",{"2":{"146":1}}],["来预测下一个时间点的值",{"2":{"110":1}}],["来等待异步操作完成",{"2":{"244":1}}],["来扩大语法模型",{"2":{"234":1}}],["来变换查询",{"2":{"230":1}}],["来达到每个warpgroup出一个warp来load的目的",{"2":{"227":1}}],["来实现的",{"2":{"225":1}}],["来",{"2":{"209":1}}],["来自两个相邻的",{"2":{"187":1}}],["来自于所有先前层",{"2":{"139":1}}],["来调整网络参数",{"2":{"177":1}}],["来计算",{"2":{"159":1}}],["来计算梯度",{"2":{"145":1}}],["来初始化",{"2":{"158":1}}],["来使用梯度下降方法训练模型",{"2":{"146":1}}],["来洞察",{"2":{"145":1}}],["来求解jjj的最小值",{"2":{"129":1}}],["来进行计算",{"2":{"124":1}}],["来标记",{"2":{"104":1}}],["来获得它的最小值",{"2":{"99":1}}],["来让triton帮我们选择吞吐最高的超参数",{"2":{"70":1}}],["来禁止某些矛盾的结果",{"2":{"64":1}}],["来说",{"2":{"49":1,"225":1}}],["001",{"2":{"305":2}}],["0001",{"2":{"193":1}}],["0zw​=0",{"2":{"298":1}}],["0>",{"2":{"285":2,"292":1}}],["0代表等待所有",{"2":{"285":1}}],["0h0​",{"2":{"282":1}}],["0​​",{"2":{"145":1}}],["0四个浮点数",{"2":{"145":1}}],["0⋅∑k=1nexk−exi+xj",{"2":{"131":1}}],["03",{"2":{"129":2,"145":2}}],["0b0​",{"2":{"129":1}}],["0w0​",{"2":{"129":1}}],["090b5e7e70c295757f55df93cb0a180b9691891a",{"2":{"126":1}}],["0∇⋅b=0",{"2":{"119":1}}],["0a=0",{"2":{"119":1}}],["0$",{"2":{"119":2}}],["0^",{"2":{"114":1,"145":1}}],["0x0​=0",{"2":{"145":1}}],["0x0​点的梯度",{"2":{"145":1}}],["0x0​点的值",{"2":{"145":1}}],["0x0​的requires",{"2":{"145":1}}],["0x0​作为初始值",{"2":{"145":1}}],["0x0​",{"2":{"114":1,"129":1,"145":3}}],["02",{"2":{"110":1,"145":2}}],["01",{"2":{"93":1,"110":2,"129":3,"145":2,"160":2,"282":1,"305":2}}],["05",{"2":{"93":1,"94":1}}],["0的结果",{"2":{"64":2}}],["0",{"2":{"64":2,"73":4,"93":5,"94":4,"99":4,"100":18,"101":1,"104":1,"106":2,"107":1,"110":5,"114":4,"115":3,"119":4,"123":4,"126":4,"129":12,"131":1,"132":5,"133":11,"136":1,"137":4,"141":2,"145":18,"158":3,"159":10,"160":18,"170":1,"178":2,"183":4,"186":6,"187":3,"188":3,"193":3,"202":2,"205":1,"209":4,"211":10,"220":3,"227":6,"233":28,"246":4,"250":2,"253":1,"257":13,"262":3,"268":11,"269":2,"270":3,"281":3,"282":2,"285":8,"286":1,"287":2,"289":1,"291":6,"292":7,"294":1,"295":6,"300":3,"305":3,"310":4,"312":5}}],["yn​",{"2":{"258":1}}],["yny",{"2":{"258":1}}],["ys",{"2":{"202":4}}],["y4​",{"2":{"159":1}}],["y4",{"2":{"159":1}}],["y3​",{"2":{"159":1}}],["y3",{"2":{"159":1}}],["y2​",{"2":{"159":1,"237":1,"258":1}}],["y2",{"2":{"159":1,"237":1,"258":1,"262":2}}],["y1​",{"2":{"159":1,"237":1}}],["y1",{"2":{"159":1,"237":1,"258":1,"262":2}}],["yty",{"2":{"146":1}}],["ylabel=",{"2":{"106":1,"300":1,"312":1}}],["yahoo",{"2":{"104":12}}],["y=gelu",{"2":{"237":5}}],["y=",{"2":{"100":2,"159":2}}],["yield",{"2":{"129":1,"187":1,"202":1}}],["yi=f",{"2":{"258":1}}],["yi=2xi2y",{"2":{"159":1}}],["yi=",{"2":{"93":1}}],["yiy",{"2":{"93":3}}],["yi",{"2":{"93":2,"106":2}}],["yi​=f",{"2":{"258":1}}],["yi​",{"2":{"93":4,"106":2}}],["yif",{"2":{"93":3,"106":1}}],["y^i",{"2":{"73":1}}],["y",{"2":{"64":4,"93":8,"100":1,"106":8,"110":2,"129":14,"133":15,"137":4,"145":3,"146":1,"158":4,"159":13,"160":25,"186":11,"187":2,"188":1,"201":6,"202":2,"209":1,"220":2,"237":3,"257":2,"258":3,"262":2,"268":2,"281":7,"282":4,"289":4,"295":13,"296":3,"300":10,"306":3,"312":9}}],["yyy",{"2":{"64":1,"159":7,"237":1,"281":1}}],["you",{"2":{"59":1,"272":1}}],["your",{"2":{"50":9}}],["假设中间激活值是以float16或bfloat16数据格式来保存的",{"2":{"297":1}}],["假设词表的大小为",{"2":{"282":1}}],["假设数量为mmm",{"2":{"275":1}}],["假设来了1k请求",{"2":{"271":1}}],["假设输入",{"2":{"269":1}}],["假设输入的通道数是",{"2":{"233":1}}],["假设输入序列中有",{"2":{"183":1}}],["假设模型的任务是翻译为英语",{"2":{"183":1}}],["假设我们有一个一维张量",{"2":{"159":1}}],["假设我们有一个查询",{"2":{"122":1}}],["假设查询和键的所有元素都是独立的随机变量",{"2":{"150":1}}],["假设当前有两个共享变量",{"2":{"64":1}}],["假如cpu",{"2":{"298":1}}],["假如说最后计算完的矩阵的某个元素类型是int32",{"2":{"293":1}}],["假如说我们当前有一个hello",{"2":{"205":1}}],["假如说一个序列满足一阶马尔科夫模型",{"2":{"110":1}}],["假如现在基于",{"2":{"150":1}}],["假如f",{"2":{"114":1}}],["假如你有使用过电子邮件",{"2":{"7":1,"13":1,"15":1,"17":1}}],["假定序列的动力学不变",{"2":{"110":1}}],["空白和标点符号",{"2":{"104":1}}],["空白",{"2":{"59":1}}],["空行的定义是显示上看起来像是空行",{"2":{"41":1}}],["句点",{"2":{"59":1}}],["项目列表很可能会不小心产生",{"2":{"59":1}}],["项目标记后面则一定要接着至少一个空白或",{"2":{"59":1}}],["udp使用socket的通信",{"2":{"272":1}}],["u32",{"2":{"268":2}}],["updater",{"2":{"300":8}}],["upper",{"2":{"292":1}}],["up",{"2":{"257":1,"268":1,"289":1}}],["ubuntu",{"2":{"253":1}}],["uint8的指令",{"2":{"298":1}}],["uint8的每个单位长度的规格",{"2":{"286":1}}],["uint8的话就是127",{"2":{"270":1}}],["uint64",{"2":{"227":1,"257":2,"268":2}}],["uint16",{"2":{"211":4}}],["uint32",{"2":{"211":14,"257":6,"268":13,"285":3}}],["uinfo",{"2":{"207":1}}],["uiname>",{"2":{"207":1}}],["uiname",{"2":{"207":2}}],["uireputation",{"2":{"207":2}}],["uiemail",{"2":{"207":4}}],["uref4",{"2":{"194":1}}],["uref3",{"2":{"194":1}}],["uref2",{"2":{"194":1}}],["uref1",{"2":{"194":1}}],["url",{"2":{"126":1,"149":1}}],["us",{"2":{"290":1}}],["uscat",{"2":{"253":1}}],["using有一个吸引人的特性",{"2":{"192":1}}],["using",{"0":{"192":1,"254":1},"1":{"265":1,"275":1,"283":1},"2":{"141":1,"192":1,"207":1,"257":1,"268":1,"290":1,"305":1}}],["user",{"2":{"207":4,"299":1}}],["userinfofields",{"2":{"207":1}}],["userinfofields2",{"2":{"207":1}}],["userinfofields1",{"2":{"207":2}}],["userinfo",{"2":{"207":2}}],["userconfig",{"2":{"89":6}}],["use",{"2":{"135":3,"202":2,"257":1,"292":3,"300":4,"305":2}}],["useful",{"2":{"101":1,"147":1}}],["used",{"2":{"101":1,"132":1}}],["util",{"2":{"196":2,"244":1}}],["util之中",{"2":{"141":1}}],["utils",{"2":{"127":5,"129":1,"221":2,"225":1,"299":1}}],["utm",{"2":{"47":2}}],["unweighted",{"2":{"312":2}}],["until",{"2":{"305":1}}],["unroll",{"2":{"257":1,"268":1}}],["unpacked",{"2":{"211":1}}],["underlying",{"2":{"207":6}}],["underscores",{"2":{"120":4}}],["unit",{"2":{"257":9,"268":8}}],["uni",{"2":{"227":2}}],["unified",{"2":{"211":1}}],["uniform",{"2":{"110":1,"295":1,"312":2}}],["universal",{"2":{"179":5}}],["unknown",{"2":{"190":1}}],["unk",{"2":{"126":2}}],["unk>",{"2":{"126":1}}],["un",{"2":{"120":1}}],["unsqueeze",{"2":{"97":2,"106":5,"132":2,"136":2,"178":4,"183":2}}],["uv",{"2":{"109":2}}],["uuu",{"2":{"109":1}}],["u^2",{"2":{"93":1}}],["u",{"2":{"93":3,"109":9,"125":2}}],["ul>",{"2":{"59":4,"89":4}}],["会自动将",{"2":{"305":1}}],["会自动转成",{"2":{"67":1}}],["会经过如下的运算",{"2":{"298":1}}],["会进入到fwd",{"2":{"290":1}}],["会进行",{"2":{"277":1}}],["会接受一些参数做一些通信和网络的相关配置",{"2":{"287":1}}],["会启动若干的进程",{"2":{"287":1}}],["会发现需要传入一个mbarrier",{"2":{"285":1}}],["会发现我们的输入其实是在不断变大的",{"2":{"110":1}}],["会使用load",{"2":{"305":1}}],["会使用float32的优化器状态",{"2":{"256":1}}],["会使用float16的模型参数进行前向传递和后向传递",{"2":{"256":1}}],["会使用新添加的构造函数",{"2":{"158":1}}],["会带来比较大的负担",{"2":{"232":1}}],["会根据当前的配置选择适合的调度策略",{"2":{"225":1}}],["会配备一个layer",{"2":{"224":1}}],["会引起整个系统重新编译",{"2":{"207":1}}],["会引入一种机制",{"2":{"152":1}}],["会缩减采样次数",{"2":{"201":1}}],["会先做一个编码转换的过程",{"2":{"198":1}}],["会遇到很多复杂的表述",{"2":{"192":1}}],["会遇到参数过大导致训练困难以及过拟合的问题",{"2":{"82":1}}],["会被推导为std",{"2":{"175":1}}],["会被转换为",{"2":{"59":2,"67":2}}],["会更加敏感",{"2":{"145":1}}],["会把下面这段",{"2":{"135":1}}],["会把项目的内容在输出时用",{"2":{"59":1}}],["会创建节点",{"2":{"133":3}}],["会调用training中的各个step",{"2":{"127":1}}],["会转为",{"2":{"198":1}}],["会转成",{"2":{"120":1,"198":1}}],["会转换成",{"2":{"67":1}}],["会针对cpu或者gpu进行优化",{"2":{"117":1}}],["会在每个node上启动一个launcher进程",{"2":{"287":1}}],["会在每个参数的grad字段累积梯度",{"2":{"105":1}}],["会在编译时带来一些编译期性能的开销",{"2":{"221":1}}],["会在environment中采取一系列动作获得奖励",{"2":{"112":1}}],["会涉及到更精细的code",{"2":{"112":1}}],["会维护多出两倍的参数占用内存",{"2":{"105":1}}],["会有更好的效果",{"2":{"223":1}}],["会有天然的优势",{"2":{"158":1}}],["会有",{"2":{"104":1}}],["会忽略单引号包起来的链接",{"2":{"104":1}}],["会产生",{"2":{"104":1,"135":2}}],["会高亮显示近两个",{"2":{"89":1}}],["会渲染为",{"2":{"67":1}}],["会用",{"2":{"67":1}}],["会将其重组",{"2":{"50":1}}],["上文中说到",{"2":{"292":1}}],["上文讲到一次前向传递中",{"2":{"291":1}}],["上文提到",{"2":{"271":1}}],["上图中",{"2":{"275":1}}],["上一个时间步生成的单词作为下一时间步的输入",{"2":{"214":1}}],["上下角标",{"0":{"148":1}}],["上述的init对应bert之中的这一段代码",{"2":{"305":1}}],["上述的各个阶段可以看出都已经产生了若干实质性的差异",{"2":{"221":1}}],["上述计算量为",{"2":{"277":1}}],["上述是一维函数举例",{"2":{"114":1}}],["上述配置在我自己的centos",{"2":{"50":1}}],["上面我们介绍了encoder",{"2":{"310":1}}],["上面介绍了注意力汇聚的建模方式",{"2":{"122":1}}],["上面两种写法都会产生下面的",{"2":{"104":1}}],["上面的列表所产生的",{"2":{"59":1}}],["加密算法等等一系列cpu加速指令集",{"2":{"253":1}}],["加载序列数据的迭代器",{"2":{"202":1}}],["加性注意力",{"0":{"136":1},"2":{"136":1}}],["加速收敛并减少震荡",{"2":{"105":1}}],["加速ai模型的推理速度",{"0":{"43":1}}],["加号",{"2":{"59":1,"213":1}}],["训练损失总和",{"2":{"312":1}}],["训练损失之和",{"2":{"295":1,"300":1}}],["训练序列到序列模型",{"2":{"312":1}}],["训练和预测",{"2":{"300":1}}],["训练模型",{"2":{"300":1}}],["训练模式下",{"2":{"137":1}}],["训练模式",{"2":{"137":1}}],["训练",{"0":{"300":1,"312":1}}],["训练准确率之和",{"2":{"295":1}}],["训练transformer模型的计算时间为",{"2":{"291":1}}],["训练时间=gpu数×gpu峰值flops×gpu利用率8×tokens数×模型参数量​",{"2":{"291":1}}],["训练时间=8×tokens数×模型参数量gpu数×gpu峰值flops×gpu利用率",{"2":{"291":1}}],["训练时间",{"2":{"291":2}}],["训练时间估计",{"0":{"291":1}}],["训练大模型时通常会采用adamw优化器",{"2":{"256":1}}],["训练过程显存占用分析",{"0":{"256":1}}],["训练过程与推理过程具有不同的特点",{"2":{"54":1}}],["训练数据批次大小",{"2":{"210":1}}],["训练完成之后就可以使用chat",{"2":{"127":1}}],["训练网络一个迭代周期",{"2":{"300":1}}],["训练网络",{"2":{"94":1}}],["训练样本数",{"2":{"93":1}}],["训练或者推理",{"2":{"49":1}}],["说出加速resnet50推理速度的一些手段",{"0":{"54":1}}],["说出resnet的模型结构",{"0":{"23":1}}],["通信库",{"2":{"272":1}}],["通信复杂",{"2":{"184":1}}],["通常会尝试减小批次大小来避免显存不足的问题",{"2":{"301":1}}],["通常会选择可以表示这个enum的最小类型",{"2":{"207":1}}],["通常比较大",{"2":{"297":1}}],["通常当我们处理图像时",{"2":{"273":1}}],["通常需要一个标量",{"2":{"203":1}}],["通常这些块我们并不希望它以一般段落文件的方式去排版",{"2":{"67":1}}],["通用寄存器",{"2":{"196":1}}],["通用引用会进行类型推导",{"2":{"172":1}}],["通道的数量从输入时的1个",{"2":{"295":1}}],["通道",{"0":{"125":1},"2":{"125":1,"186":1}}],["通俗易懂的ppo解析",{"2":{"112":1}}],["通篇读下来",{"2":{"53":1}}],["通过init",{"2":{"299":1}}],["通过控制sm数量和高效的all2all",{"2":{"290":1}}],["通过划分micro",{"2":{"275":1}}],["通过减少空间分辨率以获得更大的通道深度",{"2":{"250":1}}],["通过output",{"2":{"224":1}}],["通过同步代码的方式写异步",{"2":{"215":1}}],["通过协程的方式管理并发",{"2":{"215":1}}],["通过以上两种方式",{"2":{"202":1}}],["通过一个rnn逐步处理嵌入",{"2":{"199":1}}],["通过将输出转换为标量",{"2":{"177":1}}],["通过将优化器状态",{"2":{"121":1}}],["通过使用tanh作为激活函数",{"2":{"136":1}}],["通过在最后一个轴上掩蔽元素来执行softmax操作",{"2":{"122":1}}],["通过学习图像本身的空间特征",{"2":{"109":1}}],["通过层与层之间的叠加来实现最终整个图像的识别",{"2":{"95":1}}],["通过矩阵变换",{"2":{"82":1}}],["通过",{"2":{"50":1}}],["通过编写cmakelists",{"2":{"50":1}}],["通过简单的标记语法",{"2":{"5":1}}],[">http",{"2":{"198":1}}],[">i++",{"2":{"171":1}}],[">i",{"2":{"171":2}}],[">msn",{"2":{"104":1}}],[">yahoo",{"2":{"104":1}}],[">google",{"2":{"104":1}}],[">this",{"2":{"104":1}}],[">",{"2":{"52":19,"59":1,"67":1,"89":12,"94":2,"103":3,"104":1,"107":1,"126":1,"133":1,"137":1,"141":1,"160":6,"172":1,"181":1,"186":1,"187":1,"198":3,"201":1,"202":1,"207":2,"209":1,"211":2,"225":1,"233":1,"244":4,"250":1,"257":1,"262":1,"268":1,"275":6,"281":1,"282":1,"292":3,"296":1,"305":3,"312":2}}],["信件中引言",{"2":{"52":1}}],["🎉目录表自定义容器默认标题导入代码块数学方程标记上下角标自定义对齐属性支持任务列表脚注",{"2":{"58":1}}],["🎉",{"0":{"51":1},"2":{"51":1}}],["当前生成的词依赖于之前已经生成的词",{"2":{"304":1}}],["当前pp",{"2":{"275":1}}],["当输入的token序列为",{"2":{"304":1}}],["当输入包含多个通道时",{"2":{"233":1}}],["当生成了一个token之后",{"2":{"304":1}}],["当我们训练神经网络遇到显存不足oom",{"2":{"301":1}}],["当我们生成一个常量对象时",{"2":{"171":1}}],["当请求到来时",{"2":{"271":1}}],["当给定相同的查询",{"2":{"230":1}}],["当你有一个向量或矩阵输出时",{"2":{"177":1}}],["当出现函数重载的时候",{"2":{"171":1}}],["当一个特征图中的任意元素需要检测更广区域的输入特征时",{"2":{"139":1}}],["当查询和键是不同长度的向量时",{"2":{"136":1}}],["当",{"2":{"110":1,"241":1}}],["当然deepspeed也提供了一个自己的定制后端作为参照",{"2":{"299":1}}],["当然其本身的调度也很优秀",{"2":{"290":1}}],["当然这是一个与物理层无关的软件抽象",{"2":{"272":1}}],["当然这里只讨论补全和check",{"2":{"50":1}}],["当然不同平台的指令集不同",{"2":{"253":1}}],["当然不光是返回值",{"2":{"209":1}}],["当然对于ffn层后也会有一层layer",{"2":{"224":1}}],["当然也可以精细化设置",{"2":{"281":1}}],["当然也可以向量化ld",{"2":{"211":1}}],["当然也可以单独设置",{"2":{"201":1}}],["当然我们也可以追求对象和指针同时不可变",{"2":{"156":1}}],["当然要保证input",{"2":{"133":1}}],["当然",{"2":{"59":2,"97":1,"129":1,"281":1}}],["当然你如果有第三方库或者项目内头文件目录的依赖",{"2":{"50":1}}],["当做挖个坑吧",{"2":{"50":1}}],["接近",{"2":{"131":1}}],["接着将输入序列放入decoder中",{"2":{"310":1}}],["接着",{"2":{"104":1}}],["接着在cuda开发之中一般都需要使用torch库",{"2":{"50":1}}],["接下来引入本篇主角",{"2":{"304":1}}],["接下来引入新的概念",{"2":{"125":1}}],["接下来",{"2":{"282":1}}],["接下来就是pipedream里面提出的1f1b调度",{"2":{"275":1}}],["接下来就直接进入deepspeed",{"2":{"112":1}}],["接下来回到bert的预训练脚本中",{"2":{"305":1}}],["接下来回到launcher之中",{"2":{"272":1}}],["接下来回到cuda中的内存一致性模型",{"2":{"64":1}}],["接下来详细的比较一下各个阶段的产物差别",{"2":{"205":1}}],["接下来便是重头戏",{"2":{"145":1}}],["接下来开始正式训练模型",{"2":{"129":1}}],["接下来从代码的层面演示一下如何求解线性回归模型首先我们需要生成一个数据集",{"2":{"129":1}}],["接下来进行源码的走读",{"2":{"127":1}}],["接下来是进行词元分割",{"2":{"126":1}}],["接下来有了目标输出",{"2":{"100":1}}],["接下来会一一讲解",{"2":{"97":1}}],["接下来我们分别分析self",{"2":{"297":1}}],["接下来我们分模块针对transformer的架构实现代码",{"2":{"87":1}}],["接下来我们先提供一个官方的train",{"2":{"294":1}}],["接下来我们初始化rnn状态",{"2":{"282":1}}],["接下来我们设计一个语言模型",{"2":{"263":1}}],["接下来我们实现一下注意力优化的encoder",{"2":{"183":1}}],["接下来我们实践一下",{"2":{"110":1}}],["接下来我们开始对其进行建模",{"2":{"140":1}}],["接下来我们定义出常用的函数",{"2":{"129":1}}],["接下来我们整合所有的功能为一个函数",{"2":{"126":1}}],["接下来我们介绍一下其他的一些注意力评分函数",{"2":{"122":1}}],["接下来我们介绍注意力评分函数",{"2":{"122":1}}],["接下来我们正式介绍一下马尔科夫条件",{"2":{"110":1}}],["接下来我们详细地写一个triton",{"2":{"70":1}}],["接下来让clangd插件能够识别我们的项目",{"2":{"50":1}}],["编号从0开始",{"2":{"235":1}}],["编码器",{"2":{"308":3}}],["编码器隐状态",{"2":{"183":1}}],["编码处理",{"2":{"199":1}}],["编译速度",{"2":{"221":1}}],["编译阶段",{"2":{"221":1}}],["编译时间",{"2":{"221":1}}],["编译",{"2":{"205":1}}],["编译流程",{"0":{"205":1}}],["编译等",{"2":{"190":1}}],["编译链接",{"0":{"173":1},"1":{"190":1,"205":1,"221":1,"236":1,"253":1,"264":1}}],["编译器版本检查",{"2":{"253":1}}],["编译器将会从函数实现中推导出函数的返回类型",{"2":{"209":1}}],["编译器这里就专门讨论cpp的编译器",{"2":{"190":1}}],["编译器",{"2":{"190":1,"253":1}}],["编译器可能会对指令进行重排序",{"2":{"64":1}}],["编译器以及include",{"2":{"50":1}}],["编译是另外一回事",{"2":{"50":1}}],["编写",{"2":{"12":1,"20":1,"22":1,"24":1}}],["虚拟环境使用micromamba",{"2":{"50":1}}],["目的是将gpu组织成一个网格结构",{"2":{"302":1}}],["目的是找到一个策略",{"2":{"112":1}}],["目标均是将一个由",{"2":{"269":1}}],["目标文件生成",{"2":{"221":1}}],["目标嵌入",{"2":{"214":1}}],["目标阶段",{"2":{"205":1}}],["目标类别",{"2":{"146":1}}],["目标是为了确定一个模型函数h",{"2":{"73":1}}],["目录表",{"0":{"58":1}}],["目录开始",{"2":{"32":1}}],["目前对deepspeed的通信有了一定的了解",{"2":{"299":1}}],["目前看来这块代码还挺奇怪的",{"2":{"299":1}}],["目前的todo",{"2":{"57":1}}],["目前感觉这俩就够用了",{"2":{"50":1}}],["≠",{"2":{"49":1}}],["所有元素求和",{"2":{"188":1}}],["所有token首先都会流经shared",{"2":{"97":1}}],["所有线程看到的操作顺序必须一致",{"2":{"64":1}}],["所有支持的",{"2":{"51":1}}],["所以config的管理会比较长",{"2":{"305":1}}],["所以c++98的不限域enum总是要求定义",{"2":{"207":1}}],["所以显存占用为",{"2":{"297":1}}],["所以会尝试mps加速",{"2":{"282":1}}],["所以综上所述",{"2":{"277":1}}],["所以占据两个格子",{"2":{"275":1,"290":1}}],["所以例如ib",{"2":{"272":1}}],["所以如果nvlink不支持会降级为pcie",{"2":{"272":1}}],["所以每一次计算复杂度为",{"2":{"269":1}}],["所以有",{"2":{"269":1}}],["所以卷积层的计算复杂度为",{"2":{"269":1}}],["所以训练过程显存占用为",{"2":{"256":1}}],["所以被命名为循环神经网络",{"2":{"251":1}}],["所以就先从launcher开始看",{"2":{"249":1}}],["所以",{"2":{"241":1,"262":1,"297":1}}],["所以对于isa来说首先需要硬件层面支持",{"2":{"253":1}}],["所以对于派生类的函数重写",{"2":{"239":1}}],["所以对于计算型代码",{"2":{"232":1}}],["所以参数量为",{"2":{"224":1}}],["所以参数数量为",{"2":{"224":1}}],["所以ffn层总共需要保存的参数为",{"2":{"297":1}}],["所以f2返回int",{"2":{"209":1}}],["所以f1返回int",{"2":{"209":1}}],["所以掌握at",{"2":{"190":1}}],["所以无论这些层执行严格的卷积运算还是互相关运算",{"2":{"186":1}}],["所以更加复杂",{"2":{"184":1}}],["所以为了简单",{"2":{"160":1}}],["所以一般采用的是",{"2":{"298":1}}],["所以一般都是直接指定完整的目录",{"2":{"50":1}}],["所以一个更好的语言模型应该可以让我们更准确的预测下一个词元",{"2":{"274":1}}],["所以一把防止数据竞争的锁仍然是有必要的",{"2":{"152":1}}],["所以在长序列的计算中会很慢",{"2":{"269":1}}],["所以在init的时候会设置thread",{"2":{"227":1}}],["所以在python中",{"2":{"152":1}}],["所以在cpp中",{"2":{"64":1}}],["所以上式又可以表达为",{"2":{"146":1}}],["所以上述的注意力汇聚其实是非参数注意力汇聚模型",{"2":{"93":1}}],["所以要除以batch",{"2":{"129":1}}],["所以图像其实是一个三维张量",{"2":{"125":1}}],["所以我们在进行async",{"2":{"292":1}}],["所以我们可以近似的认为",{"2":{"284":1}}],["所以我们可以通过一个序列中所有的",{"2":{"274":1}}],["所以我们可以从图像的特点入手",{"2":{"82":1}}],["所以我们应当尽可能地在代码中应用constexpr",{"2":{"255":1}}],["所以我们使用cp",{"2":{"244":1}}],["所以我们不妨使用隐变量模型",{"2":{"234":1}}],["所以我们每个phase需要传入一个kphasebit来表示当前的阶段",{"2":{"227":1}}],["所以我们input",{"2":{"225":1}}],["所以我们考虑的是grad的传递问题",{"2":{"225":1}}],["所以我们只需要算一份",{"2":{"224":1}}],["所以我们如果对一个向量反向传播的时候",{"2":{"159":1}}],["所以我们输出x0",{"2":{"145":1}}],["所以我们需要人为的去使用mutex等同步原语来保证const线程安全",{"2":{"266":1}}],["所以我们需要更有效的模型",{"2":{"140":1}}],["所以我们需要加一个负号",{"2":{"114":1}}],["所以我们采取全部遍历求和的形式",{"2":{"125":1}}],["所以全连接层这种模型可能不符合我们的预期",{"2":{"110":1}}],["所以这里我首先使用",{"2":{"305":1}}],["所以这里就涉及到一些高效save的技术",{"2":{"305":1}}],["所以这里进行deallocate",{"2":{"225":1}}],["所以这里可以学习dualpipe的方式",{"2":{"225":1}}],["所以这里可以使用std",{"2":{"209":1}}],["所以这一部两者产生的hello",{"2":{"205":1}}],["所以这被称为",{"2":{"110":1}}],["所以这种简化的标签内也可以包含多个文字",{"2":{"104":1}}],["所以鸡鸭鹅可以表示为",{"2":{"100":1}}],["所以需要运行时才知道",{"2":{"298":1}}],["所以需要用户立即关注的关键内容",{"2":{"89":2}}],["所以需要将",{"2":{"50":1}}],["所以注意力其实是query与key的交互汇聚过程",{"2":{"79":1}}],["所以下面的yaml配置文件你只需改变一下你的env路径",{"2":{"50":1}}],["所以网络上设置",{"2":{"50":1}}],["所以很多路径需要我们手动指定",{"2":{"50":1}}],["所以你如果要在文件中插入一个著作权的符号",{"2":{"26":1,"34":1,"36":1,"39":1}}],["所占用的内存",{"2":{"49":1}}],["即不同的句子有相同的system",{"2":{"309":1}}],["即一次乘法法运算和一次加法运算",{"2":{"284":1}}],["即使在高度或宽度上移动一个元素",{"2":{"281":1}}],["即使你在成员函数或者友元函数里面调用deleted函数也不能通过编译",{"2":{"223":1}}],["即使cpp文件中的定义发生改变",{"2":{"207":1}}],["即使其他的构造函数更匹配",{"2":{"158":1}}],["即可使得输入和输出具有相同的形状",{"2":{"201":1}}],["即假设有一个",{"2":{"146":1}}],["即对角线的情况",{"2":{"131":1}}],["即上文提到的j函数",{"2":{"129":1}}],["即得到属于每个类别的概率",{"2":{"100":1}}],["即add",{"2":{"49":1}}],["即浮点计算次数",{"2":{"49":1}}],["相反",{"2":{"281":1,"295":1}}],["相同",{"2":{"221":2,"297":1}}],["相当于x",{"2":{"312":1}}],["相当于针对tensor的批量异步拷贝",{"2":{"244":1}}],["相当于torch",{"2":{"188":1}}],["相当于套了层娃",{"2":{"50":1}}],["相对于串行",{"2":{"167":1}}],["相对而言",{"2":{"26":1,"34":1,"36":1,"39":1}}],["相加",{"2":{"49":1}}],["其它",{"0":{"182":1},"1":{"198":1,"213":1}}],["其它的格式会把每个断行都转成",{"2":{"41":1}}],["其就可以调用常量函数",{"2":{"171":1}}],["其余不变",{"2":{"146":1}}],["其他",{"0":{"204":1}}],["其他文本样式",{"0":{"165":1}}],["其他全部置为0",{"2":{"146":1}}],["其他算子也有参数",{"2":{"49":1}}],["其感受野是指在前向传播中可能影响到",{"2":{"139":1}}],["其次os内核也需要支持",{"2":{"253":1}}],["其次我们使用第二个特性",{"2":{"109":1}}],["其次就是cuda的库",{"2":{"50":1}}],["其中的accuracy等函数都在前面的章节实现过",{"2":{"295":1}}],["其中的计算部分是调用的torch",{"2":{"117":1}}],["其中任意",{"2":{"258":1}}],["其中批量大小为",{"2":{"251":1}}],["其中可学习的参数为",{"2":{"230":1}}],["其中可学习的参数是",{"2":{"136":1}}],["其中output",{"2":{"225":1}}],["其中std",{"2":{"207":1}}],["其中时间步",{"2":{"183":1}}],["其中每个输入词元或者输出词元都是",{"2":{"269":1}}],["其中每个",{"2":{"159":1}}],["其中包含了从0",{"2":{"145":1}}],["其中包含了一个隐藏层",{"2":{"136":1}}],["其中xxx",{"2":{"145":1}}],["其中x为矩阵形式",{"2":{"129":1}}],["其中查询和键的长度为",{"2":{"150":1}}],["其中查询",{"2":{"122":1}}],["其中",{"2":{"93":1,"100":1,"109":1,"110":1,"114":1,"244":1,"251":2,"274":1,"289":1}}],["其实和上一轮计算的时候没有变化",{"2":{"304":1}}],["其实更加native的写法",{"2":{"292":1}}],["其实也就是使用cp",{"2":{"292":1}}],["其实通篇下来",{"2":{"237":1}}],["其实能释放就都得释放掉",{"2":{"225":1}}],["其实我们的互相关运算和卷积的差别不大",{"2":{"186":1}}],["其实是一种很大的亏损",{"2":{"260":1}}],["其实是一个loop",{"2":{"215":1}}],["其实是一系列工具链",{"2":{"190":1}}],["其实是模型的输出",{"2":{"160":1}}],["其实是为了去忽略一些值",{"2":{"122":1}}],["其实两种方法都等价于计算",{"2":{"159":1}}],["其实实际上表达的就是",{"2":{"146":1}}],["其实就对应于某个函数f",{"2":{"145":1}}],["其实就相当于存在一个x0x",{"2":{"129":1}}],["其实就是将还没训练完的各种状态保存一下",{"2":{"305":1}}],["其实就是将seq",{"2":{"283":1}}],["其实就是替代算子的过程",{"2":{"293":1}}],["其实就是使用的上文中提到的move中的st指令",{"2":{"268":1}}],["其实就是因为限域enum无法进行隐式的类型转换",{"2":{"207":1}}],["其实就是相当于计算2",{"2":{"145":1}}],["其实就是根据grad",{"2":{"133":1}}],["其实就是根据已知的量来计算y",{"2":{"129":1}}],["其实就是简单的前向计算的过程",{"2":{"133":1}}],["其实就是上文提到的j",{"2":{"129":1}}],["其实就是沿着计算图根据链式法则进行求导",{"2":{"117":1}}],["其实就是torchrun",{"2":{"272":1}}],["其实就是torch",{"2":{"117":1}}],["其实就是卷积核kernel",{"2":{"109":1}}],["其实就是我们想要的权重",{"2":{"100":1}}],["其实上述的高斯核就可以被视为注意力评分函数",{"2":{"122":1}}],["其实从式子中",{"2":{"115":1}}],["其实这里批量就是",{"2":{"106":1}}],["其实他们的样本之间都遵循着某种分布",{"2":{"96":1}}],["其实很多选项我这里也没有很清楚",{"2":{"50":1}}],["其实如果使用clion会省下来很多麻烦",{"2":{"50":1}}],["构建ast",{"2":{"221":1}}],["构建模型必备",{"2":{"1":1}}],["构造函数的调用",{"2":{"158":1}}],["构造一个pytorch数据迭代器",{"2":{"129":1}}],["构成",{"2":{"49":1}}],["例",{"2":{"214":1}}],["例子",{"2":{"49":2}}],["例如在deepspeed之中",{"2":{"305":1}}],["例如在顺序一致性模型中",{"2":{"64":1}}],["例如cpu使用gloo",{"2":{"299":1}}],["例如矩阵乘法",{"2":{"293":1}}],["例如之前的conv2d的卷积操作使用的数据类型是fp32",{"2":{"293":1}}],["例如openmpi",{"2":{"272":1}}],["例如都适合处理io密集型任务",{"2":{"232":1}}],["例如1f1b",{"2":{"225":1}}],["例如库函数跨模块内联",{"2":{"221":1}}],["例如local",{"2":{"299":1}}],["例如loss计算转为fp32提高精度",{"2":{"141":1}}],["例如llvm",{"2":{"221":1}}],["例如对于左值表达式",{"2":{"209":1}}],["例如如下的一些x",{"2":{"194":1}}],["例如tensor的释放与回收",{"2":{"225":1}}],["例如t",{"2":{"172":1}}],["例如std",{"2":{"158":1}}],["例如我们可以实现一个自己的exp运算",{"2":{"133":1}}],["例如一个卷积核所覆盖的区域中",{"2":{"125":1}}],["例如文件读取",{"2":{"124":1}}],["例如因为thread1和thread2的视角顺序不同",{"2":{"64":1}}],["例如内存池",{"2":{"23":1}}],["例如",{"2":{"7":1,"13":1,"15":1,"17":1,"19":1,"27":1,"29":1,"31":1,"46":2,"52":2,"67":3,"89":4,"96":1,"104":1,"110":1,"120":1,"135":1,"198":2,"213":1,"214":1,"230":1}}],["最好以单个token维度展现求和",{"2":{"304":1}}],["最好加上override",{"2":{"239":1}}],["最终输出一个维数与结果分类数相匹配的输出",{"2":{"295":1}}],["最终输出的形状",{"2":{"246":1}}],["最大汇聚层会输出该窗口内的最大值",{"2":{"288":1}}],["最大汇聚层与平均汇聚层",{"0":{"281":1}}],["最大汇聚的输入",{"2":{"281":1}}],["最大路径长度也是",{"2":{"269":2}}],["最大路径长度为",{"2":{"269":1}}],["最简单粗暴规避的方式就是直接实现多进程",{"2":{"271":1}}],["最常用的就是gcc和clang",{"2":{"190":1}}],["最常用的数据格式为float32",{"2":{"49":1}}],["最重要的一点",{"2":{"158":1}}],["最重要的一步就是准备数据",{"2":{"126":1}}],["最核心的逻辑",{"2":{"127":1}}],["最后的结果仍然是返回一个engin",{"2":{"302":1}}],["最后的结果会按照加权综合考虑shared",{"2":{"111":1}}],["最后注入环境变量",{"2":{"299":1}}],["最后写入memory",{"2":{"293":1}}],["最后launcher这个包",{"2":{"287":1}}],["最后再对数据进行映射",{"2":{"286":1}}],["最后我们介绍lenet",{"2":{"295":1}}],["最后我们组合在一起",{"2":{"282":1}}],["最后我们得到o",{"2":{"100":1}}],["最后多node会在每个node上启动一个python",{"2":{"280":1}}],["最后all",{"2":{"265":1}}],["最后对梯度all",{"2":{"265":1}}],["最后需要告诉编译器生成支持该指令的代码或者在软件层面自己编写该isa代码",{"2":{"253":1}}],["最后",{"2":{"230":1,"295":1}}],["最后演变为了async",{"2":{"215":1}}],["最后还可以用引号包住并加上选择性的",{"2":{"149":1}}],["最后在最外层的e2e",{"2":{"127":1}}],["最后在training",{"2":{"127":1}}],["最后一个droupout操作",{"2":{"297":1}}],["最后一轴上被掩蔽的元素使用一个非常大的负值替换",{"2":{"122":1}}],["最后一步",{"2":{"100":1}}],["最后输出shape为",{"2":{"106":1}}],["最后汇集在一起",{"2":{"97":1}}],["最小值或者局部最小值",{"2":{"99":1}}],["最小",{"2":{"73":1}}],["最多三个空白",{"2":{"59":1}}],["最高阶标题",{"2":{"46":1}}],["峰值内存占用指运行时的内存",{"2":{"49":1}}],["峰值",{"2":{"49":2}}],["访存量为",{"2":{"49":1}}],["访存量单位为",{"2":{"49":1}}],["访存量",{"2":{"49":3}}],["访存效率",{"2":{"43":1}}],["参与求梯度和迭代的拉伸和偏移参数",{"2":{"137":1}}],["参考式的图片语法则长得像这样",{"2":{"149":1}}],["参考式的链接其实重点不在于它比较好写",{"2":{"104":1}}],["参考",{"2":{"149":1}}],["参考文章",{"2":{"112":1,"311":1}}],["参考形式的链接使用另外一个方括号接在链接文字的括号后面",{"2":{"104":1}}],["参考资料",{"2":{"14":1}}],["参数冻结",{"2":{"112":2}}],["参数更新",{"2":{"112":2}}],["参数主要是由",{"2":{"49":1}}],["参数量大小为",{"2":{"241":1}}],["参数量",{"2":{"49":2}}],["k^",{"2":{"304":3}}],["kq",{"2":{"297":2}}],["k=xwk​",{"2":{"277":1}}],["k=xwk",{"2":{"277":1}}],["k=1",{"2":{"131":10}}],["knd^2",{"2":{"269":1}}],["knd2",{"2":{"269":2}}],["kw​",{"2":{"233":1}}],["kw",{"2":{"233":1}}],["kwargs",{"2":{"106":2,"136":2,"150":2,"183":4,"225":3,"246":2,"305":5,"306":2,"308":6,"310":4}}],["kh​",{"2":{"233":1}}],["kh",{"2":{"233":1}}],["kphasebit",{"2":{"227":1}}],["k$",{"2":{"224":1}}],["kv",{"0":{"195":1,"307":1},"1":{"210":1,"224":1,"241":1,"256":1,"267":1,"277":1,"284":1,"291":1,"297":1,"301":1,"304":1,"307":1,"309":2,"311":2},"2":{"267":2,"304":2}}],["kkk",{"2":{"186":1,"269":1,"277":1,"297":1}}],["k∈rdk​",{"2":{"230":1}}],["k∈rdk",{"2":{"230":1}}],["k∈rm∗d",{"2":{"150":2}}],["k∈rk",{"2":{"136":1}}],["k​",{"2":{"125":2}}],["kj​",{"2":{"122":1}}],["kj",{"2":{"122":1}}],["kittens",{"0":{"180":1},"1":{"196":1,"211":1,"227":1,"244":1,"257":1,"268":1,"278":1,"285":1,"292":1},"2":{"257":3,"268":3,"285":4,"292":4}}],["kik",{"2":{"122":1}}],["ki​",{"2":{"122":4}}],["ki",{"2":{"122":4}}],["km​",{"2":{"122":2}}],["km",{"2":{"122":2}}],["k1​",{"2":{"122":2}}],["k1",{"2":{"122":2}}],["k维度采取的是完整的k",{"2":{"70":1}}],["keeps",{"2":{"305":1}}],["keepdim=true",{"2":{"137":2,"160":2}}],["key的个数",{"2":{"136":1}}],["key的形状",{"2":{"136":1}}],["keys=true",{"2":{"305":1}}],["keys的形状",{"2":{"106":1,"150":1}}],["keys",{"2":{"106":6,"136":6,"150":2,"246":6}}],["key",{"2":{"79":1,"136":3,"183":1,"246":2,"269":1,"304":2}}],["key=lambda",{"2":{"126":1}}],["key=",{"2":{"70":1,"89":2}}],["kernel来演示一下如何利用上述的优化",{"2":{"70":1}}],["kernel",{"2":{"14":1,"53":1,"70":3,"94":2,"107":7,"123":15,"186":4,"201":5,"281":1,"295":5}}],["k",{"2":{"47":1,"70":4,"93":6,"101":20,"109":7,"122":9,"125":4,"131":10,"136":10,"150":6,"186":7,"201":4,"230":12,"233":10,"246":3,"250":13,"262":8,"269":3,"277":2,"297":1,"304":6,"305":5}}],["zp是zero",{"2":{"270":1}}],["zp",{"2":{"270":1,"286":4}}],["zip",{"2":{"160":1,"233":1}}],["z",{"2":{"126":1,"133":3,"158":4,"188":1,"257":2,"268":2,"298":6}}],["za",{"2":{"126":1}}],["zero是一种训练时的分片优化策略",{"2":{"121":1}}],["zeros",{"2":{"110":1,"129":1,"132":1,"133":1,"137":2,"160":2,"170":1,"186":2,"257":2,"269":1,"281":1,"282":3,"306":3,"310":1}}],["zero",{"0":{"121":1,"226":1,"243":1},"1":{"243":1},"2":{"65":1,"106":1,"110":1,"119":2,"121":3,"129":2,"141":1,"186":1,"193":1,"203":1,"238":1,"270":1,"295":1,"300":1,"302":2,"312":1}}],["zebra",{"2":{"45":2}}],["zhihu",{"2":{"47":1}}],["zhuanlan",{"2":{"47":1}}],["阶段",{"2":{"304":1}}],["阶马尔科夫模型又被称为",{"2":{"234":1}}],["阶马尔科夫模型",{"2":{"110":1}}],["阶",{"2":{"46":1}}],["个transformer层的向量表示为",{"2":{"304":1}}],["个transformer层的权重矩阵为",{"2":{"304":1}}],["个transformer层需要保存的中间激活占用显存大小为",{"2":{"297":1}}],["个元素",{"2":{"297":2}}],["个隐藏层的输入",{"2":{"296":1}}],["个隐藏层的输出作为第",{"2":{"296":1}}],["个隐藏层的dnn",{"2":{"296":1}}],["个请求",{"2":{"271":1}}],["个应用框架",{"2":{"271":1}}],["个进程在使用",{"2":{"271":1}}],["个进程",{"2":{"271":1}}],["个顺序操作",{"2":{"269":3}}],["个单词",{"2":{"234":1}}],["个头连结后的结果",{"2":{"230":1}}],["个注意力汇聚输出",{"2":{"230":1}}],["个注意力汇聚的输出拼接在一起",{"2":{"230":1}}],["个相同层堆叠而成",{"2":{"224":1}}],["个词元的交叉熵损失的平均值来衡量",{"2":{"274":1}}],["个词元的",{"2":{"269":1}}],["个词元组成的序列映射到另一个长度相等的序列",{"2":{"269":1}}],["个词元",{"2":{"183":1}}],["个最常用单词的频率",{"2":{"154":1}}],["个查询和",{"2":{"150":1}}],["个键值对计算注意力",{"2":{"150":1}}],["个键值对",{"2":{"122":1}}],["个键值对匹配",{"2":{"106":1}}],["个时间点跨度",{"2":{"110":1}}],["个字元",{"2":{"104":3}}],["个人感觉比较合理的学习顺序是先学一些技术",{"2":{"76":1}}],["个空白或是",{"2":{"67":2}}],["个空白或是一个",{"2":{"59":1}}],["个",{"2":{"46":1,"67":2}}],["6bsh26bsh^26bsh2",{"2":{"277":1}}],["6h",{"2":{"224":1}}],["600",{"2":{"110":1}}],["6f",{"2":{"106":1}}],["6节中残差网络的启发",{"2":{"87":1}}],["64一般都是avx",{"2":{"253":1}}],["64bit",{"2":{"227":1}}],["64位寄存器",{"2":{"196":1}}],["64等等",{"2":{"190":1}}],["64",{"2":{"50":2,"70":1,"94":1,"123":3,"127":1,"193":2,"198":2,"253":1,"264":1}}],["6",{"0":{"153":1},"2":{"46":3,"89":1,"136":1,"160":1,"186":4,"188":2,"193":1,"220":2,"233":2,"235":1,"257":2,"262":1,"268":2,"295":3}}],["到时候可能需要结合pytorch底层原理",{"2":{"302":1}}],["到这里其实可以发现一个很简单的性质",{"2":{"232":1}}],["到目前为止",{"2":{"149":1}}],["到",{"2":{"46":2}}],["1≤l≤l",{"2":{"304":2}}],["1≤i≤n",{"2":{"304":2}}],["1f",{"2":{"295":1,"300":2,"312":1}}],["1f1b调度的精髓是当一个micro",{"2":{"275":1}}],["1f1b有non",{"2":{"275":1}}],["1y",{"2":{"281":1}}],["1n∑t=1n−log⁡p",{"2":{"274":1}}],["1n−1",{"2":{"234":1}}],["1k",{"2":{"271":1}}],["1m+1",{"2":{"271":1}}],["1卷积没有这个作用",{"2":{"262":1}}],["1卷积层通常用于调整网络层的通道数量和控制模型复杂性",{"2":{"262":1}}],["1卷积层的全连接层实现",{"2":{"262":1}}],["1卷积层",{"0":{"262":1},"2":{"262":1}}],["1d",{"2":{"244":2}}],["1d或2d张量",{"2":{"122":1}}],["1a",{"2":{"237":1}}],["1$",{"2":{"224":1}}],["15",{"2":{"221":3}}],["1>",{"2":{"207":1}}],["1pw​=kw​−1",{"2":{"201":1}}],["1ph​=kh​−1",{"2":{"201":1}}],["14",{"2":{"194":1}}],["144",{"2":{"123":1}}],["1t−1",{"2":{"234":1}}],["1t",{"2":{"183":1}}],["1都会被转化为",{"2":{"158":1}}],["127",{"2":{"286":5}}],["127scale",{"2":{"286":2}}],["12lh^2",{"2":{"284":1}}],["12lh2×bs",{"2":{"284":2}}],["12lh212lh^212lh2",{"2":{"241":1,"284":1}}],["12h^2",{"2":{"241":1}}],["12h2+13h",{"2":{"241":2}}],["12h2+13h12h^2",{"2":{"241":1}}],["120",{"2":{"198":2,"295":2}}],["123",{"2":{"194":8}}],["12",{"2":{"145":1,"159":3,"209":1}}],["12∥∂p∂x∥1=12∑i",{"2":{"131":1}}],["128b",{"2":{"257":2}}],["128",{"2":{"70":3,"94":2,"97":1,"123":6,"286":2}}],["1x1",{"2":{"262":2}}],["1x1​",{"2":{"129":1,"145":2}}],["1xh",{"2":{"73":1}}],["19bsh19bsh19bsh",{"2":{"297":1}}],["19th",{"2":{"148":1}}],["19^th^",{"2":{"148":1}}],["192",{"2":{"123":3}}],["1986",{"2":{"59":2}}],["1e3",{"2":{"305":2}}],["1e",{"2":{"262":1}}],["1e6",{"2":{"122":1}}],["1e9",{"2":{"101":1}}],["1ci​",{"2":{"233":1}}],["1ci​=1",{"2":{"233":1}}],["1c",{"2":{"119":2,"233":1}}],["1^",{"2":{"114":1,"145":1}}],["1∼t1",{"2":{"110":1}}],["1β1​",{"2":{"105":1}}],["1−β2​",{"2":{"105":1}}],["1−β2",{"2":{"105":1}}],["1−β1​",{"2":{"105":1}}],["1−β1",{"2":{"105":1}}],["16bit",{"2":{"211":1}}],["160",{"2":{"123":2}}],["16",{"2":{"89":1,"110":1,"123":2,"198":1,"257":2,"281":1,"295":2}}],["13h",{"2":{"241":1}}],["13h12h2+13h",{"2":{"241":1}}],["13",{"2":{"89":1}}],["176",{"2":{"104":1}}],["17",{"2":{"89":1}}],["109",{"2":{"198":4}}],["101",{"2":{"198":2}}],["10为类别数目",{"2":{"160":1}}],["1024",{"2":{"123":1}}],["10",{"2":{"89":2,"94":2,"97":2,"103":2,"104":4,"106":5,"107":1,"110":2,"129":2,"136":2,"158":10,"160":5,"171":2,"179":1,"186":1,"220":1,"221":1,"282":1,"289":1,"295":2,"300":2,"312":2}}],["100gbps",{"2":{"272":1}}],["10000d2j​i​",{"2":{"269":2}}],["10000^",{"2":{"269":2}}],["10000",{"2":{"132":1,"269":1}}],["1000",{"2":{"110":1,"129":1}}],["100",{"2":{"51":1,"181":2,"193":2}}],["1θ0​",{"2":{"73":1,"99":2}}],["11bsh+5bs2a11bsh",{"2":{"297":1}}],["111",{"2":{"198":2}}],["115",{"2":{"198":4}}],["112",{"2":{"123":1}}],["11",{"2":{"50":3,"126":1}}],["1",{"0":{"79":1,"82":1,"96":1,"99":1,"100":1,"101":1,"141":1,"152":1,"155":1,"183":1,"186":1,"215":1,"224":1,"234":1,"253":1,"256":2,"262":1,"265":1,"267":1,"270":1,"271":1,"272":1,"281":1,"284":1,"299":1,"301":1,"306":1,"309":1},"1":{"170":1,"188":1,"199":1,"214":1,"241":1,"251":1,"256":1,"263":1,"267":1,"274":1},"2":{"46":3,"49":1,"52":2,"53":1,"59":6,"64":5,"67":4,"73":3,"89":1,"93":4,"94":4,"97":3,"99":2,"100":10,"101":4,"103":5,"104":4,"105":7,"106":33,"107":3,"110":28,"114":6,"115":4,"121":1,"122":11,"123":2,"126":3,"127":2,"129":11,"131":6,"132":3,"133":10,"136":11,"137":6,"140":4,"145":7,"146":2,"150":2,"154":1,"158":13,"159":11,"160":7,"170":4,"171":2,"172":1,"178":9,"183":11,"186":16,"187":4,"188":2,"190":4,"193":7,"197":2,"201":9,"202":6,"207":1,"211":10,"212":1,"220":6,"227":4,"230":2,"233":5,"234":5,"235":3,"237":6,"246":9,"250":1,"251":2,"253":1,"257":5,"258":4,"262":9,"268":6,"269":14,"274":6,"275":4,"277":1,"281":11,"282":2,"284":1,"285":1,"287":2,"289":5,"292":2,"293":2,"295":9,"296":4,"300":7,"304":7,"305":4,"306":3,"310":7,"312":15}}],["推导会去掉表达式的引用性ref",{"2":{"209":1}}],["推导",{"0":{"109":1}}],["推荐",{"2":{"46":1}}],["推理与kv",{"0":{"304":1}}],["推理过程中的中间结果用完会尽快释放掉",{"2":{"267":1}}],["推理过程显存占用分析",{"0":{"267":1}}],["推理阶段模型参数占用的显存大概是",{"2":{"267":1}}],["推理加速的整体原则",{"2":{"54":1}}],["推理框架",{"2":{"1":1}}],["推理infra中",{"2":{"1":1}}],["=t",{"2":{"304":1}}],["=t=1∏t​p",{"2":{"110":2,"140":1}}],["=fgelu​",{"2":{"304":2}}],["=fgelu",{"2":{"304":2}}],["=1+2+1=4=1+2+1=4=1+2+1=4",{"2":{"291":1}}],["=1",{"2":{"281":1}}],["=1y",{"2":{"281":1}}],["=12πexp⁡",{"2":{"93":1}}],["=12m∑i=1m",{"2":{"73":1}}],["=r",{"2":{"211":8,"268":2}}],["=h",{"2":{"211":2}}],["=d​q⊤k​",{"2":{"150":1}}],["=q⊤kd",{"2":{"150":1}}],["=−128−round",{"2":{"286":2}}],["=−lnpt​",{"2":{"146":1}}],["=−lnptloss",{"2":{"146":1}}],["=−i=1∑n​yi​⋅lnpi​",{"2":{"146":1}}],["=−∑i=1nyi⋅lnpiloss",{"2":{"146":1}}],["=wv⊤​tanh",{"2":{"136":1}}],["=wv⊤tanh⁡",{"2":{"136":1}}],["=θi−αddθij",{"2":{"129":1}}],["=θ0​+θ1​x",{"2":{"73":1}}],["=θ0+θ1xh",{"2":{"73":1}}],["=exp⁡",{"2":{"122":1}}],["=i=1∑m​α",{"2":{"122":1}}],["=i=1∑n​softmax",{"2":{"93":1,"106":1}}],["=i=1∑n​∑j=1n​exp",{"2":{"93":1,"106":1}}],["=i=1∑n​∑j=1n​k",{"2":{"93":1}}],["=i=1∑n​α",{"2":{"93":2,"106":1}}],["=softmax",{"2":{"115":2,"122":2,"304":2}}],["=x",{"2":{"304":3}}],["=x02​+x12​",{"2":{"114":1}}],["=x02+x12f",{"2":{"114":1}}],["=x2",{"2":{"114":1}}],["=x2f",{"2":{"114":1}}],["=∑t=1tα",{"2":{"183":1}}],["=∑j=1m​exp",{"2":{"122":1}}],["=∑i=1mα",{"2":{"122":1}}],["=∑i=1nsoftmax",{"2":{"93":1,"106":1}}],["=∑i=1nexp⁡",{"2":{"93":1,"106":1}}],["=∑i=1nα",{"2":{"93":2,"106":1}}],["=∑i=1nk",{"2":{"93":1}}],["=∑xtp",{"2":{"110":3}}],["=p",{"2":{"110":3,"140":2}}],["=∏t=1tp",{"2":{"110":2,"140":1}}],["==简洁美观==",{"2":{"134":1}}],["==",{"2":{"97":1,"101":1,"110":1,"122":1,"126":3,"134":2,"137":2,"160":1,"186":1,"193":1,"257":2,"268":3,"281":2,"285":4,"292":5,"295":4,"300":1,"305":1,"312":3}}],["=2",{"2":{"284":1}}],["=224lbsh^2",{"2":{"284":1}}],["=20bytes",{"2":{"256":2}}],["=28",{"2":{"145":1}}],["=28x",{"2":{"145":1}}],["=2xtx",{"2":{"145":2}}],["=2xtxf",{"2":{"145":2}}],["=2x",{"2":{"114":2}}],["=2π​1​exp",{"2":{"93":1}}],["=2m1​i=1∑m​",{"2":{"73":1}}],["=",{"2":{"46":2,"64":10,"67":2,"70":6,"73":2,"89":10,"93":11,"94":11,"97":11,"100":2,"101":18,"105":3,"106":19,"107":1,"109":6,"110":22,"114":7,"115":4,"116":3,"119":12,"122":7,"123":6,"125":4,"126":17,"129":33,"131":23,"132":5,"133":24,"136":14,"137":19,"140":3,"141":12,"145":12,"146":8,"147":9,"150":5,"154":1,"158":1,"159":10,"160":20,"161":13,"170":4,"178":24,"179":4,"183":14,"186":16,"187":7,"188":6,"192":1,"193":15,"194":14,"196":1,"201":8,"202":12,"207":5,"209":3,"220":10,"225":1,"230":2,"233":3,"234":1,"235":3,"237":7,"244":1,"246":19,"250":1,"251":4,"252":3,"256":1,"257":23,"258":1,"262":9,"268":27,"269":8,"275":3,"277":18,"281":11,"282":27,"284":3,"285":4,"286":5,"289":5,"291":1,"292":4,"293":4,"294":7,"295":18,"296":7,"297":1,"298":3,"299":1,"300":13,"302":7,"304":8,"305":23,"306":11,"308":4,"310":19,"312":18}}],["利用多核实现并行",{"2":{"271":1}}],["利用decoder的隐状态生成当前时间步的输出单词",{"2":{"214":1}}],["利用torch的按维度求和",{"2":{"160":1}}],["利用",{"2":{"46":1}}],["输出照例为一个output和一个state",{"2":{"310":1}}],["输出层参数",{"2":{"282":1}}],["输出层的数据可以写为",{"2":{"251":1}}],["输出x的形状",{"2":{"246":2}}],["输出x的形状为",{"2":{"183":1}}],["输出的state的shape为",{"2":{"310":1}}],["输出的y",{"2":{"300":1}}],["输出的queries",{"2":{"246":1}}],["输出的维度为",{"2":{"136":1}}],["输出后的效果",{"2":{"228":1}}],["输出大小",{"2":{"221":1}}],["输出形状就为",{"2":{"201":1}}],["输出操作数约束",{"2":{"196":1}}],["输出格式",{"2":{"190":1}}],["输出也是一个",{"2":{"131":1}}],["输出设置为",{"2":{"109":1}}],["输出",{"2":{"45":1,"51":1,"58":1,"59":1,"77":1,"89":12,"103":1,"119":1,"134":1,"148":1,"164":1,"171":2,"197":1,"201":1,"212":1,"310":2}}],["输入一个prompt序列",{"2":{"304":1}}],["输入一个长度为",{"2":{"304":1}}],["输入映射需要保存输入",{"2":{"297":1}}],["输入包含了",{"2":{"297":1}}],["输入和输出为",{"2":{"277":1}}],["输入和输出的通道数都是",{"2":{"269":1}}],["输入的均值",{"2":{"297":1}}],["输入的tokens数为",{"2":{"284":1}}],["输入的数据",{"2":{"277":1}}],["输入的高度和宽度均为3",{"2":{"201":1}}],["输入数据也需要放到gpu上",{"2":{"267":1}}],["输入维度为",{"2":{"251":1}}],["输入x的形状",{"2":{"246":1}}],["输入为",{"2":{"224":1}}],["输入到gru中",{"2":{"214":1}}],["输入到一个mlp中",{"2":{"136":1}}],["输入嵌入",{"2":{"199":1}}],["输入操作数约束",{"2":{"196":1}}],["输入不固定的情况下我们可以有以下两种策略",{"2":{"110":1}}],["输入链接的标识",{"2":{"104":1}}],["输入序列对应的每个位置",{"2":{"87":1}}],["输入",{"2":{"45":1,"51":1,"58":1,"77":1,"89":12,"103":1,"119":1,"134":1,"148":1,"164":1,"197":1,"212":1,"273":1,"297":1}}],["输入输出为自然语言",{"2":{"38":1}}],["2∗2∗bsh=4bsh2",{"2":{"297":1}}],["2bs2a+2bsh2bs^2a",{"2":{"297":1}}],["2bs2a2bs^2a2bs2a",{"2":{"297":2}}],["2bs2h+2bsh22bs^2h",{"2":{"277":1}}],["2bs2h2bs^2h2bs2h",{"2":{"277":1}}],["2bsbsh+2bs",{"2":{"297":1}}],["2bsh2bs2a+2bsh",{"2":{"297":1}}],["2bsh2bsh2bsh",{"2":{"297":3}}],["2bshv",{"2":{"277":1}}],["2bshv2bshv2bshv",{"2":{"277":1}}],["2bsh^22bs2h+2bsh2",{"2":{"277":1}}],["2了",{"2":{"275":1}}],["2+4",{"2":{"256":4}}],["2+1",{"2":{"49":2}}],["2ϕ2",{"2":{"256":1}}],["2$",{"2":{"224":1}}],["22⋅2",{"2":{"201":1,"281":1}}],["224lbsh2",{"2":{"284":1}}],["224",{"2":{"123":1}}],["2⋅22",{"2":{"201":1,"281":1}}],["29",{"2":{"179":1}}],["2的矩阵",{"2":{"170":1}}],["2的全零矩阵",{"2":{"170":1}}],["28x=",{"2":{"145":1}}],["288",{"2":{"123":1}}],["2^",{"2":{"145":1}}],["2表示完全连接层",{"2":{"137":1}}],["21​​∂x∂p​​1​=21​i",{"2":{"131":1}}],["2pi​−pi2​​",{"2":{"131":1}}],["2exi​∑k=1n​exk​−e2xi​​∑k=1n​exk​exi​​−",{"2":{"131":1}}],["2=",{"2":{"131":3}}],["24lbsh2",{"2":{"284":1}}],["24lbsh224lbsh^224lbsh2",{"2":{"284":1}}],["24bsh^2",{"2":{"277":1}}],["24bsh2+4bs2h",{"2":{"277":2}}],["24bsh2+4bs2h24bsh^2",{"2":{"277":1}}],["24",{"2":{"123":2}}],["2a",{"2":{"119":2,"237":1}}],["2x^txf",{"2":{"145":2}}],["2x",{"2":{"114":1,"131":1,"159":1}}],["20ϕ20",{"2":{"256":1}}],["20bytes",{"2":{"256":1}}],["2048",{"2":{"193":1}}],["20⋅∑k=1n​exk​−exi​+xj​​−∑k=1n​exk​exi​​⋅∑k=1n​exk​exj​​−pi​pj​​",{"2":{"131":1}}],["208",{"2":{"123":1}}],["20",{"2":{"106":1,"136":1,"171":1,"179":1,"235":1}}],["2004",{"2":{"67":2}}],["2β2​",{"2":{"105":1}}],["27",{"2":{"89":1,"194":4}}],["234",{"2":{"104":1}}],["23",{"2":{"89":1}}],["2m",{"2":{"73":1}}],["2j+1​=cos",{"2":{"269":1}}],["2j+1",{"2":{"269":1}}],["2j+1=cos⁡",{"2":{"269":1}}],["2j​=sin",{"2":{"269":1}}],["2j=sin⁡",{"2":{"269":1}}],["2j",{"2":{"73":1,"269":3}}],["256",{"2":{"70":1,"94":1,"107":1,"123":2,"160":1}}],["2",{"0":{"47":1,"93":1,"95":1,"110":1,"114":1,"115":1,"116":1,"167":1,"201":1,"203":1,"230":1,"232":1,"264":1,"267":1,"275":1,"277":1,"280":1,"282":1,"284":1,"288":1,"291":2,"302":1,"308":1,"311":1},"1":{"246":1,"284":1,"289":1,"291":1},"2":{"45":2,"46":1,"49":1,"59":2,"64":1,"73":1,"89":4,"93":12,"94":3,"97":5,"100":1,"101":3,"103":1,"104":2,"105":2,"106":18,"110":1,"114":2,"115":1,"121":1,"129":8,"131":5,"132":3,"133":4,"136":6,"137":7,"140":1,"145":14,"150":1,"158":4,"159":7,"160":3,"170":8,"171":1,"172":1,"178":1,"183":4,"186":5,"188":8,"197":2,"201":4,"207":2,"211":4,"220":8,"233":4,"235":2,"237":6,"246":4,"250":1,"252":2,"256":2,"257":3,"258":2,"262":1,"268":5,"269":3,"275":3,"277":2,"281":3,"282":1,"284":1,"287":2,"292":1,"293":1,"295":4,"296":1,"297":1,"300":1,"304":3,"306":2,"310":4,"312":2}}],["2−e",{"2":{"37":2}}],["34bsh",{"2":{"297":1}}],["34bsh+5bs2a",{"2":{"297":2}}],["3$",{"2":{"284":1}}],["35",{"2":{"282":1}}],["350m",{"2":{"127":3}}],["3∗2∗bsh23",{"2":{"277":1}}],["3>",{"2":{"257":2,"268":2}}],["3这样的标号访问",{"2":{"207":1}}],["3f",{"2":{"186":1,"295":3,"312":1}}],["3e",{"2":{"186":1}}],["30",{"2":{"179":1,"221":1}}],["3x2​",{"2":{"145":1}}],["3^",{"2":{"145":1}}],["3bsh3bsh3bsh",{"2":{"297":1}}],["3b",{"2":{"127":2}}],["320",{"2":{"123":2}}],["32",{"2":{"123":5,"127":1,"282":1}}],["3d张量",{"2":{"122":1}}],["384",{"2":{"107":1,"123":1}}],["3",{"0":{"106":1,"109":1,"126":1,"129":1,"131":1,"132":1,"217":1,"220":1,"248":1,"258":1,"283":1,"287":1,"296":1,"297":1,"301":1,"305":1,"310":1},"1":{"233":1,"250":1,"269":1,"301":1,"312":1},"2":{"45":2,"46":1,"59":1,"70":1,"89":1,"100":1,"104":2,"107":2,"121":1,"129":3,"133":1,"137":2,"145":7,"158":3,"159":7,"160":2,"170":1,"178":1,"188":1,"197":2,"201":4,"211":4,"220":6,"233":4,"235":1,"246":3,"252":2,"257":2,"262":4,"268":3,"275":1,"281":6,"291":3,"295":1}}],["|",{"2":{"45":20,"52":1,"119":15,"131":2,"140":3,"253":2,"296":2,"304":1}}],["计算交叉熵损失",{"2":{"300":1}}],["计算loss",{"2":{"300":1}}],["计算输出映射以及一个droupout操作",{"2":{"297":1}}],["计算输出o",{"2":{"282":1}}],["计算梯度时需要用到层的输入",{"2":{"297":1}}],["计算端到端训练的gpu利用率时",{"2":{"291":1}}],["计算h",{"2":{"282":1}}],["计算方式为",{"2":{"277":1}}],["计算bwd",{"2":{"275":1}}],["计算fwd",{"2":{"275":1}}],["计算复杂度为",{"2":{"269":1}}],["计算得到float16的梯度",{"2":{"256":1}}],["计算的",{"2":{"237":1}}],["计算完梯度之后完全释放",{"2":{"225":2}}],["计算完bwd之后完全释放",{"2":{"225":1}}],["计算完attention之后还会进行一次线性变换",{"2":{"224":1}}],["计算出abs",{"2":{"238":1}}],["计算出input",{"2":{"225":1}}],["计算出grad",{"2":{"133":1}}],["计算注意力权重",{"2":{"214":1}}],["计算操作",{"0":{"188":1}}],["计算每个参数的梯度",{"2":{"177":1}}],["计算这个标量相对于模型参数的梯度",{"2":{"177":1}}],["计算预测正确的数量",{"2":{"160":1}}],["计算yyy",{"2":{"145":1}}],["计算yyy的函数h",{"2":{"129":1}}],["计算通道维度上的均值和方差",{"2":{"137":1}}],["计算特征维度上的均值和方差",{"2":{"137":1}}],["计算损失函数l",{"2":{"129":1}}],["计算密集型任务",{"2":{"124":2,"167":1}}],["计算即时收益",{"2":{"112":1}}],["计算次数",{"2":{"49":1}}],["计算量与参数量关联",{"0":{"284":1}}],["计算量flops估计",{"0":{"277":1},"1":{"284":1,"291":1}}],["计算量为",{"2":{"49":1,"277":1}}],["计算量",{"2":{"49":2,"210":1}}],["计算与",{"2":{"297":1}}],["计算与通信相重叠",{"2":{"43":1}}],["计算与访存相重叠",{"2":{"43":1}}],["计算效率",{"2":{"43":1}}],["取决于访存延迟和带宽",{"2":{"43":1}}],["取决于硬件的算力",{"2":{"43":1}}],["宏观上",{"2":{"43":1}}],["还要考虑cpu加载数据",{"2":{"291":1}}],["还与gpu利用率有关",{"2":{"291":1}}],["还有一些中间结果",{"2":{"267":1}}],["还是使用交叉熵",{"2":{"312":1}}],["还是需要使用megatron",{"2":{"302":1}}],["还是多线程",{"2":{"232":1}}],["还是",{"2":{"225":1}}],["还会进入embedding层",{"2":{"224":1}}],["还没有办法指定图片的宽高",{"2":{"149":1}}],["还可以指定多个单行",{"2":{"89":1}}],["还更好阅读",{"2":{"41":1}}],["还得转换网址内的",{"2":{"26":1,"34":1,"36":1,"39":1}}],["式的",{"2":{"41":1}}],["然而当",{"2":{"233":1}}],["然而",{"2":{"96":1,"281":1}}],["然而最大灵感来源其实是纯文字的电子邮件格式",{"2":{"7":1,"13":1,"15":1,"17":1}}],["然后广播一下",{"2":{"310":1}}],["然后第",{"2":{"304":1}}],["然后最后输出一个预测的token",{"2":{"304":1}}],["然后就是构造engine",{"2":{"302":1}}],["然后这里也支持用户定制属于自己的backend",{"2":{"299":1}}],["然后依次剖析里面的细节",{"2":{"294":1}}],["然后执行不同的事情",{"2":{"287":1}}],["然后一步一步更新小批量数据的隐状态",{"2":{"282":1}}],["然后设置rnn中的各种权重",{"2":{"282":1}}],["然后必须要手动指定node",{"2":{"280":1}}],["然后异步send",{"2":{"275":1}}],["然后异步去send",{"2":{"275":1}}],["然后send出去",{"2":{"275":1}}],["然后send出去结果",{"2":{"275":1}}],["然后计算",{"2":{"275":2}}],["然后释放显存",{"2":{"275":1}}],["然后backward按逆序逐层传递梯度",{"2":{"275":1}}],["然后我们有个输入",{"2":{"310":1}}],["然后我们会开",{"2":{"271":1}}],["然后我们对输入的token进行转发",{"2":{"97":1}}],["然后均匀地将fp32等映射到现在指定的值域上",{"2":{"270":1}}],["然后利用交叉熵损失计算模型输出和标签之间的误差",{"2":{"263":1}}],["然后诸如此类",{"2":{"246":1}}],["然后如此复制第二项",{"2":{"246":1}}],["然后启动tma",{"2":{"244":1}}],["然后使用async",{"2":{"271":1}}],["然后使用cp",{"2":{"257":1}}],["然后使用",{"2":{"244":1}}],["然后使用training",{"2":{"127":1}}],["然后通过bwd计算出了input",{"2":{"225":1}}],["然后根据当前阶段的input",{"2":{"225":1}}],["然后获得output",{"2":{"225":1}}],["然后完整地进行一次batch的fwd和bwd",{"2":{"225":1}}],["然后做softmax",{"2":{"224":1}}],["然后在这个node上执行一个runner进程",{"2":{"287":1}}],["然后在训练过程中",{"2":{"263":1}}],["然后在链接的时候对全局的代码进行优化",{"2":{"221":1}}],["然后在每行的最前面加上",{"2":{"52":1}}],["然后返回响应",{"2":{"215":1}}],["然后gcc会将其转化为中间产物gimple三地址码形式",{"2":{"205":1}}],["然后",{"2":{"179":1,"230":1}}],["然后实参与param",{"2":{"179":1}}],["然后实现属于自己的forward逻辑",{"2":{"117":1}}],["然后每行都除以它对应行的和",{"2":{"160":1}}],["然后是一些配置选项",{"2":{"141":1}}],["然后进入main函数",{"2":{"141":1}}],["然后进行计算",{"2":{"282":1}}],["然后进行量化",{"2":{"238":1}}],["然后进行移动构造",{"2":{"189":1}}],["然后进行all2all通信",{"2":{"111":1}}],["然后进行批量矩阵乘法",{"2":{"106":1}}],["然后反向传播计算梯度",{"2":{"129":1}}],["然后将不同的行为作为知识组合起来",{"2":{"230":1}}],["然后将训练分为若干阶段",{"2":{"127":1}}],["然后将token进行dispatch",{"2":{"97":1}}],["然后对于用户发送的sigint或者系统发送的sigterm",{"2":{"287":1}}],["然后对于原值",{"2":{"286":1}}],["然后对于第一维中的每个矩阵",{"2":{"106":1}}],["然后对标量调用backward",{"2":{"159":1}}],["然后对每个单词按照出现频率排序",{"2":{"126":1}}],["然后定义了fwd和bwd的操作",{"2":{"117":1}}],["然后定义链接内容",{"2":{"104":1}}],["然后内部嵌入若干子module",{"2":{"117":1}}],["然后内部不断地嵌套",{"2":{"117":1}}],["然后还有更加基础和细致的ppo算法推导",{"2":{"112":1}}],["然后选择最高的topk个",{"2":{"111":1}}],["然后开始下一次step",{"2":{"105":1}}],["然后接着定义链接",{"2":{"104":1}}],["然后从图片中提取出4个特征",{"2":{"100":1}}],["然后任其自由向",{"2":{"99":1}}],["然后再求平均值",{"2":{"300":1}}],["然后再求zero",{"2":{"286":1}}],["然后再下沉到transformer",{"2":{"290":1}}],["然后再将隐藏层权重用为输出",{"2":{"251":1}}],["然后再对通道",{"2":{"233":1}}],["然后再反向传播",{"2":{"159":1}}],["然后再按照匹配程度分配到一些专属的experts上",{"2":{"111":1}}],["然后再寻找最适合的local",{"2":{"97":1}}],["然后再去看项目",{"2":{"76":1}}],["然后去著名的开源项目之中印证自己所学",{"2":{"76":1}}],["然后讲解",{"2":{"62":1}}],["然后按照列来逐个处理block",{"2":{"70":1}}],["然后按",{"2":{"41":1}}],["或梯度",{"2":{"301":1}}],["或者说这些基础环境变量完全由用户来指定",{"2":{"299":1}}],["或者是抛弃某些已经无用的像素信息",{"2":{"273":1}}],["或者gnu汇编器",{"2":{"205":1}}],["或者注释有差异",{"2":{"205":1}}],["或者模板类型推导的时候容易发生错误",{"2":{"175":1}}],["或者",{"2":{"150":1}}],["或",{"2":{"89":2,"120":2,"221":2,"246":1,"281":1}}],["或两者均指定",{"2":{"89":1}}],["或缓存未及时同步",{"2":{"64":1}}],["或斜线",{"2":{"41":1}}],["或是文件结尾",{"2":{"67":1}}],["或是你懒一点都写作",{"2":{"59":1}}],["或是空白来缩进",{"2":{"19":1,"27":1,"29":1,"31":1}}],["或是",{"2":{"19":1,"27":1,"29":1,"31":1}}],["允许任意类型",{"2":{"305":1}}],["允许通过字段名来填充数据",{"2":{"305":1}}],["允许注意力机制组合使用查询",{"2":{"230":1}}],["允许寄存器或内存",{"2":{"196":1}}],["允许我们自定义计算图节点",{"2":{"133":1}}],["允许重排序",{"2":{"64":1}}],["允许段落内的强迫断行",{"2":{"41":1}}],["允许你直接使用这些符号",{"2":{"26":1,"34":1,"36":1,"39":1}}],["若某一行只包含空白和",{"2":{"41":1}}],["比onehot更加精准",{"2":{"310":1}}],["比较偏向于半成品",{"2":{"299":1}}],["比较推荐",{"2":{"270":1}}],["比较有用的用法就是",{"2":{"227":1}}],["比较一下上面的范例",{"2":{"104":1}}],["比较反直觉",{"2":{"64":1}}],["比较难受的是",{"2":{"50":1}}],["比方说",{"2":{"41":1}}],["比如cv中的通道数",{"2":{"279":1}}],["比如cuda",{"2":{"50":1}}],["比如6b以上的llm",{"2":{"270":1}}],["比如绝大部分的cv模型",{"2":{"270":1}}],["比如int8的0就是0",{"2":{"270":1}}],["比如int8",{"2":{"270":1}}],["比如我当前是macbook",{"2":{"253":1}}],["比如x86",{"2":{"253":1}}],["比如在fwd和bwd的时候",{"2":{"290":1}}],["比如在宏展开和头文件展开的时候",{"2":{"205":1}}],["比如在这里",{"2":{"133":1}}],["比如平常见到的x86",{"2":{"190":1}}],["比如linear层的weight矩阵",{"2":{"133":1}}],["比如上述的卷积核可能特征就是具体物体的特征",{"2":{"125":1}}],["比如unsqueeze",{"2":{"106":1}}],["比如at",{"2":{"50":1}}],["比如对于",{"2":{"49":1}}],["比如",{"2":{"19":1,"27":1,"29":1,"31":1,"275":1,"297":1,"302":1,"304":1}}],["作用有如下",{"2":{"207":1}}],["作用是获取类型",{"2":{"209":1}}],["作用是提供类内部属性的安全访问",{"2":{"171":1}}],["作用是预估收益",{"2":{"112":1}}],["作用是对于每个结果都会经过共享的experts",{"2":{"111":1}}],["作者通过实验提出来了当",{"2":{"38":1}}],["作为另外一个rnn的初始隐状态",{"2":{"310":1}}],["作为model",{"2":{"237":1}}],["作为mlsys方向的必不可少的语言",{"2":{"1":1}}],["作为查询",{"2":{"183":1}}],["作为下一个节点的grad",{"2":{"133":1}}],["作为标记强调字词的符号",{"2":{"120":1}}],["作为一个股票预测员",{"2":{"110":1}}],["作为内部链接的目标",{"2":{"32":1}}],["作为底层的算子",{"2":{"1":1}}],["object",{"2":{"305":1}}],["obtain",{"2":{"101":2}}],["old",{"2":{"305":1}}],["ol>",{"2":{"59":2}}],["o^",{"2":{"304":1}}],["os自然会将其调度到各个核上实现并行",{"2":{"271":1}}],["ot​=ht​whq​+bq​",{"2":{"251":1}}],["ot=htwhq+bqo",{"2":{"251":1}}],["other",{"2":{"227":1}}],["o=wn+1​hn​+bn+1​loss=l",{"2":{"296":1}}],["o=wn+1hn+bn+1loss=l",{"2":{"296":1}}],["o=hwhq​+bq​",{"2":{"251":1}}],["o=hwhq+bqo",{"2":{"251":1}}],["o=x⋅w+b",{"2":{"100":2}}],["oci​",{"2":{"250":1}}],["owo​",{"2":{"224":1,"277":1}}],["o$",{"2":{"224":1}}],["o3",{"2":{"221":2}}],["overlap阶段",{"2":{"290":1}}],["overlap执行",{"2":{"290":1}}],["overlap起来",{"2":{"290":1}}],["overlaps",{"2":{"290":1}}],["overhead",{"2":{"290":1}}],["overrides",{"2":{"305":1}}],["override",{"0":{"239":1}}],["over",{"2":{"119":2}}],["or",{"2":{"104":4,"126":2,"141":3,"152":1,"211":1,"225":1,"232":1,"295":2,"296":1,"300":1,"305":2}}],["order的部分",{"2":{"70":1}}],["ordering可以让l2",{"2":{"70":1}}],["order",{"2":{"64":7,"70":2}}],["o",{"2":{"100":3,"101":2,"190":1,"205":2,"221":3,"230":4,"246":4,"250":1,"262":3,"269":30,"277":1,"296":4,"301":6,"304":2,"305":14}}],["out部分",{"2":{"304":1}}],["out=128",{"2":{"97":1}}],["output的shape为",{"2":{"310":1}}],["output的形状",{"2":{"246":1,"310":2}}],["outputs的形状为",{"2":{"183":3}}],["outputs=10",{"2":{"160":1}}],["outputs",{"2":{"116":1,"160":6,"161":1,"183":13,"282":6,"289":5,"308":3,"310":2}}],["output",{"2":{"97":4,"101":10,"123":1,"127":4,"133":9,"147":4,"156":2,"161":13,"178":10,"193":2,"224":1,"225":7,"246":7,"292":3,"304":1,"306":2,"310":10}}],["out",{"2":{"94":7,"97":12,"107":6,"123":3,"183":2,"186":1,"201":1,"250":2,"262":3,"277":3,"301":1,"304":6}}],["opo​",{"2":{"246":1}}],["opaque",{"2":{"227":1}}],["ops",{"2":{"196":1,"244":1}}],["opt",{"2":{"127":5}}],["optimize",{"2":{"141":2,"290":1}}],["optimizerconfig",{"2":{"305":2}}],["optimizer中",{"2":{"299":1}}],["optimizer之中",{"2":{"294":1}}],["optimizer为例",{"2":{"105":1}}],["optimizer会维护每个参数的一些状态",{"2":{"105":1}}],["optimizer",{"0":{"92":1,"105":1},"1":{"105":1,"121":1},"2":{"193":3,"294":3,"295":3,"300":1,"302":1,"305":4,"312":3}}],["optim",{"2":{"106":1,"110":1,"129":1,"193":1,"295":1,"300":2,"312":1}}],["optional",{"2":{"104":6,"149":2,"272":1}}],["options",{"2":{"89":8}}],["openrlhf",{"2":{"141":1}}],["open",{"2":{"126":1}}],["operation",{"2":{"227":1,"244":3}}],["operations",{"2":{"49":2,"227":1,"277":1}}],["operator",{"2":{"227":1}}],["operator层面可以做一些conv2d的优化",{"2":{"23":1}}],["onehot会将这个二维张量转化为三维张量",{"2":{"282":1}}],["onehot",{"2":{"146":2}}],["onehot编码将每个类别表示为一个向量",{"2":{"100":1}}],["one",{"2":{"131":1,"211":1,"244":3,"282":1,"292":1,"305":2,"306":1}}],["ones",{"2":{"106":1,"136":1,"137":2,"159":2,"178":1,"186":1,"312":1}}],["onednn",{"2":{"54":1}}],["on",{"0":{"254":1},"1":{"265":1,"275":1,"283":1},"2":{"89":2,"141":1,"161":1,"244":1,"257":1,"295":2,"312":1}}],["only模型量级分析",{"0":{"210":1},"1":{"224":1,"241":1,"256":1,"267":1,"277":1,"284":1,"291":1,"297":1,"301":1}}],["only",{"2":{"59":1,"141":2,"210":1,"272":2}}],["only架构下的transformer模型的参数量",{"2":{"210":1}}],["only架构",{"2":{"38":1}}],["offset",{"2":{"202":6}}],["offload",{"2":{"141":1}}],["offload=args",{"2":{"141":1}}],["of",{"2":{"52":1,"67":2,"97":1,"101":5,"119":8,"132":1,"135":2,"141":1,"147":2,"161":5,"227":2,"285":1,"290":1,"301":1}}],["oi=629375409599549440",{"2":{"47":1}}],["也需要考虑硬件",{"2":{"298":1}}],["也需要在",{"2":{"50":1}}],["也被称为",{"2":{"279":1}}],["也被成为一元语法",{"2":{"154":1}}],["也是本论文采取的pp调度策略",{"2":{"275":1}}],["也是值",{"2":{"183":1}}],["也不需要保存中间激活",{"2":{"267":1}}],["也不会使得头文件跟着重新编译",{"2":{"207":1}}],["也不会对它做任何转换",{"2":{"26":1,"34":1,"36":1,"39":1}}],["也有cp",{"2":{"244":1}}],["也无能为力",{"2":{"232":1}}],["也接近于我们初始设定的",{"2":{"186":1}}],["也包括左值引用int",{"2":{"172":1}}],["也会开多个进程来负载均衡",{"2":{"271":1}}],["也会有cp",{"2":{"244":1}}],["也会变成三维张量",{"2":{"125":1}}],["也会深入一些deepspeed的源码",{"2":{"112":1}}],["也就意味着获得了更多的注意力",{"2":{"93":1}}],["也就是gpu算完这么多flops的计算时间",{"2":{"291":1}}],["也就是相当于将计算单元拆小",{"2":{"290":1}}],["也就是从fp32",{"2":{"286":1}}],["也就是h0h",{"2":{"282":1}}],["也就是torch支持gloo的cpu训练以及nccl的gpu训练",{"2":{"272":1}}],["也就是人为指定的零点",{"2":{"270":1}}],["也就是我们第",{"2":{"234":1}}],["也就是8x8",{"2":{"211":1}}],["也就是在自然语言中",{"2":{"154":1}}],["也就是在行首出现数字",{"2":{"59":1}}],["也就是可以实现多核并行操作",{"2":{"152":1}}],["也就是系统级别的线程",{"2":{"152":1}}],["也就是反向传播",{"2":{"145":1}}],["也就是上述的运算只适合灰度图像",{"2":{"125":1}}],["也就是将一段段话分割为更小的单元",{"2":{"126":1}}],["也就是将",{"2":{"121":1}}],["也就是local",{"2":{"111":1}}],["也就是序列其实总是满足某个潜在的规律",{"2":{"110":1}}],["也就是说",{"2":{"110":1,"146":1,"281":1}}],["也就是说要保证每个线程的操作在全局顺序中保证其线程内的顺序",{"2":{"64":1}}],["也就是浮点数运算次数",{"2":{"38":1}}],["也能更好地利用和控制sm",{"2":{"70":1}}],["也允许",{"2":{"59":1}}],["也允许你只在整个段落的第一行最前面加上",{"2":{"52":1}}],["也可能相互依赖",{"2":{"177":1}}],["也可以实现这样的overlap",{"2":{"275":1}}],["也可以选择openmpi等一些mpi通信",{"2":{"272":1}}],["也可以写为torch",{"2":{"252":1}}],["也可以设置步幅",{"2":{"201":1}}],["也可以按照维度求",{"2":{"188":1}}],["也可以理解为definition",{"2":{"158":1}}],["也可以是单词单元",{"2":{"126":1}}],["也可以加一些缩进",{"2":{"104":1}}],["也可以使用decltype",{"2":{"209":1}}],["也可以使用llvm",{"2":{"205":1}}],["也可以使用",{"2":{"89":1}}],["也可以",{"2":{"59":1}}],["也可使用星号",{"2":{"59":1}}],["论文中对dualpipe的描述是这样的",{"2":{"290":1}}],["论文图中",{"2":{"275":1}}],["论文地址",{"2":{"42":1}}],["论文",{"2":{"38":1,"216":1}}],["论文甚至是用非常少量的代码完成最小可用原型",{"2":{"12":1,"20":1,"22":1,"24":1}}],["f32占4个bytes",{"2":{"256":1}}],["fwd执行完毕之后",{"2":{"275":1}}],["fwd",{"2":{"225":1,"275":1}}],["fwd没啥好说的",{"2":{"133":1}}],["fphp",{"2":{"253":1}}],["fp",{"2":{"253":1}}],["fp8e4m3",{"2":{"211":9}}],["fp32",{"2":{"141":3,"298":1}}],["f2",{"2":{"209":1}}],["f16占2个bytes",{"2":{"256":1}}],["f1",{"2":{"209":1}}],["fn=rnn",{"2":{"282":1}}],["fn之类的元数据来执行bwd",{"2":{"225":1}}],["fn",{"2":{"133":2,"202":3,"225":1,"282":4,"305":3}}],["full",{"2":{"181":2}}],["func",{"2":{"172":2,"225":1}}],["function的ctx",{"2":{"225":1}}],["function的函数类",{"2":{"133":1}}],["function里面",{"2":{"133":1}}],["functions",{"2":{"133":1}}],["functional中的函数可以满足我们的一部分需求",{"2":{"117":1}}],["functional中自带的函数",{"2":{"117":1}}],["functional",{"2":{"106":1,"122":2,"126":1}}],["function",{"0":{"133":1},"2":{"89":2,"133":1,"135":2,"305":1}}],["fun∣deep",{"2":{"140":2}}],["fun",{"2":{"140":5}}],["fuse一些重复启动的函数",{"2":{"133":1}}],["fff",{"2":{"230":1}}],["ffn计算",{"2":{"277":1}}],["ffn",{"2":{"224":1,"297":1}}],["ff",{"2":{"116":3,"147":4,"161":4,"178":3,"193":2}}],["field",{"2":{"305":28}}],["fields=false",{"2":{"305":1}}],["fields",{"2":{"305":13}}],["finish",{"2":{"292":1}}],["find",{"2":{"268":1}}],["finetuning",{"2":{"127":4}}],["finally",{"2":{"290":1}}],["final",{"2":{"101":1}}],["fireball",{"2":{"104":2}}],["first",{"2":{"52":3,"59":1,"70":3}}],["file",{"2":{"103":1,"196":1,"244":1}}],["fill",{"2":{"101":2,"129":1}}],["fewer",{"2":{"290":1}}],["fence",{"2":{"268":2,"285":1}}],["features",{"2":{"110":3,"116":1,"129":9,"136":4,"137":4}}],["feature",{"2":{"97":17}}],["feed",{"0":{"116":1},"2":{"87":1,"116":1,"147":3,"161":3,"224":1}}],["flto=thin",{"2":{"221":1}}],["flto",{"2":{"221":1}}],["flat",{"2":{"312":1}}],["flatten",{"2":{"94":1,"107":1,"123":1,"295":1}}],["flagm2",{"2":{"253":1}}],["flagm",{"2":{"253":1}}],["flags",{"2":{"253":3}}],["flash",{"0":{"191":1}}],["float4>",{"2":{"257":1,"268":4}}],["float4",{"2":{"257":2,"268":5}}],["float",{"2":{"106":2,"129":1,"132":2,"137":2,"160":3,"262":1,"305":3}}],["float32的模型参数来更新模型参数",{"2":{"256":1}}],["float32的梯度",{"2":{"256":1}}],["float32",{"2":{"49":3,"110":1,"136":1,"269":2,"281":1,"282":1,"306":1,"312":1}}],["floating",{"2":{"49":1,"277":1}}],["flops",{"2":{"49":1,"277":1}}],["f",{"2":{"93":9,"106":3,"110":3,"114":7,"117":1,"122":3,"126":4,"129":4,"133":2,"141":1,"145":21,"179":20,"186":1,"193":1,"194":4,"209":4,"230":1,"234":1,"257":4,"258":1,"277":1,"282":1,"294":1,"295":4,"299":1,"300":1,"304":2,"305":12,"306":1,"312":2}}],["four",{"2":{"292":1}}],["found",{"2":{"103":1}}],["followed",{"2":{"147":1,"237":1}}],["focused",{"2":{"89":2}}],["focus",{"2":{"89":4}}],["footprint",{"2":{"290":1}}],["footer",{"2":{"67":2}}],["foo",{"2":{"67":4,"89":8,"103":1,"104":3}}],["forbid",{"2":{"305":1}}],["forceinline",{"2":{"227":2}}],["formats",{"2":{"305":1}}],["formatter",{"2":{"305":1}}],["formatting",{"2":{"89":2}}],["form",{"2":{"147":1,"161":1}}],["forall",{"2":{"109":1,"115":1}}],["for=",{"2":{"89":2}}],["forward的时候会逐层计算",{"2":{"275":1}}],["forward",{"0":{"116":1},"2":{"87":1,"97":2,"101":1,"106":1,"116":2,"117":1,"123":2,"132":1,"133":1,"136":1,"137":1,"147":4,"150":1,"161":4,"178":1,"183":1,"186":1,"209":2,"224":1,"225":1,"246":1,"269":1,"282":5,"290":2,"306":1,"308":3,"310":2,"312":2}}],["forge安装的库",{"2":{"50":1}}],["for",{"2":{"38":1,"70":6,"94":3,"97":2,"101":4,"104":2,"106":1,"110":3,"116":1,"123":1,"126":12,"129":6,"133":1,"147":1,"160":2,"178":4,"183":1,"186":3,"187":3,"193":1,"202":1,"211":1,"225":4,"227":1,"233":1,"250":1,"257":1,"268":1,"272":1,"281":2,"282":2,"289":3,"292":3,"295":4,"296":3,"300":3,"305":7,"312":4}}],["false",{"2":{"257":1,"305":2}}],["fallbackflags",{"2":{"50":1}}],["family",{"2":{"141":1}}],["fashion",{"2":{"94":1,"160":1}}],["fast",{"0":{"61":1},"2":{"141":1}}],["free",{"2":{"163":1}}],["freq",{"2":{"126":3}}],["freqs",{"2":{"126":4}}],["freq=0",{"2":{"126":1}}],["frint",{"2":{"253":1}}],["fringilla",{"2":{"52":2,"59":3}}],["frigging",{"2":{"120":1}}],["from",{"2":{"89":2,"97":1,"104":8,"126":5,"129":3,"141":1,"160":2,"161":1,"211":2,"244":3,"268":1,"272":1,"292":1,"305":2}}],["frontmatter",{"2":{"25":1}}],["frac1c",{"2":{"119":4}}],["frac",{"2":{"73":1,"93":7,"105":1,"106":4,"110":2,"115":1,"119":6,"122":1,"129":1,"131":19,"145":1,"146":2,"150":2,"154":1,"159":4,"246":1,"269":4,"274":2,"275":2,"277":1,"286":5,"291":1,"296":1,"304":2}}],["fcma",{"2":{"253":1}}],["fc2",{"2":{"116":2}}],["fc1",{"2":{"116":2}}],["fc",{"2":{"49":1,"178":2}}],["分为了两个部分",{"2":{"299":1}}],["分为三个阶段",{"2":{"121":1}}],["分别表示输入和输出通道的数目",{"2":{"250":1}}],["分别初始化成1和0",{"2":{"137":1}}],["分支密集",{"2":{"221":1}}],["分支预测错误率会更低",{"2":{"221":1}}],["分割",{"2":{"220":1}}],["分割batch",{"2":{"141":1}}],["分析gil锁的释放条件",{"2":{"167":1}}],["分析得到",{"2":{"93":1}}],["分类维度",{"2":{"190":1}}],["分类精度",{"2":{"160":1}}],["分类任务",{"2":{"146":1}}],["分布",{"2":{"146":1}}],["分布的时候",{"2":{"131":1}}],["分布式训练框架的经典",{"2":{"1":1}}],["分片到多卡上",{"2":{"121":1}}],["分隔线",{"0":{"78":1}}],["分子分母除以",{"2":{"37":1}}],["容易超过float32的最大表示范围",{"2":{"37":1}}],["为每个transformer层生成key",{"2":{"304":1}}],["为每个进程持有",{"2":{"152":1}}],["为固定形状窗口",{"2":{"281":1}}],["为输出层的权重参数",{"2":{"251":1}}],["为输出维度",{"2":{"251":1}}],["为隐藏层权重参数",{"2":{"251":1}}],["为此",{"2":{"230":1}}],["为中心",{"2":{"201":1}}],["为卷积核kernel",{"2":{"186":1}}],["为原本图像",{"2":{"186":1}}],["为图片添加属性",{"2":{"181":1}}],["为",{"2":{"154":1,"282":1,"297":3,"310":2}}],["为确保无论向量长度如何",{"2":{"150":1}}],["为一个长度为4的一维张量",{"2":{"145":1}}],["为了使用gpu",{"2":{"295":1}}],["为了多个handler并行处理",{"2":{"271":1}}],["为了多注意力头的并行计算而变换形状",{"2":{"246":1}}],["为了适应急剧增长的model",{"2":{"254":1}}],["为了避免计算代价和参数代价的大幅增长",{"2":{"246":1}}],["为了和其他阶段区分",{"2":{"227":1}}],["为了和文献中一致",{"2":{"186":1}}],["为了训练语言模型",{"2":{"140":1}}],["为了更好地利用l2",{"2":{"70":1}}],["为键值对",{"2":{"93":1}}],["为查询",{"2":{"93":1}}],["为模型的输入",{"2":{"146":1}}],["为模型函数",{"2":{"146":1}}],["为模型性能",{"2":{"38":1}}],["为模型参数量",{"2":{"38":1}}],["为计算量",{"2":{"38":1}}],["为数据集大小",{"2":{"38":1}}],["为什么需要move",{"0":{"189":1}}],["为什么反向传播的起点需要是一个标量呢",{"2":{"177":1}}],["为什么python中多线程的效率这么差",{"0":{"138":1},"1":{"152":1,"167":1}}],["为什么multi",{"2":{"47":1}}],["为什么",{"0":{"37":1}}],["为im2col",{"2":{"23":1}}],["渲染为",{"2":{"32":1}}],["$2",{"2":{"267":1}}],["$4h$",{"2":{"224":2}}],["$h$",{"2":{"224":2}}],["$w",{"2":{"224":6}}],["$v$",{"2":{"224":1}}],["$k$",{"2":{"224":1}}],["$q$",{"2":{"224":1}}],["$t0",{"2":{"190":1}}],["$$",{"2":{"119":4}}],["$a",{"2":{"119":1}}],["$markdown",{"2":{"52":1}}],["$input",{"2":{"52":1}}],["$1",{"2":{"45":2}}],["$12",{"2":{"45":2}}],["$1600",{"2":{"45":2}}],["$",{"2":{"32":1,"119":12,"214":4,"224":2,"267":1,"284":1}}],["表达式",{"2":{"172":1}}],["表明在这个点上",{"2":{"145":2}}],["表示为",{"2":{"304":1}}],["表示浮点数运算次数",{"2":{"277":1}}],["表示当前解码步骤的对源句子的主要关注部分",{"2":{"214":1}}],["表示当前模型的表现好坏",{"2":{"177":1}}],["表示操作数在ptx中是output",{"2":{"196":1}}],["表示整个输出的",{"2":{"177":1}}],["表示该点f",{"2":{"145":1}}],["表示第",{"2":{"110":1}}],["表示按行复制n",{"2":{"106":1}}],["表示鸡鸭鹅这种类别数据的一种简单方式是onehot编码",{"2":{"100":1}}],["表示的代码库",{"2":{"67":1}}],["表示模型计算到底需要存取多少",{"2":{"49":1}}],["表示从",{"2":{"32":1}}],["表格",{"0":{"245":1},"2":{"19":1,"27":1,"29":1,"31":1}}],["绝对路径",{"2":{"32":1}}],["bwd的overlap上",{"2":{"290":1}}],["bwd的时候",{"2":{"117":1}}],["bwd",{"2":{"290":1}}],["bs2abs^2abs2a",{"2":{"297":1}}],["bsbsh",{"2":{"297":2}}],["bsbsbs",{"2":{"284":1,"297":1}}],["bsh+2bsbsh",{"2":{"297":1}}],["bsh",{"2":{"297":2}}],["bshbshbsh",{"2":{"297":5}}],["bsh^23∗2∗bsh2",{"2":{"277":1}}],["bs",{"2":{"284":1,"297":1}}],["b∈rb×c",{"2":{"277":1}}],["b∈rb×cb",{"2":{"277":1}}],["b∈r10∗10",{"2":{"160":2}}],["b64",{"2":{"227":6,"285":1}}],["b32",{"2":{"211":1}}],["b16意思是每次load",{"2":{"211":1}}],["b16",{"2":{"211":8}}],["bf16",{"2":{"211":6,"253":1}}],["bf16>",{"2":{"211":1}}],["bbb",{"2":{"210":1,"301":3}}],["bbedit",{"2":{"52":1}}],["bmatrix",{"2":{"145":2,"230":2,"237":2}}],["bmm",{"2":{"106":2,"136":1,"150":2}}],["bushi",{"2":{"290":1}}],["bubbles",{"2":{"290":1}}],["bubble比也降低为原来的virtual",{"2":{"275":1}}],["bubble",{"2":{"275":1}}],["bubbleall=p−1m+p−1",{"2":{"275":1}}],["build",{"2":{"272":1}}],["building",{"2":{"272":1}}],["built",{"2":{"272":1}}],["bulk操作",{"2":{"285":1}}],["bulk的时候",{"2":{"244":1}}],["bulk",{"2":{"244":11,"257":3,"268":8,"285":3}}],["buffer",{"2":{"132":1}}],["but",{"2":{"89":2}}],["b0b",{"2":{"129":1}}],["b为我们要回归的两个参数",{"2":{"129":1}}],["b⃗",{"2":{"119":2}}],["b^2",{"2":{"119":2}}],["bx",{"2":{"119":2}}],["b=true为了交换keys的最后两个维度",{"2":{"150":1}}],["b=",{"2":{"109":1}}],["b​=",{"2":{"109":1}}],["b​",{"2":{"109":5}}],["bos>",{"2":{"312":1}}],["bos",{"2":{"312":2}}],["bold",{"2":{"228":1}}],["both",{"2":{"161":1}}],["bool",{"2":{"106":2,"158":2,"178":1,"209":3,"257":1,"268":1,"305":1}}],["box",{"2":{"77":4}}],["by",{"2":{"101":2,"116":1,"120":1,"147":1,"227":1,"237":1,"272":1,"290":1,"305":1}}],["bytes",{"2":{"49":3,"227":1,"244":3,"256":1,"257":2,"267":1,"268":3,"285":4,"292":2}}],["bert微调所需的",{"2":{"295":1}}],["bert之中",{"2":{"294":1}}],["benckmarksetting",{"2":{"127":1}}],["believable",{"2":{"120":1}}],["beta$",{"2":{"224":1}}],["betas=",{"2":{"193":1}}],["beta",{"2":{"105":6,"137":4}}],["begin",{"2":{"105":1,"131":3,"145":1,"146":1,"230":1,"237":1,"282":2,"289":1,"300":1,"306":1}}],["be",{"2":{"97":1,"227":1,"272":1,"302":1,"305":2}}],["beep",{"2":{"67":2}}],["b",{"2":{"64":4,"100":4,"109":15,"119":14,"125":14,"129":16,"158":2,"160":7,"172":1,"181":2,"188":3,"211":1,"220":3,"228":1,"245":1,"251":4,"252":3,"277":31,"282":8,"296":2,"297":9,"304":1}}],["bidirectional",{"2":{"306":1}}],["bigger",{"2":{"305":1}}],["bits",{"2":{"293":1}}],["bits=8",{"2":{"293":1}}],["billion",{"0":{"237":1}}],["bias=bias",{"2":{"246":4}}],["bias=false",{"2":{"136":3,"186":1,"246":1}}],["bias",{"2":{"129":1,"133":1,"186":2}}],["bird",{"2":{"59":4}}],["bing",{"2":{"294":1}}],["bin",{"2":{"50":1}}],["bin目录等重组在一起",{"2":{"50":1}}],["ba×b",{"2":{"277":1}}],["bahdanau注意力模型",{"0":{"183":1},"1":{"199":1,"214":1}}],["ba",{"2":{"109":2}}],["basemodel",{"2":{"305":2}}],["basemoe",{"2":{"97":2}}],["base",{"2":{"225":1}}],["baseschedulestrategy",{"2":{"225":1}}],["based",{"2":{"141":1,"161":1}}],["basicexpert",{"2":{"97":2}}],["basic",{"0":{"97":1},"2":{"89":1,"97":3}}],["baz",{"2":{"89":2}}],["barrier",{"0":{"227":1},"2":{"141":1,"227":9}}],["bar",{"0":{"227":1},"2":{"89":2,"227":3,"257":2,"268":2,"285":4,"292":2}}],["backends",{"2":{"272":1,"282":1}}],["backend=",{"2":{"141":1,"299":1}}],["backend",{"2":{"141":1,"272":1,"299":5}}],["backtick",{"2":{"135":6}}],["backward这一",{"2":{"225":1}}],["backward返回的值其实就对应了forward的input",{"2":{"133":1}}],["backward的return值的数量要和forward中",{"2":{"133":1}}],["backward",{"2":{"106":1,"110":1,"129":2,"133":2,"145":2,"159":7,"186":1,"193":1,"203":1,"225":2,"290":3,"295":1,"300":2,"312":1}}],["back",{"2":{"52":1,"101":1}}],["background",{"2":{"50":1}}],["bath",{"2":{"97":1}}],["bathnorm由哪些小算子构成",{"0":{"37":1}}],["batch1的fwd执行完毕",{"2":{"275":1}}],["batch1",{"2":{"275":1}}],["batch也进一步划分为若干micro",{"2":{"265":1}}],["batches",{"2":{"187":2,"202":2,"295":4}}],["batch",{"0":{"137":1,"309":1},"2":{"94":2,"97":6,"101":12,"110":2,"129":15,"136":6,"137":2,"141":6,"150":5,"160":2,"178":4,"183":9,"187":8,"199":2,"202":9,"246":10,"265":2,"275":2,"282":6,"289":1,"300":8,"306":4,"310":19,"312":7}}],["batchnorm精度问题",{"2":{"37":1}}],["batchnorm和softmax在什么情况下计算结果可能会出现精度问题",{"0":{"37":1}}],["batchnorm",{"2":{"23":1,"137":1}}],["bra",{"2":{"227":2}}],["break",{"2":{"126":1}}],["breaks",{"2":{"41":1}}],["broadcasting",{"2":{"101":1}}],["br",{"2":{"41":4}}],["blog",{"2":{"180":1}}],["blocks",{"2":{"70":5,"94":3}}],["block",{"2":{"67":2,"70":15,"77":2,"94":2,"107":4,"265":1}}],["blockquote",{"2":{"52":3,"59":2}}],["blockquotes",{"0":{"52":1}}],["block的模型结构",{"0":{"30":1}}],["blink",{"2":{"135":1}}],["blink>`",{"2":{"135":1}}],["blue",{"2":{"59":3,"298":1}}],["blank",{"2":{"40":1}}],["才能在",{"2":{"26":1,"34":1,"36":1,"39":1}}],["才能放到链接标签的",{"2":{"26":1,"34":1,"36":1,"39":1}}],["都无法实现真正意义上的并行",{"2":{"232":1}}],["都有他对应的汇编器",{"2":{"190":1}}],["都要求满足",{"2":{"87":1}}],["都会被初始化为int",{"2":{"194":1}}],["都会被",{"2":{"183":1}}],["都会被移除",{"2":{"67":1}}],["都会帮你处理",{"2":{"67":1}}],["都可以",{"2":{"205":1}}],["都可以有效果",{"2":{"46":1}}],["都可以直接在文件里面用",{"2":{"19":1,"27":1,"29":1,"31":1}}],["都转换为",{"2":{"26":1,"34":1,"36":1,"39":1}}],["写一些优雅退出的handler去退出train进程",{"2":{"287":1}}],["写为const",{"2":{"156":1}}],["写操作",{"2":{"64":2}}],["写出batchnorm和softmax的公式",{"0":{"37":1}}],["写",{"2":{"26":1,"34":1,"36":1,"39":1}}],["将第一个warp的sync放到下一次循环的开头",{"2":{"292":1}}],["将第一项",{"2":{"246":1}}],["将dispatcher和combiner这两个all2all通信算子",{"2":{"290":1}}],["将不同的层划分到不同的机器上",{"2":{"265":1}}],["将不会对这段文字做修改",{"2":{"26":1,"34":1,"36":1,"39":1}}],["将这些索引直接输入神经网络会导致没什么意义",{"2":{"282":1}}],["将这",{"2":{"230":1}}],["将上下文向量",{"2":{"214":1}}],["将reg0中16bit数据存入smem1",{"2":{"211":1}}],["将其输入",{"2":{"214":1}}],["将其类型转化为std",{"2":{"207":1}}],["将其对应到该属于的experts中",{"2":{"111":1}}],["将输入序列",{"2":{"199":1}}],["将输出映射为概率分布",{"2":{"146":1}}],["将x变形为",{"2":{"183":1}}],["将t",{"2":{"172":1}}],["将亡值",{"2":{"172":2}}],["将moving",{"2":{"137":1}}],["将mlp层变化为多个expert",{"2":{"97":1}}],["将词元列表展平成一个列表",{"2":{"126":1}}],["将词元映射为数字",{"2":{"126":1}}],["将文本转换为数字索引序列",{"2":{"126":1}}],["将文本作为字符串加载到内存中",{"2":{"126":1}}],["将拆分的词元映射到数字索引",{"2":{"126":1}}],["将字符串拆分为词元",{"2":{"126":1}}],["将两个向量映射为标量",{"2":{"122":1}}],["将parameters分片到多卡上",{"2":{"121":1}}],["将grad分片到多卡上",{"2":{"121":1}}],["将optimizer分片",{"2":{"121":1}}],["将某层的输出",{"2":{"115":1}}],["将过去四个时间点作为数据",{"2":{"110":1}}],["将选择引导至感官输入",{"2":{"79":1}}],["将内存模型分为三类relaxd",{"2":{"64":1}}],["将各个库的lib目录",{"2":{"50":1}}],["将会把它转换为",{"2":{"26":1,"34":1,"36":1,"39":1}}],["5bs^2a",{"2":{"297":1}}],["5bs^2a11bsh+5bs2a",{"2":{"297":1}}],["55",{"2":{"291":3}}],["5d",{"2":{"257":3,"268":2}}],["528",{"2":{"123":1}}],["512支持更好",{"2":{"221":1}}],["512",{"2":{"94":2,"97":1,"123":3,"193":1,"253":1,"282":1}}],["5000",{"2":{"193":2}}],["50",{"2":{"93":1,"221":2,"235":1,"300":1}}],["5",{"0":{"139":1,"161":1,"169":1,"252":1},"1":{"187":1,"202":1},"2":{"26":2,"34":2,"36":2,"39":2,"46":1,"89":1,"93":2,"94":2,"103":1,"106":3,"107":1,"110":1,"129":1,"137":1,"160":1,"188":2,"201":2,"220":2,"221":1,"233":2,"235":2,"257":2,"268":2,"282":1,"293":1,"295":3}}],["4bsh4bsh4bsh",{"2":{"297":1}}],["4bsh2∗2∗bsh=4bsh",{"2":{"297":1}}],["4bs^2h",{"2":{"277":1}}],["4bs^2h24bsh2+4bs2h",{"2":{"277":1}}],["4h",{"2":{"277":12}}],["4h2+6h",{"2":{"224":1}}],["4h2+6h4h^2",{"2":{"224":1}}],["4+4",{"2":{"256":2}}],["4有四个元素",{"2":{"211":1}}],["4>",{"2":{"211":1}}],["4f",{"2":{"193":1}}],["4δ4",{"2":{"145":1}}],["4xi4x",{"2":{"145":1}}],["4x",{"2":{"145":4,"159":1}}],["4x3​",{"2":{"145":1}}],["4x3",{"2":{"145":1}}],["4x2​",{"2":{"145":1}}],["4x2",{"2":{"145":1}}],["4x1​=4",{"2":{"145":1}}],["4x1​",{"2":{"145":1}}],["4x1",{"2":{"145":1}}],["4x0​",{"2":{"145":1}}],["4x0",{"2":{"145":1}}],["4表示卷积层",{"2":{"137":1}}],["48",{"2":{"123":2}}],["480",{"2":{"123":1}}],["4ac",{"2":{"119":2}}],["4096",{"2":{"94":4}}],["40",{"2":{"89":1,"136":1,"221":1}}],["496012402",{"2":{"47":1}}],["4",{"0":{"122":1,"125":1,"140":1,"146":1,"147":1,"235":1,"262":1,"300":1},"1":{"136":1,"150":1,"154":1},"2":{"26":2,"34":2,"36":2,"39":2,"46":1,"59":1,"67":2,"70":2,"89":4,"94":1,"100":1,"103":1,"110":2,"119":4,"123":1,"129":3,"136":1,"137":1,"145":3,"159":5,"188":2,"211":11,"214":1,"220":9,"227":1,"233":3,"235":1,"252":2,"256":4,"257":2,"268":2,"281":2,"292":2,"305":1,"310":1}}],["那就是seq2seq模型",{"2":{"310":1}}],["那就是配置项的废弃迁移",{"2":{"305":1}}],["那就是序列往往很长",{"2":{"169":1}}],["那就是如果你有更好的exp实现方式",{"2":{"133":1}}],["那就是一个二维图像一般需要三维表达",{"2":{"125":1}}],["那什么情况不会创建节点呢",{"2":{"133":1}}],["那么这一部分我们就可以缓存下来",{"2":{"304":1}}],["那么这样的话整个序列的估计值都将通过以下的方式获得",{"2":{"110":1}}],["那么如果某个词元为",{"2":{"282":1}}],["那么如果我的自变量是二维的呢",{"2":{"114":1}}],["那么",{"2":{"277":1,"310":1}}],["那么gpu0被分配到的层会变为0",{"2":{"275":1}}],["那么梯度元素数量为",{"2":{"256":1}}],["那么梯度会一直存在",{"2":{"146":1}}],["那么当前多输入输出卷积层的weight就会有多个卷积核张量",{"2":{"250":1}}],["那么当",{"2":{"233":1}}],["那么当二者很相近的时候",{"2":{"37":1}}],["那么卷积核的输入通道数也为",{"2":{"233":1}}],["那么卷积层的实现也简单起来",{"2":{"186":1}}],["那么参数量为",{"2":{"224":1}}],["那么对于计算密集型就会有很好的表现",{"2":{"232":1}}],["那么对于io任务就会有很好的表现",{"2":{"232":1}}],["那么对于一个未知对象使用传值通常会造成不必要的拷贝",{"2":{"209":1}}],["那么对于y",{"2":{"159":1}}],["那么解码时间步",{"2":{"183":1}}],["那么具有bahdanau注意力的rnn",{"2":{"183":1}}],["那么右值引用其实就是对右值的引用",{"2":{"172":1}}],["那么各个线程之间其实无法实现真正意义上的并行",{"2":{"152":1}}],["那么查询为",{"2":{"150":1}}],["那么两个向量的点积的均值为0",{"2":{"150":1}}],["那么其实这里就会将query和key连结",{"2":{"136":1}}],["那么其实∇f",{"2":{"114":1}}],["那么你还需要返回一个weight的梯度",{"2":{"133":1}}],["那么θ",{"2":{"129":1}}],["那么权重就会变为四维张量",{"2":{"125":1}}],["那么操作也应该是将三原色拟合为一个通道",{"2":{"125":1}}],["那么注意力汇聚函数就可以表示为值的加权和",{"2":{"122":1}}],["那么它的梯度也为一维向量",{"2":{"114":1}}],["那么我们的输出其实就是输入往后移一位",{"2":{"263":1}}],["那么我们可以得知",{"2":{"251":1}}],["那么我们可以得到计算公式",{"2":{"251":1}}],["那么我们需要每一次保存前一个时间步的隐藏变量",{"2":{"251":1}}],["那么我们需要为每个输出通道创建一个",{"2":{"250":1}}],["那么我们增加了隐藏层状态该如何理解呢",{"2":{"251":1}}],["那么我们一般这样计算",{"2":{"251":1}}],["那么我们通常会使用tuple将其存起来",{"2":{"207":1}}],["那么我们希望通过",{"2":{"146":1}}],["那么我们求梯度的过程其实是对其求偏导",{"2":{"131":1}}],["那么我们",{"2":{"125":1}}],["那么我们就有了限域和非限域两种写法",{"2":{"207":1}}],["那么我们就需要不断地计算这样的概率",{"2":{"140":1}}],["那么我们就可以观察很短的一个历史",{"2":{"110":1}}],["那么我们就称这个序列满足马尔科夫条件",{"2":{"110":1}}],["那么我们每次预测",{"2":{"110":1}}],["那么我们如何使用cuda来实现一版gemm呢",{"2":{"70":1}}],["那么就会采用uint8量化的activation和int8量化的weight",{"2":{"298":1}}],["那么就会启动8个training",{"2":{"287":1}}],["那么就是mpi的上位替代",{"2":{"272":1}}],["那么就代表我们的",{"2":{"109":1}}],["那么就可以将模型表示为如下的结构",{"2":{"100":1}}],["那么分配给这个键对应的",{"2":{"93":1}}],["那也不一定需要",{"2":{"59":1}}],["那会看起来像是你强迫断行",{"2":{"52":1}}],["那",{"2":{"26":1,"34":1,"36":1,"39":1,"59":1}}],["支持rdma",{"2":{"272":1}}],["支持生成该指令代码",{"2":{"253":1}}],["支持在下面这些符号前面加上反斜线来帮助插入普通的符号",{"2":{"213":1}}],["支持比较简短的自动链接形式来处理网址和电子邮件信箱",{"2":{"198":1}}],["支持两种形式的链接语法",{"2":{"104":1}}],["支持两种标题的语法",{"2":{"46":1}}],["支持多种编程语言",{"2":{"89":1}}],["支持有序列表和无序列表",{"2":{"59":1}}],["支持",{"2":{"26":1,"34":1,"36":1,"39":1}}],["因其在计算机视觉任务中的高效性能而受到广泛关注",{"2":{"295":1}}],["因为训练过程中各种weight或者其他状态都是在显存中的",{"2":{"305":1}}],["因为训练框架参数众多",{"2":{"305":1}}],["因为我在megatron之中并没有看到弹性训练的东西",{"2":{"302":1}}],["因为我们执行计算的时候",{"2":{"293":1}}],["因为我们的0",{"2":{"286":1}}],["因为我们的目标是根据过去和当前的词元预测下一个词元",{"2":{"263":1}}],["因为我们模型生成的语言需要是更为符合语义",{"2":{"274":1}}],["因为我们不能保证释放锁的时候一定完成了某个操作数据的语句",{"2":{"152":1}}],["因为我们是cuda项目",{"2":{"50":1}}],["因为已经调用了mean函数",{"2":{"300":1}}],["因为在当今训练中",{"2":{"290":1}}],["因为在此期间模型会自我更新",{"2":{"289":1}}],["因为在c++中有规定",{"2":{"158":1}}],["因为这是一个很好的衡量",{"2":{"274":1}}],["因为这是python操作",{"2":{"133":1}}],["因为nccl局限于cuda",{"2":{"272":1}}],["因为rnn是分层的",{"2":{"269":1}}],["因为太简单了",{"2":{"261":1}}],["因为每个通道不是独立学习的",{"2":{"250":1}}],["因为是基于单线程的事件循环",{"2":{"232":1}}],["因为mbarrier可以同时用来同步threads",{"2":{"227":1}}],["因为只需要区分上一个phase",{"2":{"227":1}}],["因为由下一个stage的input",{"2":{"225":1}}],["因为对于inference来说",{"2":{"225":1}}],["因为调度策略分为很多",{"2":{"225":1}}],["因为网络io也是一个比较慢的操作",{"2":{"215":1}}],["因为右值无法绑定到左值上",{"2":{"209":1}}],["因为返回一个引用允许用户来修改容器",{"2":{"209":1}}],["因为卷积核是从数据中学习到的",{"2":{"186":1}}],["因为gil锁的粒度为进程",{"2":{"184":1}}],["因为gil机制下",{"2":{"167":1}}],["因为它提供了一个单一的度量",{"2":{"177":1}}],["因为0和null会被推断为int和整形",{"2":{"175":1}}],["因为线程的切换也是会产生开销的",{"2":{"167":1}}],["因为一次训练多条数据",{"2":{"160":1}}],["因为该语句不一定是原子操作",{"2":{"152":1}}],["因为他表达的运算其实是互相关运算",{"2":{"186":1}}],["因为他告诉了我们一种方式",{"2":{"145":1}}],["因为他可以被视为一个输入映射到下一层的空间维度的转换器",{"2":{"139":1}}],["因为反向传播计算的是总损失",{"2":{"129":1}}],["因为同时不除的话效果等价",{"2":{"129":1}}],["因为可能存在风险",{"2":{"89":2}}],["因为const承诺不会修改对象",{"2":{"172":1}}],["因为conda",{"2":{"50":1}}],["因为cudatoolkit已经被打乱重组到环境中了",{"2":{"50":1}}],["因为",{"2":{"26":1,"34":1,"36":1,"39":1}}],["因此将上述中间激活相加",{"2":{"297":1}}],["因此高度和宽度都减少了4个像素",{"2":{"295":1}}],["因此前向传递",{"2":{"291":1}}],["因此有",{"2":{"269":1}}],["因此有很多人用它写博客",{"2":{"12":1,"20":1,"22":1,"24":1}}],["因此计算复杂度为",{"2":{"269":1}}],["因此被称为",{"2":{"258":1}}],["因此其可学习的参数",{"2":{"230":1}}],["因此我们在处理数据时需要解决这个问题",{"2":{"169":1}}],["因此从形状中移除最后那个维度",{"2":{"136":1}}],["因此这一篇文章的目标就是深入了解pytorch梯度计算的代码实现与内部原理",{"2":{"130":1}}],["因此这种类型不方便模型使用",{"2":{"126":1}}],["因此下面两个链接是一样的",{"2":{"104":1}}],["因此float32类型下的计算量单位为flops",{"2":{"49":1}}],["因此",{"2":{"7":1,"12":1,"13":1,"15":1,"17":1,"20":1,"22":1,"24":1,"87":1,"96":1,"177":1,"230":1,"250":1,"256":1,"274":2,"284":1,"297":1}}],["就使用torchbackend",{"2":{"299":1}}],["就使用的是cp",{"2":{"268":1}}],["就越大",{"2":{"273":1}}],["就被破坏",{"2":{"266":1}}],["就这样我们完成了权重的更新",{"2":{"263":1}}],["就如同当前时间步下神经网络的状态和记忆一样",{"2":{"251":1}}],["就为",{"2":{"246":1}}],["就只需要理解这张图",{"2":{"237":1}}],["就得扩大",{"2":{"234":1}}],["就自动减一",{"2":{"227":1,"244":1}}],["就无法作为左值来使用",{"2":{"209":1}}],["就必须要更换汇编器",{"2":{"190":1}}],["就正常推导",{"2":{"179":1}}],["就提供了一个明确的",{"2":{"177":1}}],["就形成了encoder",{"2":{"147":1}}],["就视为不需要掩蔽",{"2":{"122":1}}],["就要用什么符号结束",{"2":{"120":1}}],["就像是注解一样",{"2":{"104":1}}],["就是用encoder和decoder都使用rnn来实现",{"2":{"310":1}}],["就是通过enum将名字和字段编号关联起来以避免上述按标号的晦涩访问",{"2":{"207":1}}],["就是如果更换平台的话",{"2":{"190":1}}],["就是在问",{"2":{"177":1}}],["就是int之类的变量或者表达式的静态属性",{"2":{"172":1}}],["就是对其求偏导",{"2":{"114":1}}],["就是一种通用的解决方案",{"2":{"100":1}}],["就是将一个",{"2":{"100":1}}],["就是列表",{"2":{"7":1,"13":1,"15":1,"17":1}}],["就需要构建概率的分布",{"2":{"100":1}}],["就需要缩进",{"2":{"59":1}}],["就很难理解文章原始的意思",{"2":{"96":1}}],["就可以返回",{"2":{"209":1}}],["就可以互相链接",{"2":{"205":1}}],["就可以计算下去",{"2":{"110":1}}],["就可以",{"2":{"67":1}}],["就可以了",{"2":{"50":1}}],["就会继续往下选择",{"2":{"298":1}}],["就会开始执行bwd",{"2":{"275":1}}],["就会较为冗余",{"2":{"207":1}}],["就会遵循一致的格式",{"2":{"205":1}}],["就会自动把它转成链接",{"2":{"198":1}}],["就会缺乏一个统一的量度来衡量整体的变化",{"2":{"177":1}}],["就会发现我们需要使用自己预测出来的数据来预测",{"2":{"110":1}}],["就会使得weight变为",{"2":{"106":1}}],["就会出现精度损失",{"2":{"37":1}}],["就会将它转为",{"2":{"26":1,"34":1,"36":1,"39":1}}],["但与输入数据的大小无关",{"2":{"301":1}}],["但包含了dropout操作需要用到的mask矩阵",{"2":{"297":1}}],["但不用",{"2":{"213":1}}],["但有时候为了高效计算",{"2":{"201":1}}],["但并无法全部挡下来",{"2":{"198":1}}],["但依旧获得高效用的模型",{"2":{"153":1}}],["但会修改原始张量",{"2":{"133":1}}],["但我们建议你显式指定",{"2":{"103":1}}],["但是总体来说config也是写的比较乱",{"2":{"305":1}}],["但是现代pytorch已经将这些繁琐的工作收敛进torch之中",{"2":{"299":1}}],["但是目前只是对torch",{"2":{"299":1}}],["但是目前可以知道的是",{"2":{"209":1}}],["但是注意activation不使用per",{"2":{"298":1}}],["但是第二项由于包含activation",{"2":{"298":1}}],["但是bytes占用为1",{"2":{"297":1}}],["但是不会进行预测",{"2":{"289":1}}],["但是不生成任何输出",{"2":{"289":1}}],["但是不声明的话",{"2":{"207":1}}],["但是为了处理方便",{"2":{"282":1}}],["但是带来的好处是",{"2":{"275":1}}],["但是self",{"2":{"269":1}}],["但是经由mutable修饰的成员变量",{"2":{"266":1}}],["但是十分流行的卷积层",{"2":{"262":1}}],["但是有了注意力机制后",{"2":{"258":1}}],["但是有的时候我们会有其他的要求",{"2":{"117":1}}],["但是从如今的视角来看",{"2":{"237":1}}],["但是无需做一次sync",{"2":{"237":1}}],["但是需要在gelu前做一次sync",{"2":{"237":1}}],["但是模型的参数会指数增长",{"2":{"234":1}}],["但是仍然不能和async的性能作比较",{"2":{"232":1}}],["但是多线程是创建更多的线程来分别去执行任务",{"2":{"232":1}}],["但是多进程有诸多缺点",{"2":{"184":1}}],["但是我们需要做一些改进",{"2":{"312":1}}],["但是我们可以先看一下load",{"2":{"305":1}}],["但是我们可以看出",{"2":{"304":1}}],["但是我们仍然需要其grad",{"2":{"225":1}}],["但是我们忽略了图像的另外一个特点",{"2":{"125":1}}],["但是chunk变了",{"2":{"275":1}}],["但是clang编译出的机器码",{"2":{"221":1}}],["但是c++14可以自动推导lambda表达式返回值",{"2":{"209":1}}],["但是可以给编译后的目标文件带来较大的提升",{"2":{"221":1}}],["但是可以通过指针来改变其指向的对象t的属性",{"2":{"156":1}}],["但是decltype也会产生一些意想不到的结果",{"2":{"209":1}}],["但是更一般化地",{"2":{"207":1}}],["但是对于ctx",{"2":{"225":1}}],["但是对于第一种",{"2":{"207":1}}],["但是对于取值的时候",{"2":{"207":1}}],["但是对于表格和图像数据",{"2":{"96":1}}],["但是并不总是这样",{"2":{"207":1}}],["但是并不区分大小写",{"2":{"104":1}}],["但是格式是相同的话",{"2":{"205":1}}],["但是格式需要符合huggingface格式",{"2":{"141":1}}],["但是输出的目标文件格式",{"2":{"205":1}}],["但是auto类型推导假定花括号初始化代表std",{"2":{"194":1}}],["但是auto就不行",{"2":{"194":1}}],["但是也有一些不同",{"2":{"194":1,"232":1}}],["但是typedef不行",{"2":{"192":1}}],["但是一种硬件架构可以有多种汇编器",{"2":{"190":1}}],["但是一般cuda开发都需要ssh",{"2":{"50":1}}],["但是提供了一个与",{"2":{"159":1}}],["但是其实我们也可以提供一个与",{"2":{"159":1}}],["但是其实也可以缩进",{"2":{"59":1}}],["但是通过实验发现",{"2":{"154":1}}],["但是由于cpython",{"2":{"152":1}}],["但是python中却不同",{"2":{"152":1}}],["但是点积操作要求查询和键具有相同的长度",{"2":{"150":1}}],["但是这里就只介绍pytorch自带的原生保存",{"2":{"305":1}}],["但是这里带来了一些问题",{"2":{"209":1}}],["但是这种数据的保存",{"2":{"225":1}}],["但是这样存在诸多局限性",{"2":{"223":1}}],["但是这样其实忽略了单词本来的意义",{"2":{"140":1}}],["但是这个",{"2":{"59":1}}],["但是如果使用g++",{"2":{"205":1}}],["但是如果我们持续预测下去",{"2":{"110":1}}],["但是如果你的",{"2":{"120":1}}],["但是如果你很懒",{"2":{"59":1}}],["但是如果你是写",{"2":{"26":1,"34":1,"36":1,"39":1}}],["但是如果你这样写",{"2":{"26":1,"34":1,"36":1,"39":1}}],["但是用行内形式的链接却会增加到",{"2":{"104":1}}],["但是在之前的auto推导中我们得知",{"2":{"209":1}}],["但是在处理图像数据的时候",{"2":{"82":1}}],["但是在计算机实现上我们有更加有趣的方法",{"2":{"73":1}}],["但是实际上会受限于sm的数量和资源",{"2":{"70":1}}],["但是优点是环境干净隔离",{"2":{"50":1}}],["但是",{"2":{"41":1,"87":1}}],["但是你要小心跳脱字元的使用",{"2":{"26":1,"34":1,"36":1,"39":1}}],["但在一些语法和渲染效果上有改动",{"2":{"7":1,"13":1,"15":1,"17":1}}],["h​tq",{"2":{"304":1}}],["h​qkt​",{"2":{"277":1}}],["hybrid",{"2":{"302":1}}],["hn​=ϕ",{"2":{"296":1}}],["hn=ϕ",{"2":{"296":1}}],["hh",{"2":{"251":2,"282":4}}],["hhh",{"2":{"109":2,"110":1,"136":2,"210":1,"230":5,"241":1,"284":1,"297":1}}],["hq",{"2":{"251":3,"282":4}}],["hw",{"2":{"251":1}}],["h=ϕ",{"2":{"251":2}}],["h∈rn⋅h",{"2":{"251":1}}],["h∈rn⋅hh",{"2":{"251":1}}],["hp",{"2":{"230":1}}],["hph​",{"2":{"201":1}}],["hvhvhv",{"2":{"224":1}}],["h~2~o",{"2":{"148":1}}],["hf",{"2":{"141":6,"305":1}}],["hi​=f",{"2":{"230":1}}],["hi=f",{"2":{"230":1}}],["hih",{"2":{"230":1}}],["hint",{"2":{"211":2,"257":1,"268":1}}],["hidden",{"2":{"136":1,"183":9,"199":2,"251":1,"306":1}}],["hiddens=16",{"2":{"310":2}}],["hiddens=num",{"2":{"183":1,"282":1}}],["hiddens=8",{"2":{"136":1}}],["hiddens",{"2":{"136":5,"183":14,"246":15,"269":4,"282":15,"306":6,"310":16}}],["highlight",{"2":{"89":3}}],["highlighted",{"2":{"89":8}}],["hub",{"2":{"126":1}}],["handle",{"2":{"257":1,"268":1}}],["hat和y",{"2":{"300":1}}],["hat的shape为",{"2":{"300":1}}],["hat",{"2":{"129":3,"137":3,"160":14,"186":2,"295":3,"300":2,"312":2}}],["has",{"2":{"104":2,"290":1}}],["have",{"2":{"101":2}}],["hardware",{"0":{"55":1}}],["hot",{"2":{"131":1,"282":1,"306":1}}],["hooks",{"2":{"225":1}}],["hook",{"2":{"70":1}}],["hook=pre",{"2":{"70":1}}],["hook=none",{"2":{"70":1}}],["hopper架构下",{"2":{"227":1}}],["hopper的新特性",{"2":{"70":1}}],["hopper",{"2":{"55":1,"227":1}}],["heavy",{"2":{"290":1}}],["heads次",{"2":{"246":1}}],["heads",{"2":{"101":25,"147":2,"161":3,"178":3,"193":2,"246":22}}],["head",{"0":{"81":1,"101":1},"2":{"47":1,"87":1,"101":3,"116":1,"147":1,"161":2,"230":1,"277":6}}],["header",{"2":{"46":6,"50":1,"52":1}}],["height",{"2":{"257":1,"268":1}}],["helps",{"2":{"116":1}}],["hello",{"2":{"89":7,"179":1,"194":1,"205":3}}],["here",{"2":{"52":1,"67":1,"104":7,"135":2}}],["hendrerit",{"2":{"52":2,"59":3}}],["h",{"2":{"49":6,"73":3,"109":12,"110":2,"125":9,"129":2,"136":3,"183":2,"186":5,"196":1,"201":5,"211":2,"230":7,"233":2,"234":3,"246":1,"250":2,"251":7,"262":3,"277":19,"281":4,"282":9,"296":2,"297":6,"304":3}}],["h6",{"2":{"46":1}}],["h5",{"2":{"46":1}}],["h4",{"2":{"46":1}}],["h3",{"2":{"46":1}}],["h2o",{"2":{"148":1}}],["h2",{"2":{"46":2}}],["h1⋮hh",{"2":{"230":1}}],["h1",{"2":{"46":2}}],["href=",{"2":{"104":5,"198":2}}],["href",{"2":{"26":1,"34":1,"36":1,"39":1}}],["ht=ϕ",{"2":{"251":1}}],["ht=f",{"2":{"234":1}}],["ht=g",{"2":{"110":1}}],["ht",{"2":{"183":2}}],["ht−1h",{"2":{"234":1,"251":1,"282":1}}],["ht−1​",{"2":{"110":1,"234":2,"251":1,"282":1}}],["ht−1",{"2":{"110":1,"234":1}}],["ht​=ϕ",{"2":{"251":1}}],["ht​=f",{"2":{"234":1}}],["ht​=g",{"2":{"110":1}}],["ht​",{"2":{"110":1,"183":2}}],["hth",{"2":{"110":2,"183":1}}],["http",{"2":{"26":2,"34":2,"36":2,"39":2,"104":24,"198":2}}],["https",{"2":{"14":2,"47":1,"89":3,"268":2}}],["html",{"0":{"19":1,"27":1,"29":1,"31":1},"2":{"7":2,"13":2,"15":2,"17":2,"19":5,"26":13,"27":5,"29":5,"31":5,"34":13,"36":13,"39":13,"41":1,"59":3,"67":2,"104":3,"135":2,"198":1,"268":2}}],["n​",{"2":{"301":1}}],["n+1",{"2":{"296":2,"304":1}}],["n1​t=1∑n​−logp",{"2":{"274":1}}],["n^2d",{"2":{"269":1}}],["n2d",{"2":{"269":2}}],["n∗dn",{"2":{"269":1}}],["nd^2",{"2":{"269":1}}],["nd2",{"2":{"269":2}}],["ny1​",{"2":{"258":1}}],["nx1​",{"2":{"258":1}}],["n−1n",{"2":{"234":1}}],["nh",{"2":{"296":1}}],["nh​−kh​+ph​+1",{"2":{"201":1}}],["nh​−kh​+1",{"2":{"186":1}}],["nh−kh+ph+1",{"2":{"201":1}}],["nh−kh+1",{"2":{"186":1}}],["nw​−kw​+pw​+1",{"2":{"201":1}}],["nw​−kw​+1",{"2":{"186":1}}],["nw−kw+pw+1",{"2":{"201":1}}],["nw−kw+1",{"2":{"186":1}}],["nwkernelregression",{"2":{"106":2}}],["nullptr",{"0":{"175":1},"2":{"175":1}}],["num的话",{"2":{"227":1}}],["numel",{"2":{"160":1,"188":1,"295":1,"300":2}}],["numpy",{"2":{"129":1}}],["numbers",{"2":{"305":1}}],["number=2",{"2":{"97":1}}],["number",{"2":{"97":5,"101":2,"285":1}}],["num",{"2":{"70":7,"94":6,"101":15,"129":10,"136":7,"137":7,"147":2,"160":10,"161":3,"178":6,"183":19,"187":11,"193":4,"199":2,"202":16,"211":1,"225":1,"227":1,"246":37,"269":4,"282":22,"289":2,"292":2,"295":10,"300":7,"306":15,"310":33,"312":9}}],["num=30",{"2":{"26":2,"34":2,"36":2,"39":2}}],["nccl一般作为gloo的备选方案",{"2":{"272":1}}],["nccl",{"2":{"141":1,"272":3,"299":1}}],["np",{"2":{"129":1}}],["ni​∝iα1​",{"2":{"154":1}}],["ni∝1iαn",{"2":{"154":1}}],["nin",{"0":{"107":1},"2":{"107":4,"154":1}}],["nisl",{"2":{"52":2,"59":3}}],["nn",{"2":{"94":16,"97":6,"101":5,"106":4,"107":14,"110":7,"116":4,"117":5,"122":2,"123":33,"126":2,"129":4,"132":1,"136":5,"137":5,"147":4,"150":2,"160":1,"161":5,"178":7,"183":3,"186":4,"193":1,"201":4,"246":5,"269":2,"281":4,"295":19,"296":1,"300":3,"306":6,"308":3,"310":5,"312":5}}],["nnn",{"2":{"38":1,"100":2,"115":1,"131":2,"146":1,"150":1,"186":1,"234":3,"251":1,"269":4,"274":1,"282":3,"296":1,"304":1}}],["native",{"2":{"216":1}}],["nas",{"2":{"216":1}}],["nasm",{"2":{"190":2}}],["nabla",{"2":{"114":3,"119":8}}],["nadaraya",{"2":{"93":2}}],["names",{"2":{"312":1}}],["namespaces=",{"2":{"305":1}}],["name=true",{"2":{"305":1}}],["name=",{"2":{"141":1}}],["name",{"2":{"89":2,"97":1,"123":1,"141":6,"193":1,"194":3,"299":1,"305":5}}],["nv",{"2":{"299":1}}],["nvlink等均不构成强依赖",{"2":{"272":1}}],["nvidia",{"2":{"50":1,"268":2}}],["nvcc",{"2":{"50":2}}],["n×c×h×wn",{"2":{"49":1}}],["need",{"2":{"305":1}}],["neighbor",{"2":{"268":8}}],["new和",{"2":{"310":1}}],["new",{"2":{"156":2,"171":2,"282":1,"305":24,"310":2}}],["neq",{"2":{"131":3,"146":1}}],["ne",{"2":{"119":2}}],["net",{"2":{"94":2,"104":3,"106":3,"107":1,"110":11,"129":9,"160":6,"282":3,"289":5,"295":14,"296":4,"300":12,"312":7}}],["networks",{"0":{"116":1},"2":{"116":1}}],["network",{"0":{"280":1},"2":{"87":1,"147":1,"161":1,"224":1,"305":2}}],["next",{"2":{"89":2,"133":1,"292":1,"295":1}}],["nested",{"2":{"52":1,"305":4}}],["necessary",{"2":{"302":1}}],["nec",{"2":{"52":2,"59":3}}],["neat",{"2":{"45":2}}],["neural",{"2":{"38":1,"147":1,"161":1}}],["node",{"2":{"290":1}}],["nodes",{"2":{"141":1}}],["noexcept也是同理",{"2":{"239":1}}],["noexcept",{"0":{"239":1},"2":{"207":3,"239":1}}],["nonlinearity",{"2":{"237":1}}],["non",{"0":{"292":1},"2":{"179":1,"257":1,"292":2}}],["none",{"2":{"101":1,"106":1,"110":1,"122":1,"126":2,"141":1,"246":1,"294":1,"295":3,"299":2,"300":2,"302":2,"305":1,"312":3}}],["nopeak",{"2":{"178":2}}],["now",{"2":{"141":1}}],["no",{"2":{"104":2,"129":3,"133":1,"160":1,"295":2,"312":1}}],["notation",{"2":{"305":1}}],["notimplementederror",{"2":{"183":1,"308":3}}],["not",{"2":{"101":1,"103":1,"126":3,"137":1,"227":1,"246":1,"294":1,"295":1,"300":1,"302":1,"305":4,"306":2}}],["note",{"2":{"77":3,"89":2,"227":1}}],["notes",{"0":{"14":1}}],["norm层",{"2":{"297":1}}],["norm3",{"2":{"161":2}}],["norm2",{"2":{"147":2,"161":2}}],["norm1",{"2":{"147":2,"161":2}}],["norm",{"2":{"137":2,"296":3}}],["normalization",{"0":{"137":1},"2":{"87":1,"147":1,"161":1,"224":2,"297":2}}],["normal",{"2":{"67":2,"93":1,"110":1,"116":1,"129":4,"136":1,"160":2,"170":1,"257":1,"262":2,"268":1,"282":4,"305":1}}],["noreferrer",{"2":{"40":1}}],["n",{"2":{"38":1,"49":5,"70":6,"93":4,"106":23,"110":3,"115":2,"131":10,"146":1,"150":2,"154":1,"159":3,"160":2,"171":2,"186":2,"201":2,"205":1,"211":6,"227":13,"251":2,"253":1,"257":11,"258":2,"268":12,"269":11,"274":2,"285":9,"292":4,"293":2,"296":4,"301":5,"304":2,"305":3,"310":1}}],["像是星号便只是星号",{"2":{"67":1}}],["像是下面这样的写法",{"2":{"59":1}}],["像是",{"2":{"26":1,"34":1,"36":1,"39":1}}],["像是在文字两旁加上星号",{"2":{"7":1,"13":1,"15":1,"17":1}}],["有16层",{"2":{"275":1}}],["有",{"2":{"269":1}}],["有隐状态的循环神经网络",{"0":{"251":1}}],["有两种tensor切割方式",{"2":{"237":1}}],["有两个字元需要特殊处理",{"2":{"26":1,"34":1,"36":1,"39":1}}],["有限",{"2":{"221":1}}],["有时称为汇聚窗口",{"2":{"281":1}}],["有时在应用多层卷积的时候",{"2":{"201":1}}],["有时间再完善实现的笔记",{"2":{"160":1}}],["有持久身份的对象",{"2":{"172":1}}],["有一个问题",{"2":{"312":1}}],["有一个已知的问题是",{"2":{"104":1}}],["有一条性质比较好用",{"2":{"171":1}}],["有天然的免疫性",{"2":{"158":1}}],["有什么区别",{"2":{"156":1}}],["有的时候我们bwd的时候",{"2":{"225":1}}],["有的时候我们创建的节点会覆盖当前的节点",{"2":{"133":1}}],["有的时候我们还想捕捉边界特征等一些其他特征",{"2":{"125":1}}],["有如下核心结构",{"2":{"97":1}}],["有助于用户更顺利达成目标的建议性信息",{"2":{"89":2}}],["有序列表则使用数字接着一个英文句点",{"2":{"59":1}}],["有三种方式来使用内部链接",{"2":{"32":1}}],["有关web框架",{"2":{"1":1}}],["你用什么符号开启标签",{"2":{"120":1}}],["你就可以将其替换掉",{"2":{"133":1}}],["你就可以增加链接而不让文章的阅读感觉被打断",{"2":{"104":1}}],["你就知道怎么在",{"2":{"52":1}}],["你还可以通过",{"2":{"89":1}}],["你还可以指定高亮显示的次数",{"2":{"89":1}}],["你也可以这样写",{"2":{"135":1}}],["你也可以把它放在文件最后面",{"2":{"104":1}}],["你也可以把",{"2":{"104":1}}],["你也可以在星号中间插入空白",{"2":{"78":1}}],["你也可以通过",{"2":{"25":1}}],["你都会得到完全相同的",{"2":{"59":1}}],["你在列表标记上使用的数字并不会影响输出的",{"2":{"59":1}}],["你要把所有的",{"2":{"26":1,"34":1,"36":1,"39":1}}],["你可以用多个反引号来开启和结束行内代码",{"2":{"135":1}}],["你可以用反引号把它包起来",{"2":{"135":1}}],["你可以用反斜线",{"2":{"120":1}}],["你可以随便用你喜欢的样式",{"2":{"120":1}}],["你可以随时修改它们",{"2":{"25":1}}],["你可以简化成",{"2":{"104":1}}],["你可以把这个标签的链接内容定义出来",{"2":{"104":1}}],["你可以把内容用固定的缩进整理好",{"2":{"59":1}}],["你可以使用特殊标记为",{"2":{"181":1}}],["你可以使用普通的",{"2":{"149":1}}],["你可以使用相对路径",{"2":{"104":1}}],["你可以使用下面的语法",{"2":{"103":1}}],["你可以在星号的前面加上反斜线",{"2":{"213":1}}],["你可以在一行中用三个或以上的星号",{"2":{"78":1}}],["你可以在句点前面加上反斜线",{"2":{"59":1}}],["你可以进行嵌套",{"2":{"67":1}}],["你可以完全不用在意数字的正确性",{"2":{"59":1}}],["你可以让",{"2":{"59":1}}],["你可以选取文字后然后从选单中选择增加引言阶层",{"2":{"52":1}}],["你可以这样写",{"2":{"26":1,"34":1,"36":1,"39":1}}],["你必须要把网址转成",{"2":{"26":1,"34":1,"36":1,"39":1}}],["你必须要写成",{"2":{"26":1,"34":1,"36":1,"39":1}}],["你必须要使用实体的形式",{"2":{"26":1,"34":1,"36":1,"39":1}}],["你无法在",{"2":{"19":1,"27":1,"29":1,"31":1}}],["中考虑",{"2":{"225":1}}],["中立领域",{"2":{"221":1}}],["中间激活占用的显存会远远超过模型参数显存",{"2":{"301":1}}],["中间激活占用的显存会同步增大",{"2":{"301":1}}],["中间激活近似估计为",{"2":{"297":1}}],["中间激活",{"2":{"267":1}}],["中间激活的显存占用后面会详细介绍",{"2":{"256":1}}],["中间激活值一般是float16或者bfloat16数据类型的",{"2":{"297":1}}],["中间激活值分析",{"0":{"297":1},"1":{"301":1}}],["中间激活值",{"2":{"210":1}}],["中间表示优化",{"2":{"221":1}}],["中每个元素相对于",{"2":{"159":1}}],["中所有元素的和",{"2":{"159":1}}],["中的一个上下文管理器",{"2":{"129":1}}],["中建立代码块很简单",{"2":{"67":1}}],["中并不适合",{"2":{"41":1}}],["中",{"2":{"25":1,"41":1}}],["主题",{"2":{"89":2,"134":2}}],["主题默认对每个",{"2":{"25":1}}],["主要解决的就是expert之间的all2all通信问题",{"2":{"290":1}}],["主要存在round误差和clip误差这两种误差",{"2":{"286":1}}],["主要需要理解",{"2":{"265":1}}],["主要就介绍的是相对于当时gpipe的tensor",{"2":{"237":1}}],["主要参考是megatron",{"2":{"225":1}}],["主要是以下几种模板定义以及三种实参定义的全连接组合",{"2":{"179":1}}],["主要是依赖tansformers库中的方法",{"2":{"141":1}}],["主要还是几个规则的记忆",{"2":{"179":1}}],["主要的用途是自定义函数",{"2":{"133":1}}],["主要的算子",{"2":{"23":1}}],["主要有俩方面",{"2":{"50":1}}],["主要讲解了如何配置一个cuda舒服的开发环境",{"2":{"50":1}}],["算子融合",{"2":{"54":1}}],["算子优化",{"2":{"54":1}}],["算子operator层面优化",{"2":{"23":1}}],["算法入门笔记",{"2":{"1":1}}],["块引言可以有阶层",{"2":{"52":1}}],["块引言",{"2":{"41":1}}],["块元素",{"0":{"33":1},"1":{"41":1,"46":1,"52":1,"59":1,"67":1,"78":1}}],["块内使用",{"2":{"19":1,"27":1,"29":1,"31":1}}],["块标签中将不会被进行处理",{"2":{"19":1,"27":1,"29":1,"31":1}}],["请勿继续",{"2":{"89":2}}],["请注意两边需要有空格",{"2":{"134":1}}],["请注意",{"2":{"19":1,"27":1,"29":1,"31":1,"104":1,"139":1,"295":1}}],["请向标题添加后缀",{"2":{"18":1}}],["xo",{"2":{"304":2}}],["xout",{"2":{"304":4}}],["xout​w1​",{"2":{"277":1}}],["xout​=softmax",{"2":{"277":1}}],["xoutw1",{"2":{"277":1}}],["xout=softmax",{"2":{"277":1}}],["xq",{"2":{"304":5}}],["xv",{"2":{"304":8}}],["xk",{"2":{"304":10}}],["xh",{"2":{"282":4}}],["x+p",{"2":{"269":2}}],["x+c",{"2":{"115":2}}],["x∈rn∗dx",{"2":{"310":1}}],["x∈rn∗d",{"2":{"269":2,"310":1}}],["x∈rn⋅d",{"2":{"251":1}}],["x∈rn⋅dx",{"2":{"251":1}}],["x∈rd",{"2":{"87":2}}],["xa2​",{"2":{"237":1}}],["xa2",{"2":{"237":1}}],["xa1​",{"2":{"237":1}}],["xa1",{"2":{"237":1}}],["xa",{"2":{"237":5}}],["xavier",{"2":{"110":1,"295":1,"312":4}}],["xs",{"2":{"202":5}}],["x70",{"2":{"198":2}}],["x72",{"2":{"198":2}}],["x74",{"2":{"198":1}}],["x65",{"2":{"198":2}}],["x6f",{"2":{"198":1}}],["x6c",{"2":{"198":3}}],["x61",{"2":{"198":5}}],["x6d",{"2":{"198":1}}],["x64",{"2":{"190":1,"198":4}}],["x以及auto",{"2":{"172":1}}],["xwdh​+bh​",{"2":{"251":1}}],["xwdh+bh",{"2":{"251":1}}],["xw",{"2":{"129":1,"251":1,"277":3}}],["xnx",{"2":{"258":1}}],["xn​",{"2":{"115":1,"258":3}}],["xn",{"2":{"115":1,"258":2}}],["x=fgelu​",{"2":{"277":1}}],["x=fgelu",{"2":{"277":1}}],["x=",{"2":{"115":1,"237":2}}],["x0x",{"2":{"145":3}}],["x0=0x",{"2":{"145":1}}],["x0=",{"2":{"145":1,"159":1}}],["x02​+x12​+x22​+x32​",{"2":{"145":1}}],["x02+x12+x22+x32",{"2":{"145":1}}],["x0​=",{"2":{"159":1}}],["x0​=​0",{"2":{"145":1}}],["x0​",{"2":{"114":4,"145":1}}],["x0",{"2":{"114":4,"145":9}}],["xj​",{"2":{"115":1}}],["xj​=xj−1​−α∇f",{"2":{"114":1}}],["xjp",{"2":{"115":1}}],["xj−1​",{"2":{"114":1}}],["xj−1",{"2":{"114":1}}],["xj=xj−1−α∇f",{"2":{"114":1}}],["xtwdh+ht−1whh+bh",{"2":{"251":1}}],["xt∣ht−1",{"2":{"234":1}}],["xt∣xt−1",{"2":{"110":4,"140":1,"234":1,"274":2}}],["xt+1​∣xt​",{"2":{"110":2}}],["xt+1​∣xt−1​",{"2":{"110":2}}],["xt+1​",{"2":{"110":1}}],["xt+1∣xt",{"2":{"110":2}}],["xt+1∣xt−1",{"2":{"110":2}}],["xt+1",{"2":{"110":1}}],["xt",{"2":{"110":4,"140":1,"234":1}}],["xt−1​",{"2":{"110":6}}],["xt−1",{"2":{"110":6}}],["xt​wdh​+ht−1​whh​+bh​",{"2":{"251":1}}],["xt​∣ht−1​",{"2":{"234":1}}],["xt​∣xt−1​",{"2":{"110":4,"140":1,"234":1,"274":2}}],["xt​",{"2":{"110":4,"140":1,"234":1}}],["xt​∼p",{"2":{"110":1}}],["xt∼p",{"2":{"110":1}}],["xtx",{"2":{"110":3,"234":1,"274":1,"282":1}}],["xlim=",{"2":{"106":1,"295":1,"300":1,"312":1}}],["xlabel=",{"2":{"106":1,"295":1,"300":1,"312":1}}],["x4​",{"2":{"100":1}}],["x4",{"2":{"100":1,"194":2,"211":2}}],["x3x",{"2":{"145":1}}],["x3​",{"2":{"100":1,"145":2}}],["x3",{"2":{"100":1,"145":1,"194":2}}],["x3c",{"2":{"19":6,"26":1,"27":6,"29":6,"31":6,"34":1,"36":1,"39":1,"59":24,"67":18,"89":9,"103":3,"104":16,"120":8,"126":2,"135":27,"158":1,"171":8,"172":1,"179":5,"181":2,"192":12,"194":5,"198":6,"205":5,"207":17,"209":7,"211":5,"227":1,"257":27,"262":1,"268":28,"285":3,"292":2,"312":2}}],["x1a1+x2a2",{"2":{"237":1}}],["x1=4x",{"2":{"145":1}}],["x1x",{"2":{"129":1,"145":2}}],["x1∣x0",{"2":{"110":1}}],["x1−xt−1x",{"2":{"110":1}}],["x1​a1​+x2​a2​",{"2":{"237":1}}],["x1​∣x0​",{"2":{"110":1}}],["x1​−xt−1​",{"2":{"110":1}}],["x1​",{"2":{"100":1,"110":5,"114":4,"115":1,"140":2,"145":1,"234":1,"237":1,"258":2,"274":2}}],["x1",{"2":{"100":1,"110":5,"114":4,"115":1,"140":2,"145":1,"194":2,"234":1,"237":1,"258":3,"274":2}}],["x−xj​",{"2":{"93":2,"106":1}}],["x−xj",{"2":{"93":2,"106":1}}],["x−xi​",{"2":{"93":3,"106":2}}],["x−xi",{"2":{"93":3,"106":2}}],["x^",{"2":{"304":17}}],["x^i",{"2":{"73":1}}],["x^2f",{"2":{"114":1}}],["x^2",{"2":{"37":1}}],["xil​",{"2":{"304":1}}],["xil",{"2":{"304":1}}],["xint​",{"2":{"298":1}}],["xint​−zx​",{"2":{"298":1}}],["xintx",{"2":{"298":1}}],["xint−zx",{"2":{"298":1}}],["xinshuowang",{"2":{"14":1}}],["xi∈rdx",{"2":{"258":1}}],["xix",{"2":{"93":1,"145":1}}],["xi​∈rd",{"2":{"258":1}}],["xi​",{"2":{"93":3,"106":1,"258":1}}],["xi",{"2":{"73":2,"93":3,"106":1,"214":2,"258":1}}],["x86一般是at",{"2":{"190":1}}],["x86",{"2":{"50":2,"190":2,"253":1}}],["xcuda来让clang知道这是cuda代码",{"2":{"50":1}}],["xcuda",{"2":{"50":1}}],["xxx",{"2":{"50":1,"64":1,"93":2,"109":2,"125":1,"139":2,"145":4,"152":1,"159":1,"201":1,"237":2,"244":2,"281":1,"297":2,"308":1,"310":2}}],["x较大时",{"2":{"37":1}}],["x2e",{"2":{"198":2}}],["x27",{"2":{"114":1,"129":1,"183":6,"310":1}}],["x2​",{"2":{"100":1,"110":1,"115":1,"140":1,"145":1,"237":1,"258":1}}],["x2",{"2":{"37":2,"100":1,"110":1,"115":1,"140":1,"145":2,"194":2,"237":1,"258":1}}],["x26",{"2":{"26":5,"34":5,"36":5,"39":5,"67":6,"135":6,"156":1,"171":1,"172":4,"178":1,"179":19,"194":17,"198":41,"209":13,"211":28,"257":16,"268":13,"285":2}}],["x",{"2":{"37":6,"64":4,"73":3,"87":4,"93":36,"97":10,"100":5,"101":7,"106":18,"109":12,"110":45,"114":22,"115":15,"116":2,"119":2,"122":7,"123":9,"125":9,"126":2,"129":12,"131":32,"132":3,"133":21,"137":17,"140":6,"145":37,"146":17,"147":10,"158":4,"159":10,"160":16,"161":14,"170":4,"179":5,"183":8,"186":12,"187":2,"188":8,"194":4,"197":1,"201":10,"202":2,"203":2,"209":8,"220":7,"233":6,"234":5,"235":3,"237":5,"246":20,"250":3,"251":1,"257":4,"258":7,"262":8,"268":3,"269":11,"274":6,"277":3,"281":23,"282":9,"293":9,"295":15,"298":13,"300":4,"304":13,"305":4,"306":4,"308":6,"310":22,"312":10}}],["ib",{"2":{"272":1}}],["i100002jd",{"2":{"269":2}}],["i+1",{"2":{"304":6}}],["i+1i+1i+1",{"2":{"296":1}}],["i++",{"2":{"257":1,"268":1}}],["i+a",{"2":{"109":6,"125":6}}],["ici​",{"2":{"233":2}}],["ihi​",{"2":{"230":1}}],["ir",{"2":{"205":1,"221":1}}],["ii其实区别不大",{"2":{"205":1}}],["ii",{"2":{"205":1}}],["iii",{"2":{"154":1,"282":2,"296":1,"304":3}}],["iostream>",{"2":{"205":1}}],["io密集型任务会使得当前线程释放锁",{"2":{"167":1}}],["io密集型任务",{"2":{"124":2}}],["ignore",{"2":{"161":2}}],["ilrcpc",{"2":{"253":1}}],["il",{"2":{"158":1}}],["i4xi​",{"2":{"145":1}}],["i≠j",{"2":{"131":1}}],["i≠ji",{"2":{"131":1}}],["ipython",{"2":{"160":1}}],["ip",{"2":{"131":1}}],["ipsum",{"2":{"52":4,"59":7,"89":2}}],["i^2yi​=2xi2​",{"2":{"159":1}}],["i^2",{"2":{"131":3}}],["i^",{"2":{"129":1,"131":1,"154":1,"230":6}}],["iki​",{"2":{"122":1}}],["it",{"2":{"116":1,"132":1,"147":1,"161":1,"290":1,"305":2}}],["iterencode",{"2":{"305":4}}],["iter=false",{"2":{"300":1}}],["iter中",{"2":{"282":1}}],["iterator",{"2":{"126":1,"187":1,"202":1}}],["iter",{"2":{"94":4,"110":5,"129":4,"160":4,"187":1,"202":9,"282":1,"295":10,"300":7,"312":2}}],["items",{"2":{"126":1,"302":2,"305":3}}],["item",{"2":{"52":2,"59":6,"193":1}}],["i​=∑j=1n​exj​exi​​",{"2":{"115":1}}],["i=j−pipj",{"2":{"131":1}}],["i=ji",{"2":{"131":1}}],["i=exi∑j=1nexjp",{"2":{"115":1}}],["i=1",{"2":{"73":1,"93":5,"106":3,"122":1,"230":2}}],["if",{"2":{"97":1,"101":2,"110":1,"122":2,"126":9,"137":4,"141":5,"160":2,"186":1,"193":1,"202":1,"209":1,"246":1,"257":4,"268":5,"272":1,"281":1,"282":1,"285":4,"292":4,"294":1,"295":5,"296":3,"299":2,"300":5,"302":3,"305":16,"306":2,"312":4}}],["ixi​",{"2":{"93":1,"145":1}}],["iyi​",{"2":{"93":3}}],["image",{"2":{"149":1}}],["images",{"2":{"26":4,"34":4,"36":4,"39":4}}],["img",{"2":{"149":3}}],["import",{"2":{"89":4,"97":2,"126":8,"129":5,"145":1,"160":3}}],["importantly",{"2":{"290":1}}],["important",{"2":{"89":2}}],["id为0",{"2":{"275":1}}],["ids",{"2":{"225":2}}],["id=",{"2":{"181":1}}],["idx",{"2":{"126":13,"160":2,"257":12,"268":9,"289":1}}],["id",{"2":{"52":2,"59":3,"70":2,"89":2,"104":5,"149":3,"227":5,"292":13,"294":1}}],["ide这里使用的是vscode",{"2":{"50":1}}],["i",{"2":{"50":5,"93":12,"104":4,"106":6,"109":31,"110":4,"115":5,"122":5,"125":12,"126":2,"129":5,"131":27,"146":3,"154":3,"156":6,"158":4,"159":6,"171":6,"186":7,"187":3,"196":1,"198":1,"201":6,"202":5,"209":15,"227":2,"228":1,"230":2,"233":3,"250":3,"257":3,"258":3,"262":3,"268":3,"269":4,"281":22,"289":2,"295":4,"304":140}}],["i$",{"2":{"50":1}}],["inval",{"2":{"227":1}}],["invalidate",{"2":{"227":1}}],["ini​",{"2":{"154":1}}],["init集中在prepare",{"2":{"294":1}}],["initiates",{"2":{"244":3}}],["initiated",{"2":{"227":1}}],["initial",{"2":{"187":7,"194":2}}],["initialized",{"2":{"299":2}}],["initializer",{"2":{"158":2,"194":4}}],["initializes",{"2":{"141":1}}],["initialize",{"0":{"294":1,"302":1},"1":{"299":1,"302":1,"305":1},"2":{"101":1,"225":2,"302":2,"305":1}}],["init",{"2":{"97":4,"101":2,"106":2,"110":3,"116":2,"117":2,"123":4,"126":1,"132":2,"136":2,"137":2,"141":2,"147":2,"150":2,"160":1,"161":2,"178":2,"183":5,"186":2,"194":1,"202":1,"225":1,"227":2,"246":2,"269":2,"282":7,"292":2,"295":3,"299":4,"302":4,"305":2,"306":2,"308":8,"310":6,"312":4}}],["inject",{"2":{"132":1}}],["indices包含子序列的随机起始索引",{"2":{"187":1}}],["indices",{"2":{"126":4,"129":6,"187":6}}],["indent=4",{"2":{"305":1}}],["indent",{"2":{"59":1,"305":5}}],["index>",{"2":{"209":5}}],["index",{"2":{"50":1,"126":2,"209":5,"268":2}}],["inception",{"2":{"123":11}}],["included",{"2":{"272":2}}],["include之中",{"2":{"50":1}}],["include",{"2":{"50":6,"196":1,"205":1,"244":1}}],["inline",{"2":{"104":2,"211":10,"228":1,"257":3,"268":3,"285":4,"292":1}}],["inputs",{"2":{"160":4,"282":4,"306":2}}],["input返回出去",{"2":{"133":1}}],["input",{"2":{"101":4,"117":2,"132":1,"133":4,"147":1,"161":2,"225":4,"289":3,"292":5,"312":2}}],["in=512",{"2":{"97":1}}],["inference",{"0":{"102":1},"2":{"127":1,"302":1}}],["information",{"2":{"104":1,"132":1,"305":1}}],["info",{"2":{"77":3,"294":1,"299":1,"305":3}}],["infra的学习笔记",{"2":{"0":1}}],["intranode使用nvlink",{"2":{"272":1}}],["intranode",{"2":{"272":1}}],["intranode是单机多卡内的通信",{"2":{"272":1}}],["introduced",{"2":{"290":1}}],["introduce",{"2":{"214":2}}],["int8",{"2":{"270":1,"286":1}}],["int8量化压缩",{"2":{"54":1}}],["int4",{"2":{"257":1,"268":1}}],["int>",{"2":{"194":2,"209":1}}],["intel使用ccl等等",{"2":{"299":1}}],["intel语法",{"2":{"190":1}}],["interface",{"2":{"272":1}}],["internode",{"2":{"272":1}}],["internode是多机间通信",{"2":{"272":1}}],["interpreter",{"2":{"152":1}}],["interleaved调度",{"2":{"290":1}}],["interleaved版本的1f1b调度中",{"2":{"275":1}}],["interleaved以及interleaved两种调度策略",{"2":{"275":1}}],["interleaved",{"0":{"275":1},"2":{"225":1,"254":1}}],["interleave",{"2":{"106":1,"122":1,"246":1}}],["into",{"2":{"97":1,"101":2,"147":1,"161":1,"268":1}}],["int",{"2":{"64":4,"94":4,"107":5,"156":6,"158":10,"171":8,"179":30,"186":2,"187":3,"194":14,"202":3,"205":1,"209":7,"225":2,"227":4,"257":12,"268":13,"281":2,"282":6,"285":2,"289":1,"292":2,"298":7,"305":1}}],["instead",{"2":{"305":1}}],["instr",{"2":{"268":2}}],["instructions",{"2":{"268":2}}],["instruction",{"2":{"211":1}}],["inside",{"2":{"59":1}}],["insertion=never",{"2":{"50":1}}],["in",{"2":{"52":2,"59":5,"70":8,"87":2,"89":2,"94":9,"97":9,"106":1,"107":2,"110":3,"115":2,"116":1,"122":3,"123":10,"126":13,"129":6,"132":1,"135":4,"136":6,"137":1,"141":1,"147":1,"150":4,"160":4,"178":4,"183":1,"186":4,"187":3,"193":1,"201":1,"202":1,"227":1,"230":9,"233":3,"250":4,"251":2,"258":2,"262":3,"268":3,"269":2,"272":1,"277":3,"281":2,"282":2,"289":3,"292":1,"294":1,"295":4,"296":3,"300":3,"304":1,"305":6,"310":1,"312":5}}],["isa",{"2":{"190":1,"253":2}}],["is∣deep",{"2":{"140":2}}],["isinstance",{"2":{"126":3,"160":1,"295":2,"296":1,"300":4,"302":1,"305":6,"306":1}}],["isn",{"2":{"89":2}}],["is",{"2":{"19":2,"27":2,"29":2,"31":2,"45":4,"46":2,"52":7,"59":4,"67":6,"77":12,"89":2,"97":6,"101":4,"104":3,"110":1,"119":4,"120":1,"122":1,"126":2,"129":1,"132":1,"133":1,"135":4,"137":1,"140":8,"227":2,"246":1,"272":1,"282":1,"299":3,"300":1,"302":1,"305":5}}],["标量或者矢量",{"2":{"246":1}}],["标准版本不同",{"2":{"221":1}}],["标准检查所检查到的错误中",{"2":{"26":1,"34":1,"36":1,"39":1}}],["标记一个async操作",{"2":{"244":1}}],["标记或达到最大长度",{"2":{"214":1}}],["标记或之前生成的词",{"2":{"214":1}}],["标记",{"0":{"134":1}}],["标记为",{"2":{"59":1}}],["标签包围",{"2":{"120":1}}],["标签包起来",{"2":{"59":1}}],["标签比文字还要多",{"2":{"104":1}}],["标签来把代码块包起来",{"2":{"67":1}}],["标签的话",{"2":{"41":1}}],["标签使用",{"2":{"26":1,"34":1,"36":1,"39":1}}],["标签",{"2":{"19":1,"27":1,"29":1,"31":1,"41":1,"149":1,"213":1}}],["标题和内容来定义",{"2":{"66":1}}],["标题能显示出文章的结构",{"2":{"46":1}}],["标题",{"0":{"46":1}}],["标题会自动应用锚点",{"2":{"11":1}}],["标题锚点自定义锚点链接内部链接github风格的表格emoji",{"2":{"58":1}}],["标题锚点",{"0":{"11":1},"1":{"18":1}}],["可定制化需要做的很强很强",{"2":{"305":1}}],["可减少空间维度",{"2":{"288":1}}],["可变长向量",{"2":{"253":1}}],["可选",{"2":{"221":1}}],["可能在没有划分virtual",{"2":{"275":1}}],["可能是有益的",{"2":{"230":1}}],["可能会在某些空白行",{"2":{"205":1}}],["可能会包含一些展开",{"2":{"190":1}}],["可能效果会更好",{"2":{"96":1}}],["可能更像是一个",{"2":{"2":1}}],["可见对于一维因变量来说",{"2":{"114":1}}],["可见",{"2":{"64":1}}],["可以只通过指定若干host来让deepspeed帮你自动排序",{"2":{"299":1}}],["可以估计所需要的训练时间",{"2":{"291":1}}],["可以看deepspeed文档",{"2":{"287":1}}],["可以看出deepspeed核心的计算和调度代码在engine之中",{"2":{"302":1}}],["可以看出dualpipev主要有以下的一些关键点",{"2":{"290":1}}],["可以看出comm包主要就各种通信op",{"2":{"299":1}}],["可以看出来我们last",{"2":{"290":1}}],["可以看出涵盖了数值运算",{"2":{"253":1}}],["可以看出这种方式",{"2":{"237":1}}],["可以看出这个fp8e4m3",{"2":{"211":1}}],["可以看出这个结构很适合parallel并行",{"2":{"97":1}}],["可以看出不管是g++",{"2":{"205":1}}],["可以看出",{"2":{"100":1,"105":1,"106":1,"115":1,"158":1,"221":1,"227":1,"287":1,"290":1,"298":1}}],["可以作用到一个比较小的vector上",{"2":{"279":1}}],["可以做到的overlap其实就是在loop的时候",{"2":{"275":1}}],["可以做到io任务的让渡",{"2":{"232":1}}],["可以让用户通过",{"2":{"272":1}}],["可以让文件更像是浏览器最后产生的结果",{"2":{"104":1}}],["可以在软件的层面上优化通信速度",{"2":{"272":1}}],["可以在编译期检测出来",{"2":{"223":1}}],["可以忽略",{"2":{"267":1}}],["可以合理利用所有的thread",{"2":{"257":1}}],["可以供该平台的程序使用",{"2":{"253":1}}],["可以有效地利用多核",{"2":{"248":1}}],["可以实现多头注意力的并行计算",{"2":{"246":1}}],["可以给我们带来更小的开销",{"2":{"239":1}}],["可以访问和修改向量的特定部分",{"2":{"235":1}}],["可以设置expect",{"2":{"227":1,"244":1}}],["可以设置tma想要load的bytes",{"2":{"227":1}}],["可以直接使用01交替",{"2":{"227":1}}],["可以直接使用数组方式创建",{"2":{"170":1}}],["可以禁止一些模板的实例化",{"2":{"223":1}}],["可以达到20",{"2":{"221":1}}],["可以帮助我们在单个进程中快速处理网络请求",{"2":{"215":1}}],["可以利用反斜线来插入一些在语法中有其它意义的符号",{"2":{"213":1}}],["可以利用高效的矩阵乘法来计算",{"2":{"23":1}}],["可以被前置声明",{"2":{"207":1}}],["可以减少命名污染",{"2":{"207":1}}],["可以优化汇编代码",{"2":{"205":1}}],["可以正常推导",{"2":{"194":1}}],["可以视为对每个元素操作",{"2":{"188":1}}],["可以视为卷积层的权重weight",{"2":{"109":1}}],["可以绑定到​​左值或右值​​",{"2":{"172":1}}],["可以创建一个1",{"2":{"170":1}}],["可以针对当前标量进行反向传播求梯度",{"2":{"159":1}}],["可以避免",{"2":{"158":1}}],["可以避免在块标签前后加上没有必要的",{"2":{"19":1,"27":1,"29":1,"31":1}}],["可以理解为w2函数declaration",{"2":{"158":1}}],["可以理解为多维数组",{"2":{"155":1}}],["可以指定当前arrive了多少次",{"2":{"227":1}}],["可以指定容器的初始元素",{"2":{"158":1}}],["可以指定本地的路径",{"2":{"141":1}}],["可以进行一系列操作",{"2":{"155":1}}],["可以得知",{"2":{"227":1}}],["可以得出",{"2":{"152":1,"167":1}}],["可以得到更简洁的实现",{"2":{"129":1}}],["可以得到以下结果",{"2":{"93":1}}],["可以用于为非静态数据成员指定默认初始值",{"2":{"158":1}}],["可以用来持续加速深层网络的收敛速度",{"2":{"137":1}}],["可以用单引号",{"2":{"104":1}}],["可以按照batch",{"2":{"129":1}}],["可以更有效地利用硬件资源",{"2":{"129":1}}],["可以解决单标签多分类问题",{"2":{"115":1}}],["可以通过以下途径来预测",{"2":{"110":1}}],["可以通过在容器的",{"2":{"89":1}}],["可以发现会出现多个参数矩阵连乘的现象",{"2":{"296":1}}],["可以发现在量化中",{"2":{"286":1}}],["可以发现它唯一的计算就在通道上",{"2":{"262":1}}],["可以发现w其实包含了所有注意力头的子线性空间",{"2":{"246":1}}],["可以发现最后的输出会变为",{"2":{"186":1}}],["可以发现",{"2":{"109":1,"284":1}}],["可以知道w∈r784∗10",{"2":{"160":1}}],["可以知道",{"2":{"109":1}}],["可以像这样对多个代码块进行分组",{"2":{"89":1}}],["可以使用pydantic比较巧妙地实现新旧字段的废弃和兼容",{"2":{"305":1}}],["可以使用gnu",{"2":{"205":1}}],["可以使用数据来训练我们的权重和偏差",{"2":{"186":1}}],["可以使用加性注意力作为评分函数",{"2":{"136":1}}],["可以使用",{"2":{"89":1,"158":1}}],["可以使用hopper写出一个超过cublas的gemm",{"2":{"53":1}}],["可以找到",{"2":{"89":1}}],["可以注意到",{"2":{"82":1}}],["可以快速异步地搬运数据",{"2":{"70":1}}],["可以对gemm有一个超级深刻的印象",{"2":{"53":1}}],["──",{"2":{"19":1,"27":1,"29":1,"31":1}}],["只考虑激活占用显存的大头",{"2":{"297":1}}],["只使用一个warp来load或者store数据",{"2":{"227":1}}],["只保留了计算图信息",{"2":{"225":1}}],["只是",{"2":{"198":1}}],["只是创建新视图",{"2":{"133":1}}],["只能绑定到​​右值​​",{"2":{"172":1}}],["只能绑定到​​左值​​",{"2":{"172":1}}],["只读",{"2":{"171":1}}],["只有大约10",{"2":{"272":1}}],["只有三种",{"2":{"172":1}}],["只有唯一的标签",{"2":{"160":1}}],["只有一个线程会执行当前执行到的python字节码",{"2":{"152":1}}],["只有块元素",{"2":{"19":1,"27":1,"29":1,"31":1}}],["只需要分治做gelu即可",{"2":{"237":1}}],["只需要执行fwd的过程",{"2":{"225":1}}],["只需要上下",{"2":{"201":1}}],["只需要水平和垂直翻转二维卷积核张量",{"2":{"186":1}}],["只需要依赖于",{"2":{"110":1}}],["只需要复制粘贴",{"2":{"67":1}}],["只要是相同的平台",{"2":{"205":1}}],["只要是用方括号包起来",{"2":{"198":1}}],["只要两者不相等",{"2":{"146":1}}],["只要我们能够找到一个时间跨度",{"2":{"110":1}}],["只要在网址后面",{"2":{"104":1}}],["只要在方块括号后面马上接着括号并插入网址链接即可",{"2":{"104":1}}],["只要简单地缩进",{"2":{"67":1}}],["只要根据层数加上不同数量的",{"2":{"52":1}}],["只要直接加标签就可以了",{"2":{"19":1,"27":1,"29":1,"31":1}}],["撰写",{"2":{"19":1,"27":1,"29":1,"31":1}}],["涵盖范围之外的标签",{"2":{"19":1,"27":1,"29":1,"31":1}}],["不知道有无什么讲究",{"2":{"302":1}}],["不知道是什么用途",{"2":{"268":1}}],["不难发现",{"2":{"296":1}}],["不仅要考虑前向传递和后向传递的计算时间",{"2":{"291":1}}],["不仅跟gpu类型有关",{"2":{"291":1}}],["不然就会出现内存泄露的情况",{"2":{"290":1}}],["不然拿不到compute需要的input",{"2":{"290":1}}],["不断地生成答案",{"2":{"310":1}}],["不断地loop去看当前的train进程还有多少正在work",{"2":{"287":1}}],["不断沿梯度改变θ0",{"2":{"99":1}}],["不同于卷积层中的输入与卷积核之间的互相关计算",{"2":{"281":1}}],["不同os对多进程的支持不同",{"2":{"184":1}}],["不能让每个part之间产生计算图的依赖",{"2":{"290":1}}],["不能随意更改传入的参数和返回值的type",{"2":{"276":1}}],["不能通过该指针来改变对象的属性",{"2":{"156":1}}],["不论是多进程",{"2":{"232":1}}],["不论是行内还是块",{"2":{"26":1,"34":1,"36":1,"39":1}}],["不是del",{"2":{"225":1}}],["不接受荒谬的隐式类型转换",{"2":{"207":1}}],["不管是input",{"2":{"225":1}}],["不管是gcc还是clang要做的都是将头文件和宏展开",{"2":{"205":1}}],["不管是哪一种",{"2":{"104":1}}],["不改变张量数据的操作",{"2":{"133":1}}],["不会创建节点",{"2":{"133":4}}],["不涉及梯度的操作",{"2":{"133":1}}],["不使其训偏",{"2":{"112":1}}],["不需要占用cpu资源",{"2":{"124":1}}],["不需要过度在意相隔较远的区域之间的联系",{"2":{"95":1}}],["不需要额外标注这是",{"2":{"19":1,"27":1,"29":1,"31":1}}],["不变性",{"2":{"95":1,"115":1}}],["不建议",{"2":{"59":1}}],["不但更好用",{"2":{"41":1}}],["不过也可以理解",{"2":{"302":1}}],["不过我观察megatron并没有使用device",{"2":{"302":1}}],["不过上述的launcher",{"2":{"287":1}}],["不过这也是比较大的项目的痛点了",{"2":{"305":1}}],["不过这部分占用的显存是很小的",{"2":{"267":1}}],["不过这样也比什么都不做好些",{"2":{"198":1}}],["不过至少有一点是确定的",{"2":{"190":1}}],["不过较少",{"2":{"49":1}}],["不过需要注意的是",{"2":{"26":1,"34":1,"36":1,"39":1}}],["不过最需要强调的便是它的可读性",{"2":{"7":1,"13":1,"15":1,"17":1}}],["不用说也知道这很容易忘记",{"2":{"26":1,"34":1,"36":1,"39":1}}],["不可以用",{"2":{"19":1,"27":1,"29":1,"31":1}}],["不在",{"2":{"19":1,"27":1,"29":1,"31":1}}],["而保存是保存在磁盘之中的",{"2":{"305":1}}],["而中间激活值与输入数据的大小",{"2":{"301":1}}],["而输入的均值和方差分别包含了",{"2":{"297":1}}],["而dualpipev采取了v形调度",{"2":{"290":1}}],["而隐状态形态保持不变",{"2":{"282":1}}],["而任何实际模型都必须超越这个上限",{"2":{"274":1}}],["而多进程是在网络框架中实现的",{"2":{"271":1}}],["而多线程因为每个线程都需要一定的内存和资源",{"2":{"232":1}}],["而每一维的隐藏层权重都需要上一维来更新",{"2":{"251":1}}],["而现实可能更为复杂一些",{"2":{"250":1}}],["而协程则是因为他的本质是基于epoll的io让渡",{"2":{"232":1}}],["而只有成员函数可被标记为private",{"2":{"223":1}}],["而clang可以使用自己的集成汇编器",{"2":{"205":1}}],["而clang则会直接将其转化为llvm",{"2":{"205":1}}],["而模板类型推导就不行",{"2":{"194":1}}],["而模型需要的输入是数字",{"2":{"126":1}}],["而y是标准答案",{"2":{"160":1}}],["而我们梯度下降的方式也很简单",{"2":{"146":1}}],["而不需要在意handler的并行处理的原因",{"2":{"271":1}}],["而不是模型参数",{"2":{"301":1}}],["而不是元素个数",{"2":{"297":1}}],["而不是",{"2":{"297":1}}],["而不是拷贝一份之后再操作",{"2":{"293":1}}],["而不是像卷积层一样在通道上对输入进行汇总",{"2":{"281":1}}],["而不是链接期",{"2":{"223":1}}],["而不是声明",{"2":{"207":1}}],["而不是卷积运算",{"2":{"186":1}}],["而不是默认的",{"2":{"18":1}}],["而不在乎它的位置",{"2":{"153":1}}],["而不变性蕴含在二维空间中",{"2":{"125":1}}],["而是选择自己手动管理process",{"2":{"302":1}}],["而是自己实现了一套launcher",{"2":{"272":1}}],["而是为了共同使用而优化的",{"2":{"250":1}}],["而是替换其数据字段为一个标量",{"2":{"225":1}}],["而是分析这种机制",{"2":{"152":1}}],["而是它比较好读",{"2":{"104":1}}],["而是照原来的样子显示",{"2":{"67":1}}],["而在pp维度其实care的是更加上层的调度",{"2":{"225":1}}],["而在多维情况下",{"2":{"177":1}}],["而在第二个方括号里面要填入用以辨识链接的标签",{"2":{"104":1}}],["而在其它情形下",{"2":{"26":1,"34":1,"36":1,"39":1}}],["而键和值来自整个编码器的输出",{"2":{"87":1}}],["而非自主性提示被称之为键",{"2":{"79":1}}],["而一个以上的空行则会切分出不同的段落",{"2":{"41":1}}],["而且self",{"2":{"269":1}}],["而且输出层的权重矩阵通常与词嵌入矩阵是参数共享的",{"2":{"224":1}}],["而且c++14的lambda函数也允许在形参声明中使用auto",{"2":{"194":1}}],["而且我们最后训练出来的",{"2":{"186":1}}],["而且因为卷积核发生了堆叠",{"2":{"125":1}}],["而且存在累加",{"2":{"37":1}}],["而且这些",{"2":{"19":1,"27":1,"29":1,"31":1}}],["而且功能比纯文本更强",{"2":{"12":1,"20":1,"22":1,"24":1}}],["这俩真可以算loss吗",{"2":{"312":1}}],["这被称为预热期",{"2":{"289":1}}],["这要求配置hostfile",{"2":{"280":1}}],["这类量化其实就是每个刻度对应一个固定的gap",{"2":{"270":1}}],["这类库是使用虚拟环境内的pip安装的",{"2":{"50":1}}],["这",{"2":{"230":1}}],["这表示源句子的编码表示",{"2":{"199":1}}],["这表示你可以很容易地以",{"2":{"67":1}}],["这段字串会变成一个可以点击的",{"2":{"198":1}}],["这段语法会产生",{"2":{"135":1}}],["这将是我们能做的最好的编码方式",{"2":{"274":1}}],["这将被渲染为",{"2":{"181":1}}],["这将为图片添加",{"2":{"181":1}}],["这需要有一个清晰定义的输出方向来应用",{"2":{"177":1}}],["这在函数重载",{"2":{"175":1}}],["这可以表示为",{"2":{"159":1}}],["这可以为我们的设计提供参考",{"2":{"69":1}}],["这两种写法的区别在于const修饰语义",{"2":{"156":1}}],["这意味着默认的backend",{"2":{"299":1}}],["这意味着",{"2":{"281":1}}],["这意味着我们无法给函数传递右值容器",{"2":{"209":1}}],["这意味着每个元素的梯度权重都是1",{"2":{"159":1}}],["这意味着pytorch将会追踪对x0x",{"2":{"145":1}}],["这意味着对于",{"2":{"109":1}}],["这让我们知道了",{"2":{"139":1}}],["这说明如果",{"2":{"131":1}}],["这时使用",{"2":{"158":1}}],["这时候该怎么办呢",{"2":{"125":1}}],["这时会恢复为",{"2":{"25":1}}],["这使得我们需要一个可以自己定义fwd和bwd逻辑",{"2":{"117":1}}],["这叫",{"2":{"110":1}}],["这种优化针对的是system",{"2":{"309":1}}],["这种方式减少的其实是中间激活占用的显存",{"2":{"301":1}}],["这种方式提供了一个重要的上限",{"2":{"274":1}}],["这种计算就像不断循环一样",{"2":{"251":1}}],["这种就被称之为隐状态",{"2":{"251":1}}],["这种设计被称为多头注意力",{"2":{"230":1}}],["这种作法虽然可以混淆不少的机器人",{"2":{"198":1}}],["这种机制由解释器实现",{"2":{"152":1}}],["这种操作一般不会在cpu上执行",{"2":{"124":1}}],["这种操作可以使得x",{"2":{"106":1}}],["这种情形下",{"2":{"104":1}}],["这种掩蔽",{"2":{"87":1}}],["这就",{"2":{"271":1}}],["这就需要通过各种不同的方法",{"2":{"238":1}}],["这就会使得以下的语句只能被解析为函数声明",{"2":{"158":1}}],["这就获得了某种意义上的",{"2":{"109":1}}],["这就是中间激活",{"2":{"297":1}}],["这就是int8量化算子的执行过程",{"2":{"293":1}}],["这就是我们使用django或者flask等应用框架的时候只需要实现url到handler的映射",{"2":{"271":1}}],["这就是我们熟知的分词操作",{"2":{"126":1}}],["这就是为什么在构建工具链中",{"2":{"205":1}}],["这就是为什么反向传播通常需要从一个标量开始的原因",{"2":{"177":1}}],["这就是pytorch的自动微分机制",{"2":{"145":1}}],["这就是整个rlhf的训练过程",{"2":{"127":1}}],["这就是torch",{"2":{"117":1}}],["这就是一个自定义的torch",{"2":{"117":1}}],["这就是optimizer干的事情",{"2":{"105":1}}],["这就是ep并行策略",{"2":{"97":1}}],["这就是最朴素的moe",{"2":{"97":1}}],["这就不是我们想看到的",{"2":{"82":1}}],["这是deepspeed源码中engine的函数",{"2":{"305":1}}],["这是const语义保证的",{"2":{"266":1}}],["这是因为我们的模型还没训练",{"2":{"289":1}}],["这是因为cpp会为每个enum选择一个底层的类型用来表示它",{"2":{"207":1}}],["这是因为还没有进行任何梯度的计算",{"2":{"145":1}}],["这是通过将上下文变量视为加性注意力池化的输出来实现的",{"2":{"183":1}}],["这是为什么呢",{"2":{"159":1}}],["这是一种高速网络技术",{"2":{"272":1}}],["这是一种朴素的并行策略",{"2":{"265":1}}],["这是一种很好的性质",{"2":{"110":1}}],["这是一个单词维度统计的频率",{"2":{"154":1}}],["这是一个从0开始实现的例子",{"2":{"129":1}}],["这是一个一维自变量和一维因变量的函数",{"2":{"114":1}}],["这是一篇杂谈",{"2":{"50":1}}],["这是对应l2",{"2":{"70":1}}],["这也是官方文档给出的例子",{"2":{"133":1}}],["这也就是为什么上述的对于矩阵block的re",{"2":{"70":1}}],["这也可能是",{"2":{"26":1,"34":1,"36":1,"39":1}}],["这一阶段我们会进行通信与计算的overlap",{"2":{"290":1}}],["这一切需要配置好",{"2":{"280":1}}],["这一步会将汇编使用汇编器转化为机器码",{"2":{"205":1}}],["这一特点并没有被我们所利用",{"2":{"82":1}}],["这一章主要是讲一些现代设计的卷积神经网络模型以及一些技术",{"2":{"69":1}}],["这一节我们将学习卷积神经网络",{"2":{"62":1}}],["这样zw=0z",{"2":{"298":1}}],["这样overlap收益不高",{"2":{"275":1}}],["这样做的好处就是不需要自己去划分不同的process",{"2":{"302":1}}],["这样做的坏处是",{"2":{"275":1}}],["这样做可以有效地避免不必要的内存开销和计算",{"2":{"129":1}}],["这样fwd的顺序会变为",{"2":{"275":1}}],["这样随着我们在神经网络中层叠的上升",{"2":{"273":1}}],["这样也会产生切换开销",{"2":{"232":1}}],["这样重新排列一下",{"2":{"220":1}}],["这样可以显著降低显存占用",{"2":{"275":1}}],["这样可以保证传入的参数c具有之前的左值or右值的特性",{"2":{"209":1}}],["这样可以使得编译器选取最小的类型来表示这个枚举",{"2":{"207":1}}],["这样对于值的语义并不直观",{"2":{"207":1}}],["这样我们可以采用batch",{"2":{"309":1}}],["这样我们可以方便的迭代外围时间步数",{"2":{"282":1}}],["这样我们在使用模板的时候",{"2":{"192":1}}],["这样我们就可以顾及到前面所有的单词",{"2":{"234":1}}],["这样我们就可以实现并行",{"2":{"184":1}}],["这样我们就可以将所有的答案输出概率select出来",{"2":{"160":1}}],["这样我们的输出就会有多个通道",{"2":{"125":1}}],["这样",{"2":{"146":1}}],["这样你就可以在区段的一开始就插入反引号",{"2":{"135":1}}],["这样最后梯度的形态应该是一个",{"2":{"131":1}}],["这样是一个生成数据的函数",{"2":{"129":1}}],["这样便构建了概率分布",{"2":{"115":1}}],["这样就不需要mpi了",{"2":{"299":1}}],["这样就不可能导向a",{"2":{"64":1}}],["这样就无法进行量化",{"2":{"298":1}}],["这样就实现了通信和计算的overlap",{"2":{"275":1}}],["这样就实现了一个web框架的高效运转",{"2":{"271":1}}],["这样就可以并行的处理请求",{"2":{"271":1}}],["这样就可以实现你自己定制的exp函数",{"2":{"133":1}}],["这样就会使得偏差越来越大",{"2":{"110":1}}],["这样的话就会出现梯度爆炸或者梯度消失现象",{"2":{"296":1}}],["这样的话每次输出",{"2":{"269":1}}],["这样的话",{"2":{"266":1}}],["这样的话我们需要填充的行和列均为偶数",{"2":{"201":1}}],["这样的话我们可以固定训练的参数数量",{"2":{"110":1}}],["这样的格式可以混淆一些不好的信箱地址收集机器人",{"2":{"198":1}}],["这样的方式让你非常容易使用",{"2":{"67":1}}],["这样会给我们的代码带来更快的运行效率",{"2":{"255":1}}],["这样会比较容易插入",{"2":{"135":1}}],["这样会比较好看",{"2":{"104":1}}],["这样会避免多block调度和创建的开销",{"2":{"70":1}}],["这组数据",{"2":{"64":1}}],["这个隐状态就是encoder出来的固定状态",{"2":{"310":1}}],["这个留到下一节讲",{"2":{"302":1}}],["这个范式trick了一下",{"2":{"292":1}}],["这个kittens中放到了warpgroup下",{"2":{"292":1}}],["这个是每个node上都有的",{"2":{"287":1}}],["这个bar会帮我们做好同步的事情",{"2":{"285":1}}],["这个对应的0其实是值域的中点",{"2":{"270":1}}],["这个就是步幅",{"2":{"201":1}}],["这个输出的每个元素可能依赖于输入的不同部分",{"2":{"177":1}}],["这个类型可以隐式地转化为指向任何内置类型的指针",{"2":{"175":1}}],["这个参数指定了张量",{"2":{"159":1}}],["这个公式有一个前提",{"2":{"154":1}}],["这个点上",{"2":{"145":1}}],["这个函数比较关键",{"2":{"285":1}}],["这个函数可以实现一个需求",{"2":{"133":1}}],["这个函数会返回词元索引列表",{"2":{"126":1}}],["这个单元可以是字符单元",{"2":{"126":1}}],["这个时候output就是我们要的答案结果",{"2":{"310":1}}],["这个时候传入decoder的rnn网络",{"2":{"310":1}}],["这个时候通常采用激活重计算技术来减少中间激活",{"2":{"301":1}}],["这个时候就需要定制的通信后端",{"2":{"299":1}}],["这个时候多个node之间不会尝试ssh验证",{"2":{"280":1}}],["这个时候micro",{"2":{"275":1}}],["这个时候bubble为",{"2":{"275":1}}],["这个时候可以使用epoll来完成异步接受",{"2":{"271":1}}],["这个时候一般如何写并行代码呢",{"2":{"260":1}}],["这个时候一个卷积核一般只能提取一个特性",{"2":{"125":1}}],["这个时候",{"2":{"237":1}}],["这个时候互相关运算的计算策略为",{"2":{"233":1}}],["这个时候epoll应运而生",{"2":{"215":1}}],["这个时候对于单个进程来说",{"2":{"215":1}}],["这个时候有一个比较好用的方法",{"2":{"207":1}}],["这个时候产物就在某种意义上共通了",{"2":{"205":1}}],["这个时候我们就需要梯度裁剪来稳定地训练",{"2":{"296":1}}],["这个时候我们就需要使用decltype",{"2":{"209":1}}],["这个时候我们必须得去sync一下",{"2":{"290":1}}],["这个时候我们c",{"2":{"209":1}}],["这个时候我们的图像大小进一步缩小",{"2":{"201":1}}],["这个时候我们通常使用",{"2":{"100":1}}],["这个时候下一个线程就可以获得锁然后去占用cpu",{"2":{"167":1}}],["这个时候会发生类型转换",{"2":{"158":1}}],["这个策略根据当前观测到的环境状态和奖励反馈",{"2":{"112":1}}],["这个特性可以帮助我们限制",{"2":{"109":1}}],["这个特性和其他大部分的",{"2":{"41":1}}],["这个权重将分配给每一个值",{"2":{"93":1}}],["这个不会被高亮显示",{"2":{"89":2}}],["这个里面包含了lib和nvcc编译器",{"2":{"50":1}}],["这里shape",{"2":{"312":1}}],["这里写的有点问题",{"2":{"304":1}}],["这里1和2是ffn层的全连接层",{"2":{"304":1}}],["这里应该是deepspeed整个框架的初始化的汇集点",{"2":{"302":1}}],["这里简单追踪一下张量shape的变化便于理解",{"2":{"300":1}}],["这里强调的是高性能所以不能使用mpi",{"2":{"299":1}}],["这里不大懂",{"2":{"296":1}}],["这里clamp",{"2":{"293":1}}],["这里clang也大概比gcc快一倍",{"2":{"221":1}}],["这里和之前算子不同的是",{"2":{"293":1}}],["这里就是将各个worker组织成二维网格结构",{"2":{"302":1}}],["这里就是属于deepep的部分了",{"2":{"290":1}}],["这里就不多赘述",{"2":{"190":1,"287":1}}],["这里就不过多赘述",{"2":{"87":1}}],["这里大部分的操作均为异步",{"2":{"290":1}}],["这里上文中也提到",{"2":{"290":1}}],["这里deepspeed提供了两种方式",{"2":{"280":1}}],["这里同样需要recv一个tensor",{"2":{"275":1}}],["这里分为intranode以及internode",{"2":{"272":1}}],["这里放一个sync版本的store",{"2":{"268":1}}],["这里打算解析一下x86",{"2":{"264":1}}],["这里针对gpu多机多卡训练的通信介绍一些知识",{"2":{"261":1}}],["这里是直接设置3",{"2":{"281":1}}],["这里是整个deepspeed启动训练任务的入口",{"2":{"261":1}}],["这里是一个我用cursor画的一个思维导图",{"2":{"249":1}}],["这里使用tanh作为激活函数",{"2":{"282":1}}],["这里使用了cp",{"2":{"257":1}}],["这里使用nn包中的卷积层",{"2":{"186":1}}],["这里着重分析参数",{"2":{"256":1}}],["这里有一些常用的isa",{"2":{"253":1}}],["这里有三条准则",{"2":{"172":1}}],["这里我本人是使用mac本地训练",{"2":{"282":1}}],["这里我认为可以将二维的神经网络堆叠成三维",{"2":{"251":1}}],["这里我们介绍一种encoder",{"2":{"310":1}}],["这里我们在gpu上训练",{"2":{"295":1}}],["这里我们初始化为全0张量",{"2":{"282":1}}],["这里我们其实有一个名为困惑度的量",{"2":{"274":1}}],["这里我们可以使用信息论",{"2":{"274":1}}],["这里我们可以构建一个词表",{"2":{"126":1}}],["这里我们就介绍汇聚层",{"2":{"273":1}}],["这里我们就得到了",{"2":{"145":1}}],["这里我们首先要知道一些细节",{"2":{"261":1}}],["这里我们讨论train的pp",{"2":{"225":1}}],["这里我们并不知道container中的类型是什么",{"2":{"209":1}}],["这里我们假设xxx是一个二维向量",{"2":{"129":1}}],["这里我们假定当前的虚拟环境叫dev",{"2":{"50":1}}],["这里我们处理数据简单分为以下步骤",{"2":{"126":1}}],["这里",{"2":{"234":1,"285":1}}],["这里需要重点讲解一下为什么会有一个for循环",{"2":{"282":1}}],["这里需要recv一个tensor",{"2":{"275":1}}],["这里需要区分是否使用tma",{"2":{"268":1}}],["这里需要区分bar",{"2":{"227":1}}],["这里需要注意kphasebit",{"2":{"227":1}}],["这里其实有一个点要注意一下",{"2":{"225":1}}],["这里input",{"2":{"225":1}}],["这里由于自身实现的差距",{"2":{"221":1}}],["这里gcc和clang的差距主要是编译时间",{"2":{"221":1}}],["这里gcc或者clang还有属于自己的tree",{"2":{"205":1}}],["这里相当于",{"2":{"201":1}}],["这里也解释了我们为什么通常将kernel的长宽均设置为奇数",{"2":{"201":1}}],["这里要区分右值引用和通用引用",{"2":{"172":1}}],["这里要区分值类型type和值类别value",{"2":{"172":1}}],["这里介绍两种对序列进行分割的方法",{"2":{"169":1}}],["这里介绍一种损失函数",{"2":{"146":1}}],["这里介绍一种比较简单的例子",{"2":{"93":1}}],["这里直接将图片展平",{"2":{"160":1}}],["这里直接对",{"2":{"159":1}}],["这里num",{"2":{"160":1}}],["这里类比vector就可以理解",{"2":{"158":1}}],["这里允许我们实现自己的",{"2":{"133":1}}],["这里补充一些会创建节点的操作",{"2":{"133":1}}],["这里变成了squared",{"2":{"129":1}}],["这里采取小批量随机梯度下降",{"2":{"129":1}}],["这里采用均方损失",{"2":{"110":1}}],["这里会通过广播机制扩散",{"2":{"129":1}}],["这里首先定义输入小批量样本",{"2":{"251":1}}],["这里首先计算",{"2":{"159":1}}],["这里首先为了简化之后的训练",{"2":{"126":1}}],["这里首先引入一个torch的简便操作",{"2":{"106":1}}],["这里只实现这两种简单的词元分割",{"2":{"126":1}}],["这里仍然使用d2l的库",{"2":{"126":1}}],["这里如果尝试使用全连接来拟合数据",{"2":{"110":1}}],["这里的激活不包含模型参数和优化器状态",{"2":{"297":1}}],["这里的激活",{"2":{"297":1}}],["这里的目的就是转换输出形态",{"2":{"282":1}}],["这里的通信与计算的overlap是这样做的",{"2":{"275":1}}],["这里的y",{"2":{"160":1}}],["这里的问题主要是const",{"2":{"156":1}}],["这里的tokens是1d列表或2d列表",{"2":{"126":1}}],["这里的",{"2":{"109":1}}],["这里的缩进",{"2":{"67":1}}],["这里以adam",{"2":{"105":1}}],["这里假设我有一张禽类图片",{"2":{"100":1}}],["这里可以发现",{"2":{"146":1}}],["这里可以使用pytorch的批量矩阵乘法",{"2":{"101":1}}],["这里可以参考deep",{"2":{"70":1}}],["这里可以找到",{"2":{"51":1}}],["这里选择先使用triton来示范如何写一个当前业界较为先进的一版gemm",{"2":{"70":1}}],["这里先放一个链接",{"2":{"47":1}}],["这里研究decode",{"2":{"38":1}}],["这确实需要花比较多功夫来插入",{"2":{"41":1}}],["这句话其实暗示了",{"2":{"41":1}}],["这项特性让你可以很容易地用",{"2":{"26":1,"34":1,"36":1,"39":1}}],["这允许将标题链接为",{"2":{"18":1}}],["这些变量",{"2":{"304":1}}],["这些具体的参数",{"2":{"287":1}}],["这些操作分别称为最大汇聚层",{"2":{"281":1}}],["这些操作不会影响模型的梯度和参数更新",{"2":{"129":1}}],["这些是硬件自带的能力",{"2":{"272":1}}],["这些知识的不同来源于相同的查询",{"2":{"246":1}}],["这些差异最终导致clang和gcc机器码的不同",{"2":{"221":1}}],["这些可以理解为是汇编语言的种类",{"2":{"190":1}}],["这些概率本质上就是语言模型的参数",{"2":{"140":1}}],["这些值累加为1",{"2":{"115":1}}],["这些超参数直接影响着kernel的吞吐",{"2":{"70":1}}],["这些都包含在targets",{"2":{"50":1}}],["这些衍生版本要么基于工具",{"2":{"7":1,"13":1,"15":1,"17":1}}],["这些功能原初的",{"2":{"7":1,"13":1,"15":1,"17":1}}],["要求",{"2":{"253":1}}],["要求枚举已定义",{"2":{"207":1}}],["要一一对应",{"2":{"133":1}}],["要训练的模型",{"2":{"112":1}}],["要用预设链接标签只要在链接文字后面加上一个空的方括号",{"2":{"104":1}}],["要建立一个行内形式的链接",{"2":{"104":1}}],["要在纯文字应用中设计一个",{"2":{"149":1}}],["要在",{"2":{"67":1}}],["要避免这样的状况",{"2":{"59":1}}],["要让列表看起来更漂亮",{"2":{"59":1}}],["要为标题指定自定义锚点而不是使用自动生成的锚点",{"2":{"18":1}}],["要么基于网站",{"2":{"7":1,"13":1,"15":1,"17":1}}],["q^",{"2":{"304":3}}],["qp⋅q",{"2":{"281":2}}],["q=xwq​",{"2":{"277":1}}],["q=xwq",{"2":{"277":1}}],["q=larry+bird",{"2":{"26":2,"34":2,"36":2,"39":2}}],["qktqk^tqkt",{"2":{"277":1,"297":3}}],["qkth",{"2":{"277":1}}],["qk^t",{"2":{"277":1}}],["qkv函数的操作",{"2":{"246":1}}],["qkv",{"2":{"246":4}}],["qk⊤d",{"2":{"150":1}}],["q$",{"2":{"224":1}}],["q∈rdq​",{"2":{"230":1}}],["q∈rdq",{"2":{"230":1}}],["q∈rn∗d",{"2":{"150":2}}],["q∈rq",{"2":{"122":1,"136":1}}],["qqq",{"2":{"122":1,"251":1,"277":1,"297":1}}],["quantize",{"2":{"293":1}}],["quant",{"0":{"118":1},"2":{"270":5,"286":2}}],["queries的形状",{"2":{"136":1,"150":1}}],["queries和attention",{"2":{"106":1}}],["queries",{"2":{"106":4,"136":6,"150":3,"246":5,"269":1}}],["query的形状为",{"2":{"183":1}}],["querys被调整为",{"2":{"106":1}}],["query",{"2":{"50":2,"79":1,"93":1,"136":4,"183":3,"246":2,"304":1}}],["quoting",{"2":{"52":1}}],["quot",{"2":{"2":2,"40":4,"89":2,"104":2,"111":2,"133":2,"171":2,"183":2,"196":2,"199":2,"209":2,"214":4,"225":2,"285":4,"290":2}}],["q",{"0":{"16":1},"1":{"23":1,"30":1,"37":1,"43":1,"49":1,"54":1},"2":{"101":11,"122":19,"136":10,"150":6,"230":12,"246":3,"251":2,"277":1,"282":4,"293":10,"297":1,"304":5}}],["v形调度",{"2":{"290":1}}],["v3",{"2":{"290":2}}],["v=xwv​",{"2":{"277":1}}],["v=xwvq",{"2":{"277":1}}],["v这三种",{"2":{"253":1}}],["v9",{"2":{"253":1}}],["vh",{"2":{"241":1}}],["vdots",{"2":{"230":1}}],["v$",{"2":{"224":1}}],["v4",{"2":{"211":1}}],["volatile",{"2":{"179":1,"196":1,"211":7,"227":6,"257":5,"268":7,"285":5,"292":1}}],["volatile实参会被认为是non",{"2":{"179":1}}],["void",{"2":{"156":2,"179":5,"194":2,"211":10,"257":3,"268":6,"285":5,"292":1}}],["vocab",{"2":{"126":5,"178":5,"183":4,"193":7,"202":1,"282":11,"289":5,"300":3,"306":6,"310":9,"312":4}}],["v∈rdv​",{"2":{"230":1}}],["v∈rdv",{"2":{"230":1}}],["v∈rn×v",{"2":{"150":2}}],["v∈rm∗v",{"2":{"150":1}}],["v仅有一个输出",{"2":{"136":1}}],["v^",{"2":{"136":1,"304":3}}],["vm​",{"2":{"122":2}}],["vm",{"2":{"122":2}}],["v1​",{"2":{"122":2}}],["v1",{"2":{"122":2}}],["vvv",{"2":{"109":2,"121":1,"150":1,"210":1,"277":2,"297":3}}],["val",{"2":{"207":4}}],["value",{"0":{"172":1},"2":{"172":1,"227":2,"246":2,"257":1,"304":1,"305":8,"312":1}}],["value=0",{"2":{"312":1}}],["value=",{"2":{"122":1}}],["values=true",{"2":{"305":1}}],["values都是",{"2":{"269":1}}],["values的小批量",{"2":{"136":1}}],["values的形状",{"2":{"106":1,"136":1,"150":1,"246":1}}],["values的形状为",{"2":{"106":1}}],["values",{"2":{"101":1,"106":7,"136":4,"150":2,"246":5}}],["validate",{"2":{"305":2}}],["valid",{"2":{"122":9,"136":4,"150":3,"183":5,"246":6,"312":11}}],["variable",{"2":{"211":3}}],["variance记录梯度平方的指数加权平均值",{"2":{"105":1}}],["variance",{"2":{"105":1}}],["var",{"2":{"137":16}}],["varepsilonε",{"2":{"105":1}}],["varepsilon",{"2":{"105":1}}],["vgg网络的超参数",{"2":{"94":1}}],["vgg以块为一个单元",{"2":{"94":1}}],["vgg",{"0":{"94":1},"2":{"94":4}}],["v",{"2":{"89":2,"101":11,"105":3,"109":16,"122":5,"125":12,"136":3,"150":4,"158":1,"190":2,"209":2,"230":14,"246":3,"253":1,"277":9,"304":6,"305":5}}],["virtual",{"2":{"275":1}}],["visible",{"2":{"227":1}}],["visit",{"2":{"104":1}}],["vi​∈rv",{"2":{"122":1}}],["vi∈rv",{"2":{"122":1}}],["view",{"2":{"101":2,"133":1,"193":2,"220":1}}],["vitepress",{"2":{"89":4}}],["vitae",{"2":{"52":2,"59":3}}],["viverra",{"2":{"52":2,"59":3}}],["version",{"2":{"305":1}}],["verl",{"2":{"14":1,"141":1}}],["vexing",{"2":{"158":1}}],["vector",{"2":{"158":1,"209":1,"279":1}}],["vec",{"2":{"119":22,"211":2}}],["velit",{"2":{"52":2,"59":3}}],["vestibulum",{"2":{"52":2,"59":3}}],["vscode",{"2":{"50":1}}],["v要先经过一层linear",{"2":{"47":1}}],["vuepress",{"2":{"25":1,"40":1,"89":4,"134":2}}],["vllm",{"2":{"1":1}}],["+t",{"2":{"304":1}}],["+zp",{"2":{"286":2}}],["+2bshv",{"2":{"277":1}}],["+2bshvl",{"2":{"277":1}}],["+21​i=j∑​pi​pj​=1−i∑​pi2​",{"2":{"131":1}}],["+vh",{"2":{"241":1}}],["+vhl",{"2":{"241":1}}],["+的运行时提升",{"2":{"221":1}}],["+x",{"2":{"145":3,"304":1}}],["+12∑i≠jpipj=1−∑ipi2",{"2":{"131":1}}],["+=",{"2":{"129":1,"305":1}}],["++",{"2":{"89":3}}],["+",{"2":{"14":2,"49":1,"70":1,"73":1,"93":2,"100":1,"105":3,"106":2,"109":4,"110":4,"114":1,"115":1,"119":7,"125":2,"126":4,"129":7,"131":2,"132":1,"133":1,"136":2,"137":5,"147":2,"154":1,"158":4,"160":3,"161":3,"172":1,"183":1,"186":9,"187":3,"201":5,"202":6,"213":1,"224":2,"227":1,"228":2,"237":1,"241":3,"250":2,"251":5,"254":2,"256":9,"257":6,"268":5,"269":2,"271":1,"275":1,"277":6,"281":10,"282":3,"284":2,"286":1,"290":1,"291":2,"295":4,"296":2,"297":4,"298":1,"300":2,"304":4,"305":5,"310":1,"312":2}}],["l×",{"2":{"277":2,"297":2}}],["ldg",{"2":{"211":2}}],["ldsm4",{"2":{"211":1}}],["lds",{"2":{"211":2,"268":2}}],["ldmatrix",{"2":{"211":4,"268":1}}],["ld",{"2":{"205":1,"211":6,"221":1,"268":1}}],["ldots",{"2":{"110":4,"140":2,"274":2}}],["lstm以元组作为隐状态",{"2":{"306":1}}],["lstm",{"2":{"306":1}}],["lstm或对于我们从零开始实现的模型是个张量",{"2":{"300":1}}],["lscpu",{"2":{"253":2}}],["ls",{"2":{"192":2}}],["lw1",{"2":{"192":1}}],["lw",{"2":{"192":1}}],["ln",{"2":{"146":1}}],["lnp",{"2":{"146":2}}],["lm2",{"0":{"254":1},"1":{"265":1,"275":1,"283":1},"2":{"254":1}}],["lm的paper",{"2":{"237":1}}],["lm中",{"2":{"225":1}}],["lm中的distribute",{"2":{"225":1}}],["lm",{"0":{"237":1,"254":1},"1":{"265":1,"275":1,"283":1},"2":{"141":1,"237":1}}],["l1l1l1",{"2":{"131":1}}],["l​",{"2":{"109":2}}],["l",{"2":{"106":4,"109":5,"110":2,"129":8,"186":3,"196":1,"211":2,"241":2,"257":5,"268":3,"295":6,"296":1,"297":1,"300":4,"304":2,"312":3}}],["lr=lr",{"2":{"295":1,"312":1}}],["lr=0",{"2":{"106":1,"193":1}}],["lrcpc",{"2":{"253":1}}],["lr为步长",{"2":{"129":1}}],["lrlrlr",{"2":{"105":1}}],["lr",{"2":{"94":2,"105":1,"110":2,"129":5,"186":2,"295":3,"300":3,"302":1,"305":3,"312":1}}],["l2",{"2":{"70":2,"257":3,"268":1}}],["llvm模块化设计",{"2":{"221":1}}],["llvm",{"2":{"205":1}}],["lld",{"2":{"205":1,"221":1}}],["llm",{"0":{"222":1},"1":{"237":1,"254":1,"265":1,"275":1,"283":1,"290":1},"2":{"65":1,"270":1}}],["lll",{"2":{"38":2,"210":1,"224":1,"241":1,"297":1}}],["lock",{"2":{"152":1}}],["local",{"2":{"97":1,"141":2}}],["lora",{"2":{"127":1,"141":6}}],["lorem",{"2":{"52":2,"59":4,"89":2}}],["lower",{"2":{"126":1}}],["long",{"2":{"158":2,"300":1,"306":1,"310":1}}],["longleftrightarrow",{"2":{"115":1}}],["longish",{"2":{"104":1}}],["losslossloss",{"2":{"146":2}}],["loss",{"2":{"106":4,"110":7,"129":11,"141":3,"146":5,"186":1,"193":4,"295":4,"296":1,"300":4,"312":8}}],["loss的一次反向传播",{"2":{"105":1}}],["logger",{"2":{"294":3,"299":1,"305":3}}],["logni​=−αlogi+c",{"2":{"154":1}}],["log⁡ni=−αlog⁡i+c",{"2":{"154":1}}],["log",{"2":{"89":6,"127":8,"132":1,"154":2,"160":2,"274":2}}],["load到显存中",{"2":{"305":1}}],["load就是将tensor或者model",{"2":{"305":1}}],["loads",{"2":{"292":1}}],["load",{"0":{"211":1,"257":1},"2":{"64":2,"94":1,"110":1,"126":1,"129":2,"141":3,"160":1,"202":1,"211":2,"227":1,"244":2,"257":8,"268":6,"285":1,"292":6,"294":3,"305":2}}],["leq",{"2":{"304":4}}],["legend=",{"2":{"295":1,"300":1}}],["learning∣deep",{"2":{"140":2}}],["learning",{"2":{"140":11,"305":2}}],["learned",{"2":{"116":1}}],["leaf",{"2":{"133":1}}],["leftarrow",{"2":{"296":1,"304":2}}],["left左对齐的内容",{"2":{"164":2}}],["left|",{"2":{"131":1}}],["left",{"2":{"93":4,"106":3,"131":1,"150":1,"269":2,"274":3,"277":1,"296":1,"298":2,"304":2}}],["len的形状",{"2":{"312":1}}],["len从",{"2":{"312":1}}],["lenet",{"0":{"295":1},"2":{"295":1}}],["len这个维度分割",{"2":{"283":1}}],["len=1000",{"2":{"269":1}}],["lens=none",{"2":{"150":1}}],["lens的形状",{"2":{"150":1}}],["lens",{"2":{"122":10,"136":4,"150":1,"183":5,"246":6}}],["length",{"2":{"97":7,"101":14,"132":3,"178":9,"193":4}}],["len",{"2":{"93":1,"126":4,"129":2,"137":2,"159":2,"160":4,"187":1,"202":1,"269":2,"295":1,"305":1,"312":11}}],["level=level",{"2":{"305":1}}],["level=0",{"2":{"305":1}}],["level中",{"2":{"268":1}}],["level",{"2":{"52":2,"70":1,"211":3,"292":2,"305":3}}],["lectus",{"2":{"52":2,"59":3}}],["luctus",{"2":{"52":2,"59":3}}],["lcudart是cuda运行时编译选项",{"2":{"50":1}}],["lcudart",{"2":{"50":1}}],["literal",{"2":{"120":1,"135":2,"213":1}}],["like",{"2":{"101":1,"133":1,"312":1}}],["li",{"2":{"89":2,"190":2}}],["li>magic",{"2":{"59":1}}],["li>mchale",{"2":{"59":1}}],["li>parish",{"2":{"59":1}}],["li>",{"2":{"59":9,"89":2}}],["li>bird",{"2":{"59":2}}],["liststruct1",{"2":{"192":1}}],["liststruct",{"2":{"192":1}}],["list",{"2":{"52":2,"57":1,"59":6,"94":2,"97":2,"126":5,"129":1,"158":2,"187":2,"192":2,"194":7,"202":1,"225":2,"295":1}}],["libero",{"2":{"52":2,"59":3}}],["lib",{"2":{"50":3,"163":1}}],["lib等",{"2":{"50":1}}],["linreg",{"2":{"129":2}}],["link",{"2":{"104":7}}],["link起来",{"2":{"50":1}}],["linkage",{"2":{"50":1}}],["lines",{"2":{"126":9}}],["lines>",{"2":{"89":1}}],["line",{"2":{"41":1,"59":1,"89":2,"126":10}}],["linear",{"0":{"21":1,"63":1},"1":{"73":1,"85":1,"99":1,"114":1,"129":1},"2":{"94":3,"97":5,"101":6,"110":3,"116":2,"123":1,"129":1,"133":1,"136":3,"141":1,"178":1,"183":1,"230":1,"246":4,"295":4,"306":5,"310":1,"312":1}}],["linux可以使用下面的指令查看当前平台支持的isa",{"2":{"253":1}}],["linux",{"2":{"14":1,"50":2,"190":3,"272":1}}],["lambda",{"2":{"289":1,"300":2,"305":1}}],["laneid",{"2":{"257":3,"268":4,"285":4,"292":2}}],["languages",{"2":{"89":1}}],["language",{"0":{"237":1,"254":1},"1":{"265":1,"275":1,"283":1},"2":{"38":1}}],["large",{"0":{"254":1},"1":{"265":1,"275":1,"283":1}}],["label的shape是",{"2":{"312":1}}],["label的形状",{"2":{"312":1}}],["label",{"2":{"312":3}}],["labels",{"2":{"110":2,"129":8}}],["lab",{"2":{"227":2}}],["last",{"2":{"101":2}}],["layer上",{"2":{"290":1}}],["layer进行进一步划分",{"2":{"275":1}}],["layernorm",{"2":{"147":2,"161":3}}],["layers=2",{"2":{"310":2}}],["layers",{"2":{"94":5,"101":1,"147":1,"161":2,"178":7,"183":4,"193":2,"225":1,"306":3,"310":9}}],["layer",{"0":{"147":1,"161":1},"2":{"87":1,"123":3,"141":1,"147":2,"161":4,"178":4,"225":2,"306":2}}],["latent",{"0":{"81":1}}],["latex",{"2":{"7":1,"12":1,"13":1,"15":1,"17":1,"20":1,"22":1,"24":1}}],["launcher的目的是管理这些进程",{"2":{"287":1}}],["launcher来选择",{"2":{"272":1}}],["launcher最难的地方其实就是多机的初始化和通信",{"2":{"261":1}}],["launcher",{"0":{"261":1},"1":{"272":1,"280":1,"287":1},"2":{"261":1,"280":1,"287":1}}],["launcher+initialize",{"2":{"76":1}}],["launch",{"2":{"70":2,"280":1,"287":1}}],["laoreet",{"2":{"52":2,"59":3}}],["laws",{"2":{"38":1}}],["lto技术是一种链接时的代码优化技术",{"2":{"221":1}}],["lto支持",{"2":{"221":1}}],["lt",{"0":{"211":1},"2":{"19":5,"26":8,"27":5,"29":5,"31":5,"34":8,"36":8,"39":8,"41":4,"59":1,"67":5,"115":3,"120":2,"135":1,"149":1,"158":1,"194":1,"213":1,"214":2,"268":1}}],["手搓一个rdma",{"2":{"14":1}}],["手搓一个pipline",{"2":{"14":1}}],["dn∗d",{"2":{"269":1}}],["d^2",{"2":{"269":1}}],["d2",{"2":{"269":2}}],["d2l",{"2":{"94":3,"106":1,"110":2,"122":1,"126":5,"129":3,"160":3,"183":1,"233":1,"246":1,"295":7,"300":4,"312":4}}],["d∗dd",{"2":{"269":1}}],["dp将model",{"2":{"265":1}}],["dp",{"2":{"265":1}}],["dpo",{"2":{"127":1}}],["dcpodp",{"2":{"253":1}}],["dcpop",{"2":{"253":1}}],["dh",{"2":{"251":3}}],["dumps",{"2":{"305":1}}],["dumps``",{"2":{"305":2}}],["during",{"2":{"290":1}}],["dualpipe其实是一种和deepep深度耦合的技术",{"2":{"290":1}}],["dualpipe",{"0":{"290":1},"2":{"290":1}}],["dualpipev是带有virtual",{"2":{"290":1}}],["dualpipev",{"2":{"225":1}}],["ducks",{"2":{"257":10,"268":7}}],["duplicate",{"2":{"237":1}}],["dwarf5",{"2":{"221":1}}],["dwarf4",{"2":{"221":1}}],["dwarf格式差异",{"2":{"221":1}}],["dxd​f",{"2":{"145":1}}],["dx",{"2":{"145":1}}],["dd∗d",{"2":{"269":1}}],["ddxf",{"2":{"145":1}}],["ddd",{"2":{"38":1,"150":3,"251":1,"269":4}}],["dtype",{"2":{"141":1,"160":2,"257":4,"268":4,"305":5}}],["dtype=args",{"2":{"141":1}}],["dtype=torch",{"2":{"110":1,"132":1,"136":1,"269":2,"281":1,"310":1,"312":1}}],["dstmem",{"2":{"244":2}}],["dst4",{"2":{"211":2}}],["dst3",{"2":{"211":2}}],["dst2",{"2":{"211":2}}],["dst1",{"2":{"211":2}}],["dst",{"2":{"211":18,"257":20,"268":22}}],["ds",{"2":{"127":1,"141":5,"305":1}}],["dschat",{"2":{"127":1}}],["d=u+∑a=−δδ∑b=−δδ∑c",{"2":{"125":1}}],["d​qk⊤​",{"2":{"150":1}}],["d​=u+a=−δ∑δ​b=−δ∑δ​c∑​",{"2":{"125":1}}],["d​",{"2":{"125":2,"150":1}}],["droupout需要保存mask矩阵",{"2":{"297":1}}],["droupout操作",{"2":{"297":1}}],["droupout",{"2":{"147":2,"178":4,"193":2}}],["dropout操作的mask矩阵",{"2":{"297":1}}],["dropout=dropout",{"2":{"183":2,"310":2}}],["dropout=args",{"2":{"141":1}}],["dropout=0",{"2":{"136":1,"183":1,"310":2}}],["dropout",{"2":{"94":2,"107":1,"123":1,"136":5,"141":1,"147":5,"150":5,"161":8,"178":4,"246":2,"269":5}}],["driver设置为nvcc编译器路径",{"2":{"50":1}}],["driver=",{"2":{"50":1}}],["daringfireball",{"2":{"104":1}}],["daring",{"2":{"104":2}}],["data∈rb×s",{"2":{"277":1}}],["data∈rb×sdata",{"2":{"277":1}}],["dataloader",{"2":{"129":1,"302":1}}],["dataset",{"2":{"129":2}}],["datasets",{"2":{"127":1}}],["data",{"2":{"89":12,"94":1,"126":2,"127":2,"129":14,"137":2,"147":1,"160":9,"163":1,"186":1,"187":4,"193":5,"202":6,"211":1,"244":1,"257":1,"268":3,"295":2,"302":2,"305":4,"312":2}}],["dangerous",{"2":{"77":2}}],["downstream",{"2":{"147":1}}],["download云端的开源tokenizer或者导入本地的tokenizer",{"2":{"141":1}}],["download",{"2":{"126":1}}],["done",{"2":{"227":2}}],["donec",{"2":{"52":2,"59":3}}],["don",{"2":{"135":2}}],["double>",{"2":{"158":1}}],["double",{"2":{"120":2,"158":4}}],["dotproductattention",{"2":{"150":2,"246":1}}],["dots",{"2":{"122":1,"234":1,"258":1}}],["dot",{"2":{"101":3,"145":1,"150":1}}],["docker",{"2":{"253":1}}],["docs",{"2":{"89":1,"268":2}}],["docbook",{"2":{"7":1,"13":1,"15":1,"17":1}}],["dolor",{"2":{"52":2,"59":4}}],["dict",{"2":{"305":3}}],["dit",{"2":{"253":1}}],["directions",{"2":{"306":5}}],["directions应该是2",{"2":{"306":1}}],["directly",{"2":{"227":1}}],["dir=$",{"2":{"50":1}}],["diagonal=1",{"2":{"178":1}}],["diagnostics",{"2":{"50":1}}],["dist",{"2":{"299":3,"302":3}}],["distribute",{"0":{"299":1}}],["distributed进行了一次包装",{"2":{"299":1}}],["distributed封装为torchbackend",{"2":{"299":1}}],["distributed同样的api设计",{"2":{"299":1}}],["distributed",{"2":{"141":6,"225":2,"272":1,"299":2,"302":1}}],["display",{"2":{"160":1}}],["dispatch",{"2":{"97":1}}],["dims",{"2":{"137":3}}],["dim",{"2":{"122":1,"141":2,"257":4,"268":3,"283":1}}],["dim=0",{"2":{"137":2,"183":1,"188":1,"220":2,"246":1,"282":1}}],["dim=1",{"2":{"106":1,"123":2,"160":2,"183":2,"188":1,"289":1,"312":1}}],["dim=",{"2":{"101":1,"122":2,"137":2,"183":1}}],["dim=2",{"2":{"97":1}}],["dimensions",{"2":{"101":2}}],["dimension",{"2":{"101":3}}],["different",{"2":{"268":1}}],["diff",{"2":{"89":1}}],["divergence",{"2":{"119":2}}],["divisible",{"2":{"101":1}}],["div>",{"2":{"67":1}}],["div",{"2":{"19":1,"27":1,"29":1,"31":1,"67":3,"132":3,"293":1}}],["deprecate",{"2":{"305":1}}],["deprecated=true",{"2":{"305":1}}],["deprecated",{"2":{"305":11}}],["dep",{"2":{"305":12}}],["dequantize",{"2":{"293":1}}],["dense",{"2":{"183":2,"310":2}}],["decode",{"2":{"304":1}}],["decoder的具体实现",{"2":{"310":1}}],["decoder架构",{"2":{"310":1}}],["decoder与attention机制步骤",{"0":{"214":1}}],["decoder会有选择地统计输入序列的不同部分",{"2":{"183":1}}],["decoderlayer",{"2":{"161":3,"178":1}}],["decoder",{"0":{"161":1,"210":1,"308":1},"1":{"224":1,"241":1,"256":1,"267":1,"277":1,"284":1,"291":1,"297":1,"301":1},"2":{"87":1,"161":6,"178":4,"183":2,"210":2,"308":7,"310":5}}],["decltype就会返回左值引用",{"2":{"209":1}}],["decltype有一个比较重要的作用就是在模板中标识返回值类型",{"2":{"209":1}}],["decltype",{"0":{"209":1},"2":{"209":15}}],["dec",{"2":{"178":6,"308":4,"312":2}}],["decimal",{"2":{"135":2}}],["delattr",{"2":{"305":1}}],["deleted函数不能以任何方式被调用",{"2":{"223":1}}],["deleted",{"0":{"223":1},"2":{"223":1}}],["delete",{"2":{"156":1,"171":1}}],["delimited",{"2":{"135":2}}],["delta4δ",{"2":{"145":1}}],["delta",{"2":{"109":4,"125":8,"131":1,"146":2}}],["deltaδ",{"2":{"109":1,"145":1}}],["description",{"2":{"119":2}}],["detail",{"2":{"257":1,"268":1}}],["details",{"2":{"77":3,"89":2,"104":1}}],["detach",{"2":{"133":1,"300":2}}],["determine",{"2":{"97":1}}],["defines",{"2":{"147":1,"161":1}}],["default=true",{"2":{"305":1}}],["defaults",{"2":{"285":1}}],["default",{"2":{"89":18,"257":2,"268":1,"272":1,"305":1}}],["def",{"2":{"70":2,"93":1,"94":2,"97":4,"101":5,"106":2,"107":1,"110":3,"116":2,"117":2,"122":1,"123":4,"126":10,"129":6,"132":2,"133":3,"136":2,"137":3,"147":2,"150":2,"160":12,"161":2,"178":3,"183":6,"186":3,"187":2,"193":1,"201":1,"202":3,"225":4,"233":1,"246":4,"250":1,"262":1,"269":2,"281":1,"282":8,"289":1,"293":2,"294":1,"295":3,"296":1,"300":2,"305":7,"306":3,"308":7,"310":5,"312":4}}],["device=x",{"2":{"312":1}}],["device=mesh",{"2":{"302":1}}],["device=none",{"2":{"295":1}}],["device=try",{"2":{"282":1}}],["device=device",{"2":{"282":4,"289":2,"300":1,"306":3,"312":1}}],["device之间的点对点通信次数",{"2":{"275":1}}],["device",{"2":{"137":4,"141":6,"211":10,"227":2,"257":3,"268":3,"269":1,"282":8,"285":4,"289":1,"292":1,"295":12,"300":7,"302":3,"306":1,"312":5}}],["devide",{"2":{"70":1}}],["dev",{"0":{"50":1},"2":{"50":7}}],["deepseek",{"2":{"290":2}}],["deepspeed实现了一个deepspeedconfigmodel",{"2":{"305":1}}],["deepspeed适合比较小的模型",{"2":{"302":1}}],["deepspeed将pp与dp+tp分割开了",{"2":{"302":1}}],["deepspeedengine",{"2":{"302":1}}],["deepspeedhybridengine",{"2":{"302":1}}],["deepspeedconfigobject",{"2":{"305":1}}],["deepspeedconfigmodel",{"2":{"305":2}}],["deepspeedconfig",{"2":{"302":2}}],["deepspeed这里的代码只能说有一定的启发作用",{"2":{"299":1}}],["deepspeed的通信包保持着和torch",{"2":{"299":1}}],["deepspeed并没有使用torch",{"2":{"272":1}}],["deepspeed+megatron",{"2":{"76":1}}],["deepspeed",{"0":{"127":1,"249":1,"302":1},"1":{"141":1,"261":1,"272":1,"280":1,"287":1,"294":1,"299":1,"302":1,"305":1},"2":{"76":1,"127":1,"141":2,"261":1,"280":1,"299":3,"302":1,"305":1}}],["deepep",{"2":{"14":1}}],["deep",{"2":{"14":1,"140":10}}],["d",{"2":{"38":3,"50":2,"87":2,"101":26,"116":6,"125":5,"129":2,"132":4,"145":1,"147":7,"150":10,"158":2,"161":9,"178":10,"193":4,"211":1,"230":6,"251":1,"257":3,"258":1,"269":4,"310":1}}],["极大地推进了动态可重复性研究的历史进程",{"2":{"12":1,"20":1,"22":1,"24":1}}],["在序列中屏蔽不相关的项",{"2":{"312":1}}],["在循环神经网络模型中",{"2":{"310":1}}],["在循环遍历prefix中的开始字符时",{"2":{"289":1}}],["在deepspeed中",{"2":{"305":1}}],["在dualpipev中",{"2":{"290":1}}],["在推断阶段",{"2":{"304":1}}],["在第一次迭代或使用随机抽样时初始化state",{"2":{"300":1}}],["在启动分布式训练的时候确实可能需要很多的网络和通信的准备工作",{"2":{"299":1}}],["在asym下",{"2":{"298":1}}],["在下面的分析中",{"2":{"297":1}}],["在下面实现中",{"2":{"246":1}}],["在分析中间激活的显存占用时",{"2":{"297":2}}],["在进行正向和反向传播之前",{"2":{"295":1}}],["在进入transformer层之前",{"2":{"224":1}}],["在整个卷积块中",{"2":{"295":1}}],["在给定训练tokens数",{"2":{"291":1}}],["在1f1b调度中",{"2":{"290":1}}],["在1中",{"2":{"201":1}}],["在prepare",{"2":{"299":1}}],["在prefix后面生成新字符",{"2":{"289":1}}],["在python的网络框架中",{"2":{"271":1}}],["在python中网络框架和应用框架是解耦的",{"2":{"271":1}}],["在python中实现多进程",{"2":{"271":1}}],["在python中书写并行",{"0":{"260":1},"1":{"271":1}}],["在python中",{"2":{"184":1}}],["在pytorch上进行量化",{"2":{"238":1}}],["在store",{"2":{"285":1}}],["在sm",{"2":{"227":1}}],["在smem中",{"2":{"227":1}}],["在一次前向传递中",{"2":{"284":1}}],["在一次训练迭代中",{"2":{"256":1,"301":1}}],["在处理多通道输入的时候",{"2":{"281":1}}],["在量化的时候",{"2":{"279":1}}],["在基线上",{"2":{"274":1}}],["在基于位置的前馈网络中",{"2":{"116":1}}],["在最坏的情况下",{"2":{"274":1}}],["在最好的情况下",{"2":{"274":1}}],["在最流行的神经网络架构中",{"2":{"250":1}}],["在自己的进程里植入了应用框架的代码",{"2":{"271":1}}],["在自回归模型中",{"2":{"110":1}}],["在运行wsgi时",{"2":{"271":1}}],["在神经网络的推理阶段",{"2":{"267":1}}],["在compute之前我们需要receive一下上一个stage的tensor",{"2":{"290":1}}],["在cpp中",{"2":{"266":1}}],["在c++98中会将其标记为private",{"2":{"223":1}}],["在c++",{"2":{"152":1}}],["在优化器更新模型参数时",{"2":{"256":1}}],["在混合精度训练中",{"2":{"256":1}}],["在训练神经网络的过程中",{"2":{"256":1}}],["在训练的一次step之中",{"2":{"105":1}}],["在本地部署了个linux",{"2":{"253":1}}],["在互相关运算中",{"2":{"250":1}}],["在轴0",{"2":{"246":1}}],["在前三节中提到了一些比较有意思的东西",{"2":{"236":1}}],["在前一部分讨论的auto初始化表达式类型推导的地方",{"2":{"209":1}}],["在时间步",{"2":{"234":1}}],["在实现config类的时候可以顺便实现一些check方法",{"2":{"305":1}}],["在实现过程中通常选择缩放点积注意力作为每一个注意力头",{"2":{"246":1}}],["在实践中",{"2":{"230":1}}],["在实际的pp中",{"2":{"225":1}}],["在具体应用的时候",{"2":{"227":1}}],["在bwd阶段",{"2":{"225":1}}],["在bahdanau注意力模型中",{"2":{"183":1}}],["在backward实现中",{"2":{"133":1}}],["在fwd",{"2":{"290":1}}],["在fwd阶段",{"2":{"225":1}}],["在functional中存在了很多torch预先帮我们设计好的函数",{"2":{"117":1}}],["在matmul算子中",{"2":{"293":1}}],["在megatron",{"2":{"225":1}}],["在moe中我们一般会设定一个topk",{"2":{"111":1}}],["在其他章节已经介绍过了",{"2":{"210":1}}],["在其作用域中",{"2":{"207":1}}],["在编译器生效",{"2":{"207":1}}],["在编码器",{"2":{"87":1}}],["在计算互相关时",{"2":{"201":1}}],["在计算编码器的自注意力时",{"2":{"87":1}}],["在浏览器里面",{"2":{"198":1}}],["在这种情况下",{"2":{"274":3}}],["在这里补充一下",{"2":{"236":1}}],["在这里clang是高指令密度",{"2":{"221":1}}],["在这里",{"2":{"187":1}}],["在这个具体的例子中",{"2":{"145":1}}],["在这个上下文中",{"2":{"129":1}}],["在随机抽样的迭代过程中",{"2":{"187":1}}],["在二维互相关运算中",{"2":{"186":1}}],["在特征维度上连结",{"2":{"183":1}}],["在解码的某个时间步",{"2":{"183":1}}],["在解码器自注意力中",{"2":{"87":1}}],["在预测词元时",{"2":{"183":1}}],["在发生类型推导的前提下",{"2":{"172":1}}],["在多核机器下",{"2":{"167":1}}],["在non",{"2":{"275":1}}],["在nv",{"2":{"272":1}}],["在n个变量上累加",{"2":{"160":1}}],["在nn",{"2":{"117":1,"133":1}}],["在gil保证下",{"2":{"152":1}}],["在gil机制中",{"2":{"152":1}}],["在x=",{"2":{"145":1}}],["在x0x",{"2":{"145":1}}],["在点",{"2":{"145":1}}],["在梯度计算之后",{"2":{"145":1}}],["在初始时",{"2":{"145":1}}],["在数学上",{"2":{"145":1,"159":1}}],["在数学中可以表示为一个向量",{"2":{"145":1}}],["在数据科学领域",{"2":{"12":1,"20":1,"22":1,"24":1}}],["在卷积神经网络中",{"2":{"139":1}}],["在维度扩展后",{"2":{"136":1}}],["在代码中找到了一个shared",{"2":{"268":1}}],["在代码码区段内",{"2":{"135":1}}],["在代码块中实现行高亮",{"2":{"89":1}}],["在代码块里面",{"2":{"67":1}}],["在机器学习中",{"2":{"130":1}}],["在training",{"2":{"294":1}}],["在training里面首先是step1",{"2":{"127":1}}],["在train",{"2":{"282":1}}],["在transformer中",{"2":{"87":1}}],["在深度学习之中",{"2":{"117":1}}],["在深度学习中",{"2":{"79":1,"131":1,"177":1,"258":1}}],["在图像处理中",{"2":{"153":1}}],["在图像任意位置扫描就可以",{"2":{"109":1}}],["在图像识别中",{"2":{"95":1}}],["在反向传播时会被更新",{"2":{"106":1}}],["在反向传播结束之后",{"2":{"105":1}}],["在文件的任意处",{"2":{"104":1}}],["在上述中",{"2":{"186":1}}],["在上述例子中就是",{"2":{"64":1}}],["在上文中",{"2":{"96":1}}],["在某一行添加",{"2":{"89":2}}],["在某一行上添加",{"2":{"89":1}}],["在残差连接的加法计算之后",{"2":{"87":1}}],["在该项目的",{"2":{"50":1}}],["在使用换行来排版的时候",{"2":{"41":1}}],["在行尾加上两个以上的空格",{"2":{"41":1}}],["在",{"2":{"19":1,"26":1,"27":1,"29":1,"31":1,"34":1,"36":1,"39":1,"89":2,"104":1,"145":1}}],["在语法上基本兼容",{"2":{"7":1,"13":1,"15":1,"17":1}}],["转置为",{"2":{"300":1}}],["转义字符",{"0":{"213":1}}],["转化为",{"2":{"310":2}}],["转化为嵌入向量",{"2":{"214":1}}],["转化为嵌入向量再惯例permute一下",{"2":{"199":1}}],["转化为演讲",{"2":{"12":1,"20":1,"22":1,"24":1}}],["转为",{"2":{"135":1}}],["转换形态为2",{"2":{"220":2}}],["转换操作",{"0":{"220":1}}],["转换成标量后",{"2":{"177":1}}],["转换成更多的格式",{"2":{"7":1,"13":1,"15":1,"17":1}}],["转换为右值",{"2":{"172":1}}],["转换为t",{"2":{"172":1}}],["转换维一个",{"2":{"100":1}}],["我发现了这个类",{"2":{"305":1}}],["我觉得写好一个config还是比较困难的",{"2":{"305":1}}],["我看的是deepspeed",{"2":{"294":1}}],["我貌似没有get到这个和tp的区别",{"2":{"283":1}}],["我需要计算一个forward",{"2":{"275":1}}],["我需要保存用户的三种属性",{"2":{"207":1}}],["我可以arrive",{"2":{"227":1}}],["我比较偏好直接放在链接出现段落的后面",{"2":{"104":1}}],["我这里给出如下环境变量定义",{"2":{"50":1}}],["我们只取最后一层",{"2":{"310":1}}],["我们只需要在少数同步点上同步一下通信",{"2":{"290":1}}],["我们只需要在一个规定的比较小的范围",{"2":{"109":1}}],["我们只需要添加",{"2":{"201":1}}],["我们只需要观测从",{"2":{"110":1}}],["我们照例embedding一下并且permute一下",{"2":{"310":1}}],["我们按照惯例将其permute一下",{"2":{"310":1}}],["我们假如输入的",{"2":{"310":1}}],["我们发现对于",{"2":{"304":1}}],["我们发现这里引入了一个隐藏层参数",{"2":{"136":1}}],["我们尝试使用lenet来训练一下",{"2":{"295":1}}],["我们成功在各个node上启动了自己的train",{"2":{"294":1}}],["我们采用量化的手段将其重写为处理int8数据类型的算子",{"2":{"293":1}}],["我们肯定会先选择一个node登录",{"2":{"287":1}}],["我们计算量近似为",{"2":{"284":1}}],["我们经常转换输入的维度",{"2":{"282":1}}],["我们看一些边界情况来更好的理解上述式子",{"2":{"274":1}}],["我们希望逐渐降低隐藏表示的空间分辨率",{"2":{"273":1}}],["我们希望模型可以基于相同的注意力机制学习到不同的行为",{"2":{"230":1}}],["我们对每个时间步的输出层的输出进行softmax操作",{"2":{"263":1}}],["我们对上述实现的组件进行组装",{"2":{"147":1}}],["我们沿着时间维度进行传播",{"2":{"251":1}}],["我们常会增加输出通道的维数",{"2":{"250":1}}],["我们常常丢失边缘像素",{"2":{"201":1}}],["我们设定",{"2":{"246":1}}],["我们展示多输入输出通道时",{"2":{"217":1}}],["我们通常计算汇聚窗口中所有元素的最大值或平均值",{"2":{"281":1}}],["我们通常关注的是如何根据损失函数",{"2":{"177":1}}],["我们通过传递引用的方式传递非常量左值引用",{"2":{"209":1}}],["我们如果要访问的话",{"2":{"207":1}}],["我们也可以重写他来制定enum的类型",{"2":{"207":1}}],["我们要优先使用限域enum",{"2":{"207":1}}],["我们总是使用编译器驱动而非直接调用底层工具的原因",{"2":{"205":1}}],["我们写出一个加载序列数据的迭代器",{"2":{"202":1}}],["我们是自上而下",{"2":{"201":1}}],["我们一般设置",{"2":{"201":1}}],["我们一般计算梯度是采取的y",{"2":{"159":1}}],["我们在定义空指针的时候",{"2":{"175":1}}],["我们传入的x就可以根据传入类型来判断",{"2":{"172":1}}],["我们输入需要为一个向量",{"2":{"160":1}}],["我们代入具体的",{"2":{"159":1}}],["我们再做一些小改动",{"2":{"295":1}}],["我们再解释一下第二种计算方式y",{"2":{"159":1}}],["我们再将点积除以",{"2":{"150":1}}],["我们不难得出两者相等",{"2":{"159":1}}],["我们不纠结具体时间",{"2":{"152":1}}],["我们来探讨一个看似没啥意义",{"2":{"262":1}}],["我们来对比一下这两种方式",{"2":{"159":1}}],["我们来看如下代码",{"2":{"156":1}}],["我们知道计算公式如下",{"2":{"277":1}}],["我们知道线程在执行了一定时间",{"2":{"232":1}}],["我们知道在使用backward",{"2":{"159":1}}],["我们知道cuda的核心开发工具包就是nv的cudatoolkit",{"2":{"50":1}}],["我们引入一个关于词频的定律",{"2":{"154":1}}],["我们创建的为",{"2":{"152":1}}],["我们更加通俗的解释一下",{"2":{"145":1}}],["我们使用交叉熵和小批量随机梯度下降来计算",{"2":{"295":1}}],["我们使用库的话",{"2":{"129":1}}],["我们使用卷积神经网络来提取图像的空间特征",{"2":{"96":1}}],["我们先将前面的常用词作为例外消除之后",{"2":{"154":1}}],["我们先定义两个真正的true",{"2":{"129":1}}],["我们先生成一下训练和测试样本",{"2":{"93":1}}],["我们想要将一个函数标记为无法使用",{"2":{"223":1}}],["我们想去用梯度下降法",{"2":{"129":1}}],["我们想提取边缘性或者其他特性",{"2":{"125":1}}],["我们选择字符词元化",{"2":{"126":1}}],["我们这里探讨一下如何处理序列数据",{"2":{"126":1}}],["我们上面得知了一个二维图像的卷积形式",{"2":{"125":1}}],["我们构建的模型",{"2":{"117":1}}],["我们需要执行矩阵乘法操作",{"2":{"293":1}}],["我们需要精细的控制计算图",{"2":{"290":1}}],["我们需要传入一些参数",{"2":{"287":1}}],["我们需要一个手段来评估我们的模型生成的语言的质量",{"2":{"274":1}}],["我们需要一个损失函数",{"2":{"146":1}}],["我们需要将每一小批数据移动到我们指定的设备上",{"2":{"295":1}}],["我们需要将input",{"2":{"225":1}}],["我们需要将若干禽类数据划分到三种类别下",{"2":{"100":1}}],["我们需要的是上一个阶段传来的output",{"2":{"225":1}}],["我们需要的是上一个阶段的input",{"2":{"225":1}}],["我们需要通过1",{"2":{"207":1}}],["我们需要对其进行分割",{"2":{"169":1}}],["我们需要计算单词的概率",{"2":{"140":1}}],["我们需要这个值来估计损失",{"2":{"129":1}}],["我们需要更好的模型",{"2":{"110":1}}],["我们找到了生成一串序列的方法",{"2":{"110":1}}],["我们现在有三种方式",{"2":{"269":1}}],["我们现在有了数据",{"2":{"140":1}}],["我们现在有一连串随时间变化的股票数据",{"2":{"110":1}}],["我们现在解决了如何预测的问题",{"2":{"110":1}}],["我们预测的其实是一个概率",{"2":{"110":1}}],["我们完成了二维卷积层conv2d的大致推导",{"2":{"109":1}}],["我们拿着这个固定的方框",{"2":{"109":1}}],["我们都有",{"2":{"109":1}}],["我们将state",{"2":{"310":1}}],["我们将推理过程优化为如下过程",{"2":{"304":1}}],["我们将其拆解",{"2":{"290":1}}],["我们将其归一化",{"2":{"109":1}}],["我们将创建一个长度为",{"2":{"282":1}}],["我们将比较cnn",{"2":{"269":1}}],["我们将词元序列输入注意力池化中",{"2":{"258":1}}],["我们将高斯核带入注意力汇聚公式",{"2":{"93":1}}],["我们有如下公式",{"2":{"109":1}}],["我们可以从每一层的shape中看出是怎么处理的",{"2":{"295":1}}],["我们可以写出这样的代码",{"2":{"293":1}}],["我们可以指定汇聚层的填充和步幅",{"2":{"288":1}}],["我们可以想到独热编码",{"2":{"282":1}}],["我们可以看到输出的维度为",{"2":{"282":1}}],["我们可以看一下pytorch的doc",{"2":{"272":1}}],["我们可以看出",{"2":{"251":1}}],["我们可以看出两点性质",{"2":{"115":1}}],["我们可以在输入表示中添加位置编码来注入绝对的或者相对的位置信息",{"2":{"269":1}}],["我们可以使用全连接层来实现",{"2":{"262":1}}],["我们可以使用动态规划来精确地计算结果",{"2":{"110":1}}],["我们可以对比一下non",{"2":{"257":1}}],["我们可以近似看为",{"2":{"241":1}}],["我们可以用独立学习得到的",{"2":{"230":1}}],["我们可以直接返回这个枚举的底层类型",{"2":{"207":1}}],["我们可以直接使用triton",{"2":{"70":1}}],["我们可以实现一个constexpr函数",{"2":{"207":1}}],["我们可以实现如下softmax函数",{"2":{"160":1}}],["我们可以通过下面的方法来访问数据",{"2":{"207":1}}],["我们可以更清晰地使用链式法则来逐步回溯",{"2":{"177":1}}],["我们可以求得它的梯度",{"2":{"146":1}}],["我们可以将其推理理解为",{"2":{"304":1}}],["我们可以将其看做是在每个像素位置应用的",{"2":{"262":1}}],["我们可以将其划分为两种类型",{"2":{"124":1}}],["我们可以将每个通道看作对不同特征的响应",{"2":{"250":1}}],["我们可以将",{"2":{"146":1}}],["我们可以构建一个更深的网络",{"2":{"139":1}}],["我们可以计算一下它的梯度",{"2":{"131":1}}],["我们可以把通道想象成一个特征",{"2":{"125":1}}],["我们可以自己定制属于自己的torch",{"2":{"117":1}}],["我们可以发现",{"2":{"110":1}}],["我们可以简单利用下标的变换获得下面的公式",{"2":{"109":1}}],["我们可以利用上述两个特点来改进多层感知机",{"2":{"109":1}}],["我们还可以分配一些索引给未知或者已删除的词元",{"2":{"126":1}}],["我们还可以快速将",{"2":{"12":1,"20":1,"22":1,"24":1}}],["我们还想有一个网络架构来对其进行计算",{"2":{"100":1}}],["我们首先回顾多层感知机的梯度消失是如何产生的",{"2":{"296":1}}],["我们首先要起一个进程",{"2":{"271":1}}],["我们首先要高效的接受请求",{"2":{"271":1}}],["我们首先要对分类问题有基本的认知",{"2":{"100":1}}],["我们首先看无隐状态的神经网络",{"2":{"251":1}}],["我们首先创建一个一维张量x0x",{"2":{"145":1}}],["我们首先进行推导",{"2":{"131":1}}],["我们首先总览一下training包",{"2":{"127":1}}],["我们首先可以统计不同的词元数目",{"2":{"126":1}}],["我们首先会定义一些超参数",{"2":{"70":1}}],["我们就可以使用梯度下降法",{"2":{"99":1}}],["我们的b一般就是weight",{"2":{"290":1}}],["我们的上下文变量",{"2":{"183":1}}],["我们的目的仍然是计算scale",{"2":{"238":1}}],["我们的目的是图像识别",{"2":{"125":1}}],["我们的目标就是让j",{"2":{"73":1}}],["我们的特征现在是平移不变的",{"2":{"109":1}}],["我们的神经网络应该对其具有相似的",{"2":{"95":1}}],["我们以图像识别为例",{"2":{"95":1}}],["我们给出一个注意力权重",{"2":{"93":1}}],["我们调整一下",{"2":{"93":1}}],["我们理解每个block是完全并行执行的",{"2":{"70":1}}],["我们会不断地将隐状态传递到下一个时间步",{"2":{"289":1}}],["我们会不断地接受请求",{"2":{"215":1}}],["我们会多一步",{"2":{"286":1}}],["我们会将这个固定状态拿去投入另外一个rnn",{"2":{"310":1}}],["我们会将每个索引映射为互不相同的单位向量",{"2":{"282":1}}],["我们会将一组在一个gpu上的连续的transformer",{"2":{"275":1}}],["我们会设置node",{"2":{"280":1}}],["我们会对multi",{"2":{"116":1}}],["我们会对调度的block进行重排",{"2":{"70":1}}],["我们会根据这个结构来对tokens进行分发",{"2":{"111":1}}],["我们会启动sm个block",{"2":{"70":1}}],["我们会使用tensor",{"2":{"70":1}}],["我个人习惯使用vscode",{"2":{"50":1}}],["我会去记录我学习过程中的一些困惑",{"2":{"2":1}}],["w^",{"2":{"304":4}}],["w^x=swsxwintxint−swzwsxxint−swsxzxwint+swzwsxzx",{"2":{"298":1}}],["w^x=sw",{"2":{"298":1}}],["wx​=sw​sx​wint​xint​−sw​zw​sx​xint​−sw​sx​zx​wint​+sw​zw​sx​zx​",{"2":{"298":1}}],["wx​=sw​",{"2":{"298":1}}],["wn​hn−1​+bn​",{"2":{"296":1}}],["wnhn−1+bn",{"2":{"296":1}}],["wn×c×h×w",{"2":{"49":1}}],["wsgi",{"2":{"271":2}}],["wsgi的master进程先通过unix",{"2":{"271":1}}],["wdh​",{"2":{"251":1}}],["wdhw",{"2":{"251":1}}],["wco​⋅ci​⋅kh​⋅kw​",{"2":{"250":1}}],["wci​⋅kh​⋅kw​",{"2":{"233":1,"250":1}}],["wo​​h1​⋮hh​​​∈rpo​",{"2":{"230":1}}],["wo​∈rpo​∗hpv​",{"2":{"230":1}}],["wo",{"2":{"230":1}}],["wo∈rpo∗hpvw",{"2":{"230":1}}],["wow",{"2":{"224":1,"277":1}}],["worker接受到unix",{"2":{"271":1}}],["worker进程在启动的时候调了run函数",{"2":{"271":1}}],["worker进程",{"2":{"271":1}}],["workspacefolder",{"2":{"50":2}}],["world",{"2":{"89":4,"141":2,"179":1,"194":1,"205":1}}],["word",{"2":{"12":1,"20":1,"22":1,"24":1,"89":3,"126":2}}],["wordpress",{"2":{"12":1,"20":1,"22":1,"24":1}}],["wpw​",{"2":{"201":1}}],["w0",{"2":{"190":1}}],["w∈r784∗10",{"2":{"160":1}}],["w4",{"2":{"158":3}}],["w3",{"2":{"158":2}}],["wv",{"2":{"304":2}}],["wv​∈rh",{"2":{"136":1}}],["wv∈rh",{"2":{"136":1}}],["wk",{"2":{"304":2}}],["wk​∈rh∗k",{"2":{"136":1}}],["wk∈rh∗k",{"2":{"136":1}}],["wq",{"2":{"304":2}}],["wq​∈rh∗q",{"2":{"136":1}}],["wq​q+wk​k",{"2":{"136":1}}],["wq∈rh∗q",{"2":{"136":1}}],["wqq+wkk",{"2":{"136":1}}],["www",{"2":{"109":1}}],["w是一个可学习的标量参数",{"2":{"106":1}}],["waits",{"2":{"292":1}}],["wait其实就是check当前这个phase是否结束",{"2":{"227":1}}],["wait",{"2":{"227":5,"244":2,"275":1,"285":6,"292":12}}],["waiting",{"2":{"227":1}}],["walkthrough",{"2":{"112":1}}],["watson核回归是一个非参数模型",{"2":{"93":1}}],["waston核回归",{"2":{"93":1}}],["warm",{"2":{"289":1}}],["warpgourp",{"2":{"292":1}}],["warpgroup",{"2":{"227":1,"292":16}}],["warpid",{"2":{"292":2}}],["warps>",{"2":{"227":1}}],["warps=w",{"2":{"70":1}}],["warp",{"2":{"196":1,"227":1,"244":1,"257":2,"268":2,"292":5}}],["warning",{"2":{"77":5,"89":9,"305":1}}],["writing",{"2":{"89":3}}],["w2​+xout​",{"2":{"277":1}}],["w2+xoutx",{"2":{"277":1}}],["w2先于r2",{"2":{"64":1}}],["w2",{"2":{"64":2,"158":3,"304":2}}],["w1先于r1",{"2":{"64":1}}],["w1",{"2":{"64":2,"158":3,"304":2}}],["wgmma",{"0":{"61":1},"2":{"70":1}}],["whh​",{"2":{"251":1}}],["whhw",{"2":{"251":1}}],["whq​",{"2":{"251":1}}],["whqw",{"2":{"251":1}}],["which",{"2":{"141":1}}],["white",{"2":{"55":2}}],["where",{"2":{"133":1}}],["when",{"2":{"110":3,"119":2,"272":1}}],["wha",{"2":{"119":2}}],["what",{"2":{"59":2}}],["wint​−zw​",{"2":{"298":1}}],["wint−zw",{"2":{"298":1}}],["wint8=clip",{"2":{"286":2}}],["wint8=round",{"2":{"286":2}}],["wint8",{"2":{"286":2}}],["windows",{"2":{"190":1}}],["wi",{"2":{"230":12}}],["widehat",{"2":{"298":2}}],["width=",{"2":{"181":1}}],["width",{"2":{"181":3,"257":1,"268":1}}],["widget",{"2":{"158":17}}],["will",{"2":{"141":2}}],["wise",{"0":{"116":1},"2":{"116":1,"147":1,"161":1}}],["wisi",{"2":{"52":2,"59":3}}],["without",{"2":{"290":1}}],["within",{"2":{"116":1,"227":1}}],["with",{"0":{"61":1,"285":1},"2":{"52":2,"59":3,"89":1,"126":1,"129":3,"133":1,"141":1,"147":1,"160":1,"161":1,"181":2,"272":1,"290":1,"295":2,"302":1,"305":2,"312":1}}],["wikipedia",{"2":{"7":1,"13":1,"15":1,"17":1}}],["we",{"2":{"257":2,"268":2,"290":1,"305":2}}],["weak",{"2":{"211":2}}],["weighted",{"2":{"312":2}}],["weight和activation经过量化后",{"2":{"298":1}}],["weight与activation的分离",{"2":{"290":1}}],["weightscale",{"2":{"286":2}}],["weights的形状",{"2":{"136":1}}],["weights的形状为",{"2":{"106":2}}],["weights",{"2":{"97":5,"106":4,"110":2,"136":2,"150":2,"183":6,"295":2,"312":7}}],["weight",{"2":{"49":1,"106":1,"110":1,"129":1,"133":1,"186":6,"238":1,"286":14,"295":2,"298":2,"305":1,"312":2}}],["welford算法",{"2":{"37":1}}],["w",{"2":{"49":5,"70":1,"100":4,"101":8,"105":2,"106":11,"109":3,"129":16,"136":13,"160":7,"186":5,"201":5,"230":7,"233":1,"246":8,"251":1,"257":2,"262":3,"268":2,"277":3,"281":4,"282":12,"296":2,"298":14,"304":13}}],["世界上最流行的博客平台",{"2":{"12":1,"20":1,"22":1,"24":1}}],["用流程图来表示就是下面这样",{"2":{"304":1}}],["用gpu训练模型",{"2":{"295":1}}],["用作nginx",{"2":{"271":1}}],["用encoder的最终隐状态初始化decoder的隐状态",{"2":{"214":1}}],["用当前的均值和方差做标准化",{"2":{"137":1}}],["用来获得输入序列中每个词元的特征向量",{"2":{"310":1}}],["用来解决变长输入输出问题",{"2":{"310":1}}],["用来表示上一层到这一层的变化",{"2":{"251":1}}],["用来不断地返回训练数据",{"2":{"202":1}}],["用来构建单标签多分类任务的输出",{"2":{"146":1}}],["用来生成数据",{"2":{"129":1}}],["用来作为一种网络内容的写作用语言",{"2":{"12":1,"20":1,"22":1,"24":1}}],["用一个卷积核来识别",{"2":{"125":1}}],["用两个",{"2":{"120":1}}],["用",{"2":{"110":1,"250":1}}],["用双引号把",{"2":{"104":1}}],["用于序列到序列学习的循环神经网络解码器",{"2":{"310":1}}],["用于序列到序列学习的循环神经网络编码器",{"2":{"310":1}}],["用于确保配置的正确性",{"2":{"305":1}}],["用于管理训练进程",{"2":{"287":1}}],["用于当我们只关心和的梯度的时候",{"2":{"159":1}}],["用于在其代码块内关闭梯度计算",{"2":{"129":1}}],["用于在指定的维度上插入一维",{"2":{"106":1}}],["用于更新该参数",{"2":{"105":1}}],["用于编写说明文档",{"2":{"12":1,"20":1,"22":1,"24":1}}],["用于扩展",{"2":{"7":1,"13":1,"15":1,"17":1}}],["用途",{"0":{"12":1,"20":1,"22":1,"24":1},"1":{"19":1,"26":1,"27":1,"29":1,"31":1,"34":1,"36":1,"39":1}}],["内观察到的实际词元",{"2":{"274":1}}],["内异步接受请求",{"2":{"271":1}}],["内核支持指令执行",{"2":{"253":1}}],["内联决策",{"2":{"221":1}}],["内聚合特征即可",{"2":{"109":1}}],["内容如下",{"2":{"205":1}}],["内容",{"2":{"104":1}}],["内容水印",{"0":{"9":1},"1":{"15":1,"22":1,"29":1,"36":1}}],["内存操作数",{"2":{"196":1}}],["内存模型可以通过操作可见性顺序",{"2":{"64":1}}],["内存一致性模型其实是存在于cpp中的概念",{"2":{"64":1}}],["内存占用以及lto效果",{"2":{"221":1}}],["内存占用以及输出大小",{"2":{"221":1}}],["内存占用低",{"2":{"129":1}}],["内存占用是模型运行时",{"2":{"49":1}}],["内存占用",{"2":{"49":2,"221":2}}],["内部会调用deepspeed的initialize",{"2":{"294":1}}],["内部链接",{"0":{"32":1},"1":{"40":1}}],["内部和外部链接都会被特殊处理",{"2":{"25":1}}],["内嵌",{"2":{"7":1,"13":1,"15":1,"17":1}}],["内嵌入训练",{"2":{"1":1}}],["g←min",{"2":{"296":1}}],["g←min⁡",{"2":{"296":1}}],["gloo",{"2":{"272":1}}],["global",{"2":{"141":2,"152":1,"211":2,"244":10,"257":4,"268":2,"292":4}}],["globalbatchsize64",{"2":{"127":1}}],["globalbatchsize",{"2":{"127":2}}],["globalbatchsize128",{"2":{"127":1}}],["gl",{"2":{"257":12,"268":8}}],["gold",{"2":{"221":1}}],["googlenet",{"0":{"123":1},"2":{"123":2}}],["google",{"2":{"26":2,"34":2,"36":2,"39":2,"104":17}}],["gqa",{"0":{"206":1}}],["g++",{"2":{"205":1,"221":1}}],["gnu",{"2":{"190":2,"221":1}}],["gcc表现各个方面较为一般",{"2":{"221":1}}],["gcc通常使用gnu的汇编器",{"2":{"205":1}}],["gcc",{"2":{"190":1,"221":7}}],["gil是一种粗粒度的锁",{"2":{"152":1}}],["gil",{"2":{"152":1}}],["github风格的表格",{"0":{"45":1}}],["github",{"2":{"7":1,"13":1,"14":2,"15":1,"17":1,"89":6}}],["gather",{"2":{"265":1,"299":1}}],["gate",{"2":{"97":2}}],["gas",{"2":{"190":1}}],["gamma$",{"2":{"224":1}}],["gamma",{"2":{"137":4}}],["g",{"2":{"105":2,"110":1,"196":1,"296":5}}],["generic",{"2":{"257":3,"268":6,"285":1}}],["generate",{"2":{"161":1,"178":2}}],["gelu",{"2":{"237":7,"277":1,"304":2}}],["getattr",{"2":{"305":2}}],["get模板实参所需要的",{"2":{"207":1}}],["getvalue",{"2":{"171":4}}],["getitem",{"2":{"126":2,"160":1}}],["getting",{"2":{"89":1}}],["get",{"2":{"70":2,"89":1,"104":4,"110":2,"126":1,"141":6,"207":4,"225":2,"257":1,"268":1,"282":4,"289":3,"299":1,"305":7}}],["gemm的实现",{"2":{"70":1}}],["gemm",{"0":{"53":1,"61":1,"70":1},"1":{"61":1,"70":1},"2":{"14":4,"70":7}}],["gpu使用nccl",{"2":{"299":1}}],["gpu只支持int8",{"2":{"298":1}}],["gpu利用率",{"2":{"291":1}}],["gpu利用率一般在",{"2":{"291":1}}],["gpu峰值flops",{"2":{"291":1}}],["gpu数",{"2":{"291":1}}],["gpu3",{"2":{"275":2}}],["gpu2",{"2":{"275":1}}],["gpu1",{"2":{"275":1}}],["gpu0",{"2":{"275":2}}],["gpu环境下",{"2":{"272":1}}],["gpu环境机器上可以run起来",{"2":{"50":1}}],["gpu感觉就是dp",{"2":{"141":1}}],["gpus",{"2":{"141":1}}],["gpu算子加速库",{"2":{"54":1}}],["gpu",{"0":{"254":1},"1":{"265":1,"275":1,"283":1},"2":{"54":1,"94":1,"141":1,"287":3,"295":3}}],["gpu机器",{"2":{"50":1}}],["guide2",{"2":{"70":1}}],["guide",{"2":{"32":1,"70":2}}],["gru以张量作为隐状态",{"2":{"306":1}}],["gru是个张量",{"2":{"300":1}}],["gru",{"2":{"183":1,"310":2,"312":1}}],["grutatext",{"2":{"7":1,"13":1,"15":1,"17":1}}],["grad本身也就没用了",{"2":{"225":1}}],["grad=4∗",{"2":{"159":2}}],["grad=true",{"2":{"106":1,"129":2,"133":8,"145":1,"160":4}}],["grad就会等于",{"2":{"145":1}}],["grad之中",{"2":{"145":1}}],["grad这个字段就会存储x0的梯度",{"2":{"145":1}}],["grad为none",{"2":{"145":1}}],["gradient",{"2":{"141":4,"159":3}}],["grad默认为false",{"2":{"133":1}}],["grad",{"2":{"106":1,"110":1,"129":6,"133":6,"137":1,"145":5,"159":1,"160":1,"186":2,"193":1,"203":1,"225":5,"275":1,"282":1,"295":3,"296":4,"300":3,"312":3}}],["graph层面可以做一些算子fusion",{"2":{"23":1}}],["graph计算图层面优化",{"2":{"23":1}}],["grep",{"2":{"253":2}}],["great",{"2":{"59":2}}],["green",{"2":{"59":3}}],["grouped",{"2":{"305":1}}],["group的形式",{"2":{"302":1}}],["group来等待",{"2":{"292":1}}],["groups",{"2":{"285":1,"292":1}}],["groupgemm",{"2":{"97":1}}],["group",{"2":{"14":1,"70":12,"141":1,"244":6,"257":1,"268":3,"279":1,"285":6,"292":1,"302":3}}],["gtg",{"2":{"105":1}}],["gt",{"0":{"211":1},"2":{"14":5,"19":5,"27":5,"29":5,"31":5,"41":4,"52":3,"59":2,"67":5,"115":6,"120":2,"135":1,"149":1,"158":1,"194":1,"213":1,"214":2,"233":3,"244":1,"268":2,"270":2,"286":2,"297":6}}],["p⋅qp",{"2":{"281":2}}],["p∈rn∗d",{"2":{"269":2}}],["pq​=pk​=pv​=ho​po​​",{"2":{"246":1}}],["pq=pk=pv=pohop",{"2":{"246":1}}],["p1",{"2":{"227":3}}],["pw=kw−1p",{"2":{"201":1}}],["pwp",{"2":{"201":1}}],["phase",{"2":{"292":4}}],["phases",{"2":{"290":1}}],["phi20ϕ",{"2":{"256":1}}],["phi2ϕ",{"2":{"256":1}}],["phiϕ",{"2":{"256":2}}],["phi",{"2":{"251":2,"267":1,"296":1}}],["ph=kh−1p",{"2":{"201":1}}],["php",{"2":{"201":1}}],["png",{"2":{"181":1}}],["public",{"2":{"156":1,"158":2,"171":1}}],["ptx内联的形式",{"2":{"196":1}}],["ptx",{"0":{"180":1},"1":{"196":1,"211":1,"227":1,"244":1,"257":1,"268":1,"278":1,"285":1,"292":1}}],["ptr",{"2":{"156":5,"171":5,"179":2,"211":1,"227":6,"257":16,"268":21,"285":4}}],["ptp",{"2":{"146":1}}],["p=softmax",{"2":{"146":2}}],["p=0",{"2":{"123":1}}],["pe",{"2":{"132":6,"190":1}}],["perplexity",{"2":{"300":1}}],["per",{"2":{"141":4,"187":3,"257":7,"268":7,"277":6,"279":5,"293":1}}],["perf",{"2":{"127":1}}],["performs",{"2":{"285":1}}],["perform",{"2":{"101":1}}],["permute之后shape是",{"2":{"312":1}}],["permute之后会将step提到前面",{"2":{"310":1}}],["permute",{"2":{"97":1,"183":4,"220":1,"246":2,"310":3,"312":1}}],["permalink",{"2":{"25":1,"32":1}}],["persistent",{"2":{"14":1,"70":1}}],["pmull",{"2":{"253":1}}],["pm",{"2":{"119":2}}],["pj​−1",{"2":{"146":1}}],["pj​⟺xi​",{"2":{"115":1}}],["pj−1",{"2":{"146":1}}],["pj⟺xi",{"2":{"115":1}}],["please",{"2":{"135":1}}],["plume",{"2":{"134":2,"181":1}}],["pl",{"2":{"104":1}}],["pipelineengine",{"2":{"302":1}}],["pipelinemodule",{"2":{"302":1}}],["pipeline",{"2":{"290":2,"302":1}}],["pipline",{"0":{"225":1},"2":{"65":1,"225":3}}],["pi​−pi2​",{"2":{"131":2}}],["pi​=softmax",{"2":{"115":1}}],["pi−pi2",{"2":{"131":3}}],["pi=softmax",{"2":{"115":1}}],["pi",{"2":{"93":1,"115":1,"119":4,"269":4}}],["pid",{"2":{"70":3}}],["p>please",{"2":{"135":1}}],["p>a",{"2":{"135":2}}],["p>use",{"2":{"135":1}}],["p>here",{"2":{"67":1}}],["p>this",{"2":{"67":1}}],["p>magic",{"2":{"59":1}}],["p>",{"2":{"59":2,"67":2,"104":6,"135":8,"181":1}}],["p>bird",{"2":{"59":1}}],["pydantic",{"2":{"305":9}}],["py或者multinode",{"2":{"261":1}}],["py调用inference相关代码",{"2":{"127":1}}],["py里",{"2":{"127":1}}],["py来描述具体的逻辑",{"2":{"127":1}}],["py",{"2":{"50":1,"127":22,"141":1,"261":2,"287":2,"294":2,"302":1}}],["pytorch模型量化",{"0":{"238":1}}],["pytorch中的梯度计算",{"0":{"130":1},"1":{"145":1,"159":1,"177":1}}],["pytorch中的梯度",{"2":{"129":1}}],["pytorch常用函数以及方法",{"0":{"128":1},"1":{"142":1,"155":1,"170":1,"188":1,"203":1,"220":1,"235":1,"252":1}}],["pytorch",{"0":{"113":1,"117":1},"1":{"133":1},"2":{"1":1,"129":1,"272":2}}],["python中",{"2":{"232":1}}],["python中多线程和async",{"0":{"108":1},"1":{"124":1,"138":1,"152":1,"167":1,"184":1,"200":1,"215":1,"232":1,"248":1,"260":1,"271":1}}],["python多线程的表现甚至差于串行",{"2":{"167":1}}],["python的多线程对于io密集型任务较为友好",{"2":{"167":1}}],["python3",{"2":{"50":3}}],["python八股速记",{"2":{"1":1}}],["python",{"0":{"28":1},"2":{"1":1}}],["pool",{"2":{"281":2}}],["pool2d",{"2":{"281":7}}],["pooling层输出通道与输入通道相同",{"2":{"281":1}}],["pooling",{"2":{"23":1,"281":2}}],["port等一些关键信息",{"2":{"280":1}}],["port等一些信息",{"2":{"280":1}}],["pow",{"2":{"269":1}}],["powerpc",{"2":{"190":1}}],["populate",{"2":{"305":1}}],["pop",{"2":{"246":1}}],["policy>",{"2":{"257":1,"268":1}}],["policy",{"2":{"211":2,"257":5,"268":5}}],["pos",{"2":{"187":3}}],["positionalencoding",{"2":{"132":2,"178":1,"269":2}}],["positional",{"0":{"132":1},"2":{"132":1,"178":3}}],["position",{"0":{"116":1},"2":{"116":1,"132":4,"147":1,"161":1}}],["positionwisefeedforward",{"2":{"116":2,"147":1,"161":1}}],["positionwise",{"2":{"87":1}}],["posuere",{"2":{"52":2,"59":3}}],["point",{"2":{"49":1,"209":1,"238":1,"270":1,"277":1,"286":1}}],["p",{"2":{"19":2,"27":2,"29":2,"31":2,"47":1,"59":1,"110":32,"115":1,"131":23,"140":17,"146":6,"181":3,"201":2,"211":1,"230":6,"234":4,"246":3,"269":8,"274":2,"275":2,"281":8,"296":5}}],["pragma",{"2":{"257":1,"268":1}}],["private",{"2":{"156":1,"158":1,"171":1,"227":1}}],["printf",{"2":{"257":1}}],["print",{"2":{"97":1,"106":1,"110":1,"123":1,"126":2,"129":2,"133":3,"136":1,"141":1,"145":3,"186":2,"193":1,"201":1,"233":1,"250":1,"281":1,"282":1,"289":1,"293":1,"295":4,"300":4,"310":2,"312":1}}],["prints",{"2":{"89":2}}],["protected",{"2":{"305":1}}],["provide",{"2":{"305":1}}],["provided",{"2":{"101":1,"305":1}}],["proxy",{"2":{"268":2,"285":1}}],["proc",{"2":{"253":1}}],["processes",{"2":{"290":1}}],["process",{"2":{"141":1,"287":4,"305":2}}],["processing",{"2":{"116":1}}],["projections",{"2":{"230":1}}],["projects",{"0":{"163":1}}],["prompt的场景",{"2":{"309":1}}],["prompting的技术",{"2":{"309":1}}],["prompting",{"0":{"309":1}}],["prompt",{"2":{"127":2,"309":1}}],["propto",{"2":{"154":1}}],["property",{"2":{"126":2,"183":2}}],["proportional",{"2":{"119":2}}],["prod",{"2":{"110":2,"140":1}}],["product",{"2":{"101":3,"150":1}}],["probs",{"2":{"101":3}}],["probabilities",{"2":{"101":1}}],["profile方法",{"2":{"14":1}}],["prepare",{"2":{"294":1}}],["prev",{"2":{"292":1}}],["previous",{"2":{"285":1,"292":1}}],["preventing",{"2":{"101":1}}],["pred的形状",{"2":{"312":1}}],["preds步",{"2":{"289":1}}],["preds",{"2":{"289":2}}],["predict",{"2":{"289":2,"300":5}}],["prediction",{"0":{"90":1}}],["pred",{"2":{"227":1,"312":3}}],["prefill阶段",{"2":{"304":1}}],["prefix",{"2":{"289":4,"300":2,"305":4}}],["prefix=",{"2":{"50":1}}],["prefetch",{"2":{"211":1,"244":1}}],["pretrained传入的参数是model",{"2":{"141":1}}],["pre>",{"2":{"67":6}}],["pre",{"2":{"19":1,"27":1,"29":1,"31":1,"67":1,"70":2,"76":1,"294":1}}],["pp的配置",{"2":{"302":1}}],["pp的混合并行策略",{"2":{"254":1}}],["ppl",{"2":{"300":3}}],["pp来说",{"2":{"275":1}}],["pp调度",{"2":{"275":2}}],["ppp",{"2":{"274":1}}],["pp进一步拆分transformer",{"2":{"265":1}}],["pp",{"2":{"265":1,"275":4,"290":1}}],["pp部分",{"2":{"225":1}}],["ppo原理",{"0":{"112":1}}],["ppo",{"0":{"98":1},"1":{"112":1,"127":1,"141":1},"2":{"14":1,"127":1}}],["ppt",{"2":{"12":1,"20":1,"22":1,"24":1}}],["pacg",{"2":{"253":1}}],["paca",{"2":{"253":1}}],["packages",{"2":{"50":3}}],["package",{"2":{"14":1}}],["passing",{"2":{"272":1}}],["pass",{"2":{"225":4,"305":1}}],["passed",{"2":{"141":1}}],["page",{"0":{"208":1},"2":{"104":1}}],["padding主要依照kernel",{"2":{"201":1}}],["padding代表上下左右都添加1行",{"2":{"201":1}}],["padding=",{"2":{"201":1,"281":1}}],["padding=3",{"2":{"123":1}}],["padding=2",{"2":{"107":1,"123":1,"295":2}}],["padding=0",{"2":{"107":1}}],["padding=1",{"2":{"94":1,"107":1,"123":5,"201":2,"281":2}}],["padding",{"2":{"101":1,"107":2,"141":1}}],["pair",{"2":{"94":3}}],["parity",{"2":{"227":1}}],["parish",{"2":{"59":2}}],["parse",{"2":{"158":1}}],["parser",{"2":{"141":2}}],["partition",{"2":{"302":1}}],["partial",{"2":{"119":8,"131":14,"146":4,"159":8}}],["part",{"2":{"147":1,"161":1}}],["parts",{"2":{"101":1,"161":2}}],["part3",{"2":{"61":1}}],["part2",{"2":{"61":1}}],["part1",{"2":{"61":1}}],["param=",{"2":{"305":1}}],["param都会成为它的一份copy",{"2":{"179":1}}],["param",{"2":{"129":4,"179":20,"194":1,"282":2,"296":2,"302":2,"305":19,"312":3}}],["params=get",{"2":{"282":1}}],["params",{"2":{"129":2,"282":12,"296":5,"300":1}}],["parameter参与计算",{"2":{"133":1}}],["parameter",{"0":{"237":1},"2":{"106":1,"137":4,"186":2,"305":3}}],["parameters=optimizer",{"2":{"305":1}}],["parameters就是模型的可学习权重",{"2":{"105":1}}],["parameters",{"2":{"105":1,"106":1,"110":1,"129":1,"141":1,"193":1,"295":2,"296":1,"300":1,"302":1,"305":1,"312":2}}],["paragraphs",{"2":{"52":2,"59":2}}],["paragraph",{"2":{"19":2,"27":2,"29":2,"31":2,"59":1,"67":2}}],["parallelism",{"2":{"290":3,"302":1}}],["parallel已经是时代的眼泪了",{"2":{"237":1}}],["parallel策略",{"2":{"237":1}}],["parallel的基石",{"2":{"237":1}}],["parallel如何实现",{"2":{"225":1}}],["parallel",{"0":{"222":1,"265":1,"283":1},"1":{"237":1,"254":1,"265":1,"275":1,"283":1,"290":1},"2":{"14":1,"65":2,"97":1,"225":2,"254":3,"265":1,"268":2,"302":5}}],["path=args",{"2":{"141":1}}],["path=",{"2":{"50":1}}],["path的方法可能不适用",{"2":{"50":1}}],["path",{"2":{"50":3,"104":1,"141":4,"149":2}}],["paper",{"0":{"55":1},"2":{"55":2,"237":1,"254":1,"290":1}}],["paper阅读记录",{"0":{"38":1}}],["papers",{"0":{"35":1,"216":1}}],["pandoc",{"2":{"7":1,"13":1,"15":1,"17":1}}],["如高度和宽度",{"2":{"288":1}}],["如今都由pytorch解决了",{"2":{"287":1}}],["如下是一个作用于3个输入通道与一个输出通道的例子",{"2":{"262":1}}],["如图中橙色映射关系",{"2":{"251":1}}],["如elf格式",{"2":{"205":1}}],["如变量",{"2":{"172":1}}],["如单词和字符",{"2":{"126":1}}],["如上图所示",{"2":{"100":1}}],["如上述例子",{"2":{"159":1}}],["如上述",{"2":{"23":1}}],["如果未提及状态",{"2":{"310":1}}],["如果rnn是双向的",{"2":{"306":1}}],["如果cdb最后还是为none",{"2":{"299":1}}],["如果精度不达标的话",{"2":{"298":1}}],["如果当前node",{"2":{"287":1}}],["如果当前mbarrier设置的是warp",{"2":{"227":1}}],["如果超出的话就取设定的上下界的值",{"2":{"286":1}}],["如果是真正的大模型",{"2":{"302":1}}],["如果是nv环境",{"2":{"272":1}}],["如果是用纯",{"2":{"104":1}}],["如果使用tma的话",{"2":{"268":1}}],["如果使用kv",{"2":{"267":1}}],["如果使用float16来进行推理",{"2":{"267":1}}],["如果卷积核的窗口形状是",{"2":{"233":1}}],["如果可以做到多核并行",{"2":{"232":1}}],["如果设置的bytes数量到达",{"2":{"227":1,"244":1}}],["如果改变了定义",{"2":{"207":1}}],["如果改成用链接名称的方式写",{"2":{"104":1}}],["如果维度不同则广播机制",{"2":{"188":1}}],["如果不满足广播机制就报错",{"2":{"188":1}}],["如果不是所有输入词元都是相关的",{"2":{"183":1}}],["如果不使用多进程来运行",{"2":{"152":1}}],["如果expr是右值",{"2":{"179":1}}],["如果expr是左值",{"2":{"179":1}}],["如果形参是通用引用",{"2":{"179":1}}],["如果形参是ref",{"2":{"179":2}}],["如果直接从这样的结构开始反向传播",{"2":{"177":1}}],["如果正常的构造函数",{"2":{"158":1}}],["如果",{"2":{"145":1}}],["如果gradient",{"2":{"141":1}}],["如果x不在内存上",{"2":{"137":1}}],["如果要标记一小段行内代码",{"2":{"135":1}}],["如果要在代码内插入反引号",{"2":{"135":1}}],["如果要在文字前后直接插入普通的星号或底线",{"2":{"120":1}}],["如果要在列表项目内放进引言",{"2":{"59":1}}],["如果对于pytorch的梯度计算有疑问可以看我的另外一篇文章",{"2":{"129":1}}],["如果没有显式声明",{"2":{"276":1}}],["如果没有使用tma",{"2":{"268":1}}],["如果没有传入valid",{"2":{"122":1}}],["如果没有内存一致性模型约束",{"2":{"64":1}}],["如果我想checkpoint",{"2":{"305":1}}],["如果我改变这个参数一点点",{"2":{"177":1}}],["如果我们在没有任何压缩的情况下存储序列",{"2":{"274":1}}],["如果我们的程序不能支持并行",{"2":{"260":1}}],["如果我们当前代码运行机制",{"2":{"232":1}}],["如果我们使用限域enum来进行声明的话",{"2":{"207":1}}],["如果我们目标类别是",{"2":{"146":1}}],["如果我们想让函数接受右值",{"2":{"209":1}}],["如果我们想生成",{"2":{"140":1}}],["如果我们想获得软性类别",{"2":{"100":1}}],["如果我钦定一个x0x",{"2":{"114":1}}],["如果顺序被随机地重排",{"2":{"96":1}}],["如果键",{"2":{"93":1}}],["如果列表项目间用空行分开",{"2":{"59":1}}],["如果通过",{"2":{"37":1}}],["如果你已经掌握了单机单卡简单使用pytorch训练model之后",{"2":{"237":1}}],["如果你想要用星号加在文字旁边的方式来做出强调效果",{"2":{"213":1}}],["如果你想要在代码块里输入用",{"2":{"67":1}}],["如果你需要的话",{"2":{"149":1}}],["如果你有更好的exp实现方式",{"2":{"133":1}}],["如果你还想要加上链接的",{"2":{"104":1}}],["如果你只想导入这个文件的一部分",{"2":{"103":1}}],["如果你只是想要使用这些符号",{"2":{"26":1,"34":1,"36":1,"39":1}}],["如果你很懒惰",{"2":{"59":1}}],["如果你很熟悉如何在",{"2":{"52":1}}],["如果你每行都有缩进",{"2":{"59":1}}],["如果你的列表标记写成",{"2":{"59":1}}],["如果你真的想要插入",{"2":{"41":1}}],["如果你是要链接到同样主机的资源",{"2":{"104":1}}],["如果你是使用",{"2":{"26":1,"34":1,"36":1,"39":1}}],["如果你是在",{"2":{"26":1,"34":1,"36":1,"39":1}}],["如果你要让",{"2":{"104":1}}],["如果你要链接到",{"2":{"26":1,"34":1,"36":1,"39":1}}],["如果你要打",{"2":{"26":1,"34":1,"36":1,"39":1}}],["如何选择",{"0":{"298":1}}],["如何做量化",{"0":{"279":1},"1":{"286":1}}],["如何实现真正意义上的并行",{"0":{"184":1}}],["如何理解",{"0":{"114":1}}],["如何解决",{"0":{"37":1}}],["如何分析整理",{"2":{"14":1}}],["如",{"2":{"7":2,"13":2,"15":2,"17":2}}],["如表格",{"2":{"7":1,"13":1,"15":1,"17":1}}],["等到达之后tx",{"2":{"227":1}}],["等价于",{"2":{"201":1}}],["等价于x0=torch",{"2":{"145":1}}],["等标签",{"2":{"19":1,"27":1,"29":1,"31":1}}],["等",{"2":{"7":1,"13":1,"15":1,"17":1,"201":1}}],["等等",{"2":{"7":1,"13":1,"15":1,"17":1}}],["efficient",{"0":{"254":1},"1":{"265":1,"275":1,"283":1},"2":{"290":1}}],["everything",{"2":{"305":1}}],["evtstrm",{"2":{"253":1}}],["eval",{"2":{"127":3,"136":1,"160":1,"295":1,"310":2}}],["evaluation",{"2":{"127":2}}],["evaluate",{"2":{"110":1,"160":1,"295":2}}],["e>>",{"2":{"207":2}}],["e>",{"2":{"207":6}}],["eax",{"2":{"190":1}}],["each",{"2":{"132":1,"225":1,"257":1,"268":1}}],["eot",{"2":{"141":2}}],["equivalent",{"2":{"135":2}}],["equation",{"2":{"119":2}}],["equations",{"2":{"119":2}}],["e2e",{"2":{"127":1}}],["elapsed",{"2":{"294":3}}],["elem",{"2":{"257":5,"268":5}}],["elf",{"2":{"190":6}}],["elif",{"2":{"126":1,"281":1,"305":3}}],["elit",{"2":{"52":2,"59":4}}],["else",{"2":{"122":2,"126":1,"137":3,"141":1,"202":1,"257":3,"268":2,"282":1,"292":1,"295":1,"296":1,"300":4,"302":2,"305":5,"306":2}}],["e⃗",{"2":{"119":1}}],["eye",{"2":{"106":2}}],["eye可以生成单位矩阵",{"2":{"106":1}}],["error",{"2":{"89":7,"158":2,"305":2}}],["etc",{"2":{"54":1}}],["ettext",{"2":{"7":1,"13":1,"15":1,"17":1}}],["echo",{"2":{"52":1}}],["emphasize",{"2":{"228":1}}],["embed",{"2":{"183":5,"199":1,"310":14}}],["embedded",{"2":{"178":4}}],["embedding层的参数量也相同",{"2":{"224":1}}],["embedding",{"2":{"178":6,"183":3,"224":1,"310":6}}],["em>",{"2":{"120":2}}],["em>single",{"2":{"120":2}}],["em",{"2":{"120":1,"213":1}}],["emoji",{"0":{"51":1},"2":{"51":1}}],["email",{"2":{"41":1,"52":3}}],["emax",{"2":{"37":2}}],["enabling",{"2":{"290":1}}],["enables",{"2":{"161":1}}],["enabled",{"2":{"137":1,"302":1}}],["enable",{"2":{"50":1,"141":2}}],["enumerator",{"2":{"207":6}}],["enumerate",{"2":{"126":1,"295":1}}],["enum",{"0":{"207":1},"2":{"207":2,"305":1}}],["entropy",{"2":{"160":2}}],["enter",{"2":{"41":1}}],["enc",{"2":{"161":4,"178":6,"183":12,"308":5,"310":2}}],["encapsulates",{"2":{"147":1}}],["encoded",{"2":{"135":2}}],["encoderdecoder",{"2":{"308":2}}],["encoder步骤",{"0":{"199":1}}],["encoder和decoder的运行步骤如下",{"2":{"183":1}}],["encoderlayer",{"2":{"147":3,"178":1}}],["encoder",{"0":{"30":1,"147":1,"308":1},"2":{"87":1,"147":4,"161":5,"178":4,"183":1,"210":1,"308":6,"310":5}}],["encoding",{"0":{"132":1},"2":{"132":1,"178":3}}],["ensure",{"2":{"101":1}}],["en",{"2":{"89":1}}],["engine",{"2":{"76":1,"127":1,"302":8}}],["end",{"2":{"67":2,"105":1,"131":3,"145":1,"146":1,"214":1,"230":1,"237":1}}],["enim",{"2":{"52":2,"59":3}}],["envs",{"2":{"50":7}}],["env",{"0":{"50":1}}],["e^",{"2":{"37":1,"115":2,"131":19}}],["exception",{"2":{"305":2}}],["except",{"2":{"305":3}}],["exists",{"2":{"305":1}}],["existing",{"2":{"290":1}}],["exi∑k=1nexk",{"2":{"131":1}}],["exi∑k=1nexk−",{"2":{"131":1}}],["exi∑k=1nexk−e2xi",{"2":{"131":1}}],["exp⁡",{"2":{"274":1}}],["expected",{"2":{"285":1}}],["expect",{"2":{"227":2,"285":2,"292":1}}],["expert结构最初应该是出现在qwen2",{"2":{"111":1}}],["experts和local",{"2":{"111":1}}],["experts",{"0":{"111":1},"2":{"97":7,"111":2}}],["expert",{"2":{"97":20,"290":1}}],["expr",{"2":{"179":1}}],["exp",{"2":{"93":4,"106":3,"122":3,"132":1,"133":2,"160":8,"274":2,"300":1}}],["export",{"2":{"50":1,"89":20}}],["execution",{"2":{"268":2}}],["exec",{"2":{"52":1}}],["exe^xex",{"2":{"37":1}}],["examples",{"2":{"129":6,"295":1}}],["example",{"2":{"52":1,"67":2,"104":13,"198":5,"294":1}}],["extra=",{"2":{"305":1}}],["extra",{"2":{"7":1,"13":1,"15":1,"17":1,"305":3}}],["e",{"2":{"37":4,"119":9,"198":2,"205":1,"207":3,"305":5}}],["eps=1e",{"2":{"137":1,"193":1}}],["eps",{"2":{"137":3}}],["epoch",{"2":{"106":5,"110":3,"129":6,"186":1,"193":3,"294":3,"295":4,"300":6,"312":4}}],["epochs",{"2":{"94":2,"110":2,"129":4,"295":6,"300":3,"312":3}}],["ep",{"2":{"14":1}}],["它是最早发布的卷积神经网络之一",{"2":{"295":1}}],["它应该允许我们在压缩序列时花费更少的比特",{"2":{"274":1}}],["它会根据单机or多机分配到launch",{"2":{"261":1}}],["它会根据上下文选择最佳处理方式",{"2":{"205":1}}],["它对应着",{"2":{"230":1}}],["它可以包含多个卷积层",{"2":{"153":1}}],["它可以使普通文本内容具有一定的格式",{"2":{"5":1}}],["它的作用有如下两点",{"2":{"273":1}}],["它的梯度正好是目标分布与预测分布之差",{"2":{"146":1}}],["它的",{"2":{"131":1}}],["它的元素可正可负",{"2":{"115":1}}],["它们俩的共同点就是",{"2":{"232":1}}],["它们最大的区别就是",{"2":{"232":1}}],["它们也存在诸多共同点",{"2":{"232":1}}],["它们就只会被当成普通的符号",{"2":{"120":1}}],["它们和",{"2":{"89":1}}],["它们能让",{"2":{"7":1,"13":1,"15":1,"17":1}}],["它则会被转换成",{"2":{"26":1,"34":1,"36":1,"39":1}}],["它不会被转换",{"2":{"26":1,"34":1,"36":1,"39":1}}],["它能让文件更容易阅读",{"2":{"12":1,"20":1,"22":1,"24":1}}],["尚不具备",{"2":{"7":1,"13":1,"15":1,"17":1}}],["脚注",{"0":{"212":1},"2":{"7":1,"13":1,"15":1,"17":1}}],["嗯",{"2":{"7":1,"13":1,"15":1,"17":1}}],["是torch",{"2":{"305":1}}],["是成正相关的",{"2":{"301":1}}],["是pytorch中的函数",{"2":{"293":1}}],["是在每次循环的最后",{"2":{"292":1}}],["是用户提供的一个包含多个字符的字符串",{"2":{"289":1}}],["是上述式子的指数形式",{"2":{"274":1}}],["是时间步",{"2":{"274":1}}],["是nvidia发布的一个高效的集体通信库",{"2":{"272":1}}],["是可以被const成员函数改变的",{"2":{"266":1}}],["是关于数据搬运的",{"2":{"211":1}}],["是int",{"2":{"209":2}}],["是标准的",{"2":{"205":1}}],["是通过以输入",{"2":{"201":1}}],["是硬件架构的上一层封装",{"2":{"190":1}}],["是因为我们需要考虑标签",{"2":{"187":1}}],["是对应给右值的一种静态类型",{"2":{"172":1}}],["是指不会修改所属类的成员变量的函数",{"2":{"171":1}}],["是图片参考的名称",{"2":{"149":1}}],["是一组软件层面约定的和cpu硬件执行的接口",{"2":{"253":1}}],["是一种通用的技术",{"2":{"272":1}}],["是一种更直接的方法",{"2":{"159":1}}],["是一种可以使用普通文本编辑器编写的标记语言",{"2":{"5":1}}],["是一类特殊的神经网络",{"2":{"153":1}}],["是一个",{"2":{"134":2}}],["是否是叶子节点",{"2":{"133":1}}],["是",{"2":{"129":1}}],["是具体的训练逻辑",{"2":{"127":1}}],["是离散值时",{"2":{"110":1}}],["是从",{"2":{"110":1}}],["是梯度",{"2":{"105":1}}],["是训练启动时固定的超参数",{"2":{"105":1}}],["是偏置量",{"2":{"100":1}}],["是query与key之间的关系建模",{"2":{"93":1}}],["是的",{"2":{"41":1}}],["是为了让它们看起来就像所要表达的意思",{"2":{"7":1,"13":1,"15":1,"17":1}}],["并在后向传递过程中需要用到的所有张量",{"2":{"297":1}}],["并将第",{"2":{"282":1}}],["并将这些偏导数加和",{"2":{"159":1}}],["并将这个梯度存储在x0",{"2":{"145":1}}],["并对应2个优化器状态",{"2":{"256":1}}],["并用混合精度训练来加速训练",{"2":{"256":1}}],["并用argmax或采样选择下一个单词",{"2":{"214":1}}],["并自动配置正确的编译环境",{"2":{"205":1}}],["并非带有",{"2":{"172":1}}],["并非会变成完全意义上的并行",{"2":{"70":1}}],["并发也是会导致数据竞争问题",{"2":{"152":1}}],["并不会直接出现在文件之中",{"2":{"104":1}}],["并保存在对应的",{"2":{"25":1}}],["并且编为onehot",{"2":{"282":1}}],["并且每两个node之间需要可以ssh免密登录",{"2":{"280":1}}],["并且可以做到通信的overlap",{"2":{"275":1}}],["并且可以在计算图之中创建一个节点",{"2":{"117":1}}],["并且引入一个新的权重",{"2":{"251":1}}],["并且通过另一个可以学习的线性投影进行变换",{"2":{"230":1}}],["并且gradient",{"2":{"159":1}}],["并且都满足零均值和单位方差",{"2":{"150":1}}],["并且禁用偏置项",{"2":{"136":1}}],["并且自己来优化对应的函数",{"2":{"133":1}}],["并且层中使用了残差连接和层规范化",{"2":{"87":1}}],["并且给出具体的代码实现",{"2":{"21":1}}],["并且以",{"2":{"12":1,"20":1,"22":1,"24":1}}],["并且看起来不会像是由许多标签或是格式指令所构成",{"2":{"7":1,"13":1,"15":1,"17":1}}],["并经过严谨慎选",{"2":{"7":1,"13":1,"15":1,"17":1}}],["的shape",{"2":{"310":1}}],["的tokens",{"2":{"304":1}}],["的type就是右值引用",{"2":{"172":1}}],["的逐渐增大",{"2":{"301":1}}],["的增大",{"2":{"301":1}}],["的全0向量",{"2":{"282":1}}],["的汇聚层被称之为",{"2":{"281":1}}],["的线性映射为",{"2":{"277":1}}],["的加权以及之后",{"2":{"277":1}}],["的加权平均",{"2":{"93":1}}],["的工具",{"2":{"274":1}}],["的矩阵",{"2":{"269":1}}],["的权重",{"2":{"297":1}}],["的权重矩阵",{"2":{"269":1}}],["的权重就会更大",{"2":{"93":1}}],["的卷积层",{"2":{"269":1}}],["的卷积核三维张量",{"2":{"250":1}}],["的基础指令",{"2":{"268":1}}],["的形状为",{"2":{"297":1}}],["的形状",{"2":{"246":2,"310":2}}],["的条件概率仅取决于前面",{"2":{"234":1}}],["的三维张量",{"2":{"233":1}}],["的计算方式为",{"2":{"230":1}}],["的指令",{"2":{"221":1}}],["的英文翻译",{"2":{"214":1}}],["的ptx指令",{"2":{"211":1}}],["的上下文变量是注意力集中的输出",{"2":{"183":1}}],["的类型转换表达式",{"2":{"172":1}}],["的函数调用",{"2":{"172":1}}],["的行为",{"2":{"171":1}}],["的时候",{"2":{"159":1}}],["的缘故",{"2":{"152":1}}],["的偏导数",{"2":{"145":1,"159":1}}],["的变化率",{"2":{"145":1}}],["的导数在",{"2":{"145":1}}],["的所有操作",{"2":{"145":1}}],["的所有元素",{"2":{"139":1}}],["的运算",{"2":{"133":1}}],["的梯度为",{"2":{"131":1}}],["的索引就应该更新为",{"2":{"125":1}}],["的注意力权重是通过注意力评分函数",{"2":{"122":1}}],["的组合",{"2":{"117":1}}],["的模型结构中",{"2":{"111":1}}],["的更新我们可以递推地使用",{"2":{"110":1}}],["的范围",{"2":{"109":1}}],["的值相同与否",{"2":{"281":2}}],["的值",{"2":{"109":1,"115":1}}],["的参考式链接",{"2":{"104":1}}],["的代码仓库中",{"2":{"89":1}}],["的渲染方式相同",{"2":{"89":1}}],["的写操作",{"2":{"64":1}}],["的数据中保留的特征",{"2":{"110":1}}],["的数据",{"2":{"49":1,"110":1}}],["的float32",{"2":{"49":2}}],["的方法在",{"2":{"41":1}}],["的默认行为",{"2":{"25":1}}],["的",{"2":{"25":1,"41":1,"134":2,"181":1,"268":1}}],["的解析器有智慧型判断",{"2":{"19":1,"27":1,"29":1,"31":1}}],["的开始与结尾标签",{"2":{"19":1,"27":1,"29":1,"31":1}}],["的文件名保存在软件的目录下面",{"2":{"12":1,"20":1,"22":1,"24":1}}],["的格式语法只涵盖纯文字可以涵盖的范围",{"2":{"12":1,"20":1,"22":1,"24":1}}],["的重点在于",{"2":{"12":1,"20":1,"22":1,"24":1}}],["的语法来插入图片是有一定难度的",{"2":{"149":1}}],["的语法简洁明了",{"2":{"12":1,"20":1,"22":1,"24":1}}],["的语法有个主要的目的",{"2":{"12":1,"20":1,"22":1,"24":1}}],["的语法全由标点符号所组成",{"2":{"7":1,"13":1,"15":1,"17":1}}],["的功能",{"2":{"7":1,"13":1,"15":1,"17":1}}],["的列表看起来",{"2":{"7":1,"13":1,"15":1,"17":1}}],["的目标是实现",{"2":{"5":1}}],["和序列长度",{"2":{"301":1}}],["和launcher模块面临的处境差不多",{"2":{"299":1}}],["和方差",{"2":{"297":1}}],["和方括号都会被转成",{"2":{"135":1}}],["和其余的computation",{"2":{"290":1}}],["和平均汇聚层",{"2":{"281":1}}],["和self",{"2":{"269":1}}],["和cp",{"2":{"244":1}}],["和值",{"2":{"230":1}}],["和缩放参数",{"2":{"224":1}}],["和当前嵌入向量结合",{"2":{"214":1}}],["和右值引用int",{"2":{"172":1}}],["和deepspeed的parser兼容",{"2":{"141":1}}],["和一个",{"2":{"129":1}}],["和一些util的实现",{"2":{"127":1}}],["和键",{"2":{"122":1}}],["和底线",{"2":{"120":1}}],["和代码相关的写作或是标签语言原始码通常会有已经排版好的代码块",{"2":{"67":1}}],["和多段落的",{"2":{"41":1}}],["和",{"2":{"7":2,"13":2,"15":2,"17":2,"26":5,"34":5,"36":5,"39":5,"46":3,"67":2,"89":1,"109":1,"120":1,"122":1,"129":3,"149":1,"158":2,"210":1,"224":1,"238":1,"281":2,"298":1,"301":1}}],["rmda实现",{"2":{"290":1}}],["rvv",{"2":{"253":1}}],["rv64gc",{"2":{"253":1}}],["r^",{"2":{"251":2,"277":3,"304":1,"310":1}}],["r^qq∈rq",{"2":{"122":1}}],["round",{"2":{"257":1,"268":1,"286":5,"293":2}}],["router是一个核心网络结构",{"2":{"111":1}}],["router",{"0":{"0":1,"111":1},"1":{"1":1,"2":1},"2":{"97":1}}],["rows",{"2":{"257":1,"268":1}}],["row",{"2":{"237":2,"257":15,"268":12}}],["rw",{"2":{"127":1}}],["runner是主进程",{"2":{"287":1}}],["runner",{"2":{"261":1,"287":2}}],["run",{"2":{"127":2,"257":1,"268":1,"294":1}}],["runtime等等",{"2":{"50":1}}],["runtime",{"2":{"50":1}}],["runtime层面主要是运行时对程序进行系统层面的优化",{"2":{"23":1}}],["rho∇×b−c1​∂t∂e​=c4π​j​∇⋅e=4πρ",{"2":{"119":1}}],["rho$",{"2":{"119":1}}],["rnn网络",{"2":{"310":2}}],["rnn的作用是根据输入来计算出隐状态",{"2":{"310":1}}],["rnn的引入是为了解决序列信息引入的模型架构",{"2":{"96":1}}],["rnnmodel",{"2":{"306":2}}],["rnnmodelscratch",{"2":{"282":2}}],["rnn在时间步过长的时候",{"2":{"296":1}}],["rnn和self",{"2":{"269":1}}],["rnn介绍",{"0":{"218":1},"1":{"234":1,"251":1,"263":1,"274":1,"282":1,"289":1,"296":1,"300":1}}],["rnn",{"2":{"183":2,"269":2,"282":3,"306":10,"310":4}}],["rnn引入",{"0":{"83":1},"1":{"96":1,"110":1,"126":1,"140":1,"154":1,"169":1,"187":1,"202":1}}],["ralyattention",{"0":{"311":1}}],["raise",{"2":{"183":1,"305":2,"308":3}}],["ray分布式训练",{"2":{"141":1}}],["raw",{"2":{"127":1}}],["rate=0",{"2":{"305":1}}],["rate",{"2":{"119":2,"305":1}}],["ratio",{"2":{"94":2}}],["rank这种",{"2":{"299":1}}],["rank做完stage1的forward的时候",{"2":{"290":1}}],["rank",{"2":{"141":6,"280":2,"290":1}}],["randint",{"2":{"187":1,"193":2,"202":1}}],["random",{"2":{"126":2,"129":1,"141":1,"187":3,"202":4,"300":4}}],["rand",{"2":{"97":1,"106":1,"170":1,"186":1,"201":1}}],["randn",{"2":{"93":1,"188":2,"252":2,"282":1}}],["range",{"2":{"94":1,"97":1,"106":1,"110":2,"126":1,"129":4,"160":2,"178":2,"186":3,"187":2,"193":1,"202":1,"281":2,"289":1,"295":1,"300":1,"312":1}}],["r",{"2":{"87":2,"115":2,"122":2,"126":1,"136":6,"150":4,"160":2,"196":1,"211":10,"227":10,"230":9,"257":14,"258":2,"268":18,"269":2,"285":2}}],["r2",{"2":{"64":2}}],["r1",{"2":{"64":2}}],["riscv64",{"2":{"190":1}}],["risc",{"2":{"190":2,"253":2}}],["risus",{"2":{"52":2,"59":3}}],["right右对齐的内容",{"2":{"164":2}}],["right|",{"2":{"131":1}}],["right",{"2":{"45":2,"93":4,"106":3,"131":1,"150":1,"269":2,"274":3,"277":1,"296":1,"298":2,"304":2}}],["rl介绍",{"0":{"242":1}}],["rlhf",{"2":{"127":5}}],["rl训练的相关代码在application",{"2":{"127":1}}],["rl训练",{"2":{"112":1}}],["rl",{"0":{"88":1},"2":{"14":1,"112":1}}],["rdma",{"2":{"14":3}}],["removing",{"2":{"305":1}}],["removed",{"2":{"89":2}}],["remove",{"2":{"89":2,"305":1}}],["remaining",{"2":{"285":1}}],["recv的就是上一轮异步send的tensor",{"2":{"275":1}}],["recv",{"2":{"275":1}}],["recv一个tensor",{"2":{"275":1}}],["reinterpret",{"2":{"257":1,"268":1}}],["refactor",{"2":{"305":1}}],["ref实参会去掉ref",{"2":{"179":1}}],["ref",{"2":{"163":1,"179":13}}],["reference",{"2":{"104":1,"112":1}}],["repr",{"2":{"305":2}}],["representations",{"2":{"161":1}}],["representation",{"2":{"147":1,"230":1}}],["replacing",{"2":{"305":2}}],["replace",{"2":{"305":1}}],["repeats=self",{"2":{"246":1}}],["repeat",{"2":{"106":4,"122":1,"136":1,"246":1,"310":1}}],["reverse=true",{"2":{"126":1}}],["reading",{"2":{"292":1}}],["ready",{"2":{"292":3}}],["read不知道是啥意思",{"2":{"285":1}}],["readlines",{"2":{"126":1}}],["read",{"2":{"126":3,"285":2,"292":1}}],["readme",{"0":{"176":1,"185":1,"219":1,"229":1,"240":1},"2":{"12":1,"20":1,"22":1,"24":1,"127":1}}],["reward",{"2":{"112":1,"127":2}}],["requires",{"2":{"106":1,"129":2,"133":10,"145":2,"160":4,"282":1,"296":1}}],["required",{"2":{"59":1}}],["restore",{"2":{"302":2}}],["restructuredtext",{"2":{"7":1,"13":1,"15":1,"17":1}}],["res",{"2":{"292":1}}],["reset",{"2":{"160":1}}],["reserved",{"2":{"126":4}}],["resnet系列",{"2":{"270":1}}],["resnet",{"0":{"151":1}}],["resource",{"2":{"104":1}}],["results",{"2":{"101":1}}],["reshapes",{"2":{"101":1}}],["reshape",{"2":{"101":2,"106":5,"110":1,"122":3,"129":2,"136":1,"160":2,"186":2,"201":2,"202":2,"220":1,"246":4,"262":3,"269":1,"281":1,"282":1,"289":2,"300":1,"306":1,"312":1}}],["resize=224",{"2":{"94":1}}],["residual",{"2":{"87":1,"147":2,"161":1}}],["re",{"2":{"59":1,"70":2,"126":2}}],["reduce来获得结果",{"2":{"265":1}}],["reduce",{"2":{"244":1,"265":1,"299":1,"305":1}}],["reduction=",{"2":{"106":1,"110":1,"312":1}}],["red",{"2":{"59":3,"298":1}}],["return",{"2":{"50":1,"52":1,"70":1,"89":12,"93":1,"94":2,"97":2,"101":4,"106":1,"107":1,"110":1,"116":1,"117":1,"122":2,"123":1,"126":12,"129":4,"132":1,"133":3,"136":1,"137":2,"147":1,"150":1,"160":9,"161":1,"171":2,"172":2,"178":2,"183":3,"186":2,"187":1,"201":1,"202":1,"205":1,"207":3,"209":7,"227":1,"233":1,"246":3,"250":1,"262":1,"269":1,"281":1,"282":7,"289":1,"293":2,"295":1,"299":1,"300":1,"302":3,"305":9,"306":3,"308":1,"310":3,"312":2}}],["relationships",{"2":{"147":1}}],["relaxed",{"2":{"64":1}}],["release语义可以实现上述的内存一致性约束",{"2":{"64":1}}],["release",{"2":{"64":6,"227":2}}],["rel=",{"2":{"40":1}}],["relu",{"2":{"23":1,"94":3,"107":3,"110":1,"116":3,"117":1,"123":8,"133":1}}],["reg",{"2":{"227":1,"292":1}}],["register",{"2":{"132":1,"211":1}}],["regressive",{"2":{"87":1}}],["regression",{"0":{"21":1,"63":1},"1":{"73":1,"85":1,"99":1,"114":1,"129":1}}],["regular",{"2":{"19":2,"27":2,"29":2,"31":2}}],["格式中",{"2":{"104":1}}],["格式来写",{"2":{"104":1}}],["格式不一样",{"2":{"41":1}}],["格式的影响",{"2":{"7":1,"13":1,"15":1,"17":1}}],["格式撰写的文件应该可以直接以纯文字发佈",{"2":{"7":1,"13":1,"15":1,"17":1}}],["t​​",{"2":{"304":1}}],["tq",{"2":{"304":3}}],["t^",{"2":{"304":5}}],["t^2",{"2":{"105":1}}],["tn​",{"2":{"304":1}}],["tn+1​",{"2":{"304":1}}],["tn+1",{"2":{"304":1}}],["tn",{"2":{"304":1}}],["tcp等等",{"2":{"272":1}}],["tc0",{"2":{"244":2}}],["tmp",{"2":{"268":6}}],["tma无法做到async",{"2":{"292":1}}],["tma的load",{"2":{"285":1}}],["tma的版本下",{"2":{"257":1}}],["tma的版本",{"2":{"257":2}}],["tma",{"0":{"285":1,"292":1},"2":{"61":1,"70":1,"244":1,"257":14,"268":14,"285":2,"292":9}}],["tp聚焦于节点内部",{"2":{"265":1}}],["tp之间的",{"2":{"265":1}}],["tp",{"2":{"254":1,"290":1}}],["tpt​",{"2":{"146":1}}],["tw",{"2":{"251":2}}],["two",{"2":{"52":2,"59":2,"119":2}}],["t−1t",{"2":{"234":1}}],["tx",{"2":{"227":3,"244":4,"257":2,"268":1,"285":1,"292":4}}],["txt",{"2":{"126":1}}],["txt​",{"2":{"110":3,"234":1,"274":1,"282":1}}],["txt来导出compile",{"2":{"50":1}}],["t是std",{"2":{"207":1}}],["t就可以了",{"2":{"190":1}}],["t风格",{"2":{"190":1}}],["t语法",{"2":{"190":1}}],["t和param",{"2":{"179":1}}],["t>>",{"2":{"192":2}}],["t>",{"2":{"179":5,"192":6,"194":3,"207":2,"211":1,"257":6,"268":8,"285":1}}],["tgt",{"2":{"161":3,"178":21,"193":7,"312":2}}],["tgt​",{"2":{"105":1}}],["t2",{"2":{"158":1,"171":2}}],["t1​",{"2":{"304":1}}],["t1",{"2":{"158":1,"171":2,"304":1}}],["t1∼t",{"2":{"110":1}}],["t代表的t是一个常量指针",{"2":{"156":1}}],["tyt​",{"2":{"146":1}}],["typically",{"2":{"147":1,"161":1}}],["typing",{"2":{"126":1}}],["types",{"2":{"211":1,"305":1}}],["type>",{"2":{"207":1,"257":1,"268":1}}],["type用于获取枚举类型的底层数据类型",{"2":{"207":1}}],["typedef",{"2":{"192":1}}],["type都会被推导为左值引用",{"2":{"179":1}}],["type进行模式匹配来决定t",{"2":{"179":1}}],["typename",{"2":{"179":5,"192":5,"194":2,"207":5,"209":10,"211":1,"257":4,"268":4}}],["type",{"2":{"50":1,"89":5,"106":2,"110":1,"160":2,"172":1,"179":1,"192":3,"207":6,"211":3,"227":1,"282":1,"293":1,"295":2,"305":2,"312":2}}],["tb",{"2":{"141":2}}],["t+1",{"2":{"110":5}}],["t=1",{"2":{"110":1,"183":1,"274":2}}],["ttt",{"2":{"110":2,"146":1,"183":1,"234":1,"251":1,"274":1}}],["tuple的连接操作",{"2":{"201":1}}],["tuple",{"2":{"94":1,"126":3,"137":1,"186":1,"187":1,"202":1,"207":1,"281":1,"282":1,"300":1,"302":1}}],["ts",{"2":{"89":2}}],["ti∈rb×1×h",{"2":{"304":1}}],["ti∈rb×1×ht^i",{"2":{"304":1}}],["tiny",{"0":{"163":1}}],["timeout",{"2":{"299":2}}],["timer",{"2":{"295":5,"300":3,"312":3}}],["timemachine",{"2":{"126":1}}],["time",{"2":{"110":2,"126":6,"202":1,"257":1,"268":1,"289":1,"294":5,"300":2,"310":8}}],["times",{"2":{"49":8,"104":4,"119":4,"150":1,"277":11,"284":1,"291":4,"297":1,"304":2}}],["tile的主对角线元素被移除",{"2":{"106":1}}],["tile的形状",{"2":{"106":2}}],["tile",{"2":{"106":4,"244":1,"257":7,"268":6}}],["title=",{"2":{"104":4}}],["title",{"2":{"104":15,"149":3}}],["tip",{"2":{"77":3,"89":2}}],["taking",{"2":{"161":1}}],["take",{"2":{"141":1}}],["tasks",{"2":{"147":1}}],["tanh",{"2":{"136":2,"282":1}}],["tags",{"2":{"135":2}}],["tau",{"2":{"110":6}}],["tauτ",{"2":{"110":3}}],["tada",{"2":{"51":1}}],["target",{"2":{"161":2}}],["targets",{"2":{"50":1}}],["target=",{"2":{"40":1}}],["tabs",{"2":{"89":2}}],["tab",{"2":{"19":1,"27":1,"29":1,"31":1,"41":1,"59":2,"67":2,"89":5,"104":1}}],["tables",{"2":{"45":2}}],["table>",{"2":{"19":2,"27":2,"29":2,"31":2}}],["table",{"2":{"19":1,"27":1,"29":1,"31":1}}],["t",{"0":{"211":1},"2":{"26":4,"34":4,"36":4,"39":4,"89":2,"105":9,"110":37,"119":4,"135":2,"140":5,"146":9,"156":19,"171":9,"172":7,"175":1,"179":18,"183":14,"192":2,"194":1,"207":5,"209":1,"211":24,"214":2,"227":1,"234":8,"251":4,"257":5,"268":10,"274":4,"282":5,"285":2,"300":1,"304":15,"306":1}}],["th",{"2":{"132":1,"304":2}}],["tht​",{"2":{"110":2,"183":1}}],["than",{"2":{"104":4,"305":1}}],["that",{"2":{"101":1,"161":1,"227":2,"272":1,"305":1}}],["threadblocks",{"2":{"268":1}}],["threadidx",{"2":{"257":2,"268":1}}],["threads>",{"2":{"257":2,"268":1}}],["threads",{"2":{"227":2,"257":5,"268":5}}],["thread2",{"2":{"64":3}}],["thread1",{"2":{"64":1}}],["thread",{"2":{"64":2,"227":2,"257":1,"268":2}}],["themselves",{"2":{"299":1}}],["them",{"2":{"147":1,"227":1,"285":1}}],["theme",{"2":{"25":1,"134":2}}],["these",{"2":{"147":1}}],["they",{"2":{"119":2}}],["thereby",{"2":{"290":2}}],["there",{"2":{"119":2,"305":2}}],["thetaθ的变化公式为",{"2":{"129":1}}],["theta",{"2":{"73":8,"99":8,"129":5,"296":4}}],["the",{"2":{"52":4,"59":4,"89":2,"97":1,"101":10,"116":4,"119":2,"132":1,"135":4,"141":4,"147":5,"161":16,"225":3,"227":1,"244":1,"257":1,"272":1,"285":1,"290":3,"299":1,"305":5}}],["this",{"2":{"19":2,"27":2,"29":2,"31":2,"46":2,"52":7,"59":4,"67":2,"77":12,"89":4,"101":2,"104":4,"120":1,"161":1,"171":3,"227":1,"257":1,"268":1,"305":3}}],["td>",{"2":{"19":1,"27":1,"29":1,"31":1}}],["td>foo",{"2":{"19":1,"27":1,"29":1,"31":1}}],["tried",{"2":{"305":2}}],["triu",{"2":{"178":1}}],["triton",{"2":{"14":1,"70":7}}],["true",{"2":{"129":10,"133":1,"145":1,"158":5,"172":1,"282":2,"305":2}}],["truth",{"2":{"93":1}}],["try",{"2":{"94":1,"227":2,"282":3,"289":1,"295":1,"305":2}}],["traveller",{"2":{"289":1,"300":3}}],["traffic",{"2":{"104":4}}],["transfer",{"2":{"268":1}}],["transform",{"2":{"147":1}}],["transformation",{"2":{"101":1}}],["transformations",{"2":{"101":1}}],["transforming",{"2":{"101":1,"116":1}}],["transformer模型加速推断的一个常用策略就是使用",{"2":{"304":1}}],["transformer模型由",{"2":{"224":1}}],["transformer解码器也是由多个相同的层叠加而成的",{"2":{"87":1}}],["transformer编码器都将输出一个维表示向量",{"2":{"87":1}}],["transformer的编码器是由多个相同的层叠加而成的",{"2":{"87":1}}],["transformer是如此的重要",{"2":{"75":1}}],["transformer架构",{"0":{"75":1},"1":{"87":1,"101":1,"116":1,"132":1,"147":1,"161":1,"178":1,"193":1}}],["transformer论文",{"0":{"42":1},"1":{"47":1}}],["transformer",{"0":{"30":1,"178":1},"2":{"116":1,"147":2,"161":2,"178":2,"193":5}}],["transaction",{"2":{"227":1,"244":1}}],["transpose",{"2":{"101":4,"150":1,"246":6}}],["trans",{"2":{"97":1,"211":1}}],["train脚本",{"2":{"294":1}}],["trainingconfig",{"2":{"305":2}}],["training",{"0":{"237":1,"254":1},"1":{"265":1,"275":1,"283":1},"2":{"127":9,"141":1,"287":3,"290":1,"294":1,"295":1,"302":1}}],["train=true",{"2":{"110":1,"129":1}}],["trainer",{"2":{"106":3,"110":3,"127":1,"129":3}}],["train次",{"2":{"106":1}}],["train",{"2":{"93":6,"94":3,"106":23,"110":10,"129":4,"141":7,"160":1,"193":3,"282":1,"290":1,"295":16,"300":8,"312":2}}],["train的精髓之一就是各种parallel策略",{"2":{"76":1}}],["train的专题合集",{"2":{"57":1}}],["tr>",{"2":{"19":2,"27":2,"29":2,"31":2}}],["tout",{"2":{"304":4}}],["toutype",{"2":{"207":4}}],["total",{"2":{"257":2,"268":2}}],["together",{"2":{"147":1,"305":1}}],["top",{"2":{"136":1,"150":2}}],["tolist",{"2":{"133":1}}],["tokens数",{"2":{"291":1}}],["tokens=additional",{"2":{"141":1}}],["tokens=",{"2":{"126":1}}],["tokens=none",{"2":{"126":2}}],["tokens",{"2":{"126":24,"141":3,"202":5,"312":3}}],["token=",{"2":{"126":1}}],["tokenize",{"2":{"126":3}}],["tokenizer相关代码",{"2":{"141":1}}],["tokenizer=true",{"2":{"141":1}}],["tokenizer以及create",{"2":{"141":1}}],["tokenizer和model",{"2":{"141":1}}],["tokenizer",{"2":{"126":1,"141":5}}],["token",{"0":{"90":1},"2":{"126":30,"132":1,"141":2,"279":1,"289":1}}],["toc",{"2":{"58":1}}],["torchbackend",{"2":{"299":1}}],["torch",{"0":{"133":1,"142":1},"1":{"155":1,"170":1,"188":1,"203":1,"220":1,"235":1,"252":1},"2":{"50":3,"93":5,"97":4,"101":3,"106":11,"110":5,"117":2,"122":1,"123":2,"126":4,"129":16,"132":6,"133":16,"136":6,"137":13,"141":5,"145":3,"150":2,"159":2,"160":25,"170":4,"178":2,"183":4,"186":8,"187":4,"188":3,"193":2,"201":3,"202":4,"220":7,"233":5,"235":2,"246":1,"250":5,"252":3,"262":7,"269":6,"281":5,"282":13,"289":1,"293":2,"295":3,"296":2,"299":2,"300":2,"305":4,"306":4,"310":2,"312":6}}],["todos",{"2":{"89":2}}],["todo",{"0":{"14":1},"2":{"88":1,"89":6,"102":1,"118":1,"160":1,"285":1,"296":1,"304":1}}],["to",{"2":{"7":1,"13":1,"15":1,"17":1,"41":1,"50":2,"52":1,"59":1,"101":7,"104":1,"119":4,"126":12,"132":1,"137":2,"141":2,"147":2,"149":3,"161":6,"179":1,"211":1,"227":1,"244":3,"257":4,"268":7,"269":1,"282":1,"285":3,"289":1,"290":1,"292":3,"295":6,"300":2,"305":5,"306":1,"312":2}}],["temporary",{"2":{"305":1}}],["template",{"2":{"179":5,"192":4,"194":2,"207":3,"209":5,"211":3,"227":1,"257":10,"268":8,"285":2,"292":1}}],["term",{"2":{"132":3}}],["test",{"2":{"93":4,"94":2,"160":1,"227":1,"295":8}}],["tell",{"2":{"67":3}}],["tensor就可以满足精度要求",{"2":{"298":1}}],["tensor来load",{"2":{"268":1}}],["tensor来保存",{"2":{"225":1}}],["tensormap3",{"2":{"244":1}}],["tensormap0",{"2":{"244":1}}],["tensor等的data信息来计算梯度",{"2":{"225":1}}],["tensor等等",{"2":{"50":1}}],["tensor中的grad取出来",{"2":{"225":1}}],["tensor中",{"2":{"225":1}}],["tensor已经经过伪释放",{"2":{"225":1}}],["tensor的async",{"2":{"268":1}}],["tensor的data一般不会释放",{"2":{"225":1}}],["tensor的data",{"2":{"225":1}}],["tensor的数据其实已经不需要了",{"2":{"225":1}}],["tensor的生成",{"2":{"220":1}}],["tensor都应该压入栈中等待fwd",{"2":{"225":1}}],["tensor和output",{"2":{"225":3}}],["tensor发送给下一个stage作为input",{"2":{"225":1}}],["tensorboard",{"2":{"141":2}}],["tensorboard=args",{"2":{"141":1}}],["tensors",{"2":{"133":1}}],["tensordataset",{"2":{"129":1}}],["tensor",{"0":{"142":1},"1":{"155":1,"170":1,"188":1,"203":1,"220":1,"235":1,"252":1},"2":{"49":1,"101":2,"117":1,"123":1,"129":2,"133":12,"136":1,"137":6,"160":11,"170":1,"186":4,"187":4,"188":3,"201":2,"202":4,"220":9,"225":17,"233":5,"235":3,"237":1,"244":4,"250":3,"257":4,"262":3,"268":2,"279":1,"281":2,"282":1,"289":1,"290":1,"293":3,"298":1,"312":1}}],["tensor相加",{"2":{"49":1}}],["tensorflow",{"2":{"1":1}}],["textile",{"2":{"7":1,"13":1,"15":1,"17":1}}],["text",{"2":{"7":1,"13":1,"15":1,"17":1,"41":1,"89":2,"93":1,"104":2,"105":1,"106":1,"110":1,"120":1,"122":1,"149":3,"150":1,"228":2,"277":2,"291":6,"298":6}}],["扩展",{"0":{"6":1},"1":{"11":1,"18":1,"25":1,"32":1,"40":1,"45":1,"51":1,"58":1,"66":1,"77":1,"89":1,"103":1,"119":1,"134":1,"148":1,"164":1,"181":1,"197":1,"212":1}}],["易读易写",{"2":{"5":1}}],["must",{"2":{"302":1}}],["muμ",{"2":{"297":1}}],["mul",{"2":{"188":1}}],["multihead",{"2":{"230":1}}],["multiheadattention",{"2":{"101":2,"147":1,"161":2,"246":2}}],["multiple",{"2":{"147":1,"161":1}}],["multiply",{"2":{"101":1}}],["multi",{"0":{"81":1,"90":1,"101":1,"237":1},"2":{"87":1,"101":2,"147":1,"161":2,"233":2,"250":3,"262":3}}],["multimarkdown",{"2":{"7":1,"13":1,"15":1,"17":1}}],["mul等",{"2":{"23":1}}],["mpu",{"2":{"302":6}}],["mps",{"2":{"282":6,"289":1}}],["mpi",{"2":{"272":2}}],["m+1m",{"2":{"271":1}}],["m2pro",{"2":{"253":1}}],["mbar0",{"2":{"244":1}}],["mbar",{"2":{"227":3,"244":1,"257":3}}],["mbarrier对象是不透明的",{"2":{"227":1}}],["mbarrier",{"0":{"227":1},"2":{"227":14,"244":3,"257":2,"268":7,"285":1}}],["m8n8意思是8x8的matrix",{"2":{"211":1}}],["m8n8",{"2":{"211":2}}],["mm",{"2":{"252":1,"262":1,"282":3}}],["mma",{"2":{"211":1}}],["mmm",{"2":{"121":1,"122":1,"150":1,"271":2}}],["mqa优化技术",{"0":{"206":1}}],["mha",{"0":{"206":1}}],["mc",{"2":{"205":1}}],["mchale",{"2":{"59":2}}],["mlp",{"2":{"116":1}}],["mt=β1⋅mt−1+",{"2":{"105":1}}],["msvc",{"2":{"190":1}}],["mseloss",{"2":{"106":1,"110":1,"129":1}}],["msn",{"2":{"104":12}}],["msg",{"2":{"89":12,"305":4}}],["mnist",{"2":{"94":1,"160":1}}],["m",{"2":{"70":10,"73":1,"105":3,"110":3,"122":4,"150":2,"196":1,"271":1,"275":1,"280":1,"295":4,"312":6}}],["mix",{"0":{"265":1},"2":{"254":1}}],["mips",{"2":{"190":3}}],["micro",{"2":{"141":2,"275":1}}],["micromamba在下载lib的时候",{"2":{"50":1}}],["mid",{"2":{"110":9,"140":1,"234":2,"274":2}}],["min=1e",{"2":{"293":1}}],["mini",{"2":{"265":1}}],["min",{"2":{"70":1,"126":2,"129":1,"286":3,"296":1}}],["mi",{"2":{"52":2,"59":3}}],["mesh组织的",{"2":{"302":1}}],["mesh",{"2":{"302":7}}],["message",{"2":{"272":1}}],["memcpy",{"2":{"257":8,"268":8}}],["memory和reg等",{"2":{"70":1}}],["memory",{"0":{"56":1,"64":1},"1":{"64":1},"2":{"64":7,"196":1,"211":1,"227":7,"244":2,"257":5,"268":5,"285":3,"290":1,"292":12,"301":1}}],["mechanism",{"2":{"147":1,"161":2,"244":1}}],["mechanisms",{"2":{"116":1}}],["meaningful",{"2":{"161":1}}],["mean和moving",{"2":{"137":2}}],["mean=0",{"2":{"129":1}}],["mean",{"2":{"129":1,"137":21,"188":1,"281":1,"300":1,"312":1}}],["meticulously",{"2":{"290":1}}],["metric",{"2":{"160":4,"295":11,"300":5,"312":7}}],["methods",{"2":{"290":1}}],["method",{"2":{"101":2,"299":2,"305":1}}],["metadata",{"2":{"70":1}}],["metadata=",{"2":{"70":1}}],["medium=social",{"2":{"47":1}}],["megatronv2提出了更加完备的并行策略",{"2":{"254":1}}],["megatron",{"0":{"237":1,"254":2},"1":{"265":2,"275":2,"283":2},"2":{"1":1,"76":1,"237":1,"254":1}}],["mold",{"2":{"221":1}}],["most",{"2":{"158":1}}],["mov",{"2":{"190":2}}],["movement",{"2":{"268":2}}],["move将当前的值转化为将亡值",{"2":{"189":1}}],["move",{"0":{"157":1,"211":1},"1":{"172":1,"189":1,"204":1},"2":{"172":1,"211":3,"257":1,"268":4}}],["moving",{"2":{"137":21}}],["movabletype",{"2":{"41":1}}],["momentum=0",{"2":{"137":1}}],["momentum是记录梯度的指数加权平均值",{"2":{"105":1}}],["momentum",{"2":{"105":1,"137":5}}],["more",{"2":{"104":5,"211":1,"290":1}}],["moe的核心思想是",{"2":{"97":1}}],["moe",{"0":{"97":1},"2":{"97":2}}],["moe架构按照顺序的话",{"2":{"97":1}}],["moe架构",{"0":{"84":1},"1":{"97":1,"111":1}}],["mode",{"2":{"281":2}}],["mode=",{"2":{"281":1}}],["model=model",{"2":{"305":1}}],["model都实现在dschat",{"2":{"141":1}}],["model的ft",{"2":{"127":1}}],["model",{"0":{"56":1,"64":1,"254":1},"1":{"64":1,"265":1,"275":1,"283":1},"2":{"101":19,"112":4,"116":3,"123":2,"127":4,"132":4,"141":17,"147":6,"161":8,"178":7,"193":4,"294":5,"299":1,"302":2,"305":7}}],["models",{"0":{"237":1},"2":{"38":1,"305":1}}],["module中调用",{"2":{"133":1}}],["module中充当一个计算点的工具",{"2":{"117":1}}],["modulelist",{"2":{"97":1,"178":2}}],["module",{"2":{"94":1,"97":2,"101":1,"106":1,"116":1,"117":4,"123":2,"127":1,"132":1,"136":1,"137":1,"141":1,"147":1,"150":1,"160":1,"161":1,"178":1,"186":1,"246":1,"269":1,"295":1,"296":1,"300":2,"306":1,"308":3}}],["motd",{"2":{"89":2}}],["many",{"2":{"257":1,"268":1}}],["mapping",{"2":{"305":1}}],["mapa",{"2":{"268":4}}],["map",{"2":{"244":1,"257":1,"305":1}}],["making",{"2":{"227":1}}],["make",{"2":{"141":1,"257":1,"268":1}}],["master",{"2":{"280":4}}],["masm",{"2":{"190":1}}],["mask",{"2":{"101":4,"122":1,"147":2,"161":8,"178":17,"312":3}}],["mask=none",{"2":{"101":2}}],["maskedsoftmaxceloss",{"2":{"312":3}}],["masked",{"2":{"87":1,"101":2,"122":1,"136":1,"150":1}}],["mach",{"2":{"190":1}}],["machine",{"2":{"126":6,"202":1}}],["macos",{"2":{"190":1}}],["main函数如下",{"2":{"294":1}}],["main",{"2":{"97":1,"127":4,"141":1,"179":1,"193":1,"205":1,"221":2,"294":1}}],["matrices",{"2":{"211":1}}],["matrix",{"2":{"70":1}}],["math",{"2":{"101":1,"132":1,"150":1,"300":1}}],["mathbb",{"2":{"87":2,"115":2,"122":2,"136":6,"150":4,"160":2,"230":9,"258":2,"269":2}}],["mathbf",{"2":{"87":2,"100":7,"109":7,"115":4,"119":22,"122":17,"125":4,"131":3,"136":12,"146":8,"150":10,"160":2,"183":3,"214":2,"230":16,"258":6,"269":4,"296":3,"298":16}}],["matmul",{"2":{"23":1,"101":2,"129":2,"160":2,"252":1}}],["magic",{"2":{"59":2}}],["maxlen",{"2":{"312":4}}],["maximum",{"2":{"281":1,"285":1}}],["maxwell",{"2":{"119":2}}],["maxpool2d",{"2":{"94":1,"107":2,"123":5,"281":4}}],["max",{"2":{"37":1,"126":3,"132":3,"178":2,"193":4,"202":2,"238":2,"269":3,"281":3,"286":4,"293":5}}],["maruku",{"2":{"7":1,"13":1,"15":1,"17":1}}],["markdown基础",{"2":{"32":1}}],["markdown",{"0":{"5":1,"6":1},"1":{"7":1,"11":1,"12":1,"18":1,"19":1,"25":1,"26":1,"32":1,"33":1,"40":1,"41":1,"45":1,"46":1,"51":1,"52":1,"58":1,"59":1,"66":1,"67":1,"77":1,"78":1,"89":1,"91":1,"103":1,"104":1,"119":1,"120":1,"134":1,"135":1,"148":1,"149":1,"164":1,"165":1,"181":1,"182":1,"197":1,"198":1,"212":1,"213":1,"228":1,"245":1},"2":{"5":2,"7":10,"12":7,"13":10,"15":10,"17":10,"19":6,"20":7,"22":7,"24":7,"26":7,"27":6,"29":6,"31":6,"32":5,"34":7,"36":7,"39":7,"41":3,"46":1,"52":4,"59":4,"67":9,"89":1,"104":4,"120":1,"135":1,"149":2,"181":1,"198":5,"213":2,"228":1}}],["myalloc",{"2":{"192":2}}],["myalloclist1",{"2":{"192":3}}],["myalloclist",{"2":{"192":3}}],["mystruct>",{"2":{"192":2}}],["mystruct",{"2":{"192":1}}],["myexp",{"2":{"133":2}}],["myrelu",{"2":{"117":2}}],["mycomponent",{"2":{"89":2}}],["my",{"2":{"18":2,"104":1,"133":1}}],["mdash",{"2":{"135":2}}],["md",{"2":{"12":1,"20":1,"22":1,"24":1,"25":2,"32":3,"127":2}}],["友情链接",{"0":{"3":1}}],["希望这个项目也会变得更加完善",{"2":{"2":1}}],["以评估模式运行",{"2":{"310":1}}],["以上是dualpipev的schedule以及和1f1b的bubble等数据的对比",{"2":{"290":1}}],["以求在更少的device上有更低的bubble率",{"2":{"290":1}}],["以wsgi网络框架举例",{"2":{"271":1}}],["以流水线的形式进行forward与backward",{"2":{"265":1}}],["以下一些和模板类型推导一致",{"2":{"194":1}}],["以0为基准",{"2":{"170":1}}],["以产生最终输出",{"2":{"230":1}}],["以产生",{"2":{"135":1}}],["以便同一组词元同时充当查询",{"2":{"258":1}}],["以便与输入进行互相关运算",{"2":{"233":1}}],["以便我们更好的训练模型",{"2":{"126":1}}],["以便满足残差连接",{"2":{"87":1}}],["以至于我们需要单开一章来重点讲解",{"2":{"75":1}}],["以利与内容区隔",{"2":{"19":1,"27":1,"29":1,"31":1}}],["以此来对抗自己的知识遗忘",{"2":{"2":1}}],["以及平均汇聚层",{"2":{"295":1}}],["以及多个通道",{"2":{"281":1}}],["以及cp",{"2":{"244":1}}],["以及构造析构函数的时候",{"2":{"239":1}}],["以及代表注意力汇聚的函数",{"2":{"230":1}}],["以及同步aync",{"2":{"227":1}}],["以及计算图的保存问题",{"2":{"225":1}}],["以及计算的持续而不被打断",{"2":{"43":1}}],["以及偏置",{"2":{"224":1}}],["以及寄存器分配",{"2":{"221":1}}],["以及拼接分割",{"2":{"220":1}}],["以及是否设置偏差conv2d的weight参数会被随机初始化",{"2":{"186":1}}],["以及一个",{"2":{"181":1}}],["以及一些可以出现的短语",{"2":{"140":1}}],["以及一些难点",{"2":{"2":1}}],["以及函数返回的非引用对象",{"2":{"172":1}}],["以及广播机制",{"2":{"160":1}}],["以及lora",{"2":{"141":1}}],["以及llm",{"2":{"0":1}}],["以及给定前面几个单词后",{"2":{"140":1}}],["以及键",{"2":{"136":1,"150":1,"230":1}}],["以及词表",{"2":{"126":1}}],["以及",{"2":{"105":1,"121":1,"238":1,"269":1,"297":1}}],["以及3d混合并行",{"2":{"65":1}}],["以及运行时runtime层面优化",{"2":{"23":1}}],["以及python基础知识的学习",{"2":{"1":1}}],["面试速记",{"2":{"2":1}}],["本质上是时间换空间",{"2":{"301":1}}],["本质上都是在一个进程中运行",{"2":{"232":1}}],["本身const成员函数就肩负着的线程安全的逻辑意义",{"2":{"266":1}}],["本身博客包含了一些其他作者的博客",{"2":{"53":1}}],["本节主要就伪代码来演示pipline",{"2":{"225":1}}],["本地传播",{"2":{"221":1}}],["本章先分析decoder",{"2":{"210":1}}],["本章主要是对其进行的完善补充",{"2":{"112":1}}],["本专题的初衷是学习机器学习以及深度学习相关的算法",{"2":{"21":1}}],["本文主要研究dualpipev",{"2":{"290":1}}],["本文主要包含了使用主题的过程中可能会遇到的常见问题与解决方法",{"2":{"4":1}}],["本文你可以当做",{"2":{"1":1}}],["本项目会长期更新",{"2":{"2":1}}],["本项目其实并不会像小林coding一样",{"2":{"2":1}}],["一句话简单概括",{"2":{"310":1}}],["一句话概括",{"2":{"305":1}}],["一种是ssh",{"2":{"280":1}}],["一种是进入io阻塞状态",{"2":{"152":1}}],["一次推理只会生成一个token",{"2":{"304":1}}],["一次训练迭代中",{"2":{"284":1}}],["一次训练迭代包含了前向传递和后向传递",{"2":{"284":1}}],["一次训练迭代的计算量为",{"2":{"277":1}}],["一次训练中",{"2":{"277":1}}],["一次前向+一次反向",{"2":{"38":1}}],["一共四块gpu",{"2":{"275":1}}],["一篇论文",{"2":{"270":1}}],["一篇讲gpipe和pipedream的文章",{"2":{"225":1}}],["一篇超级赞的博客",{"2":{"53":1}}],["一步步展开",{"2":{"205":1}}],["一行结束时输入两个空格",{"2":{"165":1}}],["一阶马尔科夫模型",{"2":{"154":1}}],["一阶马尔科夫模型如下",{"2":{"110":1}}],["一些有关basemodel的配置",{"2":{"305":1}}],["一些不可拷贝对象",{"2":{"158":1}}],["一些单机或者多机的不同种类模型的训练启动脚本",{"2":{"127":4}}],["一些代码实现",{"2":{"127":1}}],["一些想法",{"0":{"2":1}}],["一款高吞吐的gemm",{"2":{"70":1}}],["一组数据到内存中",{"2":{"64":1}}],["一",{"0":{"64":1,"65":1,"68":1,"71":1,"73":1,"80":1,"83":1,"86":1,"87":1,"105":1,"112":1,"124":1,"142":1,"156":1,"158":1,"172":1,"179":1,"190":1,"196":1,"210":1,"243":1,"247":1,"261":1},"1":{"79":1,"82":1,"93":1,"95":1,"96":1,"100":1,"101":1,"106":1,"109":1,"110":1,"115":1,"116":1,"122":1,"125":1,"126":1,"131":1,"132":1,"136":1,"138":1,"139":1,"140":1,"146":1,"147":1,"150":1,"152":1,"153":1,"154":1,"155":1,"161":1,"167":1,"169":1,"170":1,"178":1,"184":1,"187":1,"188":1,"202":1,"203":1,"211":1,"220":1,"224":1,"227":1,"235":1,"241":1,"244":1,"252":1,"256":1,"257":1,"267":1,"268":1,"272":1,"277":1,"278":1,"280":1,"284":1,"285":1,"287":1,"291":1,"292":1,"297":1,"301":1}}],["一般model保存的是state",{"2":{"305":1}}],["一般选择per",{"2":{"298":1}}],["一般来讲",{"2":{"291":1}}],["一般来说",{"2":{"136":1}}],["一般都会开启virtual",{"2":{"290":1}}],["一般和tma的load",{"2":{"285":1}}],["一般这个时候会使用multiprocessing库中的pool创建进程池来实现多进程的管理",{"2":{"271":1}}],["一般比较适用于llm",{"2":{"270":1}}],["一般放到torch",{"2":{"225":1}}],["一般没啥差别",{"2":{"205":1}}],["一般用的是cpp这种底层工具",{"2":{"205":1}}],["一般需要将其sum",{"2":{"159":1}}],["一般作为神经网络的一层",{"2":{"146":1}}],["一般是使用梯度下降来优化损失函数",{"2":{"130":1}}],["一般的",{"2":{"67":1,"224":1}}],["一般的段落不需要用空白或断行缩进",{"2":{"41":1}}],["一般通过conda",{"2":{"50":1}}],["一个接一个地生成词",{"2":{"304":1}}],["一个典型的大模型生成式推断包含了两个阶段",{"2":{"304":1}}],["一个是init阶段",{"2":{"299":1}}],["一个是你的vscode需要识别到你的clangd",{"2":{"50":1}}],["一个sigmod激活函数",{"2":{"295":1}}],["一个完善的卷积神经网络自然不会只有卷积层",{"2":{"273":1}}],["一个包含文字的段落",{"2":{"181":2}}],["一个",{"2":{"181":1}}],["一个标量",{"2":{"177":1}}],["一个进程内多个线程竞争一把锁",{"2":{"152":1}}],["一个普通括号",{"2":{"149":1}}],["一个方括号",{"2":{"149":1}}],["一个惊叹号",{"2":{"149":1}}],["一个简单的梯度计算例子",{"0":{"145":1}}],["一个简单的聊天脚本",{"2":{"127":1}}],["一个以上的空白或",{"2":{"104":1}}],["一个以上相连接的行句组成",{"2":{"41":1}}],["一个代码块会一直持续到没有缩进的那一行",{"2":{"67":1}}],["一个有关pre",{"2":{"57":1}}],["一个段落是由一个以上相连接的行句组成",{"2":{"41":1}}],["一份使用",{"2":{"7":1,"13":1,"15":1,"17":1}}],["一份涵盖了llm算法",{"2":{"0":1}}],["aync",{"2":{"285":1}}],["a×b×ca",{"2":{"277":1}}],["a×ba",{"2":{"277":1}}],["a∈ra×b",{"2":{"277":1}}],["a∈ra×ba",{"2":{"277":1}}],["affine",{"2":{"270":1}}],["aes",{"2":{"253":1}}],["a64",{"2":{"253":1}}],["a2​",{"2":{"237":1}}],["a2",{"2":{"237":1}}],["a1​",{"2":{"237":1}}],["a1​a2​​",{"2":{"237":1}}],["a1",{"2":{"237":1}}],["a1a2",{"2":{"237":1}}],["available",{"2":{"282":1}}],["avg",{"2":{"281":1}}],["avgpool2d",{"2":{"123":1,"295":2}}],["average",{"2":{"281":1}}],["avx2",{"2":{"253":1}}],["avx",{"2":{"221":1,"253":1}}],["aaaa",{"2":{"245":2}}],["aaaaaaaaa",{"2":{"245":1}}],["aaa",{"2":{"210":1,"237":2}}],["aarch64",{"2":{"190":1}}],["authandaccess",{"2":{"209":5}}],["auto的类型推导",{"2":{"209":1}}],["auto类型推导通常和模板类型推导相同",{"2":{"194":1}}],["auto类型推导有很多和模板类型推导一致",{"2":{"194":1}}],["auto类型推导",{"0":{"194":1}}],["automodelforcausallm",{"2":{"141":1}}],["autograd之中实现的功能",{"2":{"117":1}}],["autograd",{"0":{"117":1,"133":1},"1":{"133":1},"2":{"133":2,"225":1}}],["auto",{"2":{"87":1,"194":13,"207":6,"209":8,"305":1}}],["autotune",{"2":{"70":2}}],["autofrontmatter",{"2":{"25":1}}],["a0",{"2":{"190":1}}],["absmax",{"2":{"293":1}}],["abs",{"2":{"238":1,"262":1,"286":4,"293":1}}],["abstractmethod",{"2":{"225":3}}],["abc",{"2":{"225":1,"305":2}}],["abi",{"2":{"190":1}}],["about",{"2":{"104":2,"305":1}}],["axis>",{"2":{"257":6,"268":5}}],["axis",{"2":{"257":4,"268":4}}],["axis=1",{"2":{"160":1}}],["ax2+bx+c=0",{"2":{"119":2}}],["ax^2",{"2":{"119":2}}],["a≠0a",{"2":{"119":1}}],["asym",{"2":{"298":1}}],["asymmetric",{"2":{"270":1,"286":1}}],["async一起使用",{"2":{"285":1}}],["async一样",{"2":{"244":1}}],["async之前一般加上这么一句",{"2":{"285":1}}],["async的实现是使用的",{"2":{"268":1}}],["async貌似只能用来load",{"2":{"268":1}}],["async来异步搬运数据",{"2":{"257":1}}],["async其实是在一个线程中运行",{"2":{"232":1}}],["asynchronous",{"2":{"227":2,"244":3,"285":1}}],["async协程其实本质上也是在单进程中写并发代码",{"2":{"215":1}}],["async",{"0":{"200":1,"244":1,"257":1,"268":1},"1":{"215":1,"232":1,"248":1,"257":1,"268":1,"278":1,"285":1,"292":1},"2":{"163":1,"244":16,"257":12,"268":16,"285":9,"292":12}}],["assignment=true",{"2":{"305":1}}],["assume",{"2":{"257":2,"268":2}}],["assert",{"2":{"101":1,"137":1,"262":1,"302":1,"305":1}}],["asimdfhm",{"2":{"253":1}}],["asimddp",{"2":{"253":1}}],["asimdrdm",{"2":{"253":1}}],["asimdhp",{"2":{"253":1}}],["asimd",{"2":{"253":1}}],["asm",{"2":{"196":1,"211":7,"227":6,"257":5,"268":7,"285":5,"292":1}}],["asterisks",{"2":{"120":5,"213":1}}],["as",{"2":{"116":1,"126":3,"129":2,"147":1,"160":1,"161":1,"190":3,"205":1,"305":3}}],["agent在一个environment中",{"2":{"112":1}}],["a=",{"2":{"109":1,"125":2,"237":4}}],["await处理",{"2":{"271":1}}],["await异步编程",{"0":{"200":1},"1":{"215":1,"232":1,"248":1}}],["await异步",{"0":{"108":1},"1":{"124":1,"138":1,"152":1,"167":1,"184":1,"200":1,"215":1,"232":1,"248":1,"260":1,"271":1}}],["awq",{"2":{"270":1}}],["awesome",{"2":{"89":2}}],["a>",{"2":{"104":5,"198":1}}],["across",{"2":{"290":1}}],["acc",{"2":{"295":10}}],["accessed",{"2":{"227":1}}],["accelerator",{"2":{"141":2,"299":1}}],["account",{"2":{"161":1}}],["accumulator",{"2":{"160":2,"295":2,"300":1,"312":1}}],["accumulation",{"2":{"141":4}}],["accuracy",{"2":{"160":3,"295":4}}],["activate",{"2":{"305":1}}],["activation可以使用uint8类型的量化",{"2":{"298":1}}],["activations",{"2":{"297":1}}],["activation的backward",{"2":{"290":1}}],["activation",{"2":{"238":1,"298":2}}],["active",{"2":{"89":1}}],["acting",{"2":{"116":1}}],["actor",{"2":{"112":1,"127":1}}],["acquire的协同作用可以视为内存屏障机制",{"2":{"64":1}}],["acquire",{"2":{"64":6}}],["allbubble​=m+p−1p−1​",{"2":{"275":1}}],["all",{"2":{"225":1,"257":6,"265":1,"268":4,"275":1,"299":2,"305":1}}],["allowed=true",{"2":{"305":1}}],["allows",{"2":{"305":1}}],["allow",{"2":{"147":1}}],["alt",{"2":{"149":3}}],["along",{"2":{"141":1,"237":3}}],["alphaα又被成为步长",{"2":{"114":1}}],["alphaα",{"2":{"93":1,"122":1,"183":1}}],["alpha",{"2":{"93":2,"106":1,"114":1,"122":2,"129":1,"154":2,"183":1}}],["alerts",{"2":{"89":1}}],["alexnet",{"0":{"80":1}}],["align=",{"2":{"181":1}}],["align=center",{"2":{"181":1}}],["align",{"2":{"105":2}}],["aligned",{"2":{"45":2,"131":4,"211":3,"257":2,"268":2}}],["aliquam",{"2":{"52":4,"59":6}}],["approx",{"2":{"234":1}}],["appropriate",{"2":{"147":1}}],["app",{"2":{"221":2}}],["append",{"2":{"94":4,"126":1,"183":2,"282":1,"289":2}}],["applied",{"2":{"101":1,"147":1}}],["application",{"2":{"67":2}}],["apply",{"2":{"101":3,"110":1,"133":1,"295":1,"312":1}}],["applescript",{"2":{"67":2}}],["api",{"2":{"50":1}}],["adaptiveavgpool2d",{"2":{"107":1}}],["adamw优化器元素数量为",{"2":{"256":1}}],["adam",{"2":{"110":1,"193":1,"312":1}}],["adam的公式如下",{"2":{"105":1}}],["adam优化器梯度的一阶动量和二阶动量",{"2":{"256":1}}],["adam优化器",{"2":{"105":1}}],["adam优化器包含三个部分",{"2":{"105":1}}],["adipiscing",{"2":{"52":4,"59":7}}],["addr",{"2":{"268":7,"280":2}}],["addressing",{"2":{"290":1}}],["addressable",{"2":{"211":2}}],["address",{"2":{"198":2}}],["additiveattention",{"2":{"136":3,"183":1}}],["additional",{"2":{"116":1,"141":1}}],["added",{"2":{"89":2}}],["add",{"2":{"50":1,"89":2,"106":1,"133":1,"141":3,"160":2,"295":4,"300":2,"312":2}}],["amx",{"2":{"253":1}}],["amet",{"2":{"52":6,"59":10}}],["ampare",{"2":{"55":1}}],["amp",{"2":{"26":18,"34":18,"36":18,"39":18,"47":1,"67":2,"70":1,"105":3,"131":12,"135":3,"172":17,"190":3,"209":1,"290":3}}],["arbitrary",{"2":{"305":1}}],["arrived",{"2":{"292":5}}],["arrive",{"2":{"227":4,"285":1,"292":2}}],["arr2",{"2":{"194":1}}],["arr1",{"2":{"194":1}}],["arrays",{"2":{"129":2}}],["array",{"2":{"110":1,"129":2}}],["arm",{"2":{"190":2,"253":2}}],["argmax",{"2":{"160":1,"289":1}}],["args=args",{"2":{"305":1}}],["args",{"2":{"141":17,"160":2,"183":1,"225":3,"294":7,"302":3,"308":5,"310":2}}],["args来在deepspeed的基础上新增一些选项",{"2":{"141":1}}],["arguments",{"2":{"50":1,"141":1,"294":1}}],["arange",{"2":{"93":1,"106":1,"110":1,"132":2,"136":1,"145":2,"220":2,"269":2,"281":1,"282":1,"312":1}}],["arch",{"2":{"55":2,"94":6}}],["are",{"2":{"45":4,"89":2,"119":4,"147":1,"161":1,"272":1}}],["atomics",{"2":{"253":1}}],["atomic",{"2":{"158":1}}],["attr=",{"2":{"181":2}}],["attribute",{"2":{"104":2,"149":1}}],["attends",{"2":{"161":1}}],["atten",{"2":{"101":2,"147":2}}],["attention块计算量估计",{"2":{"277":1}}],["attention使用序列的顺序信息而设计的",{"2":{"269":1}}],["attention的计算复杂度和序列长度成平方关系",{"2":{"269":1}}],["attention的最大路径长度最短",{"2":{"269":1}}],["attention的输出应用一层mlp",{"2":{"116":1}}],["attention都有并行计算的优势",{"2":{"269":1}}],["attention三种架构的计算复杂性",{"2":{"269":1}}],["attention层",{"2":{"224":1}}],["attention层和ffn层的中间激活",{"2":{"297":1}}],["attention层和ffn层",{"2":{"224":1}}],["attention计算",{"2":{"214":1}}],["attentiondecoder",{"2":{"183":3}}],["attention",{"0":{"81":1,"101":1,"191":1,"208":1},"2":{"87":2,"101":8,"106":2,"116":2,"136":6,"147":1,"150":3,"161":2,"183":9,"216":1,"224":1,"230":1,"246":2,"258":1,"269":1,"297":1}}],["attention中q",{"2":{"47":1}}],["attn",{"2":{"101":8,"147":2,"161":8}}],["at",{"2":{"26":4,"34":4,"36":4,"39":4,"190":1}}],["atx",{"2":{"7":1,"13":1,"15":1,"17":1,"46":2}}],["any",{"2":{"135":2,"227":1}}],["animator",{"2":{"106":3,"295":4,"300":3,"312":3}}],["an",{"2":{"46":2,"67":2,"77":2,"104":3,"116":1,"211":2,"214":2,"227":1,"244":3,"272":1}}],["answer",{"2":{"23":1,"30":1,"37":1,"43":1,"49":1,"54":1}}],["another",{"2":{"19":1,"27":1,"29":1,"31":1,"59":1,"244":3}}],["anchor",{"2":{"18":2}}],["and",{"0":{"111":1},"2":{"1":1,"89":4,"97":2,"101":3,"119":2,"141":1,"147":2,"159":3,"160":1,"161":3,"227":2,"268":2,"272":2,"285":1,"290":2,"292":1,"299":2,"300":1,"305":5,"310":2}}],["a",{"0":{"16":1},"1":{"23":1,"30":1,"37":1,"43":1,"49":1,"54":1},"2":{"19":1,"27":1,"29":1,"31":1,"52":3,"59":8,"64":2,"67":6,"77":10,"97":2,"101":2,"104":7,"109":21,"116":1,"122":9,"125":12,"135":8,"136":3,"147":4,"150":3,"160":2,"161":5,"172":7,"181":2,"188":3,"198":3,"211":3,"220":3,"227":3,"237":7,"245":1,"252":3,"253":1,"257":1,"268":1,"277":10,"285":1,"297":9,"305":5}}],["ai领域的优化分为三类",{"2":{"23":1}}],["ai",{"0":{"0":1},"1":{"1":1,"2":1}}],["框架熟悉",{"2":{"1":1}}],["sx​",{"2":{"298":1}}],["sx",{"2":{"298":1}}],["s文件的汇编语言含义",{"2":{"264":1}}],["skipping",{"2":{"257":1}}],["sb",{"2":{"253":1}}],["sve2",{"2":{"253":1}}],["sme",{"2":{"253":1}}],["smem3",{"2":{"244":1}}],["smem0",{"2":{"244":1}}],["small",{"2":{"94":2}}],["ssh模式",{"2":{"280":1}}],["ssh",{"2":{"280":1}}],["sse基础优化",{"2":{"221":1}}],["ss",{"2":{"211":3}}],["sss",{"2":{"210":1,"301":2}}],["ssa或者opt汇编优化器",{"2":{"205":1}}],["s就会有比较大的区别",{"2":{"205":1}}],["srcmem",{"2":{"244":2}}],["src4",{"2":{"211":2}}],["src3",{"2":{"211":2}}],["src2",{"2":{"211":2}}],["src1",{"2":{"211":2}}],["src",{"2":{"161":3,"178":18,"193":5,"211":14,"257":11,"268":22}}],["speed",{"2":{"300":2}}],["special",{"2":{"141":3}}],["sparse",{"2":{"216":1}}],["space",{"2":{"211":2,"244":3}}],["spaces",{"2":{"181":2}}],["span",{"2":{"135":4}}],["splits",{"2":{"220":1}}],["split",{"2":{"101":5,"126":1,"220":1,"237":3,"305":1}}],["sft",{"0":{"141":1},"2":{"127":1}}],["save就是将tensor或者model保存到磁盘中",{"2":{"305":1}}],["saved",{"2":{"133":1}}],["save",{"2":{"126":2,"133":1,"160":1,"225":2,"269":1,"282":1,"289":1,"295":2,"296":1,"305":1}}],["same",{"2":{"59":1}}],["sgd",{"2":{"106":1,"129":3,"295":1,"300":2}}],["sglang",{"2":{"1":1}}],["snippet",{"2":{"103":6}}],["swap",{"2":{"101":1}}],["sq",{"2":{"282":3}}],["squared",{"2":{"129":2}}],["squeeze",{"2":{"97":1,"136":1}}],["sqrt",{"2":{"93":1,"101":1,"105":1,"119":2,"137":2,"150":4,"277":1,"296":1,"301":1,"304":2}}],["sym",{"2":{"298":1}}],["symmetric",{"2":{"270":1,"286":1}}],["syncwarp",{"2":{"285":3}}],["synchronizing",{"2":{"227":1}}],["sync",{"2":{"211":3,"292":1}}],["synthetic",{"2":{"129":3}}],["syntax",{"2":{"89":1}}],["sychronizing",{"2":{"141":1}}],["system",{"0":{"57":1},"1":{"65":1,"76":1}}],["scientific",{"2":{"305":1}}],["scientificnotationencoder",{"2":{"305":1}}],["schema",{"2":{"305":3}}],["scheduler",{"2":{"302":1}}],["schedule",{"0":{"275":1},"2":{"225":2,"254":1}}],["schedule的选择是通过get",{"2":{"225":1}}],["scoped",{"0":{"207":1}}],["scores的形状",{"2":{"136":1}}],["scores",{"2":{"101":6,"136":2,"150":2}}],["scalescales",{"2":{"293":1}}],["scales",{"2":{"293":6}}],["scalemin",{"2":{"286":1}}],["scale的分母就会变成255",{"2":{"286":1}}],["scaleweight​",{"2":{"286":2}}],["scale=127abs",{"2":{"286":1}}],["scale=127max",{"2":{"286":1}}],["scale=abs",{"2":{"286":1}}],["scale=max",{"2":{"286":1}}],["scale",{"0":{"254":1},"1":{"265":1,"275":1,"283":1},"2":{"270":1,"286":4}}],["scaled",{"2":{"101":3,"150":1}}],["scaling",{"2":{"38":1}}],["scripts来启动该step的训练",{"2":{"127":1}}],["scripts",{"2":{"127":6}}],["scripts里面启动main",{"2":{"127":1}}],["script",{"2":{"52":1}}],["shot",{"2":{"305":1}}],["shot=false",{"2":{"305":1}}],["short",{"2":{"299":1}}],["should",{"2":{"227":1,"305":1}}],["shm",{"2":{"211":1}}],["shuffle=is",{"2":{"129":1}}],["shuffle",{"2":{"129":1,"187":1}}],["sh",{"2":{"127":2}}],["share",{"2":{"268":1}}],["shared",{"0":{"111":1},"2":{"97":1,"111":1,"211":8,"227":7,"244":11,"257":7,"268":14,"285":3,"292":7}}],["sha512",{"2":{"253":1}}],["sha3",{"2":{"253":1}}],["sha2",{"2":{"253":1}}],["sha1",{"2":{"253":1}}],["shape为",{"2":{"300":1,"310":4}}],["shape均为",{"2":{"300":1}}],["shape",{"2":{"97":8,"101":2,"106":2,"122":5,"123":2,"129":2,"136":1,"137":8,"150":1,"160":4,"186":5,"201":3,"202":1,"211":1,"246":8,"257":1,"262":2,"268":1,"269":1,"281":4,"282":3,"295":3,"300":1,"306":1,"310":4,"312":2}}],["shikijs",{"2":{"89":1}}],["shiki",{"2":{"89":5}}],["shell",{"2":{"52":1}}],["shh",{"2":{"50":1}}],["s",{"2":{"52":1,"70":1,"101":2,"119":2,"147":1,"161":5,"183":1,"209":5,"221":1,"235":1,"268":2,"272":2,"277":31,"297":12,"298":10,"300":2}}],["such",{"2":{"147":1}}],["subconfig",{"2":{"305":2}}],["subprocess",{"0":{"287":1}}],["subspaces",{"2":{"230":1}}],["subset",{"2":{"227":1}}],["subseqs",{"2":{"187":3}}],["sub",{"2":{"126":1}}],["sublayer",{"2":{"87":3}}],["surrounded",{"2":{"120":1}}],["supports",{"2":{"227":1}}],["support",{"2":{"101":1}}],["suppress",{"2":{"50":1}}],["supervised",{"2":{"127":1}}],["super",{"2":{"97":2,"101":1,"106":1,"116":1,"117":1,"123":2,"132":1,"136":1,"137":1,"147":1,"150":1,"161":1,"178":1,"183":2,"186":1,"246":1,"269":1,"305":2,"306":1,"308":3,"310":2,"312":1}}],["sum",{"2":{"73":1,"93":7,"106":7,"109":8,"110":4,"115":1,"122":2,"125":6,"129":1,"131":14,"133":1,"146":1,"159":7,"160":3,"183":1,"186":3,"188":3,"233":1,"262":1,"274":2,"295":1,"296":2,"312":3}}],["suspendisse",{"2":{"52":2,"59":3}}],["sigma^2σ2",{"2":{"297":1}}],["sigmoid",{"2":{"295":4}}],["simd向量化",{"2":{"221":1}}],["sim",{"2":{"110":2}}],["single",{"2":{"101":1,"120":2,"135":2,"147":1,"161":1,"292":1}}],["sin",{"2":{"93":1,"110":1,"132":1,"269":2}}],["size为ppp",{"2":{"275":1}}],["size决定",{"2":{"201":1}}],["size+num",{"2":{"183":1,"310":1}}],["size的计算方式是dp",{"2":{"141":1}}],["size来获得平均损失",{"2":{"129":1}}],["size来分割数据",{"2":{"129":1}}],["size=8",{"2":{"310":2}}],["size=x",{"2":{"300":1}}],["size=len",{"2":{"282":1}}],["size=shape",{"2":{"282":1}}],["size=num",{"2":{"183":2}}],["size=7",{"2":{"123":2}}],["size=",{"2":{"110":1,"129":1,"160":2,"186":1,"201":3,"281":1}}],["size=5",{"2":{"107":1,"123":1,"295":3}}],["size=10",{"2":{"310":2}}],["size=11",{"2":{"107":1}}],["size=1",{"2":{"107":2,"123":5,"289":1,"300":1,"306":1}}],["size=20",{"2":{"136":1}}],["size=2",{"2":{"94":1,"136":1,"295":2}}],["size=3",{"2":{"94":1,"107":1,"123":7,"201":3}}],["size",{"2":{"70":7,"94":2,"97":7,"101":14,"107":2,"110":2,"129":12,"132":1,"136":10,"141":7,"150":5,"160":2,"178":12,"183":17,"186":2,"187":5,"193":7,"199":4,"202":9,"207":5,"211":1,"244":2,"246":16,"254":1,"268":2,"277":6,"281":2,"282":13,"300":7,"306":10,"310":37,"312":8}}],["sizeof",{"2":{"49":1,"257":2,"268":2}}],["sit",{"2":{"52":6,"59":10}}],["site",{"2":{"50":3}}],["st>",{"2":{"257":1,"268":1}}],["st>>",{"2":{"257":2,"268":1}}],["stmatrix",{"2":{"211":1,"268":1}}],["stg",{"2":{"211":2,"268":2}}],["stsm4",{"2":{"211":1}}],["sts",{"2":{"211":2,"257":1}}],["st",{"2":{"183":4,"211":7,"257":14,"268":10}}],["steps的序列",{"2":{"187":1}}],["steps的子序列的起始索引",{"2":{"187":1}}],["steps=2的话",{"2":{"141":1}}],["steps是一种训练优化技术",{"2":{"141":1}}],["steps",{"2":{"141":2,"183":4,"187":7,"199":2,"202":11,"282":2,"300":4,"310":14,"312":4}}],["step3就是真正的rlft",{"2":{"127":1}}],["step3",{"2":{"127":1}}],["step2是reward",{"2":{"127":1}}],["step2",{"2":{"127":2}}],["step1",{"0":{"141":1},"2":{"127":1,"141":1}}],["step",{"2":{"106":1,"110":1,"116":1,"129":1,"193":1,"295":1,"300":1,"312":1}}],["style",{"2":{"89":1,"104":1}}],["style=detailed",{"2":{"50":1}}],["stack",{"2":{"220":1,"250":2}}],["stacked",{"2":{"147":1,"161":1}}],["start",{"2":{"214":1,"294":5,"295":1}}],["started",{"2":{"89":2}}],["state的形状",{"2":{"310":2}}],["state的形状为",{"2":{"183":2}}],["state对于nn",{"2":{"300":2}}],["state=init",{"2":{"282":1}}],["state共用一套量化参数",{"2":{"279":1}}],["states",{"2":{"199":1}}],["state",{"2":{"183":10,"211":2,"244":3,"251":1,"282":15,"289":6,"300":9,"306":5,"308":5,"310":14}}],["static",{"2":{"172":1,"207":4,"211":10,"257":6,"268":8,"285":5,"292":1}}],["staticmethod",{"2":{"133":2}}],["stage的dualpipe",{"2":{"290":1}}],["stage的时候",{"2":{"275":1}}],["stage之后计算成本",{"2":{"275":1}}],["stage倍",{"2":{"275":2}}],["stage",{"2":{"141":1,"225":2,"275":2,"290":1}}],["stage=args",{"2":{"141":1}}],["stages=s",{"2":{"70":1}}],["stop",{"2":{"295":1,"300":1,"312":1}}],["stop危险区域",{"2":{"89":2}}],["store的时候",{"2":{"292":1}}],["stores",{"2":{"285":1}}],["store两个方法",{"2":{"244":1}}],["store",{"0":{"211":1,"268":1},"2":{"64":2,"211":2,"227":1,"244":1,"268":9,"285":6,"292":9}}],["str",{"2":{"282":3,"295":1,"300":1,"305":3,"312":1}}],["strategies",{"2":{"225":1}}],["strategy",{"0":{"222":1},"1":{"237":1,"254":1,"265":1,"275":1,"283":1,"290":1},"2":{"65":1,"225":2}}],["struct",{"2":{"192":4,"209":1,"211":3,"227":2}}],["structure",{"2":{"163":1}}],["strong>",{"2":{"120":2}}],["strong>double",{"2":{"120":2}}],["strong",{"2":{"120":1}}],["strict",{"2":{"305":1}}],["strict=false",{"2":{"305":1}}],["string",{"2":{"135":2,"207":2,"209":4}}],["strip",{"2":{"126":1}}],["stripes",{"2":{"45":2}}],["stride",{"2":{"201":1,"257":4,"268":4}}],["stride=",{"2":{"281":1}}],["stride=1",{"2":{"123":2}}],["stride=2",{"2":{"94":1,"107":2,"123":5,"201":1,"281":2,"295":2}}],["strides=1",{"2":{"107":2}}],["strides=4",{"2":{"107":1}}],["strides",{"2":{"107":2}}],["std=0",{"2":{"129":1}}],["std=c++20",{"2":{"50":1}}],["std",{"2":{"64":7,"158":3,"171":2,"172":1,"192":2,"194":3,"205":1,"207":15,"209":6}}],["socket的请求后会调python函数handler",{"2":{"271":1}}],["socket转发请求到其他wsgi",{"2":{"271":1}}],["so",{"2":{"227":1}}],["source",{"2":{"161":2,"272":1}}],["sourcedir",{"2":{"32":1}}],["solutions",{"2":{"119":2}}],["sorted",{"2":{"126":1}}],["sort",{"2":{"93":1,"305":1}}],["softmax层输出结果",{"2":{"224":1}}],["softmax函数",{"2":{"160":1}}],["softmaxsoftmaxsoftmax",{"2":{"100":1,"115":2,"131":2,"146":1}}],["softmax精度问题",{"2":{"37":1}}],["softmax",{"0":{"74":1},"1":{"86":1,"100":1,"115":1,"131":1,"146":1,"160":1},"2":{"23":1,"93":1,"101":2,"106":2,"115":4,"122":4,"123":1,"131":3,"136":1,"146":1,"150":4,"160":4,"224":1,"277":1,"304":2}}],["some",{"0":{"14":1,"216":1},"2":{"52":1}}],["serialization",{"2":{"305":1}}],["serialize",{"2":{"305":1}}],["serializer",{"2":{"305":1}}],["server",{"2":{"14":1}}],["send之后完全释放",{"2":{"225":1}}],["send出去",{"2":{"225":1}}],["search",{"2":{"104":16}}],["season",{"2":{"59":2}}],["seed",{"2":{"141":3}}],["see",{"2":{"104":1}}],["seq2seqdecoder",{"2":{"310":3}}],["seq2seqencoder",{"2":{"310":3}}],["seq2seq",{"0":{"310":1},"1":{"312":1},"2":{"312":1}}],["seq2seqattentiondecoder",{"2":{"183":2}}],["seqdataloader",{"2":{"202":1,"282":1}}],["sequence",{"0":{"283":1},"2":{"122":1,"132":1,"161":2,"254":1,"302":2,"305":1,"312":2}}],["sequential",{"2":{"94":4,"107":3,"110":1,"123":4,"129":1,"202":2,"295":1}}],["seq",{"2":{"97":7,"101":14,"132":3,"178":9,"187":1,"193":4,"202":3}}],["self",{"2":{"87":1,"97":10,"101":26,"106":6,"116":9,"117":3,"123":16,"126":22,"132":5,"136":14,"137":17,"147":17,"150":7,"160":10,"161":22,"178":21,"183":20,"186":6,"202":12,"224":2,"225":2,"246":18,"258":1,"269":10,"277":1,"282":13,"297":1,"305":16,"306":30,"308":15,"310":17,"312":3}}],["sec",{"2":{"295":1,"312":1}}],["seconds",{"2":{"294":1}}],["second",{"2":{"52":1,"59":1,"101":1}}],["sections",{"0":{"1":1}}],["semaphore",{"0":{"227":1},"2":{"227":1,"257":1,"268":1,"285":1,"292":2}}],["sem",{"2":{"52":2,"59":3}}],["semper",{"2":{"52":2,"59":3}}],["setting",{"2":{"305":1}}],["settings",{"2":{"50":1}}],["setattr",{"2":{"305":1}}],["set",{"2":{"141":4,"299":1,"305":10}}],["setext",{"2":{"7":1,"13":1,"15":1,"17":1,"46":2}}],["学习率",{"2":{"186":1}}],["学习容易",{"2":{"12":1,"20":1,"22":1,"24":1}}],["学习各种parallel策略",{"2":{"1":1}}],["学习cpp可以增强自己对于底层cpu以及内存的理解",{"2":{"1":1}}],["学会如何去写出性能高效的kernel",{"2":{"1":1}}],["cdb=",{"2":{"299":1}}],["cdb",{"2":{"299":5}}],["cdot",{"2":{"100":1,"105":5,"119":4,"131":2,"146":1,"186":1,"201":2,"233":2,"250":5,"251":2,"277":2,"281":3,"304":14}}],["cclbackendintel通信库",{"2":{"299":1}}],["ccc",{"2":{"38":1,"183":1}}],["cvta",{"2":{"257":3,"268":5,"285":1}}],["cg",{"2":{"244":1,"257":2}}],["circuit",{"2":{"299":1}}],["ci⋅kh⋅kwc",{"2":{"233":1,"250":1}}],["ci",{"2":{"233":1,"250":1}}],["ci=1c",{"2":{"233":1}}],["cic",{"2":{"233":2}}],["c++11解决类型推断的方法是",{"2":{"207":1}}],["c++14允许auto用于函数返回值并会被推导",{"2":{"194":1}}],["close",{"2":{"305":2}}],["clobber列表",{"2":{"196":1}}],["clipping",{"2":{"296":1,"300":2,"312":1}}],["clip是一个截断操作",{"2":{"286":1}}],["clip",{"2":{"286":1}}],["cluster",{"2":{"257":2,"268":4}}],["clusters",{"0":{"254":1},"1":{"265":1,"275":1,"283":1}}],["cls=scientificnotationencoder",{"2":{"305":1}}],["cls",{"2":{"225":2}}],["clamp",{"2":{"293":2}}],["clang生成代码通常小5",{"2":{"221":1}}],["clang的dwarf5更强大",{"2":{"221":1}}],["clang普遍快30",{"2":{"221":1}}],["clang有更加完善的格式",{"2":{"221":1}}],["clang比gcc优势大很多",{"2":{"221":1}}],["clang一般要优于gcc",{"2":{"221":1}}],["clang++",{"2":{"221":1}}],["clang++最后编译得到机器码之后",{"2":{"205":1}}],["clang++更多的是一个智能的预处理调度器",{"2":{"205":1}}],["clang++就是按照下述这个顺序",{"2":{"205":1}}],["clang",{"2":{"190":1,"221":9}}],["clangd中加上你的",{"2":{"50":1}}],["clangd文件不支持访问环境变量",{"2":{"50":1}}],["clangd文件来告诉clangd我的编译选项",{"2":{"50":1}}],["clangd",{"2":{"50":4}}],["classmethod",{"2":{"225":2}}],["classes",{"2":{"123":2}}],["class",{"2":{"97":2,"101":1,"106":1,"116":1,"117":1,"123":3,"126":1,"132":1,"133":1,"136":1,"137":1,"141":1,"147":2,"150":1,"156":1,"158":3,"160":1,"161":2,"171":1,"178":1,"181":1,"183":2,"186":1,"202":1,"207":1,"225":2,"246":1,"269":1,"282":1,"302":3,"305":6,"306":1,"308":3,"310":2,"312":1}}],["class=",{"2":{"67":2,"181":1}}],["ctrl",{"2":{"228":2}}],["cta",{"2":{"211":2,"227":9,"244":4,"268":11,"285":2}}],["ct",{"2":{"183":4}}],["ctx之后的输入值的数量一致",{"2":{"133":1}}],["ctx",{"2":{"133":4}}],["cx",{"2":{"179":5,"194":2}}],["cmp",{"2":{"160":2}}],["crc32",{"2":{"253":1}}],["criterion",{"2":{"193":2}}],["critic",{"2":{"112":1,"127":1}}],["crx",{"2":{"179":5,"194":2}}],["crossentropyloss",{"2":{"193":1,"295":1,"300":1,"312":1}}],["cross",{"2":{"160":2,"161":3,"290":1}}],["created",{"2":{"227":1}}],["create",{"2":{"141":1,"299":1}}],["c是一个干扰量",{"2":{"129":1}}],["c​",{"2":{"125":4}}],["c4=128",{"2":{"123":3}}],["c4=64",{"2":{"123":5}}],["c4=32",{"2":{"123":1}}],["c4",{"2":{"123":2}}],["c3=",{"2":{"123":9}}],["c3",{"2":{"123":4}}],["c2=",{"2":{"123":9}}],["c2",{"2":{"123":4}}],["c1=384",{"2":{"123":1}}],["c1=256",{"2":{"123":2}}],["c1=112",{"2":{"123":1}}],["c1=160",{"2":{"123":1}}],["c1=192",{"2":{"123":1}}],["c1=128",{"2":{"123":2}}],["c1=64",{"2":{"123":1}}],["c1",{"2":{"123":2}}],["center",{"2":{"181":1}}],["center居中的内容",{"2":{"164":2}}],["centered",{"2":{"45":2}}],["certain",{"2":{"101":1,"161":2}}],["check",{"2":{"305":4}}],["checkpoint的源码中是如何设计的",{"2":{"305":1}}],["checkpoint的操作",{"2":{"305":1}}],["checkpoint",{"2":{"294":3,"305":1}}],["checkpointing",{"2":{"141":1}}],["ch8",{"2":{"289":2,"300":4}}],["challenge",{"2":{"290":1}}],["chatbot",{"2":{"127":2}}],["chat之中",{"2":{"127":1}}],["chat",{"0":{"127":1},"1":{"141":1},"2":{"127":2}}],["chat的源码走读环节",{"2":{"112":1}}],["char",{"2":{"126":2,"179":3,"194":3}}],["channel还是per",{"2":{"298":1}}],["channel",{"2":{"279":1,"298":1}}],["channels=1",{"2":{"186":2,"201":2}}],["channels=192",{"2":{"123":1}}],["channels=64",{"2":{"123":4}}],["channels=out",{"2":{"94":1}}],["channels=in",{"2":{"94":1}}],["channels",{"2":{"94":13,"107":8,"123":7}}],["change",{"2":{"119":2}}],["ch6",{"2":{"94":1,"295":2}}],["ca×b×c",{"2":{"277":1}}],["ca",{"2":{"244":1}}],["calls",{"2":{"257":2,"268":2}}],["call",{"2":{"225":2,"282":1}}],["calculate",{"2":{"101":1}}],["cast",{"2":{"172":1,"207":4,"257":4,"268":6,"285":1}}],["cases",{"2":{"131":2,"146":2}}],["capture",{"2":{"147":1}}],["causal",{"2":{"141":1}}],["caution",{"2":{"77":1,"89":4}}],["care",{"2":{"141":1}}],["category",{"0":{"172":1},"2":{"172":2}}],["cat",{"2":{"97":1,"123":1,"183":2,"220":1,"253":1,"281":1,"282":1,"310":1,"312":1}}],["cannot",{"2":{"305":1}}],["can",{"2":{"97":1,"257":1,"268":1,"272":1,"305":1}}],["cache延伸技术",{"0":{"307":1},"1":{"309":1,"311":1}}],["cache的计算过程为",{"2":{"304":1}}],["cache的re",{"2":{"70":1}}],["cache和value",{"2":{"304":2}}],["cache占用的显存下文会详细介绍",{"2":{"267":1}}],["cache也需要占用显存",{"2":{"267":1}}],["cache来加速推理过程",{"2":{"267":1}}],["cache更加友好的原因",{"2":{"70":1}}],["cache",{"0":{"195":1,"304":1},"1":{"210":1,"224":1,"241":1,"256":1,"267":1,"277":1,"284":1,"291":1,"297":1,"301":1,"304":1,"307":1,"309":1,"311":1},"2":{"70":4,"211":4,"257":4,"268":4,"304":4}}],["cp",{"0":{"244":1},"1":{"257":1,"268":1,"278":1,"285":1,"292":1},"2":{"244":12,"257":5,"268":7,"285":3,"292":1}}],["cpu",{"2":{"282":1}}],["cpuid",{"2":{"253":1}}],["cpuinfo",{"2":{"253":1}}],["cpu支持该指令集",{"2":{"253":1}}],["cpu指令集架构",{"2":{"190":1}}],["cpu算子加速库",{"2":{"54":1}}],["cpp14",{"2":{"207":1}}],["cpp文件",{"2":{"205":1}}],["cpp",{"0":{"44":1,"163":1},"2":{"1":2,"205":2,"221":4}}],["custom",{"2":{"305":1}}],["customize",{"2":{"181":2}}],["cuh",{"2":{"196":1,"244":1}}],["curl",{"2":{"119":2}}],["cutlass",{"0":{"61":1}}],["cublas",{"2":{"54":1}}],["cudnn",{"2":{"54":1}}],["cudnn内部采用这样计算conv2d",{"2":{"23":1}}],["cuda实战01",{"0":{"174":1}}],["cuda库的编译一般是使用setup",{"2":{"50":1}}],["cudacc",{"2":{"50":2}}],["cuda入门",{"2":{"1":1}}],["cuda",{"0":{"48":1,"50":1},"2":{"1":1,"50":3,"54":1,"268":2,"272":1}}],["csrc",{"2":{"50":1}}],["c",{"2":{"38":1,"49":6,"50":1,"115":2,"119":4,"125":16,"129":1,"154":1,"183":2,"188":1,"209":11,"214":2,"220":2,"245":1,"250":2,"252":1,"262":6,"277":1}}],["cnn",{"0":{"168":1},"1":{"186":1,"201":1,"217":1,"233":1,"250":1,"262":1},"2":{"49":1,"153":1,"269":1}}],["cn",{"2":{"38":2}}],["coords",{"2":{"257":10,"268":10}}],["coordinates",{"2":{"257":1,"268":1}}],["coord",{"2":{"257":23,"268":17,"292":6}}],["cool",{"2":{"45":2}}],["co⋅ci⋅kh⋅kwc",{"2":{"250":1}}],["co​",{"2":{"250":1}}],["coc",{"2":{"250":1}}],["cop",{"2":{"211":2}}],["copy到不同机器上",{"2":{"265":1}}],["copy",{"2":{"26":1,"34":1,"36":1,"39":1,"67":2,"244":3,"268":1}}],["coff",{"2":{"190":1}}],["cout",{"2":{"171":2,"205":1}}],["count会自动减少",{"2":{"227":1}}],["count+transaction",{"2":{"227":2}}],["count",{"2":{"126":2,"227":4,"292":4}}],["counter",{"2":{"126":3}}],["costly",{"2":{"290":1}}],["cos",{"2":{"132":1,"269":2}}],["corr2d",{"2":{"186":3,"233":3,"250":3,"262":3}}],["corresponding",{"2":{"161":1}}],["correct",{"2":{"141":1}}],["corpus",{"2":{"126":7,"187":5,"202":7,"282":1}}],["corporation",{"2":{"67":2}}],["core来进行计算",{"2":{"70":1}}],["core",{"2":{"14":1}}],["concat",{"2":{"246":2,"304":2}}],["concat的形状",{"2":{"246":1}}],["container>",{"2":{"209":1}}],["container",{"2":{"209":10}}],["context",{"2":{"183":2,"302":2,"310":4}}],["context的形状为",{"2":{"183":1}}],["content",{"2":{"181":2}}],["contiguous",{"2":{"101":1,"193":2}}],["connections",{"2":{"147":1,"161":1}}],["connection",{"2":{"87":1,"147":1}}],["consists",{"2":{"161":1}}],["consistency",{"0":{"64":1}}],["console",{"2":{"89":6}}],["construct",{"2":{"294":1}}],["const成员函数无法修改成员变量",{"2":{"266":1}}],["const成员函数的线程安全",{"0":{"266":1}}],["constexpr可以将一部分在运行时进行的计算转移到编译时进行",{"2":{"255":1}}],["constexpr",{"0":{"255":1},"2":{"207":3,"257":5,"268":5}}],["const修饰的函数被称为常量函数",{"2":{"171":1}}],["const修饰函数",{"0":{"171":1}}],["const修饰变量",{"0":{"156":1}}],["const",{"0":{"143":1},"1":{"156":1,"171":1},"2":{"67":2,"89":8,"156":7,"171":3,"172":1,"179":25,"194":9,"209":5,"211":4,"257":7,"268":9,"285":2}}],["consectetuer",{"2":{"52":4,"59":7}}],["configdict",{"2":{"305":1}}],["config是管理各种配置选项的",{"2":{"305":1}}],["configs=gemm",{"2":{"70":1}}],["configs",{"2":{"70":2,"305":1}}],["config",{"0":{"305":1},"2":{"50":1,"70":1,"89":12,"141":6,"302":5,"305":14}}],["conda",{"2":{"50":9}}],["conversion",{"2":{"268":2}}],["converting",{"2":{"305":1}}],["convert",{"2":{"41":1,"141":1,"257":1,"268":1}}],["conv4",{"2":{"123":2}}],["conv3",{"2":{"123":2}}],["conv2",{"2":{"123":2}}],["conv2d可以通过转换成矩阵乘法来计算",{"2":{"23":1}}],["conv2d",{"2":{"23":1,"94":1,"107":3,"123":9,"186":8,"201":12,"295":4}}],["conv1",{"2":{"123":2}}],["convs",{"2":{"94":4}}],["conv",{"2":{"49":1,"94":9}}],["color",{"2":{"298":2}}],["cols",{"2":{"257":2,"268":2}}],["collectively",{"2":{"211":1}}],["collections",{"2":{"126":2,"305":2}}],["col",{"2":{"45":4,"237":1,"257":9,"268":6}}],["code>`foo`",{"2":{"135":1}}],["code>`",{"2":{"135":1}}],["code>printf",{"2":{"135":1}}],["code>there",{"2":{"135":1}}],["code>this",{"2":{"67":1}}],["code>tell",{"2":{"67":1}}],["code>",{"2":{"67":4,"135":10}}],["code",{"2":{"26":3,"34":3,"36":3,"39":3,"52":1,"67":3,"70":1,"89":24,"103":4,"135":4,"228":1}}],["comm",{"2":{"299":1}}],["committed",{"2":{"292":1}}],["commits",{"2":{"285":1}}],["commit",{"2":{"244":2,"257":1,"268":1,"285":3}}],["communication",{"0":{"225":1,"272":1},"2":{"290":2,"299":1}}],["commands",{"2":{"50":3}}],["com>",{"2":{"198":1}}],["combination",{"2":{"161":1}}],["combines",{"2":{"101":1}}],["combine",{"2":{"97":1,"101":3}}],["computation",{"2":{"290":1}}],["compute",{"2":{"141":1,"292":1}}],["compared",{"2":{"290":1}}],["compatible",{"2":{"141":1}}],["comp",{"2":{"201":2}}],["completing",{"2":{"292":1}}],["completion",{"2":{"50":1,"227":1,"244":1}}],["complete",{"2":{"147":1,"161":1,"244":3,"257":2,"268":1,"292":1}}],["complex",{"2":{"147":1}}],["components",{"2":{"147":1}}],["compiler",{"2":{"50":1}}],["compileflags",{"2":{"50":1}}],["compile",{"2":{"50":1}}],["com",{"2":{"14":2,"26":2,"34":2,"36":2,"39":2,"47":1,"89":2,"104":22,"198":4,"268":2}}]],"serializationVersion":2}';export{e as default};
