<!doctype html><html lang="zh-CN"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="generator" content="VuePress 2.0.0-rc.20" /><meta name="theme" content="VuePress Theme Plume 1.0.0-rc.140" /><script id="check-mac-os">document.documentElement.classList.toggle('mac', /Mac|iPhone|iPod|iPad/i.test(navigator.platform))</script><script id="check-dark-mode">;(function () {const um= localStorage.getItem('vuepress-theme-appearance') || 'auto';const sm = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;const isDark = um === 'dark' || (um !== 'light' && sm);document.documentElement.dataset.theme = isDark ? 'dark' : 'light';})();</script><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><meta name="google-site-verification" content="AaTP7bapCAcoO9ZGE67ilpy99GL6tYqtD30tRHjO9Ps"><title>LLM Parallel Strategy | AI Router</title><meta name="description" content=""><link rel="preload" href="/AI-Router/assets/style-BJrL0BLw.css" as="style"><link rel="stylesheet" href="/AI-Router/assets/style-BJrL0BLw.css"><link rel="modulepreload" href="/AI-Router/assets/app-0p9pLXBN.js"><link rel="modulepreload" href="/AI-Router/assets/index.html-hWJtf7xJ.js"></head><body><div id="app"><!--[--><!--[--><div class="theme-plume vp-layout" vp-container data-v-68cd6b44><!--[--><!--[--><!--]--><!--[--><span tabindex="-1" data-v-d5a8d0bc></span><a href="#VPContent" class="vp-skip-link visually-hidden" data-v-d5a8d0bc> Skip to content </a><!--]--><!----><header class="vp-nav" data-v-68cd6b44 data-v-d34f28d6><div class="vp-navbar" vp-navbar data-v-d34f28d6 data-v-70d97d16><div class="wrapper" data-v-70d97d16><div class="container" data-v-70d97d16><div class="title" data-v-70d97d16><div class="vp-navbar-title has-sidebar" data-v-70d97d16 data-v-1a4f50af><a class="vp-link no-icon link title" href="/AI-Router/" data-v-1a4f50af data-v-442a52aa><!--[--><!--[--><!--]--><!--[--><!--[--><!--[--><img class="vp-image dark logo" style="" src="/AI-Router/plume.png" alt data-v-eda4b9bd><!--]--><!--[--><img class="vp-image light logo" style="" src="/AI-Router/plume.png" alt data-v-eda4b9bd><!--]--><!--]--><!--]--><span data-v-1a4f50af>AI Router</span><!--[--><!--]--><!--]--><!----></a></div></div><div class="content" data-v-70d97d16><div class="content-body" data-v-70d97d16><!--[--><!--]--><div class="vp-navbar-search search" data-v-70d97d16><div class="search-wrapper" data-v-97535d1e><!----><div id="local-search" data-v-97535d1e><button type="button" class="mini-search mini-search-button" aria-label="搜索文档" data-v-97535d1e><span class="mini-search-button-container"><span class="mini-search-search-icon vpi-mini-search" aria-label="search icon"></span><span class="mini-search-button-placeholder">搜索文档</span></span><span class="mini-search-button-keys"><kbd class="mini-search-button-key"></kbd><kbd class="mini-search-button-key">K</kbd></span></button></div></div></div><nav aria-labelledby="main-nav-aria-label" class="vp-navbar-menu menu" data-v-70d97d16 data-v-d43c1732><span id="main-nav-aria-label" class="visually-hidden" data-v-d43c1732>Main Navigation</span><!--[--><!--[--><a class="vp-link no-icon link navbar-menu-link" href="/AI-Router/algorithm/" tabindex="0" data-v-d43c1732 data-v-9970a379 data-v-442a52aa><!--[--><!----><span data-v-9970a379>算法</span><!--]--><!----></a><!--]--><!--[--><a class="vp-link no-icon link navbar-menu-link" href="/AI-Router/cpp/" tabindex="0" data-v-d43c1732 data-v-9970a379 data-v-442a52aa><!--[--><!----><span data-v-9970a379>C++</span><!--]--><!----></a><!--]--><!--[--><a class="vp-link no-icon link navbar-menu-link" href="/AI-Router/python/" tabindex="0" data-v-d43c1732 data-v-9970a379 data-v-442a52aa><!--[--><!----><span data-v-9970a379>Python</span><!--]--><!----></a><!--]--><!--[--><a class="vp-link no-icon link navbar-menu-link" href="/AI-Router/cuda/" tabindex="0" data-v-d43c1732 data-v-9970a379 data-v-442a52aa><!--[--><!----><span data-v-9970a379>CUDA</span><!--]--><!----></a><!--]--><!--[--><a class="vp-link no-icon link navbar-menu-link active" href="/AI-Router/system/" tabindex="0" data-v-d43c1732 data-v-9970a379 data-v-442a52aa><!--[--><!----><span data-v-9970a379>System</span><!--]--><!----></a><!--]--><!--[--><a class="vp-link no-icon link navbar-menu-link" href="/AI-Router/blog/" tabindex="0" data-v-d43c1732 data-v-9970a379 data-v-442a52aa><!--[--><!----><span data-v-9970a379>博客</span><!--]--><!----></a><!--]--><!--[--><div class="vp-flyout vp-navbar-menu-group" data-v-d43c1732 data-v-31c474b3><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-31c474b3><span class="text" data-v-31c474b3><!----><!----><span data-v-31c474b3>更多</span><span class="vpi-chevron-down text-icon" data-v-31c474b3></span></span></button><div class="menu" data-v-31c474b3><div class="vp-menu" data-v-31c474b3 data-v-709dc2b1><div class="items" data-v-709dc2b1><!--[--><!--[--><div class="vp-menu-link" data-v-709dc2b1 data-v-aaf95230><a class="vp-link no-icon link" href="/AI-Router/faq/" data-v-aaf95230 data-v-442a52aa><!--[--><!----> 常见问题<!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-709dc2b1 data-v-aaf95230><a class="vp-link no-icon link" href="/AI-Router/sponsor/" data-v-aaf95230 data-v-442a52aa><!--[--><!----> 喝杯奶茶<!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-709dc2b1 data-v-aaf95230><a class="vp-link no-icon link" href="/AI-Router/tools/" data-v-aaf95230 data-v-442a52aa><!--[--><!----> 主题工具<!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-709dc2b1 data-v-aaf95230><a class="vp-link no-icon link" href="/AI-Router/friends/" data-v-aaf95230 data-v-442a52aa><!--[--><!----> 友情链接<!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-group" data-v-709dc2b1 data-v-c497e9e3><p class="title" data-v-c497e9e3><!----><span data-v-c497e9e3>Vuepress</span></p><!--[--><!--[--><div class="vp-menu-link" data-v-c497e9e3 data-v-aaf95230><a class="vp-link no-icon link" href="https://v2.vuepress.vuejs.org" target="_blank" rel="noreferrer" data-v-aaf95230 data-v-442a52aa><!--[--><!----> 官方文档<!--]--><span class="vpi-external-link icon" data-v-442a52aa></span></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-c497e9e3 data-v-aaf95230><a class="vp-link no-icon link" href="https://ecosystem.vuejs.press/" target="_blank" rel="noreferrer" data-v-aaf95230 data-v-442a52aa><!--[--><!----> 生态系统<!--]--><span class="vpi-external-link icon" data-v-442a52aa></span></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="vp-flyout vp-navbar-menu-group" data-v-d43c1732 data-v-31c474b3><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-31c474b3><span class="text" data-v-31c474b3><!----><!----><span data-v-31c474b3>1.0.0</span><span class="vpi-chevron-down text-icon" data-v-31c474b3></span></span></button><div class="menu" data-v-31c474b3><div class="vp-menu" data-v-31c474b3 data-v-709dc2b1><div class="items" data-v-709dc2b1><!--[--><!--[--><div class="vp-menu-link" data-v-709dc2b1 data-v-aaf95230><a class="vp-link no-icon link" href="/AI-Router/changelog/" data-v-aaf95230 data-v-442a52aa><!--[--><!----> 更新日志<!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-709dc2b1 data-v-aaf95230><a class="vp-link no-icon link" href="/AI-Router/contributing/" data-v-aaf95230 data-v-442a52aa><!--[--><!----> 参与贡献<!--]--><!----></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><!----><div class="vp-navbar-appearance appearance" data-v-70d97d16 data-v-a295abf6><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-a295abf6 data-v-596c25a9 data-v-7eb32327><span class="check" data-v-7eb32327><span class="icon" data-v-7eb32327><!--[--><span class="vpi-sun sun" data-v-596c25a9></span><span class="vpi-moon moon" data-v-596c25a9></span><!--]--></span></span></button></div><div class="vp-social-links vp-navbar-social-links social-links" data-v-70d97d16 data-v-ad52545c data-v-40bac536><!--[--><a class="vp-social-link no-icon" href="https://github.com/zfan2356/AI-Router" aria-label="github" target="_blank" rel="noopener" data-v-40bac536 data-v-67b21932><span class="vpi-social-github" /></a><!--]--></div><div class="vp-flyout vp-navbar-extra extra" data-v-70d97d16 data-v-652282fd data-v-31c474b3><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-31c474b3><span class="vpi-more-horizontal icon" data-v-31c474b3></span></button><div class="menu" data-v-31c474b3><div class="vp-menu" data-v-31c474b3 data-v-709dc2b1><!----><!--[--><!--[--><!----><div class="group" data-v-652282fd><div class="item appearance" data-v-652282fd><p class="label" data-v-652282fd>外观</p><div class="appearance-action" data-v-652282fd><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-652282fd data-v-596c25a9 data-v-7eb32327><span class="check" data-v-7eb32327><span class="icon" data-v-7eb32327><!--[--><span class="vpi-sun sun" data-v-596c25a9></span><span class="vpi-moon moon" data-v-596c25a9></span><!--]--></span></span></button></div></div></div><div class="group" data-v-652282fd><div class="item social-links" data-v-652282fd><div class="vp-social-links social-links-list" data-v-652282fd data-v-40bac536><!--[--><a class="vp-social-link no-icon" href="https://github.com/zfan2356/AI-Router" aria-label="github" target="_blank" rel="noopener" data-v-40bac536 data-v-67b21932><span class="vpi-social-github" /></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="vp-navbar-hamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="nav-screen" data-v-70d97d16 data-v-2b50024d><span class="container" data-v-2b50024d><span class="top" data-v-2b50024d></span><span class="middle" data-v-2b50024d></span><span class="bottom" data-v-2b50024d></span></span></button></div></div></div></div><div class="divider" data-v-70d97d16><div class="divider-line" data-v-70d97d16></div></div></div><!----></header><div class="vp-local-nav reached-top" data-v-68cd6b44 data-v-3944d8e8><button class="menu" aria-expanded="false" aria-controls="SidebarNav" data-v-3944d8e8><span class="vpi-align-left menu-icon" data-v-3944d8e8></span><span class="menu-text" data-v-3944d8e8>Menu</span></button><div class="vp-local-nav-outline-dropdown" style="--vp-vh:0px;" data-v-3944d8e8 data-v-4114a62c><button data-v-4114a62c>返回顶部</button><!----></div></div><aside class="vp-sidebar" vp-sidebar data-v-68cd6b44 data-v-3c61d592><div class="curtain" data-v-3c61d592></div><nav id="SidebarNav" class="nav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-3c61d592><span id="sidebar-aria-label" class="visually-hidden" data-v-3c61d592> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-473fd05b><section class="vp-sidebar-item sidebar-item level-0 collapsible" data-v-473fd05b data-v-e8cce3b3><div class="item" role="button" tabindex="0" data-v-e8cce3b3><div class="indicator" data-v-e8cce3b3></div><!----><h2 class="text" data-v-e8cce3b3>Inference</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-e8cce3b3><span class="vpi-chevron-right caret-icon" data-v-e8cce3b3></span></div></div><div data-v-e8cce3b3 data-v-e8cce3b3><div class="items" data-v-e8cce3b3><!--[--><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-e8cce3b3 data-v-e8cce3b3><div class="item" data-v-e8cce3b3><div class="indicator" data-v-e8cce3b3></div><!----><a class="vp-link no-icon link link" href="/AI-Router/system/inference/flash_attention/" data-v-e8cce3b3 data-v-442a52aa><!--[--><p class="text" data-v-e8cce3b3>Flash Attention 优化</p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-e8cce3b3 data-v-e8cce3b3><div class="item" data-v-e8cce3b3><div class="indicator" data-v-e8cce3b3></div><!----><a class="vp-link no-icon link link" href="/AI-Router/system/inference/kvcache/" data-v-e8cce3b3 data-v-442a52aa><!--[--><p class="text" data-v-e8cce3b3>KV Cache</p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-e8cce3b3 data-v-e8cce3b3><div class="item" data-v-e8cce3b3><div class="indicator" data-v-e8cce3b3></div><!----><a class="vp-link no-icon link link" href="/AI-Router/system/inference/gqa/" data-v-e8cce3b3 data-v-442a52aa><!--[--><p class="text" data-v-e8cce3b3>MHA/GQA/MQA优化技术</p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-e8cce3b3 data-v-e8cce3b3><div class="item" data-v-e8cce3b3><div class="indicator" data-v-e8cce3b3></div><!----><a class="vp-link no-icon link link" href="/AI-Router/system/inference/page-attn/" data-v-e8cce3b3 data-v-442a52aa><!--[--><p class="text" data-v-e8cce3b3>Page Attention 显存优化</p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-e8cce3b3 data-v-e8cce3b3><div class="item" data-v-e8cce3b3><div class="indicator" data-v-e8cce3b3></div><!----><a class="vp-link no-icon link link" href="/AI-Router/system/inference/paper/" data-v-e8cce3b3 data-v-442a52aa><!--[--><p class="text" data-v-e8cce3b3>some papers</p><!--]--><!----></a><!----></div><!----></div><!--]--></div></div></section></div><div class="no-transition group" data-v-473fd05b><section class="vp-sidebar-item sidebar-item level-0 collapsible has-active" data-v-473fd05b data-v-e8cce3b3><div class="item" role="button" tabindex="0" data-v-e8cce3b3><div class="indicator" data-v-e8cce3b3></div><!----><h2 class="text" data-v-e8cce3b3>Pre-Train</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-e8cce3b3><span class="vpi-chevron-right caret-icon" data-v-e8cce3b3></span></div></div><div data-v-e8cce3b3 data-v-e8cce3b3><div class="items" data-v-e8cce3b3><!--[--><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-e8cce3b3 data-v-e8cce3b3><div class="item" data-v-e8cce3b3><div class="indicator" data-v-e8cce3b3></div><!----><a class="vp-link no-icon link link" href="/AI-Router/system/pre-train/model-parallel/" data-v-e8cce3b3 data-v-442a52aa><!--[--><p class="text" data-v-e8cce3b3>LLM Parallel Strategy</p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-e8cce3b3 data-v-e8cce3b3><div class="item" data-v-e8cce3b3><div class="indicator" data-v-e8cce3b3></div><!----><a class="vp-link no-icon link link" href="/AI-Router/system/pre-train/pp/" data-v-e8cce3b3 data-v-442a52aa><!--[--><p class="text" data-v-e8cce3b3>Pipline Communication</p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-e8cce3b3 data-v-e8cce3b3><div class="item" data-v-e8cce3b3><div class="indicator" data-v-e8cce3b3></div><!----><a class="vp-link no-icon link link" href="/AI-Router/system/pre-train/zero/" data-v-e8cce3b3 data-v-442a52aa><!--[--><p class="text" data-v-e8cce3b3>ZeRO</p><!--]--><!----></a><!----></div><!----></div><section class="vp-sidebar-item sidebar-item level-1 collapsible collapsed" data-v-e8cce3b3 data-v-e8cce3b3><div class="item" role="button" tabindex="0" data-v-e8cce3b3><div class="indicator" data-v-e8cce3b3></div><!----><h3 class="text" data-v-e8cce3b3>DeepSpeed</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-e8cce3b3><span class="vpi-chevron-right caret-icon" data-v-e8cce3b3></span></div></div><div style="display:none;" data-v-e8cce3b3 data-v-e8cce3b3><div class="items" data-v-e8cce3b3><!--[--><div class="vp-sidebar-item sidebar-item level-2 is-link" data-v-e8cce3b3 data-v-e8cce3b3><div class="item" data-v-e8cce3b3><div class="indicator" data-v-e8cce3b3></div><!----><a class="vp-link no-icon link link" href="/AI-Router/system/pre-train/deepspeed/deepspeed01/" data-v-e8cce3b3 data-v-442a52aa><!--[--><p class="text" data-v-e8cce3b3>DeepSpeed 源码解读01</p><!--]--><!----></a><!----></div><!----></div><!--]--></div></div></section><!--]--></div></div></section></div><div class="no-transition group" data-v-473fd05b><section class="vp-sidebar-item sidebar-item level-0 collapsible" data-v-473fd05b data-v-e8cce3b3><div class="item" role="button" tabindex="0" data-v-e8cce3b3><div class="indicator" data-v-e8cce3b3></div><!----><h2 class="text" data-v-e8cce3b3>Quant</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-e8cce3b3><span class="vpi-chevron-right caret-icon" data-v-e8cce3b3></span></div></div><div data-v-e8cce3b3 data-v-e8cce3b3><div class="items" data-v-e8cce3b3><!--[--><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-e8cce3b3 data-v-e8cce3b3><div class="item" data-v-e8cce3b3><div class="indicator" data-v-e8cce3b3></div><!----><a class="vp-link no-icon link link" href="/AI-Router/system/quant/intro/" data-v-e8cce3b3 data-v-442a52aa><!--[--><p class="text" data-v-e8cce3b3>大模型量化简介</p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-e8cce3b3 data-v-e8cce3b3><div class="item" data-v-e8cce3b3><div class="indicator" data-v-e8cce3b3></div><!----><a class="vp-link no-icon link link" href="/AI-Router/system/quant/pytorch-quant/" data-v-e8cce3b3 data-v-442a52aa><!--[--><p class="text" data-v-e8cce3b3>PyTorch模型量化</p><!--]--><!----></a><!----></div><!----></div><!--]--></div></div></section></div><div class="no-transition group" data-v-473fd05b><section class="vp-sidebar-item sidebar-item level-0 collapsible" data-v-473fd05b data-v-e8cce3b3><div class="item" role="button" tabindex="0" data-v-e8cce3b3><div class="indicator" data-v-e8cce3b3></div><!----><h2 class="text" data-v-e8cce3b3>RL</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-e8cce3b3><span class="vpi-chevron-right caret-icon" data-v-e8cce3b3></span></div></div><div data-v-e8cce3b3 data-v-e8cce3b3><div class="items" data-v-e8cce3b3><!--[--><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-e8cce3b3 data-v-e8cce3b3><div class="item" data-v-e8cce3b3><div class="indicator" data-v-e8cce3b3></div><!----><a class="vp-link no-icon link link" href="/AI-Router/system/rl/intro/" data-v-e8cce3b3 data-v-442a52aa><!--[--><p class="text" data-v-e8cce3b3>RL介绍</p><!--]--><!----></a><!----></div><!----></div><!--]--></div></div></section></div><!--]--><!--[--><!--]--></nav></aside><!--[--><div id="VPContent" vp-content class="vp-content has-sidebar" data-v-68cd6b44 data-v-eb709286><div class="vp-doc-container has-sidebar has-aside" data-v-eb709286 data-v-db1f3b4c><!--[--><!--]--><div class="container" data-v-db1f3b4c><div class="aside" vp-outline data-v-db1f3b4c><div class="aside-curtain" data-v-db1f3b4c></div><div class="aside-container" data-v-db1f3b4c><div class="aside-content" data-v-db1f3b4c><div class="vp-doc-aside" data-v-db1f3b4c data-v-5976474c><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="vp-doc-aside-outline" role="navigation" data-v-5976474c data-v-aa56eba0><div class="content" data-v-aa56eba0><div class="outline-marker" data-v-aa56eba0></div><div id="doc-outline-aria-label" aria-level="2" class="outline-title" role="heading" data-v-aa56eba0><span data-v-aa56eba0>此页内容</span><span class="vpi-print icon" data-v-aa56eba0></span></div><ul class="root" data-v-aa56eba0 data-v-3e6b023c><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-5976474c></div><!--[--><!--]--></div></div></div></div><div class="content" data-v-db1f3b4c><div class="content-container" data-v-db1f3b4c><!--[--><!--]--><main class="main" data-v-db1f3b4c><nav class="vp-breadcrumb" data-v-db1f3b4c data-v-1ae4ad7a><ol vocab="https://schema.org/" typeof="BreadcrumbList" data-v-1ae4ad7a><!--[--><li property="itemListElement" typeof="ListItem" data-v-1ae4ad7a><a class="vp-link no-icon link breadcrumb" href="/AI-Router/" property="item" typeof="WebPage" data-v-1ae4ad7a data-v-442a52aa><!--[-->首页<!--]--><!----></a><span class="vpi-chevron-right" data-v-1ae4ad7a></span><meta property="name" content="首页" data-v-1ae4ad7a><meta property="position" content="1" data-v-1ae4ad7a></li><li property="itemListElement" typeof="ListItem" data-v-1ae4ad7a><span class="vp-link no-icon breadcrumb" href="/AI-Router/" property="item" typeof="WebPage" data-v-1ae4ad7a data-v-442a52aa><!--[-->Pre-Train<!--]--><!----></span><span class="vpi-chevron-right" data-v-1ae4ad7a></span><meta property="name" content="Pre-Train" data-v-1ae4ad7a><meta property="position" content="2" data-v-1ae4ad7a></li><li property="itemListElement" typeof="ListItem" data-v-1ae4ad7a><a class="vp-link no-icon link breadcrumb current" href="/AI-Router/system/pre-train/model-parallel/" property="item" typeof="WebPage" data-v-1ae4ad7a data-v-442a52aa><!--[-->LLM Parallel Strategy<!--]--><!----></a><!----><meta property="name" content="LLM Parallel Strategy" data-v-1ae4ad7a><meta property="position" content="3" data-v-1ae4ad7a></li><!--]--></ol></nav><!--[--><h1 class="vp-doc-title page-title" data-v-7e9208b4>LLM Parallel Strategy <!----></h1><div class="vp-doc-meta" data-v-7e9208b4><p class="reading-time" data-v-7e9208b4><span class="vpi-books icon" data-v-7e9208b4></span><span data-v-7e9208b4>约 1718 字</span><span data-v-7e9208b4>大约 6 分钟</span></p><p data-v-7e9208b4><span class="vpi-tag icon" data-v-7e9208b4></span><!--[--><span class="vp-link no-icon tag vp-tag-vozi" href="/AI-Router/" data-v-7e9208b4 data-v-442a52aa><!--[-->system<!--]--><!----></span><span class="vp-link no-icon tag vp-tag-l2yw" href="/AI-Router/" data-v-7e9208b4 data-v-442a52aa><!--[-->pre-train<!--]--><!----></span><!--]--></p><p class="create-time" data-v-7e9208b4><span class="vpi-clock icon" data-v-7e9208b4></span><span data-v-7e9208b4>2025-04-11</span></p></div><!--]--><div class="_system_pre-train_model-parallel_ external-link-icon-enabled vp-doc plume-content" vp-content data-v-db1f3b4c><div data-v-db1f3b4c><h2 id="megatron-lm-training-multi-billion-parameter-language-models" tabindex="-1"><a class="header-anchor" href="#megatron-lm-training-multi-billion-parameter-language-models"><span>Megatron-LM: Training Multi-Billion Parameter Language Models</span></a></h2><p>作为model parallel的基石，如果你已经掌握了单机单卡简单使用pytorch训练model之后, 建议来细读这一篇Megatron-LM的paper。</p><p><a href="https://arxiv.org/pdf/1909.08053" target="_blank" rel="noopener noreferrer">Megatron-LM paper</a></p><p>总结：其实通篇下来，就只需要理解这张图</p><p><img src="/AI-Router/assets/image-Drv08i9x.png" alt="图片" width="616" height="638"></p><p>处理GEMM followed by a nonlinearity: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><mi>G</mi><mi>e</mi><mi>L</mi><mi>U</mi><mo stretchy="false">(</mo><mi>X</mi><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Y=GeLU(XA)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.10903em;">LU</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord mathnormal">A</span><span class="mclose">)</span></span></span></span>, 有两种tensor切割方式:</p><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span>: split along col, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>: split along row:</li></ul><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>X</mi><mo>=</mo><mo stretchy="false">[</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>X</mi><mn>2</mn></msub><mo stretchy="false">]</mo><mo separator="true">,</mo><mtext> </mtext><mi>A</mi><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>A</mi><mn>1</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>A</mi><mn>2</mn></msub></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">X = [X_1, X_2], \, A = \begin{bmatrix} A_1 \\ A_2 \end{bmatrix}. </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">]</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4em;vertical-align:-0.95em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">[</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.95em;"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">]</span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">.</span></span></span></span></span></p><p>这个时候 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><mi>G</mi><mi>e</mi><mi>L</mi><mi>U</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><msub><mi>A</mi><mn>1</mn></msub><mo>+</mo><msub><mi>X</mi><mn>2</mn></msub><msub><mi>A</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Y = GeLU(X_1A_1 + X_2A_2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.10903em;">LU</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>, 但是需要在GeLU前做一次sync</p><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span>: split along row, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>: duplicate</li></ul><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mo>=</mo><mo stretchy="false">[</mo><msub><mi>A</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>A</mi><mn>2</mn></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">A = [A_1, A_2] </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span></p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">[</mo><msub><mi>Y</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>Y</mi><mn>2</mn></msub><mo stretchy="false">]</mo><mo>=</mo><mo stretchy="false">[</mo><mi>G</mi><mi>e</mi><mi>L</mi><mi>U</mi><mo stretchy="false">(</mo><mi>X</mi><msub><mi>A</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>G</mi><mi>e</mi><mi>L</mi><mi>U</mi><mo stretchy="false">(</mo><mi>X</mi><msub><mi>A</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[Y_1, Y_2] = [GeLU(XA_1), GeLU(XA_2)] </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathnormal">G</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.10903em;">LU</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.10903em;">LU</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)]</span></span></span></span></span></p><p>可以看出这种方式，计算的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span> 仍然保持分割状态，但是无需做一次sync，只需要分治做GeLU即可</p><p>对于MegatronV1来说，主要就介绍的是相对于当时Gpipe的tensor parallel策略，但是从如今的视角来看，tensor parallel已经是时代的眼泪了。</p><h2 id="megatron-lm2-efficient-large-scale-language-model-training-on-gpu-clusters-using-megatron-lm" tabindex="-1"><a class="header-anchor" href="#megatron-lm2-efficient-large-scale-language-model-training-on-gpu-clusters-using-megatron-lm"><span>Megatron-LM2: Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM</span></a></h2><p><a href="https://arxiv.org/pdf/2104.04473" target="_blank" rel="noopener noreferrer">Megatron-LM2 paper</a></p><p>为了适应急剧增长的model size，MegatronV2提出了更加完备的并行策略，结合了Gpipe与Data Parallel，提出了DP + TP + PP的混合并行策略，整篇论文中有如下三个要点：</p><ul><li><p>interleaved schedule.</p></li><li><p>mix parallel.</p></li><li><p>sequence parallel.</p></li></ul><h3 id="_1-mix-parallel" tabindex="-1"><a class="header-anchor" href="#_1-mix-parallel"><span>1. Mix Parallel</span></a></h3><p>对于mix parallel, 主要需要理解，DP, PP, TP之间的“正交性”，DP将model copy到不同机器上，划分batch为若干mini-batch，最后对梯度all reduce，这是一种朴素的并行策略。PP进一步拆分transformer block，将不同的层划分到不同的机器上，mini-batch也进一步划分为若干micro-batch，以流水线的形式进行forward与backward，TP聚焦于节点内部，划分weight到不同GPU上，最后all gather/all reduce来获得结果</p><h3 id="_2-interleaved-schedule" tabindex="-1"><a class="header-anchor" href="#_2-interleaved-schedule"><span>2. Interleaved Schedule</span></a></h3><p><img src="/AI-Router/assets/image2--iH1Qv7k.png" alt="图片" width="2194" height="620"> 首先需要理解Gpipe中的native pp调度：对于native pp来说，forward的时候会逐层计算，然后backward按逆序逐层传递梯度，通过划分micro-batch（假设数量为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span>），当前pp_size为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span>，这个时候bubble为</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><mi>b</mi><mi>u</mi><mi>b</mi><mi>b</mi><mi>l</mi><mi>e</mi></mrow><mrow><mi>a</mi><mi>l</mi><mi>l</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>P</mi><mo>−</mo><mn>1</mn></mrow><mrow><mi>M</mi><mo>+</mo><mi>P</mi><mo>−</mo><mn>1</mn></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{bubble}{all} = \frac{P - 1}{M + P - 1} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.0574em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">ll</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="mord mathnormal">u</span><span class="mord mathnormal">bb</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.1297em;vertical-align:-0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3603em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">1</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>接下来就是PipeDream里面提出的1F1B调度，也是本论文采取的pp调度策略，1F1B有non-Interleaved以及Interleaved两种调度策略</p><p><img src="/AI-Router/assets/image1-Z4dEP15h.png" alt="图片" width="2202" height="1000"></p><p>上图中，由于bwd耗时往往为fwd的两倍，所以占据两个格子。1F1B调度的精髓是当一个micro-batch fwd执行完毕之后，立马执行bwd，然后释放显存，这样可以显著降低显存占用</p><p>对于Interleaved pp调度，我们会将一组在一个GPU上的连续的transformer layer进行进一步划分，成为多个chunk，比如，之前GPU0的layer id为0, 1, 2, 3, 一共四块GPU，有16层，现在如果我们规定<code>virtual_pp_stage = 2</code>, 那么GPU0被分配到的层会变为<code>0, 1, 8, 9</code>, 层数不变，但是chunk变了，这样fwd的顺序会变为</p><div class="language-" data-highlighter="shiki" data-ext="" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span>micro-batch1 fwd:</span></span>
<span class="line"><span>GPU0 -&gt; GPU1 -&gt; GPU2 -&gt; GPU3 -&gt; GPU0 -&gt; ... -&gt; GPU3</span></span></code></pre></div><p>这个时候<code>micro-batch1</code>的fwd执行完毕，就会开始执行bwd</p><p>论文图中，深色为chunk1，浅色为chunk2，<code>virtual_pp_stage = 2</code></p><p>这样做的坏处是，Device之间的点对点通信次数(量)直接变为<code>virtual_pp_stage</code>倍，但是带来的好处是，bubble比也降低为原来的<code>virtual_pp_stage</code>倍。并且可以做到通信的overlap</p><p>这里的通信与计算的overlap是这样做的：对于一个stage，我需要计算一个forward，这里需要recv一个tensor，然后计算，然后send出去结果。之后计算一个backward，这里同样需要recv一个tensor，然后计算，然后send出去。</p><p>可以做到的overlap其实就是在loop的时候，wait recv一个tensor，计算fwd，然后异步去send，之后wait recv grad，计算bwd，然后异步send，再下一轮的时候wait recv的就是上一轮异步send的tensor，这样就实现了通信和计算的overlap，（虽然这里我感觉，在non-interleaved版本的1f1b调度中，也可以实现这样的overlap，可能在没有划分virtual stage的时候，这样overlap收益不高，大头在计算，划分完virtual stage之后计算成本/2了）</p><h3 id="_3-sequence-parallel" tabindex="-1"><a class="header-anchor" href="#_3-sequence-parallel"><span>3. Sequence Parallel</span></a></h3><p>其实就是将seq len这个维度分割，我貌似没有get到这个和tp的区别，虽然tp分割的是hidden_dim</p><h2 id="dualpipe" tabindex="-1"><a class="header-anchor" href="#dualpipe"><span>Dualpipe</span></a></h2><p><a href="https://arxiv.org/pdf/2412.19437" target="_blank" rel="noopener noreferrer">DeepSeek V3 paper</a></p><p>论文中对Dualpipe的描述是这样的： efficient pipeline parallelism. Compared with existing PP methods, DualPipe has fewer pipeline bubbles. More importantly, it overlaps the computation and communication phases across forward and backward processes, thereby addressing the challenge of heavy communication overhead introduced by cross-node expert parallelism.</p><p>可以看出，Dualpipe其实是一种和DeepEP深度耦合的技术，主要解决的就是expert之间的all2all通信问题，将dispatcher和combiner这两个all2all通信算子, 和其余的computation overlap起来, 提高了效率. 当然其本身的调度也很优秀，拥有更少的bubbles</p><p>题外话：Finally, we meticulously optimize the memory footprint during training, thereby enabling us to train DeepSeek-V3 without using costly Tensor Parallelism (TP). 果然TP已经是时代的眼泪了（bushi</p><p>DualPipeV是带有virtual stage的dualpipe, 本文主要研究DualpipeV, 因为在当今训练中, 一般都会开启virtual stage, 以求在更少的device上有更低的bubble率.</p><p><img src="/AI-Router/assets/image3-Cb-3DPCV.png" alt="图片" width="1752" height="984"></p><p>以上是DualPipeV的Schedule以及和1F1B的Bubble等数据的对比, 可以看出DualPipeV主要有以下的一些关键点:</p><ul><li><p>V形调度: 观察1F1B Interleaved调度, 可以看出来我们last rank做完stage1的forward的时候, 开启stage2的forward需要再度传给first rank, 而DualPipeV采取了V形调度, 抹去了这一次通信</p></li><li><p>backward weight与activation的分离: 在1F1B调度中, 我们的B一般就是weight + activation的backward, 这里上文中也提到&quot;由于bwd耗时往往为fwd的两倍，所以占据两个格子&quot;, 在DualPipeV中, 我们将其拆解, 也就是相当于将计算单元拆小, 灵活地进行调度, 减少了Bubble</p></li><li><p>forward &amp; backward overlap执行: 从图中可以看出, 稳定阶段的DualPipeV, 会进入到fwd &amp; bwd overlap阶段, 这一阶段我们会进行通信与计算的overlap, 通过控制sm数量和高效的all2all rmda实现, 来完成overlap.</p></li><li><p>更加精细的异步与tensor内存释放: 这里大部分的操作均为异步, 我们只需要在少数同步点上同步一下通信, 获得数据. 比如在fwd和bwd的时候, 在compute之前我们需要receive一下上一个stage的tensor, 这个时候我们必须得去sync一下, 不然拿不到compute需要的input. 然后再下沉到transformer layer上, 在fwd &amp; bwd的overlap上, 我们需要精细的控制计算图, 不能让每个part之间产生计算图的依赖, 不然就会出现内存泄露的情况, 这里就是属于DeepEP的部分了.</p></li></ul></div><!----><!----><!----></div></main><footer class="vp-doc-footer" data-v-db1f3b4c data-v-fda6bbae><!--[--><!--]--><div class="edit-info" data-v-fda6bbae><div class="edit-link" data-v-fda6bbae><a class="vp-link no-icon link edit-link-button" href="https://github.com/zfan2356/AI-Router/edit/main/docs/notes/system/pre-train/model_parallel.md" target="_blank" rel="noreferrer" data-v-fda6bbae data-v-442a52aa><!--[--><span class="vpi-square-pen edit-link-icon" aria-label="edit icon" data-v-fda6bbae></span> 编辑此页<!--]--><!----></a></div><!----></div><!----><nav class="prev-next" data-v-fda6bbae><div class="pager" data-v-fda6bbae><a class="vp-link no-icon link pager-link prev" href="/AI-Router/system/inference/paper/" data-v-fda6bbae data-v-442a52aa><!--[--><span class="desc" data-v-fda6bbae>上一页</span><span class="title" data-v-fda6bbae>some papers</span><!--]--><!----></a></div><div class="pager" data-v-fda6bbae><a class="vp-link no-icon link pager-link next" href="/AI-Router/system/pre-train/pp/" data-v-fda6bbae data-v-442a52aa><!--[--><span class="desc" data-v-fda6bbae>下一页</span><span class="title" data-v-fda6bbae>Pipline Communication</span><!--]--><!----></a></div></nav></footer><!----><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!--]--><button style="display:none;" type="button" class="vp-back-to-top" aria-label="back to top" data-v-68cd6b44 data-v-bcf8d9a6><span class="percent" data-allow-mismatch data-v-bcf8d9a6>0%</span><span class="show icon vpi-back-to-top" data-v-bcf8d9a6></span><svg aria-hidden="true" data-v-bcf8d9a6><circle cx="50%" cy="50%" data-allow-mismatch style="stroke-dasharray:calc(0% - 12.566370614359172px) calc(314.1592653589793% - 12.566370614359172px);" data-v-bcf8d9a6></circle></svg></button><footer class="vp-footer has-sidebar" vp-footer data-v-68cd6b44 data-v-400675cf><!--[--><div class="container" data-v-400675cf><p class="message" data-v-400675cf>Powered by <a target="_blank" href="https://v2.vuepress.vuejs.org/">VuePress</a> & <a target="_blank" href="https://theme-plume.vuejs.press">vuepress-theme-plume</a></p><p class="copyright" data-v-400675cf>Copyright © 2021-present zfan</p></div><!--]--></footer><!--[--><!--]--><!--]--></div><!----><!--]--><!--[--><!--]--><!--]--></div><script type="module" src="/AI-Router/assets/app-0p9pLXBN.js" defer></script></body></html>