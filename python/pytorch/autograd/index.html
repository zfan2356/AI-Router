<!doctype html><html lang="zh-CN"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="generator" content="VuePress 2.0.0-rc.20" /><meta name="theme" content="VuePress Theme Plume 1.0.0-rc.140" /><script id="check-mac-os">document.documentElement.classList.toggle('mac', /Mac|iPhone|iPod|iPad/i.test(navigator.platform))</script><script id="check-dark-mode">;(function () {const um= localStorage.getItem('vuepress-theme-appearance') || 'auto';const sm = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;const isDark = um === 'dark' || (um !== 'light' && sm);document.documentElement.dataset.theme = isDark ? 'dark' : 'light';})();</script><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><meta name="google-site-verification" content="AaTP7bapCAcoO9ZGE67ilpy99GL6tYqtD30tRHjO9Ps"><title>PyTorch AutoGrad | AI Router</title><meta name="description" content=""><link rel="preload" href="/AI-Router/assets/style-BJrL0BLw.css" as="style"><link rel="stylesheet" href="/AI-Router/assets/style-BJrL0BLw.css"><link rel="modulepreload" href="/AI-Router/assets/app-0p9pLXBN.js"><link rel="modulepreload" href="/AI-Router/assets/index.html-CPdEiMwJ.js"></head><body><div id="app"><!--[--><!--[--><div class="theme-plume vp-layout" vp-container data-v-68cd6b44><!--[--><!--[--><!--]--><!--[--><span tabindex="-1" data-v-d5a8d0bc></span><a href="#VPContent" class="vp-skip-link visually-hidden" data-v-d5a8d0bc> Skip to content </a><!--]--><!----><header class="vp-nav" data-v-68cd6b44 data-v-d34f28d6><div class="vp-navbar" vp-navbar data-v-d34f28d6 data-v-70d97d16><div class="wrapper" data-v-70d97d16><div class="container" data-v-70d97d16><div class="title" data-v-70d97d16><div class="vp-navbar-title has-sidebar" data-v-70d97d16 data-v-1a4f50af><a class="vp-link no-icon link title" href="/AI-Router/" data-v-1a4f50af data-v-442a52aa><!--[--><!--[--><!--]--><!--[--><!--[--><!--[--><img class="vp-image dark logo" style="" src="/AI-Router/plume.png" alt data-v-eda4b9bd><!--]--><!--[--><img class="vp-image light logo" style="" src="/AI-Router/plume.png" alt data-v-eda4b9bd><!--]--><!--]--><!--]--><span data-v-1a4f50af>AI Router</span><!--[--><!--]--><!--]--><!----></a></div></div><div class="content" data-v-70d97d16><div class="content-body" data-v-70d97d16><!--[--><!--]--><div class="vp-navbar-search search" data-v-70d97d16><div class="search-wrapper" data-v-97535d1e><!----><div id="local-search" data-v-97535d1e><button type="button" class="mini-search mini-search-button" aria-label="搜索文档" data-v-97535d1e><span class="mini-search-button-container"><span class="mini-search-search-icon vpi-mini-search" aria-label="search icon"></span><span class="mini-search-button-placeholder">搜索文档</span></span><span class="mini-search-button-keys"><kbd class="mini-search-button-key"></kbd><kbd class="mini-search-button-key">K</kbd></span></button></div></div></div><nav aria-labelledby="main-nav-aria-label" class="vp-navbar-menu menu" data-v-70d97d16 data-v-d43c1732><span id="main-nav-aria-label" class="visually-hidden" data-v-d43c1732>Main Navigation</span><!--[--><!--[--><a class="vp-link no-icon link navbar-menu-link" href="/AI-Router/algorithm/" tabindex="0" data-v-d43c1732 data-v-9970a379 data-v-442a52aa><!--[--><!----><span data-v-9970a379>算法</span><!--]--><!----></a><!--]--><!--[--><a class="vp-link no-icon link navbar-menu-link" href="/AI-Router/cpp/" tabindex="0" data-v-d43c1732 data-v-9970a379 data-v-442a52aa><!--[--><!----><span data-v-9970a379>C++</span><!--]--><!----></a><!--]--><!--[--><a class="vp-link no-icon link navbar-menu-link active" href="/AI-Router/python/" tabindex="0" data-v-d43c1732 data-v-9970a379 data-v-442a52aa><!--[--><!----><span data-v-9970a379>Python</span><!--]--><!----></a><!--]--><!--[--><a class="vp-link no-icon link navbar-menu-link" href="/AI-Router/cuda/" tabindex="0" data-v-d43c1732 data-v-9970a379 data-v-442a52aa><!--[--><!----><span data-v-9970a379>CUDA</span><!--]--><!----></a><!--]--><!--[--><a class="vp-link no-icon link navbar-menu-link" href="/AI-Router/system/" tabindex="0" data-v-d43c1732 data-v-9970a379 data-v-442a52aa><!--[--><!----><span data-v-9970a379>System</span><!--]--><!----></a><!--]--><!--[--><a class="vp-link no-icon link navbar-menu-link" href="/AI-Router/blog/" tabindex="0" data-v-d43c1732 data-v-9970a379 data-v-442a52aa><!--[--><!----><span data-v-9970a379>博客</span><!--]--><!----></a><!--]--><!--[--><div class="vp-flyout vp-navbar-menu-group" data-v-d43c1732 data-v-31c474b3><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-31c474b3><span class="text" data-v-31c474b3><!----><!----><span data-v-31c474b3>更多</span><span class="vpi-chevron-down text-icon" data-v-31c474b3></span></span></button><div class="menu" data-v-31c474b3><div class="vp-menu" data-v-31c474b3 data-v-709dc2b1><div class="items" data-v-709dc2b1><!--[--><!--[--><div class="vp-menu-link" data-v-709dc2b1 data-v-aaf95230><a class="vp-link no-icon link" href="/AI-Router/faq/" data-v-aaf95230 data-v-442a52aa><!--[--><!----> 常见问题<!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-709dc2b1 data-v-aaf95230><a class="vp-link no-icon link" href="/AI-Router/sponsor/" data-v-aaf95230 data-v-442a52aa><!--[--><!----> 喝杯奶茶<!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-709dc2b1 data-v-aaf95230><a class="vp-link no-icon link" href="/AI-Router/tools/" data-v-aaf95230 data-v-442a52aa><!--[--><!----> 主题工具<!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-709dc2b1 data-v-aaf95230><a class="vp-link no-icon link" href="/AI-Router/friends/" data-v-aaf95230 data-v-442a52aa><!--[--><!----> 友情链接<!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-group" data-v-709dc2b1 data-v-c497e9e3><p class="title" data-v-c497e9e3><!----><span data-v-c497e9e3>Vuepress</span></p><!--[--><!--[--><div class="vp-menu-link" data-v-c497e9e3 data-v-aaf95230><a class="vp-link no-icon link" href="https://v2.vuepress.vuejs.org" target="_blank" rel="noreferrer" data-v-aaf95230 data-v-442a52aa><!--[--><!----> 官方文档<!--]--><span class="vpi-external-link icon" data-v-442a52aa></span></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-c497e9e3 data-v-aaf95230><a class="vp-link no-icon link" href="https://ecosystem.vuejs.press/" target="_blank" rel="noreferrer" data-v-aaf95230 data-v-442a52aa><!--[--><!----> 生态系统<!--]--><span class="vpi-external-link icon" data-v-442a52aa></span></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="vp-flyout vp-navbar-menu-group" data-v-d43c1732 data-v-31c474b3><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-31c474b3><span class="text" data-v-31c474b3><!----><!----><span data-v-31c474b3>1.0.0</span><span class="vpi-chevron-down text-icon" data-v-31c474b3></span></span></button><div class="menu" data-v-31c474b3><div class="vp-menu" data-v-31c474b3 data-v-709dc2b1><div class="items" data-v-709dc2b1><!--[--><!--[--><div class="vp-menu-link" data-v-709dc2b1 data-v-aaf95230><a class="vp-link no-icon link" href="/AI-Router/changelog/" data-v-aaf95230 data-v-442a52aa><!--[--><!----> 更新日志<!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-709dc2b1 data-v-aaf95230><a class="vp-link no-icon link" href="/AI-Router/contributing/" data-v-aaf95230 data-v-442a52aa><!--[--><!----> 参与贡献<!--]--><!----></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><!----><div class="vp-navbar-appearance appearance" data-v-70d97d16 data-v-a295abf6><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-a295abf6 data-v-596c25a9 data-v-7eb32327><span class="check" data-v-7eb32327><span class="icon" data-v-7eb32327><!--[--><span class="vpi-sun sun" data-v-596c25a9></span><span class="vpi-moon moon" data-v-596c25a9></span><!--]--></span></span></button></div><div class="vp-social-links vp-navbar-social-links social-links" data-v-70d97d16 data-v-ad52545c data-v-40bac536><!--[--><a class="vp-social-link no-icon" href="https://github.com/zfan2356/AI-Router" aria-label="github" target="_blank" rel="noopener" data-v-40bac536 data-v-67b21932><span class="vpi-social-github" /></a><!--]--></div><div class="vp-flyout vp-navbar-extra extra" data-v-70d97d16 data-v-652282fd data-v-31c474b3><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-31c474b3><span class="vpi-more-horizontal icon" data-v-31c474b3></span></button><div class="menu" data-v-31c474b3><div class="vp-menu" data-v-31c474b3 data-v-709dc2b1><!----><!--[--><!--[--><!----><div class="group" data-v-652282fd><div class="item appearance" data-v-652282fd><p class="label" data-v-652282fd>外观</p><div class="appearance-action" data-v-652282fd><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-652282fd data-v-596c25a9 data-v-7eb32327><span class="check" data-v-7eb32327><span class="icon" data-v-7eb32327><!--[--><span class="vpi-sun sun" data-v-596c25a9></span><span class="vpi-moon moon" data-v-596c25a9></span><!--]--></span></span></button></div></div></div><div class="group" data-v-652282fd><div class="item social-links" data-v-652282fd><div class="vp-social-links social-links-list" data-v-652282fd data-v-40bac536><!--[--><a class="vp-social-link no-icon" href="https://github.com/zfan2356/AI-Router" aria-label="github" target="_blank" rel="noopener" data-v-40bac536 data-v-67b21932><span class="vpi-social-github" /></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="vp-navbar-hamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="nav-screen" data-v-70d97d16 data-v-2b50024d><span class="container" data-v-2b50024d><span class="top" data-v-2b50024d></span><span class="middle" data-v-2b50024d></span><span class="bottom" data-v-2b50024d></span></span></button></div></div></div></div><div class="divider" data-v-70d97d16><div class="divider-line" data-v-70d97d16></div></div></div><!----></header><div class="vp-local-nav reached-top" data-v-68cd6b44 data-v-3944d8e8><button class="menu" aria-expanded="false" aria-controls="SidebarNav" data-v-3944d8e8><span class="vpi-align-left menu-icon" data-v-3944d8e8></span><span class="menu-text" data-v-3944d8e8>Menu</span></button><div class="vp-local-nav-outline-dropdown" style="--vp-vh:0px;" data-v-3944d8e8 data-v-4114a62c><button data-v-4114a62c>返回顶部</button><!----></div></div><aside class="vp-sidebar" vp-sidebar data-v-68cd6b44 data-v-3c61d592><div class="curtain" data-v-3c61d592></div><nav id="SidebarNav" class="nav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-3c61d592><span id="sidebar-aria-label" class="visually-hidden" data-v-3c61d592> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-473fd05b><section class="vp-sidebar-item sidebar-item level-0 collapsible" data-v-473fd05b data-v-e8cce3b3><div class="item" role="button" tabindex="0" data-v-e8cce3b3><div class="indicator" data-v-e8cce3b3></div><!----><h2 class="text" data-v-e8cce3b3>Language</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-e8cce3b3><span class="vpi-chevron-right caret-icon" data-v-e8cce3b3></span></div></div><div data-v-e8cce3b3 data-v-e8cce3b3><div class="items" data-v-e8cce3b3><!--[--><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-e8cce3b3 data-v-e8cce3b3><div class="item" data-v-e8cce3b3><div class="indicator" data-v-e8cce3b3></div><!----><a class="vp-link no-icon link link" href="/AI-Router/python/language/async/" data-v-e8cce3b3 data-v-442a52aa><!--[--><p class="text" data-v-e8cce3b3>Python中多线程和async/await异步</p><!--]--><!----></a><!----></div><!----></div><!--]--></div></div></section></div><div class="no-transition group" data-v-473fd05b><section class="vp-sidebar-item sidebar-item level-0 collapsible" data-v-473fd05b data-v-e8cce3b3><div class="item" role="button" tabindex="0" data-v-e8cce3b3><div class="indicator" data-v-e8cce3b3></div><!----><h2 class="text" data-v-e8cce3b3>PyTorch</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-e8cce3b3><span class="vpi-chevron-right caret-icon" data-v-e8cce3b3></span></div></div><div data-v-e8cce3b3 data-v-e8cce3b3><div class="items" data-v-e8cce3b3><!--[--><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-e8cce3b3 data-v-e8cce3b3><div class="item" data-v-e8cce3b3><div class="indicator" data-v-e8cce3b3></div><!----><a class="vp-link no-icon link link" href="/AI-Router/python/pytorch/basic/" data-v-e8cce3b3 data-v-442a52aa><!--[--><p class="text" data-v-e8cce3b3>PyTorch常用函数以及方法</p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-e8cce3b3 data-v-e8cce3b3><div class="item" data-v-e8cce3b3><div class="indicator" data-v-e8cce3b3></div><!----><a class="vp-link no-icon link link" href="/AI-Router/python/pytorch/gradient/" data-v-e8cce3b3 data-v-442a52aa><!--[--><p class="text" data-v-e8cce3b3>PyTorch中的梯度计算</p><!--]--><!----></a><!----></div><!----></div><!--]--></div></div></section></div><!--]--><!--[--><!--]--></nav></aside><!--[--><div id="VPContent" vp-content class="vp-content has-sidebar" data-v-68cd6b44 data-v-eb709286><div class="vp-doc-container has-sidebar has-aside" data-v-eb709286 data-v-db1f3b4c><!--[--><!--]--><div class="container" data-v-db1f3b4c><div class="aside" vp-outline data-v-db1f3b4c><div class="aside-curtain" data-v-db1f3b4c></div><div class="aside-container" data-v-db1f3b4c><div class="aside-content" data-v-db1f3b4c><div class="vp-doc-aside" data-v-db1f3b4c data-v-5976474c><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="vp-doc-aside-outline" role="navigation" data-v-5976474c data-v-aa56eba0><div class="content" data-v-aa56eba0><div class="outline-marker" data-v-aa56eba0></div><div id="doc-outline-aria-label" aria-level="2" class="outline-title" role="heading" data-v-aa56eba0><span data-v-aa56eba0>此页内容</span><span class="vpi-print icon" data-v-aa56eba0></span></div><ul class="root" data-v-aa56eba0 data-v-3e6b023c><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-5976474c></div><!--[--><!--]--></div></div></div></div><div class="content" data-v-db1f3b4c><div class="content-container" data-v-db1f3b4c><!--[--><!--]--><main class="main" data-v-db1f3b4c><nav class="vp-breadcrumb" data-v-db1f3b4c data-v-1ae4ad7a><ol vocab="https://schema.org/" typeof="BreadcrumbList" data-v-1ae4ad7a><!--[--><li property="itemListElement" typeof="ListItem" data-v-1ae4ad7a><a class="vp-link no-icon link breadcrumb" href="/AI-Router/" property="item" typeof="WebPage" data-v-1ae4ad7a data-v-442a52aa><!--[-->首页<!--]--><!----></a><span class="vpi-chevron-right" data-v-1ae4ad7a></span><meta property="name" content="首页" data-v-1ae4ad7a><meta property="position" content="1" data-v-1ae4ad7a></li><li property="itemListElement" typeof="ListItem" data-v-1ae4ad7a><a class="vp-link no-icon link breadcrumb current" href="/AI-Router/python/pytorch/autograd/" property="item" typeof="WebPage" data-v-1ae4ad7a data-v-442a52aa><!--[-->PyTorch AutoGrad<!--]--><!----></a><!----><meta property="name" content="PyTorch AutoGrad" data-v-1ae4ad7a><meta property="position" content="2" data-v-1ae4ad7a></li><!--]--></ol></nav><!--[--><h1 class="vp-doc-title page-title" data-v-7e9208b4>PyTorch AutoGrad <!----></h1><div class="vp-doc-meta" data-v-7e9208b4><p class="reading-time" data-v-7e9208b4><span class="vpi-books icon" data-v-7e9208b4></span><span data-v-7e9208b4>约 1056 字</span><span data-v-7e9208b4>大约 4 分钟</span></p><p data-v-7e9208b4><span class="vpi-tag icon" data-v-7e9208b4></span><!--[--><span class="vp-link no-icon tag vp-tag-i4ue" href="/AI-Router/" data-v-7e9208b4 data-v-442a52aa><!--[-->pytorch<!--]--><!----></span><!--]--></p><p class="create-time" data-v-7e9208b4><span class="vpi-clock icon" data-v-7e9208b4></span><span data-v-7e9208b4>2025-04-13</span></p></div><!--]--><div class="_python_pytorch_autograd_ external-link-icon-enabled vp-doc plume-content" vp-content data-v-db1f3b4c><div data-v-db1f3b4c><p>在深度学习之中,我们构建的模型,其实就是<code>torch.nn.Module</code> 的组合, 然后内部不断地嵌套, 我们可以自己定制属于自己的<code>torch.nn.Module</code>, 然后内部嵌入若干子<code>Module</code>, 然后实现属于自己的forward逻辑</p><div class="language-python" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">class</span><span style="--shiki-light:#2E8F82;--shiki-dark:#5DA994;"> MyRelu</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">nn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">Module</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">):</span></span>
<span class="line"><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">     def</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;"> __init__</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">self</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">):</span></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">          super</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">MyRelu</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> self</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">).</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">__init__</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">     def</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;"> forward</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">self</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> input</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Tensor</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">):</span></span>
<span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">          return</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> F</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">relu</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">input</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span></code></pre></div><p>这就是一个自定义的<code>torch.nn.Module</code>, 其中的计算部分是调用的<code>torch.nn.functional</code>中自带的函数. 在<code>functional</code>中存在了很多torch预先帮我们设计好的函数, 会针对CPU或者GPU进行优化, 并且可以在计算图之中创建一个节点, 然后定义了fwd和bwd的操作.</p><p>根据pytorch的自动微分机制, bwd的时候, 其实就是沿着计算图根据链式法则进行求导. <code>functional</code>中的函数可以满足我们的一部分需求, 但是有的时候我们会有其他的要求, 这使得我们需要一个可以自己定义fwd和bwd逻辑, 在<code>nn.Module</code>中充当一个计算点的工具, 这就是<code>torch.autograd</code>之中实现的功能</p><h2 id="torch-autograd-function" tabindex="-1"><a class="header-anchor" href="#torch-autograd-function"><span><code>torch.autograd.Function</code></span></a></h2><p>允许我们自定义计算图节点, 实现计算操作, 主要的用途是自定义函数, fuse一些重复启动的函数, 实现一些高效的GPU算子.</p><p>对于继承了<code>torch.autograd.Function</code>的函数类, 需要自己实现fwd和bwd方法, 在<code>nn.Module</code>中调用, 视为创建一个计算图节点.(当然要保证<code>input.requires_grad = True</code>), 这里补充一些会创建节点的操作:</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 数学运算</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">x </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">tensor</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">([</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">1.0</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">],</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> requires_grad</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">True</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">y </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> x </span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">+</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 2</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">      # 创建加法节点</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">z </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> y </span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">*</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 3</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">      # 创建乘法节点</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 神经网络操作</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">x </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">tensor</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">([</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">1.0</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">],</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> requires_grad</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">True</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">y </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> F</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">relu</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">x</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">  # 创建ReLU节点</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">z </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> F</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">linear</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">y</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> weight</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> bias</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">  # 创建线性层节点</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 张量操作</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">x </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">tensor</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">([</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">1.0</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">],</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> requires_grad</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">True</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">y </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> x</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">view</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">-</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">1</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">  # 创建视图节点</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">z </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> y</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">sum</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">()</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">     # 创建求和节点</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 条件操作</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">x </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">tensor</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">([</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">1.0</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">],</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> requires_grad</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">True</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">y </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">where</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">x </span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">&gt;</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 0</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> x</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">zeros_like</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">x</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">))</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">  # 会创建节点</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 索引操作</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">x </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">tensor</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">([</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">1.0</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">],</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> requires_grad</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">True</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">y </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> x</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">[</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">0</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">]</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">  # 会创建节点</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>那什么情况不会创建节点呢?</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 不涉及梯度的操作</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">x </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">tensor</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">([</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">1.0</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">])</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">  # requires_grad默认为False</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">y </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> x </span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">*</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 2</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">  # 不会创建节点</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">with</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">no_grad</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">():</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    y </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> x </span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">*</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 2</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">  # 不会创建节点</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 纯Python操作</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">x </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">tensor</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">([</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">1.0</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">],</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> requires_grad</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">True</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">y </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> x</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">tolist</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">()</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">  # 不会创建节点，因为这是Python操作</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 不改变张量数据的操作</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">x </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">tensor</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">([</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">1.0</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">],</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> requires_grad</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">True</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">y </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> x</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">detach</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">()</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">  # 不会创建节点，只是创建新视图</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>有的时候我们创建的节点会覆盖当前的节点:</p><div class="language-python" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 原地操作</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">x </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">tensor</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">([</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">1.0</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">],</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> requires_grad</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">True</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">x</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">add_</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">2</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">  # 会创建节点，但会修改原始张量</span></span></code></pre></div><p>每个计算图的节点都有如下的一些属性: 他们会包含fwd和bwd所需的信息</p><div class="language-python" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 节点信息</span></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">print</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">y</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">grad_fn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">  # 显示创建y的操作</span></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">print</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">y</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">grad_fn</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">next_functions</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">  # 显示前驱节点</span></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">print</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">y</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">is_leaf</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">  # 是否是叶子节点</span></span></code></pre></div><p>回到<code>autograd.Function</code>里面, 这里允许我们实现自己的&quot;创建计算图节点&quot;的运算, 并且自己来优化对应的函数, 例如我们可以实现一个自己的exp运算, 这也是官方文档给出的例子:</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">class</span><span style="--shiki-light:#2E8F82;--shiki-dark:#5DA994;"> _MyExp</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">autograd</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">Function</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">):</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">     @</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">staticmethod</span></span>
<span class="line"><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">     def</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;"> forward</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">ctx</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> input</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Tensor</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">):</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">          output </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;"> input</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">exp</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">()</span><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"> # 如果你有更好的exp实现方式</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">          ctx</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">save_for_backward</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">output</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">          return</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> output</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">     @</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">staticmethod</span></span>
<span class="line"><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">     def</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;"> backward</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">ctx</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> grad_output</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Tensor</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">):</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">          output</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#999999;--shiki-dark:#666666;"> =</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> ctx</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">saved_tensors</span></span>
<span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">          return</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> grad_output </span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">*</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> output</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">def</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;"> my_exp</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">input</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Tensor</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">):</span></span>
<span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">     return</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> _MyExp</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">apply</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">input</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这个函数可以实现一个需求, 那就是如果你有更好的exp实现方式, 你就可以将其替换掉, 这样就可以实现你自己定制的exp函数</p><p>fwd没啥好说的, 其实就是简单的前向计算的过程, 对于bwd来说, 每一个节点的任务, 其实就是根据<code>grad_output</code>, 计算出<code>grad_input</code>返回出去, 作为下一个节点的<code>grad_output</code>. 事实上如果当前有<code>nn.Parameter</code>参与计算, 比如linear层的weight矩阵, 那么你还需要返回一个weight的梯度.</p><p>在backward实现中, backward的return值的数量要和forward中 ctx之后的输入值的数量一致, 要一一对应, 比如在这里, backward返回的值其实就对应了forward的input.</p><p>对于一个exp函数来说,</p></div><!----><!----><!----></div></main><footer class="vp-doc-footer" data-v-db1f3b4c data-v-fda6bbae><!--[--><!--]--><div class="edit-info" data-v-fda6bbae><div class="edit-link" data-v-fda6bbae><a class="vp-link no-icon link edit-link-button" href="https://github.com/zfan2356/AI-Router/edit/main/docs/notes/python/pytorch/autograd.md" target="_blank" rel="noreferrer" data-v-fda6bbae data-v-442a52aa><!--[--><span class="vpi-square-pen edit-link-icon" aria-label="edit icon" data-v-fda6bbae></span> 编辑此页<!--]--><!----></a></div><!----></div><!----><!----></footer><!----><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!--]--><button style="display:none;" type="button" class="vp-back-to-top" aria-label="back to top" data-v-68cd6b44 data-v-bcf8d9a6><span class="percent" data-allow-mismatch data-v-bcf8d9a6>0%</span><span class="show icon vpi-back-to-top" data-v-bcf8d9a6></span><svg aria-hidden="true" data-v-bcf8d9a6><circle cx="50%" cy="50%" data-allow-mismatch style="stroke-dasharray:calc(0% - 12.566370614359172px) calc(314.1592653589793% - 12.566370614359172px);" data-v-bcf8d9a6></circle></svg></button><footer class="vp-footer has-sidebar" vp-footer data-v-68cd6b44 data-v-400675cf><!--[--><div class="container" data-v-400675cf><p class="message" data-v-400675cf>Powered by <a target="_blank" href="https://v2.vuepress.vuejs.org/">VuePress</a> & <a target="_blank" href="https://theme-plume.vuejs.press">vuepress-theme-plume</a></p><p class="copyright" data-v-400675cf>Copyright © 2021-present zfan</p></div><!--]--></footer><!--[--><!--]--><!--]--></div><!----><!--]--><!--[--><!--]--><!--]--></div><script type="module" src="/AI-Router/assets/app-0p9pLXBN.js" defer></script></body></html>